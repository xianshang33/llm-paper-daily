<h2 align='center'>llm-paper-daily æ—¥å¸¸è®ºæ–‡ç²¾é€‰</h2>
<div align='center'>

[![Status](https://img.shields.io/badge/status-Update_07.03_20:51-success.svg)]() [![ç®€ä½“ä¸­æ–‡ badge](https://img.shields.io/badge/%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87-Simplified%20Chinese-blue)](./README.md) [![English badge](https://img.shields.io/badge/%E8%8B%B1%E6%96%87-English-blue)](./README_en.md) 

</div>

æ¬¢è¿æ¥åˆ° **llm-paper-daily**! è¿™æ˜¯ä¸€ä¸ªè·å–æœ€æ–°ç ”ç©¶è®ºæ–‡çš„æ¯æ—¥æ›´æ–°å’Œåˆ†ç±»çš„å¹³å°ã€‚å¸Œæœ›ä¸ºçˆ±å¥½è€…æä¾› LLM ç ”ç©¶çš„å‰æ²¿èµ„è®¯ï¼Œè®©æ‚¨æ›´è½»æ¾åœ°äº†è§£è¯¥é¢†åŸŸçš„æœ€æ–°å‘å±•ã€‚

ğŸ“š **æ¯æ—¥æ›´æ–°:** ä»“åº“æ¯å¤©ä¼šå¸¦æ¥æœ€æ–°çš„ LLM ç ”ç©¶ï¼Œå¹¶é™„æœ‰arxivåœ°å€ã€ç›¸å…³ git ä»“åº“å’ŒåŸºäº GPT-4 çš„ç®€å•æ€»ç»“

ğŸ’ **åˆ†ç±»æ‘˜è¦:** å°†æ¯ç¯‡è®ºæ–‡åˆ†ç±»åˆ°å¦‚æ¨ç†ã€ä»£ç†ã€æ£€ç´¢ã€åº”ç”¨ã€é¢„è®­ç»ƒä¸æŒ‡ä»¤å¾®è°ƒç­‰ä¸åŒéƒ¨åˆ†ï¼Œå¸®åŠ©æ‚¨èƒ½è½»æ¾å¯¼èˆªå¹¶å‘ç°ç›¸å…³çš„ç ”ç©¶

ğŸŒˆ **äº¤æµå­¦ä¹ :** æœ€è¿‘å‡†å¤‡æ‹‰ä¸€ä¸ªè®¨è®ºå°ç»„æ–¹ä¾¿å¤§å®¶äº¤æµå’Œäº’ç›¸å­¦ä¹ ã€‚
æ¬¢è¿å¯¹å¤§æ¨¡å‹è½åœ°ã€è®ºæ–‡ç­‰ç­‰æ–¹é¢æœ‰å…´è¶£çš„å°ä¼™ä¼´åŠ å…¥ğŸ™Œ 

<img src='./images/qrcode.JPG' width=15%  alt=/>

## ç›®å½•
- [æœ€æ–°è®ºæ–‡(å«æ€»ç»“)](#æœ€æ–°è®ºæ–‡)
- [åˆ†ç±»](#åˆ†ç±»)
  - [ğŸ’¡ Reasoning](CATEGORIES.md#Reasoning)
  - [ğŸ¤– Agent](CATEGORIES.md#Agent)
  - [ğŸ¦‰ Knowledge and Retrieval](CATEGORIES.md#Knowledge-and-Retrieval)
  - [ğŸ‘©â€ğŸ« Alignment and Hallucination](CATEGORIES.md#Alignment-and-Hallucination)
  - [ğŸ¨ Application](CATEGORIES.md#Application)
  - [ğŸ“ Pre-training and Instruction Fine-tuning](CATEGORIES.md#Pre-training-and-Instruction-Fine-tuning)
  - [ğŸ“„ Survey](CATEGORIES.md#Survey)
## æœ€æ–°è®ºæ–‡
### 07æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>07-01</span> | **We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?**<br><sub>æœºæ„: Beijing University of Posts and Telecommunications, Tencent Inc., Huazhong University of Science and Technology<br>è¿™ç¯‡è®ºæ–‡åˆ›å»ºäº†ä¸€ä¸ªåä¸ºWE-MATHçš„è§†è§‰æ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¶…è¶Šä¼ ç»Ÿçš„ç«¯åˆ°ç«¯æ€§èƒ½è¯„ä¼°ï¼Œæ·±å…¥æ¢è®¨å’Œè¯„ä»·LMMsçš„é—®é¢˜è§£å†³åŸç†åŠå®ƒä»¬çš„çŸ¥è¯†è·å–å’Œæ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡æ–°çš„å¤šç»´åº¦è¯„ä¼°æ–¹æ³•æ­ç¤ºå‡ºå¤šæ¨¡æ€æ¨¡å‹åœ¨å†…åœ¨æ¨ç†è¿‡ç¨‹ä¸­çš„æŒ‘æˆ˜ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†çŸ¥è¯†å¢å¼ºç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œæ¨åŠ¨äº†LMMsåœ¨è§†è§‰æ•°å­¦æ¨ç†æ–¹é¢çš„è¿›æ­¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2407.01284v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-07/2407.01284.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/We-Math/We-Math)</div> |

---

### 06æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>06-30</span> | **Step-Controlled DPO: Leveraging Stepwise Error for Enhanced Mathematical Reasoning**<br><sub>æœºæ„: Multimedia Laboratory (MMLab), The Chinese University of Hong Kong<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ•°å­¦æ¨ç†ä¼˜åŒ–æ–¹æ³•â€”â€”SCDPOï¼Œé€šè¿‡åœ¨ç‰¹å®šæ­¥éª¤ç›‘ç£é”™è¯¯çš„æ–¹å¼ï¼Œè‡ªåŠ¨åŒ–åœ°ç”Ÿæˆè®­ç»ƒæ ·æœ¬ï¼Œæ˜¾è‘—æå‡äº†LLMsåœ¨æ•°å­¦é—®é¢˜æ±‚è§£æ–¹é¢çš„æ€§èƒ½ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2407.00782v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2407.00782.md)  |
| <span style='display: inline-block; width: 42px;'>06-29</span> | **LiteSearch: Efficacious Tree Search for LLM**<br><sub>æœºæ„: Xiamen University, Tencent AI Lab<br>è¯¥è®ºæ–‡é€šè¿‡æå‡ºä¸€ç§æ•ˆç‡æ›´é«˜çš„æ ‘æœç´¢ç®—æ³•æ¥é™ä½åœ¨è¾…åŠ©å¤§å‹è¯­è¨€æ¨¡å‹è§£å†³å¤æ‚æ•°å­¦æ¨ç†ä»»åŠ¡æ—¶çš„èµ„æºæ¶ˆè€—ï¼ŒåŒæ—¶ç¡®ä¿ä¿æŒé«˜æ€§èƒ½æ°´å¹³ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2407.00320v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2407.0032.md)  |
| <span style='display: inline-block; width: 42px;'>06-28</span> | **Scaling Synthetic Data Creation with 1,000,000,000 Personas**<br><sub>æœºæ„: Tencent AI Lab Seattle<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºâ€œPersona Hubâ€çš„åˆæˆæ•°æ®å¹³å°ï¼Œåœ¨ä¿è¯ç”Ÿæˆæ•°æ®å¤šæ ·åŒ–å’Œä¸°å¯Œæ€§çš„åŒæ—¶ï¼Œé‡ç‚¹å…³æ³¨åˆæˆæ•°æ®çš„å®‰å…¨å’Œè´Ÿè´£ä»»ä½¿ç”¨ã€‚é€šè¿‡ä¸€ç³»åˆ—ç”¨ä¾‹è¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¤šå…ƒåŒ–ã€å¯æ‰©å±•æ€§ã€çµæ´»æ€§å’Œæ˜“ç”¨æ€§æ–¹é¢çš„ä¼˜åŠ¿ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.20094v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.20094.md)  |
| <span style='display: inline-block; width: 42px;'>06-27</span> | **From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data**<br><sub>æœºæ„: University of Wisconsin-Madison<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªé€šè¿‡åœ¨åˆæˆæ•°æ®é›†ä¸Šå¾®è°ƒLLMsæ¥æé«˜å…¶åœ¨é•¿æ–‡æœ¬ä»»åŠ¡ä¸Šæ£€ç´¢å’Œæ¨ç†èƒ½åŠ›çš„æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥åœ¨ä¸æ˜¾è‘—å½±å“æ¨¡å‹æ•´ä½“èƒ½åŠ›çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜æ¨¡å‹åœ¨é•¿æ–‡æœ¬ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¹¶é™ä½å¹»è§‰çš„ç”Ÿæˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.19292v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.19292.md)  |
| <span style='display: inline-block; width: 42px;'>06-27</span> | **SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation**<br><sub>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºSEAKRçš„æ–°å‹è‡ªé€‚åº”æ£€ç´¢å¢å¼ºç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡åˆ©ç”¨LLMsçš„å†…éƒ¨çŠ¶æ€è‡ªæˆ‘æ„è¯†æ¥åŠ¨æ€å†³å®šä½•æ—¶è¿›è¡Œæ£€ç´¢ï¼Œå¹¶æœ‰æ•ˆæ•´åˆæ£€ç´¢åˆ°çš„çŸ¥è¯†ï¼Œä»è€Œæé«˜äº†åœ¨é—®ç­”ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.19215v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.19215.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/THU-KEG/SeaKR)</div> |
| <span style='display: inline-block; width: 42px;'>06-26</span> | **Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs**<br><sub>æœºæ„: The Chinese University of Hong Kong, Harbin Institute of Technology (Shenzhen), SmartMore<br>è¿™ä»½è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„ä¼˜åŒ–æ–¹æ³•Step-DPOï¼Œå®ƒé€šè¿‡å¯¹å•ä¸ªæ¨ç†æ­¥éª¤è¿›è¡Œä¼˜åŒ–è€Œéæ•´ä½“è¯„ä¼°ç­”æ¡ˆï¼Œæå‡äº†LLMsåœ¨é•¿é“¾æ•°å­¦æ¨ç†ä¸Šçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.18629v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.18629.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/dvlab-research/Step-DPO)</div> |
| <span style='display: inline-block; width: 42px;'>06-25</span> | **The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale**<br><sub>æœºæ„: Hugging Face<br>æœ¬è®ºæ–‡é€šè¿‡ä»‹ç»FineWebæ•°æ®é›†ï¼Œçªå‡ºäº†å¦‚ä½•ç­–åˆ’å‡ºä¸€ä¸ªæœ‰æ•ˆçš„åŸºäºCommon Crawlçš„é¢„è®­ç»ƒæ•°æ®é›†çš„é‡è¦æ€§ï¼Œå¹¶é€šè¿‡å®éªŒè¯æ˜äº†å…¶å¯¹äºæå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½çš„è´¡çŒ®ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.17557v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.17557.md)  |
| <span style='display: inline-block; width: 42px;'>06-24</span> | **WARP: On the Benefits of Weight Averaged Rewarded Policies**<br><sub>æœºæ„: Google DeepMind<br>æœ¬æ–‡æå‡ºäº†WARPï¼Œä¸€ç§æ–°çš„LLMå¯¹é½ç­–ç•¥ï¼Œé€šè¿‡æƒé‡å¹³å‡åˆå¹¶æ¨¡å‹ä»¥è§£å†³RLHFè¿‡ç¨‹ä¸­çš„æŒ‘æˆ˜ï¼Œæ”¹å–„KLä¸å¥–åŠ±ä¹‹é—´çš„æƒè¡¡ã€‚å®éªŒè¯æ˜ï¼ŒWARPèƒ½å¤Ÿæå‡æ¨¡å‹æ€§èƒ½å’Œä¸äººç±»ä»·å€¼çš„å¯¹é½åº¦ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.16768v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.16768.md)  |
| <span style='display: inline-block; width: 42px;'>06-22</span> | **Semantic Entropy Probes: Robust and Cheap Hallucination Detection in LLMs**<br><sub>æœºæ„: OATML, Department of Computer Science, University of Oxford  <br>è®ºæ–‡æå‡ºSEPsä¸ºæˆæœ¬é«˜æ•ˆå’Œå¯é çš„å¹»è§‰æ£€æµ‹æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨æ— éœ€ç”Ÿæˆå¤šæ ·æœ¬çš„æ¡ä»¶ä¸‹ï¼Œç›´æ¥ä»LLMså•æ¬¡ç”Ÿæˆçš„éšè—çŠ¶æ€ä¸­æ•æ‰åˆ°è¯­ä¹‰ä¸ç¡®å®šæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.15927v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.15927.md)  |
| <span style='display: inline-block; width: 42px;'>06-21</span> | **LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs**<br><sub>æœºæ„: University of Waterloo<br>LongRAGæ˜¯ä¸€ä¸ªé’ˆå¯¹å¼€æ”¾é¢†åŸŸé—®ç­”ä»»åŠ¡çš„æ–°æ¡†æ¶ï¼Œå®ƒé€šè¿‡å¢å¤§æ£€ç´¢å•å…ƒå’Œåˆ©ç”¨é•¿æ–‡æœ¬è¯­è¨€æ¨¡å‹æ¥è§£å†¤ä¼ ç»ŸRAGæ¡†æ¶çš„é™åˆ¶ã€‚é€šè¿‡å‡å°‘æ£€ç´¢å•å…ƒå’Œæå‡æ£€ç´¢å™¨æ•ˆèƒ½ï¼Œä»¥åŠä½¿ç”¨é•¿æ–‡æœ¬LLMsè¿›è¡Œé›¶æ¬¡å­¦ä¹ çš„ç­”æ¡ˆæå–ï¼ŒLongRAGåœ¨æ€§èƒ½ä¸Šå–å¾—äº†æ˜¾ç€çš„æ”¹å–„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.15319v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.15319.md)  |
| <span style='display: inline-block; width: 42px;'>06-19</span> | **Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?**<br><sub>æœ¬è®ºæ–‡é€šè¿‡å¼•å…¥LOFTåŸºå‡†ï¼Œæ¢ç´¢äº†é•¿ä¸Šä¸‹æ–‡è¯­è¨€æ¨¡å‹åœ¨æ›¿ä»£ç°æœ‰èŒƒå¼å’Œå¤„ç†æ–°é¢–ä»»åŠ¡æ–¹é¢çš„æ½œåŠ›ã€‚å‘ç°LCLMsåœ¨æœªç»æ˜ç¡®è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿåœ¨ç‰¹å®šä»»åŠ¡ä¸Šä¸ç°æœ‰çš„æ£€ç´¢å’ŒRAGç³»ç»Ÿç›¸åª²ç¾ï¼Œå¹¶æŒ‡å‡ºäº†æœªæ¥åœ¨æé«˜é—®é¢˜è¡¨ç°ä¸Šéœ€è¦ç»§ç»­ç ”ç©¶çš„é¢†åŸŸã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.13121v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.13121.md)  |
| <span style='display: inline-block; width: 42px;'>06-18</span> | **Judging the Judges: Evaluating Alignment and Vulnerabilities in LLMs-as-Judges**<br><sub>æœ¬ç ”ç©¶é€šè¿‡è¯„ä¼°LLMsä½œä¸ºè¯„åˆ¤åœ¨å¯¹é½å’Œè¯„åˆ¤å¼±ç‚¹æ–¹é¢çš„è¡¨ç°ï¼Œä¸ºä½¿ç”¨LLMsä½œä¸ºæœªæ¥è¯„åˆ¤æä¾›äº†æœ‰ç”¨çš„æ´å¯Ÿã€‚é‡è¦çš„å‘ç°åŒ…æ‹¬é€‚åˆä½œä¸ºè¯„åˆ¤çš„ä»…æœ‰éƒ¨åˆ†é¡¶å°–æ¨¡å‹ï¼Œä»¥åŠCohen's Kappaæ˜¯ä¸€ä¸ªæ›´å¥½çš„å¯¹é½åº¦é‡æ ‡å‡†ï¼Œèƒ½åœ¨åŒºåˆ†è¯„åˆ¤è€…æ–¹é¢åšå¾—æ¯”ç™¾åˆ†æ¯”å¯¹é½æ›´å¥½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.12624v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.12624.md)  |
| <span style='display: inline-block; width: 42px;'>06-13</span> | **Test of Time: A Benchmark for Evaluating LLMs on Temporal Reasoning**<br><sub>æœºæ„: Google Research, Google DeepMind, Google<br>æœ¬æ–‡å¼•å…¥äº†ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯• ToTï¼Œé€šè¿‡åˆæˆæ•°æ®é›†å’Œä¼—åŒ…ä»»åŠ¡ï¼Œå…¨é¢è¯„ä¼°äº†LLMsåœ¨å„ç§æƒ…å¢ƒä¸­å¯¹æ—¶é—´æ¨ç†èƒ½åŠ›çš„è¡¨ç°ï¼ŒåŒæ—¶æ­ç¤ºäº†è¿™äº›æ¨¡å‹åœ¨æ—¶é—´æ¨ç†æ–¹é¢çš„ä¼˜åŠ¿å’Œä¸è¶³ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.09170v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.0917.md)  |
| <span style='display: inline-block; width: 42px;'>06-12</span> | **Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing**<br><sub>æœºæ„: University of Washington, Allen Institute for AI<br>æœ¬æ–‡æå‡ºäº†MAGPIEï¼Œä¸€ä¸ªè‡ªåˆæˆæ–¹æ³•ç”Ÿæˆå¤§è§„æ¨¡çš„é«˜è´¨é‡å¯¹é½æ•°æ®ï¼Œè¯¥æ–¹æ³•ä¸ä¾èµ–äºäººçš„å‚ä¸æˆ–æç¤ºå·¥ç¨‹ã€‚å®éªŒè¯æ˜ï¼Œä½¿ç”¨MAGPIEå¾®è°ƒçš„æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†ä¸Šå‡æ˜¾ç¤ºå‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†LLMsåœ¨è‡ªåŠ¨æ•°æ®ç”Ÿæˆå’Œå¯¹é½æ–¹é¢çš„æ½œèƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.08464v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.08464.md)  |
| <span style='display: inline-block; width: 42px;'>06-12</span> | **TasTe: Teaching Large Language Models to Translate through Self-Reflection**<br><sub>æœºæ„: Harbin Institute of Technology, Tencent Inc<br>æœ¬æ–‡æå‡ºçš„TASTEæ¡†æ¶é€šè¿‡è‡ªæˆ‘åæ€è¿‡ç¨‹æå‡äº†LLMsçš„æœºå™¨ç¿»è¯‘èƒ½åŠ›ï¼Œå®ƒä»£è¡¨äº†åˆ©ç”¨LLMsç¿»è¯‘æ½œåŠ›çš„ä¸€ç§æ–°æ–¹æ³•ï¼Œä¸ºç†è§£å’Œåˆ©ç”¨LLMsçš„å¤æ‚æ¨ç†å’Œè¯­è¨€å»ºæ¨¡èƒ½åŠ›æ ‘ç«‹äº†æ–°çš„å…¸èŒƒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.08434v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.08434.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/YutongWang1216/ReflectionLLMMT)</div> |
| <span style='display: inline-block; width: 42px;'>06-12</span> | **Designing a Dashboard for Transparency and Control of Conversational AI**<br><sub>æœºæ„: Harvard University, Google Research<br>è¿™ç¯‡è®ºæ–‡è‡´åŠ›äºå¢åŠ LLMsåœ¨å¯¹è¯AIç³»ç»Ÿä¸­çš„é€æ˜åº¦ï¼Œå¹¶é€šè¿‡è®¾è®¡ä¸€ä¸ªå¯è§†åŒ–çš„ç”¨æˆ·ç•Œé¢â€”ä¸€ä¸ªä¸èŠå¤©æœºå™¨äººæ¥å£ç›¸é…å¥—çš„çœ‹æ¿â€”å®ç°äº†è¿™ä¸€ç‚¹ã€‚ç”¨æˆ·èƒ½å¤Ÿå®æ—¶çœ‹åˆ°ç³»ç»Ÿçš„å†…éƒ¨ç”¨æˆ·æ¨¡å‹ï¼Œå¹¶å¯ä»¥é€šè¿‡ç•Œé¢æ›´æ”¹è¿™äº›æ¨¡å‹ã€‚åŸºäºç”¨æˆ·åé¦ˆï¼Œçœ‹æ¿è¿˜æœ‰åŠ©äºæ­éœ²å¹¶ä¸”å¯¹æŠ—æ¨¡å‹çš„åè§è¡Œä¸ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.07882v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.07882.md)  |
| <span style='display: inline-block; width: 42px;'>06-11</span> | **Needle In A Multimodal Haystack**<br><sub>æœºæ„: OpenGVLab, Shanghai AI Laboratory, Fudan University<br>è¯¥è®ºæ–‡æå‡ºäº†MM-NIAHï¼Œé¦–ä¸ªé•¿ç¯‡å¤šæ¨¡æ€æ–‡ä»¶ç†è§£çš„è¯„ä¼°åŸºå‡†ï¼Œæ—¨åœ¨è€ƒéªŒå’Œæå‡MLLMsçš„æ€§èƒ½ã€‚é€šè¿‡ä¸åŒçš„è¯„ä¼°ä»»åŠ¡ï¼Œè®ºæ–‡æŒ‡å‡ºäº†ç°æœ‰MLLMsåœ¨é•¿ç¯‡å¤šæ¨¡æ€æ–‡æ¡£ç†è§£æ–¹é¢çš„å±€é™å’ŒæŒ‘æˆ˜ã€‚è¿›ä¸€æ­¥çš„ï¼Œè¯¥åŸºå‡†ä¸ºMLLMsçš„é•¿ç¯‡å¤šæ¨¡æ€æ–‡æ¡£ç†è§£ç ”ç©¶æä¾›äº†æœ‰æ•ˆçš„å¹³å°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.07230v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.0723.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OpenGVLab/MM-NIAH)</div> |
| <span style='display: inline-block; width: 42px;'>06-11</span> | **Delving into ChatGPT usage in academic writing through excess vocabulary**<br><sub>æœºæ„: Hertie Institute for AI in Brain Health, University of TÃ¼bingen, Germany, TÃ¼bingen AI Center, Northwestern University<br>æ­¤è®ºæ–‡é’ˆå¯¹å­¦æœ¯æ–‡æœ¬ä¸­å¹¿æ³›ä½¿ç”¨ LLMs çš„ç°è±¡ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„æ— åå·®çš„å¤§è§„æ¨¡æ–¹æ³•æ¥ç ”ç©¶ LLM çš„ä½¿ç”¨æƒ…å†µï¼Œå¹¶å¯¹ LLM å¯¼è‡´çš„ç§‘å­¦å†™ä½œå˜åŒ–è¿›è¡Œäº†å‰æ‰€æœªæœ‰çš„é‡åŒ–æ¯”è¾ƒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.07016v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.07016.md)  |
| <span style='display: inline-block; width: 42px;'>06-10</span> | **Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching**<br><sub>æœºæ„: The Chinese University of Hong Kong, Tencent AI Lab, Centre for Perceptual and Interactive Intelligence<br>è®ºæ–‡é€šè¿‡å¼•å…¥SELF-TUNINGï¼Œæå‡ºäº†ä¸€ç§æ”¹è¿›LLMé€šè¿‡è‡ªæˆ‘æ•™å­¦è·å–çŸ¥è¯†èƒ½åŠ›çš„æ¡†æ¶ï¼Œå¹¶é€šè¿‡Wiki-Newpages-QAæ•°æ®é›†åœ¨å¤šä¸ªå…³é”®çŸ¥è¯†è·å–ä»»åŠ¡ä¸ŠéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.06326v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.06326.md)  |
| <span style='display: inline-block; width: 42px;'>06-10</span> | **Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies**<br><sub>æœºæ„: Duke University, AWS AI Labs<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªè€ƒè™‘è®¡ç®—é¢„ç®—çš„LLMæ¨ç†ç­–ç•¥è¯„ä¼°æ¡†æ¶ï¼Œå¹¶å±•ç¤ºäº†ç®€å•ç­–ç•¥åœ¨åŒç­‰è®¡ç®—èµ„æºä¸‹å¯è¶…è¶Šå¤æ‚ç­–ç•¥çš„èƒ½åŠ›ã€‚é€šè¿‡æ­ç¤ºè‡ªæˆ‘è¯„ä¼°çš„é‡è¦æ€§ï¼Œä¸ºæ›´åŠ é«˜æ•ˆçš„é¢„ç®—åˆ©ç”¨å’Œæ›´æœ‰æ•ˆç­–ç•¥çš„å¼€å‘å¥ å®šäº†åŸºç¡€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.06461v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.06461.md)  |
| <span style='display: inline-block; width: 42px;'>06-10</span> | **Transforming Wearable Data into Health Insights using Large Language Model Agents**<br><sub>æœºæ„: Google LLC<br>æœ¬è®ºæ–‡é€šè¿‡ä»‹ç»€åä¸ºPHIAçš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ç³»ç»Ÿï¼ŒæˆåŠŸåœ°å°†å¯ç©¿æˆ´è®¾å¤‡æ•°æ®è½¬åŒ–ä¸ºä¸ªäººå¥åº·æ´å¯Ÿã€‚PHIAç»“åˆäº†ä»£ç ç”Ÿæˆå’Œä¿¡æ¯æ£€ç´¢å·¥å…·ï¼Œæœ‰æ•ˆè§£å†³äº†ä»å¤§é‡å¥åº·æ•°æ®ä¸­æ´¾ç”Ÿä¸ªæ€§åŒ–å¥åº·æŒ‡å¯¼çš„æŒ‘æˆ˜ã€‚é€šè¿‡å¹¿æ³›çš„äººå·¥å’Œè‡ªåŠ¨åŒ–è¯„ä¼°ï¼Œè¯æ˜äº†è¿™ç§æ–¹æ³•åœ¨å¤„ç†å®é™…å¥åº·é—®é¢˜ä¸Šçš„å‡†ç¡®æ€§å’Œåº”ç”¨å¯èƒ½æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.06464v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.06464.md)  |
| <span style='display: inline-block; width: 42px;'>06-10</span> | **Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning**<br><sub>æœºæ„: University of Washington, MetaAI, Allen Institute for AI<br>HUSKYæ˜¯é¦–ä¸ªç»Ÿä¸€ã€å¼€æºçš„å¤šæ­¥æ¨ç†è¯­è¨€ä»£ç†ï¼Œè§£å†³äº†æˆæœ¬é«˜å’Œæ‰©å±•å›°éš¾çš„é—®é¢˜ï¼Œä¸”åœ¨å¤šä»»åŠ¡ç¯å¢ƒä¸­å–å¾—ä¼˜å¼‚è¡¨ç°ï¼Œå±•ç°äº†å¼€æºè¯­è¨€ä»£ç†çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.06469v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.06469.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/agent-husky/Husky-v1)</div> |
| <span style='display: inline-block; width: 42px;'>06-09</span> | **Do LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses**<br><sub>æœºæ„: University of Washington, University of Washington - Bothell<br>æœ¬ç ”ç©¶å¼ºè°ƒäº† LLM åœ¨ç¤¾äº¤æ¨ç†æ–¹é¢çš„ä¸è¶³ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•é€šè¿‡æ•´åˆäººç±»çš„æ„å›¾å’Œæƒ…ç»ªæ¥å¢å¼ºå…¶æœ‰æ•ˆæ€§ã€‚ç ”ç©¶ç»“æœå‡¸æ˜¾äº† LLM ç†è§£äººç±»å¿ƒç†çŠ¶æ€å¹¶åœ¨å¼€æ”¾å¼é—®é¢˜ä¸­è¿›è¡Œç¤¾äº¤æ¨ç†çš„éœ€æ±‚ï¼Œæ ‡æ˜äº†æœªæ¥å‘å±•çš„å…³é”®é¢†åŸŸã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.05659v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.05659.md)  |
| <span style='display: inline-block; width: 42px;'>06-07</span> | **WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild**<br><sub>WILDBENCH ä½œä¸ºä¸€ä¸ªè¯„ä»·åŸºå‡†ï¼Œæä¾›äº†ä¸€ä¸ªç»“åˆäº†çœŸå®ç”¨æˆ·ä»»åŠ¡æŒ‘æˆ˜ã€è‡ªåŠ¨åŒ–æŒ‡æ ‡å’Œè§£é‡Šæ€§æ¸…å•çš„è¯„ä»·æ¡†æ¶ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°å’ŒåŒºåˆ«å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.04770v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.0477.md)  |
| <span style='display: inline-block; width: 42px;'>06-07</span> | **Mixture-of-Agents Enhances Large Language Model Capabilities**<br><sub>æœºæ„: Duke University, Together AI, University of Chicago<br>è¿™ç¯‡è®ºæ–‡é€šè¿‡æå‡ºMixture-of-Agents (MoA) æ–¹æ³•ï¼Œå±•ç¤ºäº†å¦‚ä½•é€šè¿‡ç»“åˆå¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹çš„é›†ä½“ä¸“é•¿æ¥å¢å¼ºå®ƒä»¬åœ¨ç†è§£å’Œç”Ÿæˆè‡ªç„¶è¯­è¨€æ–¹é¢çš„èƒ½åŠ›ã€‚ä½œè€…é€šè¿‡å®éªŒéªŒè¯äº†è¿™ç§æ–¹æ³•å¯ä»¥æ˜¾è‘—æé«˜æ¨¡å‹çš„è¡¨ç°ï¼Œå¹¶åœ¨å¤šä¸ªç«äº‰åŠ›å¾ˆå¼ºçš„åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€æ–°çš„æœ€ä½³æˆç»©ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.04692v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.04692.md)  |
| <span style='display: inline-block; width: 42px;'>06-06</span> | **FastGAS: Fast Graph-based Annotation Selection for In-Context Learning**<br><sub>æœºæ„: Department of ECE, University of Virginia<br>è®ºæ–‡æå‡ºçš„FastGASæ–¹æ³•åœ¨é€‰æ‹©ICLå®ä¾‹æ—¶ï¼Œä¸ä»…èƒ½æé«˜å¤šæ ·æ€§å’Œä»£è¡¨æ€§ï¼ŒåŒæ—¶è¿˜æ˜¾è‘—å‡å°‘äº†æ‰€éœ€çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚å®éªŒç»“æœéªŒè¯äº†å…¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„æ•ˆèƒ½å’Œæ•ˆç‡ï¼Œè¯æ˜äº†å…¶ä½œä¸ºä¸€ç§æœ‰æ•ˆçš„å®ä¾‹é€‰æ‹©æ–¹æ³•çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.03730v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.0373.md)  |
| <span style='display: inline-block; width: 42px;'>06-06</span> | **Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models**<br><sub>æœºæ„: Peking University, UC Berkeley, Stanford University<br>BoTé€šè¿‡ä¸ºLLMsæä¾›ä¸€ä¸ªå­˜å‚¨é«˜å±‚æ¬¡æ€ç»´æ¨¡æ¿çš„meta-bufferï¼Œå¢å¼ºäº†æ¨ç†çš„å‡†ç¡®æ€§ã€æ•ˆç‡å’Œé²æ£’æ€§ï¼Œå…‹æœäº†ç°æœ‰æ–¹æ³•çš„é™åˆ¶ï¼Œå¹¶å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.04271v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.04271.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/YangLing0818/buffer-of-thought-llm)</div> |
| <span style='display: inline-block; width: 42px;'>06-06</span> | **The Prompt Report: A Systematic Survey of Prompting Techniques**<br><sub>è¯¥è®ºæ–‡æä¾›äº†å¯¹æç¤ºæŠ€æœ¯çš„å…¨é¢è°ƒç ”ï¼Œç³»ç»Ÿåˆ†æäº†æç¤ºçš„æ¦‚å¿µã€ç±»å‹å’Œåº”ç”¨ï¼Œå¹¶å¯¹æ­¤è¿›è¡Œäº†è¯¦ç»†çš„å…ƒåˆ†æã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.06608v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.06608.md)  |
| <span style='display: inline-block; width: 42px;'>06-04</span> | **Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models**<br><sub>æœºæ„: Zhejiang University, School of Engineering (Westlake University), Shanghai AI Laboratory<br>æ–‡ç« æå‡ºäº†ä¸€ç§æ–°é¢–çš„åä½œæ–¹æ³•ä»¥è§£å†³è·¨æ–‡æ¡£äº‹ä»¶å…±æŒ‡æ¶ˆè§£ä»»åŠ¡ã€‚é€šè¿‡å°†LLMsçš„æ™®éèƒ½åŠ›ä¸ä»»åŠ¡ç‰¹å®šçš„SLMsç»“åˆï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.02148v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.02148.md)  |
| <span style='display: inline-block; width: 42px;'>06-04</span> | **To Believe or Not to Believe Your LLM**<br><sub>æœºæ„: Google DeepMind<br>æœ¬è®ºæ–‡é‡ç‚¹ç ”ç©´å¹¶æå‡ºäº†ä¸€ä¸ªæ–°çš„ä¿¡æ¯è®ºåº¦é‡æ–¹æ³•ä»¥åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­é‡åŒ–ä¸ç¡®å®šæ€§ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹LLMsç”Ÿæˆå“åº”æ—¶çš„å¹»è§‰ç°è±¡ã€‚è¿™é¡¹ç ”ç©¶ä¸ºå¦‚ä½•è¯†åˆ«å’Œå¤„ç†LLMsä¸­çš„å¹»è§‰æä¾›äº†æ–°çš„ç†è§£å’Œè§£å†³æ–¹æ¡ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.02543v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.02543.md)  |
| <span style='display: inline-block; width: 42px;'>06-03</span> | **Self-Improving Robust Preference Optimization**<br><sub>æœºæ„: Cohere<br>SRPOé€šè¿‡åœ¨ç†è®ºä¸Šåˆç†çš„ç¦»çº¿RLHFæ¡†æ¶å†…è¡¨ç°å‡ºå¯¹ä»»åŠ¡å˜åŒ–çš„å¼ºå¤§é²æ£’æ€§ï¼ŒæˆåŠŸåœ°è§£å†³äº†ä¾èµ–ç‰¹å®šä»»åŠ¡çš„é—®é¢˜ï¼Œå¹¶é€šè¿‡éå¯¹æŠ—æ€§ç¦»çº¿æŸå¤±çš„ä¼˜åŒ–æä¾›äº†æ›´ç®€å•çš„è®­ç»ƒå’Œéƒ¨ç½²è¿‡ç¨‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºSRPOåœ¨åŒ…æ‹¬OODè®¾ç½®åœ¨å†…çš„å„ç§ç¯å¢ƒä¸‹ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.01660v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.0166.md)  |
| <span style='display: inline-block; width: 42px;'>06-03</span> | **Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration**<br><sub>æœºæ„: Beijing Jiaotong University, Alibaba Group<br>Mobile-Agent-v2æ˜¯ä¸€ä¸ªå¤šä»£ç†æ¶æ„ï¼Œèƒ½æœ‰æ•ˆè§£å†³ç§»åŠ¨è®¾å¤‡æ“ä½œä»»åŠ¡ä¸­çš„å¯¼èˆªæŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯ä»»åŠ¡è¿›å±•å’Œç„¦ç‚¹å†…å®¹çš„å¯¼èˆªé—®é¢˜ã€‚é€šè¿‡å¼•å…¥ä¸‰ä¸ªä¸“é—¨çš„ä»£ç†è§’è‰²ï¼Œç›¸è¾ƒäºä¼ ç»Ÿçš„å•ä»£ç†æ¶æ„ï¼Œæ˜¾è‘—æé«˜äº†ä»»åŠ¡å®Œæˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.01014v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.01014.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/X-PLUG/MobileAgent)</div> |

---

### 05æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>05-31</span> | **Preemptive Answer "Attacks" on Chain-of-Thought Reasoning**<br><sub>æœºæ„: Tsinghua University<br>è®ºæ–‡ç ”ç©¶äº†é¢„å…ˆç­”æ¡ˆå¯¹LLMsæ¨ç†èƒ½åŠ›çš„è´Ÿé¢å½±å“ï¼Œå¹¶æå‡ºäº†å‡è½»å…¶å½±å“çš„ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™äº›ç­–ç•¥ä¸èƒ½å®Œå…¨æŠµæ¶ˆé¢„å…ˆç­”æ¡ˆçš„å½±å“ï¼Œæç¤ºéœ€è¦è¿›ä¸€æ­¥å¢å¼ºCoTçš„é²æ£’æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.20902v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.20902.md)  |
| <span style='display: inline-block; width: 42px;'>05-31</span> | **Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality**<br><sub>æœºæ„: Princeton University, Carnegie Mellon University<br>æœ¬è®ºæ–‡å±•ç¤ºäº†ä¸€ä¸ªå…¨æ–°çš„çŠ¶æ€ç©ºé—´å¯¹å¶æ€§ï¼ˆSSDï¼‰æ¡†æ¶ï¼Œè¿æ¥äº†ç»“æ„åŒ–çš„çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰å’Œæ³¨æ„åŠ›æœºåˆ¶å˜ä½“ã€‚è®ºæ–‡çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬å°†åŸæœ¬é’ˆå¯¹Transformersçš„ç®—æ³•å’Œç³»ç»Ÿä¼˜åŒ–åº”ç”¨åˆ°SSMsä¸Šï¼Œä»¥åŠå¼€å‘äº†ä¸€ç§æ–°çš„SSDç®—æ³•ï¼Œæœ‰æ•ˆæé«˜äº†æ¨¡å‹è®­ç»ƒå’Œæ¨ç†çš„æ•ˆç‡ã€‚Mamba-2æ¶æ„ä½œä¸ºæœ€ç»ˆäº§å“ï¼Œå®ç°äº†ç†æƒ³çš„æ€§èƒ½è¡¨ç°ï¼Œä¸ºæœªæ¥çš„æ·±åº¦å­¦ä¹ æ¨¡å‹è®¾è®¡å’Œä¼˜åŒ–æä¾›äº†æ–°çš„æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.21060v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.2106.md)  |
| <span style='display: inline-block; width: 42px;'>05-30</span> | **Similarity is Not All You Need: Endowing Retrieval Augmented Generation with Multi Layered Thoughts**<br><sub>æœºæ„: Ant Group<br>METRAGæå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡å®ç”¨æ€§å’Œç´§å‡‘æ€§æ€ç»´æ¥è§£å†³ç°æœ‰æ¨¡å‹çš„å±€é™æ€§ï¼Œå¹¶åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæ›´å¥½çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.19893v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.19893.md)  |
| <span style='display: inline-block; width: 42px;'>05-30</span> | **Jina CLIP: Your CLIP Model Is Also Your Text Retriever**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.20204v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.20204.md)  |
| <span style='display: inline-block; width: 42px;'>05-29</span> | **LLMs achieve adult human performance on higher-order theory of mind tasks**<br><sub>æœºæ„: Google Research, Google DeepMind, Johns Hopkins University Applied Physics Lab<br>æœ¬è®ºæ–‡å±•ç¤ºäº†LLMsåœ¨é«˜é˜¶ç†è®ºå¿ƒæ™ºï¼ˆToMï¼‰ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯è¯æ˜äº†æŸäº›æ¨¡å‹å¦‚GPT-4èƒ½å¤Ÿåœ¨æŸäº›ä»»åŠ¡ä¸Šè¾¾åˆ°æˆäººæ°´å¹³çš„è¡¨ç°ã€‚é€šè¿‡å¼•å…¥åŸºäºçœŸå®äººç±»æˆäººåŸºå‡†çš„æ–°è¯„æµ‹æŒ‡æ ‡ï¼Œæœ¬ç ”ç©¶æœ‰åŠ©äºæ­ç¤ºå’Œç†è§£LLMsåœ¨å¤æ‚ç¤¾äº¤äº’åŠ¨ä¸­çš„æ½œåŠ›ä¸é™åˆ¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.18870v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.1887.md)  |
| <span style='display: inline-block; width: 42px;'>05-29</span> | **MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.19327v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.19327.md)  |
| <span style='display: inline-block; width: 42px;'>05-28</span> | **RealitySummary: On-Demand Mixed Reality Document Enhancement using Large Language Models**<br><sub>æœºæ„: University of Calgary<br>æ­¤è®ºæ–‡ä»‹ç»äº†RealitySummaryç³»ç»Ÿï¼Œå®ƒç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹å’Œæ··åˆç°å®æŠ€æœ¯ï¼Œæä¾›äº†ä¸€ä¸ªå³æ—¶çš„é˜…è¯»è¾…åŠ©å·¥å…·ï¼Œå¹¶ä¸”å±•ç°äº†è¿™ç§æŠ€æœ¯åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›å’Œç¡®ç«‹äº†æœªæ¥ç ”ç©¶çš„æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.18620v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.1862.md)  |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models**<br><sub>æœºæ„: The Ohio State University, Stanford University<br>HippoRAGæ˜¯ä¸€ä¸ªå—äººç±»è®°å¿†ç³»ç»Ÿå¯å‘çš„æ–°å‹æ£€ç´¢æ¡†æ¶ï¼Œè§£å†³äº†ä¼ ç»ŸLLMsåœ¨é•¿æœŸè®°å¿†å’ŒçŸ¥è¯†æ•´åˆæ–¹é¢çš„ä¸è¶³ã€‚é€šè¿‡æ¨¡æ‹Ÿäººè„‘ç»“æ„å’Œè¿ä½œæœºåˆ¶ï¼ŒHippoRAGæœ‰æ•ˆåœ°æå‡äº†LLMså¤„ç†å¤æ‚çŸ¥è¯†æ•´åˆä»»åŠ¡çš„èƒ½åŠ›ï¼Œå¹¶ä¸”åœ¨æ•ˆç‡å’Œæ€§èƒ½ä¸Šå‡è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14831v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14831.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OSU-NLP-Group/HippoRAG)</div> |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **Agent Planning with World Knowledge Model**<br><sub>æœºæ„: Zhejiang University, Zhejiang University - Ant Group Joint Laboratory of Knowledge Graph, National University of Singapore, Alibaba Group<br>æœ¬è®ºæ–‡é€šè¿‡åˆ›å»ºä¸€ä¸ªå‚æ•°åŒ–çš„ä¸–ç•ŒçŸ¥è¯†æ¨¡å‹ (WKM)ï¼Œæ¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ‰§è¡Œäº¤äº’å¼è§„åˆ’ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚è¿™ä¸ªæ¨¡å‹ä½¿ç”¨äº†æ¥è‡ªä¸“å®¶å’Œæ¢ç´¢æ€§è½¨è¿¹çš„çŸ¥è¯†ï¼Œå¹¶é€šè¿‡åœ¨ä»¿çœŸç¯å¢ƒä¸­ä¸å¤šç§å¼ºåŸºå‡†è¿›è¡Œæ¯”è¾ƒï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œå¹¶å¤„ç†äº†ç”Ÿæˆå¹»è§†åŠ¨ä½œå’Œç›²ç›®è¯•é”™çš„é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14205v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14205.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/zjunlp/WKM)</div> |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration**<br><sub>æœºæ„: Tsinghua University, Northwestern Polytechnical University, Shanghai AI Laboratory<br>æœ¬æ–‡é’ˆå¯¹å¤šä»£ç†åˆä½œä»»åŠ¡ä¸­LLMsçš„æœ‰æ•ˆè§„åˆ’æå‡ºäº†ReAdæ¡†æ¶ï¼Œè¯æ˜äº†å…¶é™ä½äº¤äº’æ¬¡æ•°å¹¶æé«˜æˆåŠŸç‡çš„èƒ½åŠ›ï¼Œä¸ºLLMsåœ¨å¤šä»£ç†ç³»ç»Ÿä¸­çš„åº”ç”¨å¥ å®šäº†åŸºç¡€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14314v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14314.md)  |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **RaFe: Ranking Feedback Improves Query Rewriting for RAG**<br><sub>æœºæ„: Zhejiang University, Alibaba Group, Nanjing University<br>RaFeæ˜¯ä¸€ä¸ªæ–°é¢–çš„æŸ¥è¯¢é‡å†™æ¡†æ¶ï¼Œåˆ©ç”¨é‡æ’åºå™¨åé¦ˆæ¥è®­ç»ƒæ¨¡å‹ï¼Œæ— éœ€æ³¨é‡Šï¼Œæ”¯æŒç¦»çº¿å’Œåœ¨çº¿åé¦ˆè®­ç»ƒï¼Œå…·æœ‰è‰¯å¥½çš„æ™®é€‚æ€§å’Œæœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14431v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14431.md)  |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **RefChecker: Reference-based Fine-grained Hallucination Checker and Benchmark for Large Language Models**<br><sub>æœºæ„: Amazon AWS AI, Shanghai AI Lab, Shanghai Jiaotong University<br>REFCHECKERæ˜¯ä¸€ä¸ªç”¨äºæ£€æµ‹LLMsä¸­ç»†ç²’åº¦å¹»è§‰å¹¶è¿›è¡ŒåŸºå‡†æµ‹è¯•çš„æ¡†æ¶ã€‚å…¶é€šè¿‡ä½¿ç”¨claim-tripletsï¼Œèƒ½åœ¨ç»†ç²’åº¦ä¸Šæ£€æµ‹å¹¶éªŒè¯å›åº”ä¸­çš„äº‹å®ä¸€è‡´æ€§ï¼Œæ˜¾è‘—æé«˜äº†æ£€æµ‹çš„ç²¾åº¦å’Œä¸äººç±»åˆ¤æ–­çš„ä¸€è‡´æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14486v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14486.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/amazon-science/RefChecker)</div> |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **PerLLM: Personalized Inference Scheduling with Edge-Cloud Collaboration for Diverse LLM Services**<br><sub>æœºæ„: Institute of Computing Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences<br>æœ¬è®ºæ–‡æå‡ºäº†PerLLMæ¡†æ¶ï¼Œé€šè¿‡è¾¹ç¼˜-äº‘åä½œæ¥å¤„ç†å¤§é‡æ¨ç†æœåŠ¡ï¼Œä¸ä»…ä¼˜åŒ–äº†æœåŠ¡è°ƒåº¦å’Œèµ„æºåˆ†é…ï¼Œè¿˜æ˜¾è‘—æé«˜äº†ååé‡å¹¶é™ä½äº†èƒ½æºæˆæœ¬ï¼Œå…·æœ‰çªå‡ºçš„åº”ç”¨ä»·å€¼ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14636v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14636.md)  |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **AGILE: A Novel Framework of LLM Agents**<br><sub>æœºæ„: ByteDance Research, University of Science and Technology of China, Shanghai Jiao Tong University<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°å‹çš„LLMä»£ç†æ¡†æ¶AGILEï¼Œå®ƒé€šè¿‡æ•´åˆä¸åŒçš„ç»„ä»¶ï¼Œå¹¶é‡‡ç”¨å¼ºåŒ–å­¦ä¹ æ¥å®ç°ç«¯åˆ°ç«¯çš„è®­ç»ƒã€‚è¯¥æ¡†æ¶åœ¨å¤æ‚çš„é—®ç­”ä»»åŠ¡ä¸­å±•ç°å‡ºè¾ƒä¼ ç»ŸLLMç‹¬ç«‹ä½¿ç”¨æ›´ä¼˜çš„æ€§èƒ½ï¼Œå¹¶è¯æ˜äº†ç»„ä»¶æ•´åˆå’Œç«¯åˆ°ç«¯ä¼˜åŒ–çš„æœ‰æ•ˆæ€§ã€‚æ•°æ®é›†å’Œä»£ç å·²å…¬å¼€å‘å¸ƒï¼Œä»¥ä¿ƒè¿›ç›¸å…³é¢†åŸŸçš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14751v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14751.md)  |
| <span style='display: inline-block; width: 42px;'>05-21</span> | **SmartFlow: Robotic Process Automation using LLMs**<br><sub>æœºæ„: TCS Research<br>SmartFlowæ˜¯ä¸€ä¸ªåŸºäºAIçš„RPAç³»ç»Ÿï¼Œå®ƒæ•´åˆäº†æ·±åº¦å­¦ä¹ çš„è§†è§‰ç†è§£ä¸LLMsï¼Œèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆå¯¼èˆªå·¥ä½œæµå¹¶è‡ªä¸»æ‰§è¡Œç”¨æˆ·æŒ‡æ´¾çš„ä»»åŠ¡ï¼Œå±•ç¤ºäº†å…¶åœ¨é€‚åº”GUIå˜åŒ–å’Œå¤„ç†å¤æ‚ä»»åŠ¡ä¸Šçš„é«˜æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.12842v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.12842.md)  |
| <span style='display: inline-block; width: 42px;'>05-21</span> | **G-DIG: Towards Gradient-based DIverse and hiGh-quality Instruction Data Selection for Machine Translation**<br><sub>æœºæ„: ByteDance Research<br>è¯¥è®ºæ–‡ä¸ºè§£å†³LLMsåœ¨æœºå™¨ç¿»è¯‘ä¸­æŒ‡ä»¤å¾®è°ƒæ•°æ®çš„å¤šæ ·æ€§å’Œè´¨é‡é—®é¢˜ï¼Œæå‡ºäº†åŸºäºæ¢¯åº¦çš„æ•°æ®é€‰æ‹©æ–¹æ³•G-DIGï¼Œé€šè¿‡å®éªŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.12915v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.12915.md)  |
| <span style='display: inline-block; width: 42px;'>05-20</span> | **OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework**<br><sub>æœºæ„: OpenLLMAI Team, ByteDance Inc., Netease Fuxi AI Lab<br>OpenRLHFæ˜¯ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œå®ƒä½¿å¾—åœ¨70äº¿ä»¥ä¸Šå‚æ•°æ¨¡å‹ä¸Šå®ç°å…¨å°ºåº¦RLHFè®­ç»ƒæˆä¸ºå¯èƒ½ã€‚å®ƒé€šè¿‡Rayåˆ†å¸ƒå¼è®¡ç®—æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨vLLMä¼˜åŒ–æ•ˆç‡ï¼ŒåŒæ—¶å®ç°äº†å¤šç§å¯¹é½ç®—æ³•ï¼Œå¹¶ä¸HuggingFaceåº“æ— ç¼æ•´åˆï¼Œä»è€Œæä¾›å³å¼€å³ç”¨çš„ç”¨æˆ·ä½“éªŒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.11143v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.11143.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OpenLLMAI/OpenRLHF)</div> |
| <span style='display: inline-block; width: 42px;'>05-20</span> | **Multiple-Choice Questions are Efficient and Robust LLM Evaluators**<br><sub>æœºæ„: Shanghai Jiao Tong University<br>è¯¥ç ”ç©¶æˆåŠŸå°†å¸¸è§„çš„å¼€æ”¾å¼ç”Ÿæˆé—®é¢˜è½¬æ¢ä¸ºå¤šé¡¹é€‰æ‹©æ ¼å¼ï¼Œä»¥æé«˜LLMsçš„è¯„ä¼°æ•ˆç‡å’Œå‡†ç¡®åº¦ã€‚è¿™ä¸€æ–¹æ³•åœ¨é˜²æ­¢æ— æ•ˆç­”æ¡ˆçš„å½±å“ã€æé«˜è¯„ä¼°æ•ˆç‡æ–¹é¢å–å¾—äº†çªç ´ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.11966v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.11966.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Geralt-Targaryen/MC-Evaluation)</div> |
| <span style='display: inline-block; width: 42px;'>05-20</span> | **xFinder: Robust and Pinpoint Answer Extraction for Large Language Models**<br><sub>æœºæ„: Institute for Advanced Algorithms Research, Shanghai,Renmin University of China<br>è¿™ç¯‡æ–‡ç« çš„é‡ç‚¹æ˜¯æå‡ºä¸€ä¸ªåä¸ºxFinderçš„æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜ä»LLMsè¾“å‡ºä¸­æå–å…³é”®ç­”æ¡ˆçš„å‡†ç¡®åº¦ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•æ— æ³•æ»¡è¶³çš„é¢†åŸŸéœ€æ±‚ï¼Œä¸ºLLMsè¯„ä¼°æä¾›äº†æ›´å¯é çš„æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.11874v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.11874.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/IAAR-Shanghai/xFinder)</div> |
| <span style='display: inline-block; width: 42px;'>05-20</span> | **Octo: An Open-Source Generalist Robot Policy**<br><sub>æœºæ„: UC Berkeley, Stanford<br>è®ºæ–‡ä»‹ç»äº†Octoï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå˜æ¢å™¨çš„ç­–ç•¥ï¼Œå¯¹å¤šæ ·åŒ–çš„æœºå™¨äººä»»åŠ¡æä¾›å¼€æºçš„è§£å†³æ–¹æ¡ˆï¼Œèƒ½é€šè¿‡å¾®è°ƒé€‚åº”æ–°çš„è§‚æµ‹å’ŒåŠ¨ä½œç©ºé—´ã€‚å®ƒåœ¨å¤šä¸ªæœºå™¨äººå¹³å°ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå¹¶é€šè¿‡å®Œå…¨å¼€æ”¾çš„æºç é¼“åŠ±å¹¿æ³›åº”ç”¨å’Œè¿›ä¸€æ­¥å‘å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.12213v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.12213.md)  |
| <span style='display: inline-block; width: 42px;'>05-19</span> | **Your Transformer is Secretly Linear**<br><sub>æœºæ„: AIRI, Skoltech, SberAI<br>è¿™é¡¹ç ”ç©¶å±•ç¤ºäº†å˜å‹å™¨ç¼–ç å±‚ä¹‹é—´å¯èƒ½å­˜åœ¨é«˜åº¦çš„çº¿æ€§åŠ¨æ€ï¼Œè¿™ä¸€å‘ç°æ¨ç¿»äº†å˜å‹å™¨ä¸­çº¿æ€§å’Œéçº¿æ€§æ“ä½œçš„ä¼ ç»Ÿç†è§£ï¼Œå¹¶å‘ç°å¯ä»¥åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„æƒ…å†µä¸‹è¿›è¡Œæ¨¡å‹ä¿®æ”¹ä»¥æé«˜æ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.12250v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.1225.md)  |
| <span style='display: inline-block; width: 42px;'>05-17</span> | **Prompt Exploration with Prompt Regression**<br><sub>æœºæ„: Carnegie Mellon University, Massachusetts Institute of Technology, University of Michigan<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶PEPRï¼Œç”¨äºé¢„æµ‹LLMsä¸­æç¤ºå…ƒç´ ç»„åˆçš„å½±å“ï¼Œå¹¶é€‰æ‹©æœ€é€‚ç”¨äºç‰¹å®šä»»åŠ¡çš„æç¤ºã€‚è¯¥æ¡†æ¶ä¸ä»…æå‡ºäº†åˆ›æ–°æ€§çš„è§£å†³æ–¹æ¡ˆï¼Œè¿˜é€šè¿‡åœ¨å¤šä¸ªæ•°æ®é›†å’Œä»»åŠ¡ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.11083v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.11083.md)  |
| <span style='display: inline-block; width: 42px;'>05-16</span> | **Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models**<br><sub>æœºæ„: BITS Pilani, MDSR Labs, Adobe, IIT Guhawati, National University of Singapore<br>è¿™é¡¹ç ”ç©¶å¼€å‘å¹¶è¯„ä¼°äº†ä¸€ä¸ªé’ˆå¯¹ç«¯åˆ°ç«¯ç”¨æˆ·çš„è¿­ä»£æ¶ˆåæ¡†æ¶ï¼Œè¯¥æ¡†æ¶æä¾›äº†ä¸€ç§éè®­ç»ƒå‹çš„æ¶ˆé™¤LLMsåè§çš„æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•ä½¿ç”¨å¤æ‚çš„promptingç­–ç•¥åœ¨ä¸å‡å°‘ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½çš„å‰æä¸‹æ˜¾è‘—é™ä½äº†è¾“å‡ºçš„å¹³å‡åè§åº¦ï¼Œå¹¶ä¸ºæœªæ¥ç ”ç©¶LLMsçš„prompt-basedæ¶ˆåæ–¹æ³•é“ºå¹³äº†é“è·¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.10431v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.10431.md)  |
| <span style='display: inline-block; width: 42px;'>05-16</span> | **SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation**<br><sub>æœºæ„: Amazon, The University of Texas at Austin<br>SYNTHESIZRRæ˜¯ä¸€ç§æ–°æ–¹æ³•ï¼Œé€šè¿‡æ£€ç´¢å¢å¼ºä¸ºæ•™å¸ˆ-å­¦ç”Ÿè’¸é¦çš„ç¤ºä¾‹åˆæˆé›†æˆäº†è·å–ä¿¡æ¯ã€‚ç ”ç©¶è¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSYNTHESIZRRç”Ÿæˆçš„æ•°æ®åœ¨å†…åœ¨æ•°æ®å¤šæ ·æ€§å’Œä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®æ€§æ–¹é¢è¡¨ç°æ›´ä½³ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.10040v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.1004.md)  |
| <span style='display: inline-block; width: 42px;'>05-16</span> | **SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation**<br><sub>æœºæ„: Amazon, The University of Texas at Austin<br>SYNTHESIZRRé€šè¿‡æ£€ç´¢å¢å¼ºè§£å†³äº†è¿‡å»åˆæˆæ•°æ®çš„å¤šæ ·æ€§ä¸è¶³å’Œä¸äººç±»æ–‡æœ¬ç›¸å¼‚çš„é—®é¢˜ï¼Œé€šè¿‡æ£€ç´¢ä¸åŒæ–‡æ¡£å’Œå†…å®¹ï¼Œç”Ÿæˆçš„æ ·æœ¬å…·æœ‰æ›´é«˜çš„å¤šæ ·æ€§å’Œæ›´æ¥è¿‘äººç±»æ–‡æœ¬çš„é£æ ¼ï¼Œè¿™æ”¹å–„äº†è’¸é¦æ¨¡å‹çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.10040v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.1004.md)  |
| <span style='display: inline-block; width: 42px;'>05-16</span> | **MarkLLM: An Open-Source Toolkit for LLM Watermarking**<br><sub>æœºæ„: Tsinghua University, Shanghai Jiao Tong University, The University of Sydney<br>MARKLLMä¸ºç ”ç©¶äººå‘˜å’Œå…¬ä¼—æä¾›ä¸€ä¸ªæ˜“äºè®¿é—®å’Œä½¿ç”¨çš„å®éªŒå¹³å°ï¼Œæ—¨åœ¨æé«˜LLMæ°´å°æŠ€æœ¯çš„æ™®åŠåº¦å’Œå‚ä¸åº¦ï¼Œæ¨åŠ¨ç ”ç©¶å’Œåº”ç”¨è¿›ä¸€æ­¥å‘å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.10051v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.10051.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/THU-BPM/MarkLLM)</div> |
| <span style='display: inline-block; width: 42px;'>05-16</span> | **Listen Again and Choose the Right Answer: A New Paradigm for Automatic Speech Recognition with Large Language Models**<br><sub>æœºæ„: Nanyang Technological University, University of Science and Technology of China, University of Aberdeen<br>æœ¬è®ºæ–‡æˆåŠŸæå‡ºå¹¶éªŒè¯äº†ç»“åˆå¤šæ¨¡æ€LLMçš„æ–°ASRé”™è¯¯ä¿®æ­£èŒƒå¼ï¼Œä¸ä»…è§£å†³äº†æºè¯­éŸ³å¿½è§†å’Œè¾“å…¥å†—ä½™çš„é—®é¢˜ï¼Œè¿˜åœ¨å®é™…åº”ç”¨ä¸­å–å¾—äº†æ˜¾è‘—æ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.10025v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.10025.md)  |
| <span style='display: inline-block; width: 42px;'>05-15</span> | **LoRA Learns Less and Forgets Less**<br><sub>æœºæ„: Columbia University, Databricks<br>LoRAè™½ç„¶åœ¨ç›®æ ‡ä»»åŠ¡çš„å­¦ä¹ æ•ˆç‡å’Œç²¾ç¡®åº¦æ–¹é¢é€šå¸¸ä¸å¦‚å…¨å‚æ•°å¾®è°ƒï¼Œä½†åœ¨ä¿æŒæºä»»åŠ¡æ€§èƒ½æ–¹é¢å±•ç°äº†æ›´å¥½çš„è¡¨ç°å’Œæ›´å¼ºçš„æ­£åˆ™åŒ–èƒ½åŠ›ã€‚æ ¹æ®æœ¬æ–‡ç ”ç©¶ï¼Œå¯¹ä½¿ç”¨LoRAåšå¾®è°ƒæ—¶çš„æœ€ä½³å®è·µåšå‡ºäº†å»ºè®®ï¼Œå°¤å…¶æ³¨æ„åˆ°å­¦ä¹ ç‡ã€ç›®æ ‡æ¨¡å—é€‰æ‹©å’Œæ‰°åŠ¨çš„ç§©ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.09673v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.09673.md)  |
| <span style='display: inline-block; width: 42px;'>05-15</span> | **ALPINE: Unveiling the Planning Capability of Autoregressive Learning in Language Models**<br><sub>æœºæ„: Microsoft Research Asia, Harvard University, Peking University<br>ALPINEé¡¹ç›®è€ƒå¯Ÿäº†è‡ªå›å½’å­¦ä¹ å¦‚ä½•ä½¿Transformerå…·å¤‡ç½‘ç»œä¸­çš„è§„åˆ’èƒ½åŠ›ï¼Œå¹¶æ­ç¤ºäº†åœ¨æ‰§è¡Œè·¯å¾„å¯»æ‰¾ä»»åŠ¡ä¸­Transformerçš„è¡¨ç°èƒ½åŠ›åŠå…¶å±€é™æ€§ï¼Œä¸ºæˆ‘ä»¬ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å…¶ä»–ç›¸å…³é¢†åŸŸçš„ä¸€èˆ¬è§„åˆ’èƒ½åŠ›æä¾›äº†æ–°è§è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.09220v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.0922.md)  |
| <span style='display: inline-block; width: 42px;'>05-14</span> | **Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Intent Resolution in LLMs**<br><sub>æœºæ„: Carnegie Mellon University, Allen Institute for AI  <br>æœ¬ç ”ç©¶é€šè¿‡å¼•å…¥ä¸€ä¸ªå…¨æ–°çš„ç”Ÿæˆæ€§è¯„ä¼°æ¡†æ¶ï¼Œæ¢ç´¢äº†LLMsåœ¨ç†è§£å’Œç”Ÿæˆä¸æ„å›¾å¯¹é½çš„å›åº”æ–¹é¢çš„æ½œåŠ›å’ŒæŒ‘æˆ˜ï¼Œæ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨è¯­ç”¨ç†è§£æ–¹é¢çš„ä¸è¶³ï¼Œå¹¶æŒ‡å‡ºäº†æœªæ¥æå‡æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.08760v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.0876.md)  |
| <span style='display: inline-block; width: 42px;'>05-13</span> | **RLHF Workflow: From Reward Modeling to Online RLHF**<br><sub>æœºæ„: Salesforce AI Research, University of Illinois Urbana-Champaign  <br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå®Œæ•´çš„åœ¨çº¿è¿­ä»£ RLHF å·¥ä½œæµç¨‹ï¼Œä¸ä»…ç†è®ºä¸Šåˆ›æ–°ï¼Œè¿˜é€šè¿‡è¯¦ç»†çš„å®è·µå®ç°æŒ‡å—æä¾›äº†å®é™…åº”ç”¨çš„æ¡†æ¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.07863v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.07863.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RLHFlow/RLHF-Reward-Modeling)</div> |
| <span style='display: inline-block; width: 42px;'>05-13</span> | **DoLLM: How Large Language Models Understanding Network Flow Data to Detect Carpet Bombing DDoS**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.07638v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.07638.md)  |
| <span style='display: inline-block; width: 42px;'>05-10</span> | **Mitigating Hallucinations in Large Language Models via Self-Refinement-Enhanced Knowledge Retrieval**<br><sub>æœºæ„: Imperial College London, Huawei<br>è¿™é¡¹å·¥ä½œé€šè¿‡ä¸€ä¸ªæ–°çš„è‡ªæˆ‘å®Œå–„å¢å¼ºçš„çŸ¥è¯†å›¾è°±æ£€ç´¢æ–¹æ³•æœ‰æ•ˆåœ°å‡å°‘äº†å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰ç°è±¡ï¼Œå°¤å…¶æé«˜äº†åœ¨åŒ»ç–—é¢†åŸŸä¸­çš„åº”ç”¨å®æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.06545v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.06545.md)  |
| <span style='display: inline-block; width: 42px;'>05-10</span> | **A Survey on RAG Meets LLMs: Towards Retrieval-Augmented Large Language Models**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.06211v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.06211.md)  |
| <span style='display: inline-block; width: 42px;'>05-10</span> | **Automatic Generation of Model and Data Cards: A Step Towards Responsible AI**<br><sub>æœºæ„: CMU, MPI, ETH ZÃ¼rich<br>è®ºæ–‡æˆåŠŸå¼€å‘äº†ä¸€ç§ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è‡ªåŠ¨åŒ–ç”Ÿæˆæœºå™¨å­¦ä¹ æ¨¡å‹å¡ç‰‡å’Œæ•°æ®å¡ç‰‡çš„æ–¹æ³•ï¼Œå¹¶é€šè¿‡åˆ›å»ºç›¸åº”çš„æ•°æ®é›†å’Œè¯„ä¼°æœºåˆ¶ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆæ–‡æ¡£çš„è´¨é‡å’Œæ ‡å‡†åŒ–ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.06258v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.06258.md)  |
| <span style='display: inline-block; width: 42px;'>05-10</span> | **UniDM: A Unified Framework for Data Manipulation with Large Language Models**<br><sub>æœºæ„: Alibaba Group, University of Science and Technology of China<br>UniDMæ˜¯ä¸€ä¸ªåˆ›æ–°çš„ç»Ÿä¸€æ•°æ®æ“ä½œæ¡†æ¶ï¼Œé€šè¿‡æœ‰æ•ˆçš„æç¤ºè®¾è®¡ä¸æ­¥éª¤åˆ†è§£ï¼Œæ˜¾è‘—æé«˜äº†å¤„ç†å¤šç§æ•°æ®ä»»åŠ¡çš„æ•ˆç‡å’Œè´¨é‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.06510v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.0651.md)  |
| <span style='display: inline-block; width: 42px;'>05-10</span> | **Value Augmented Sampling for Language Model Alignment and Personalization**<br><sub>VASä¸ºLLMçš„é€‚é…å’Œä¸ªæ€§åŒ–æä¾›äº†ä¸€ä¸ªé«˜æ•ˆä¸”å¼ºå¤§çš„æ–¹æ³•ã€‚å®ƒå…‹æœäº†ç°æœ‰RLç®—æ³•çš„ä¸ç¨³å®šæ€§ï¼Œå®ç°äº†é«˜æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡çš„åŒé‡ä¼˜åŠ¿ï¼ŒåŒæ—¶æ”¯æŒé»‘ç›’æ¨¡å‹çš„é€‚åº”ï¼Œä¸ºæœªæ¥çš„LLMä¸ªæ€§åŒ–å’Œå¯¹é½å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.06639v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.06639.md)  |
| <span style='display: inline-block; width: 42px;'>05-09</span> | **Exploring the Potential of Human-LLM Synergy in Advancing Qualitative Analysis: A Case Study on Mental-Illness Stigma**<br><sub>CHALETæ–¹æ³•æ¡†æ¶å±•ç¤ºäº†äººç±»-LLM åä½œåœ¨å®šæ€§ç ”ç©¶ä¸­çš„å·¨å¤§æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨æ·±åŒ–ç†è§£å’Œæ´è§ç”Ÿæˆæ–¹é¢ï¼Œä¸ºæœªæ¥çš„HCIå’Œå®šæ€§åˆ†æç ”ç©¶æä¾›äº†æ–°æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05758v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05758.md)  |
| <span style='display: inline-block; width: 42px;'>05-09</span> | **An Automatic Prompt Generation System for Tabular Data Tasks**<br><sub>æœ¬è®ºæ–‡æˆåŠŸå¼€å‘äº†ä¸€ä¸ªæ—¢é€‚åº”å¤šç§LLMsåˆæ— éœ€å¹¿æ³›è®­ç»ƒçš„è‡ªåŠ¨æç¤ºç”Ÿæˆç³»ç»Ÿï¼Œé€šè¿‡ä¸¤ç§åˆ›æ–°æ–¹æ³•æ˜¾è‘—æé«˜äº†å¤„ç†è¡¨æ ¼æ•°æ®ä»»åŠ¡çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05618v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05618.md)  |
| <span style='display: inline-block; width: 42px;'>05-09</span> | **Can large language models understand uncommon meanings of common words?**<br><sub>æœºæ„: Tsinghua University, Chinese Academy of Science<br>æœ¬ç ”ç©¶é€šè¿‡å»ºç«‹æ–°çš„è¯„ä¼°ä½“ç³»å’Œæ•°æ®é›†ï¼Œæ­ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç†è§£å¸¸è§è¯æ±‡çš„ç½•è§å«ä¹‰æ–¹é¢å­˜åœ¨çš„é‡å¤§ä¸è¶³ï¼Œä¸ºæé«˜æ¨¡å‹çš„NLUèƒ½åŠ›æä¾›äº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05741v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05741.md)  |
| <span style='display: inline-block; width: 42px;'>05-09</span> | **LLMPot: Automated LLM-based Industrial Protocol and Physical Process Emulation for ICS Honeypots**<br><sub>æœºæ„: New York University Abu Dhabi  <br>LLMPotæ˜¯ä¸€ç§åˆ›æ–°çš„ICSç½‘ç»œå®‰å…¨é˜²å¾¡å·¥å…·ï¼Œå…¶åˆ©ç”¨LLMçš„èƒ½åŠ›ï¼Œé€šè¿‡è‡ªåŠ¨åŒ–ç”Ÿæˆä¸åè®®å’Œç‰©ç†è¿‡ç¨‹ç´§å¯†ç›¸å…³çš„å“åº”ï¼Œæ˜¾è‘—æé«˜äº†èœœç½çš„å®ç”¨æ€§å’Œæ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05999v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05999.md)  |
| <span style='display: inline-block; width: 42px;'>05-08</span> | **Air Gap: Protecting Privacy-Conscious Conversational Agents**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05175v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05175.md)  |
| <span style='display: inline-block; width: 42px;'>05-08</span> | **ADELIE: Aligning Large Language Models on Information Extraction**<br><sub>æœºæ„: Tsinghua University<br>æœ¬æ–‡æå‡ºçš„ADELIEæ¨¡å‹æœ‰æ•ˆåœ°è§£å†³äº†LLMåœ¨ä¿¡æ¯æå–ä»»åŠ¡ä¸­çš„å¯¹é½é—®é¢˜ï¼Œå¹¶é€šè¿‡åˆ›æ–°çš„æ•°æ®é›†å’Œè®­ç»ƒæ–¹æ³•æå‡äº†æ¨¡å‹åœ¨è¿™äº›ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼ŒåŒæ—¶ç»´æŠ¤äº†è‰¯å¥½çš„é€šç”¨èƒ½åŠ›ï¼Œä¸ºæœªæ¥ç›¸å…³ç ”ç©¶æä¾›äº†æœ‰ä»·å€¼çš„è§è§£å’ŒåŸºç¡€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05008v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05008.md)  |
| <span style='display: inline-block; width: 42px;'>05-08</span> | **"They are uncultured": Unveiling Covert Harms and Social Threats in LLM Generated Conversations**<br><sub>æœºæ„: University of Washington, MBZUAI<br>è¿™é¡¹ç ”ç©¶é€šè¿‡åˆ›æ–°çš„CHASTè¯„ä¼°ä½“ç³»ï¼Œæ­ç¤ºäº†LLMsåœ¨å¤„ç†æ¶µç›–å¹¿æ³›æ–‡åŒ–å’Œèº«ä»½çš„å¤æ‚ç¤¾ä¼šäº’åŠ¨ä¸­å¯èƒ½å¯¼è‡´çš„æ½œåœ¨ä¼¤å®³ï¼Œå¼ºè°ƒäº†åœ¨éƒ¨ç½²è¿™äº›æ¨¡å‹ä¹‹å‰è¿›è¡Œå½»åº•çš„åè§å®¡è®¡çš„å¿…è¦æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05378v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05378.md)  |
| <span style='display: inline-block; width: 42px;'>05-07</span> | **Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application**<br><sub>æœºæ„: Kuaishou Technology, Southeast University<br>æœ¬è®ºæ–‡æˆåŠŸåœ°å°†å¤§å‹è¯­è¨€æ¨¡å‹çš„å¼€æ”¾ä¸–ç•ŒçŸ¥è¯†åº”ç”¨äºæ¨èç³»ç»Ÿï¼Œé€šè¿‡ä¸€ä¸ªåˆ›æ–°çš„åŒå¡”ç»“æ„è§£å†³äº†å®é™…åº”ç”¨ä¸­çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œä¸ºæå‡æ¨èç³»ç»Ÿçš„æ€§èƒ½æä¾›äº†æ–°çš„æ€è·¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.03988v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.03988.md)  |
| <span style='display: inline-block; width: 42px;'>05-07</span> | **Toward In-Context Teaching: Adapting Examples to Students' Misconceptions**<br><sub>æœºæ„: MIT CSAIL  <br>æœ¬è®ºæ–‡æˆåŠŸå±•ç¤ºäº†åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œé€‚åº”æ€§æ•™å­¦çš„æ½œåŠ›ï¼Œå¹¶é€šè¿‡ATOMæ¨¡å‹å®ç°äº†å¯¹å­¦ç”Ÿè¯¯è§£çš„æœ‰æ•ˆè¯†åˆ«å’Œæ•™å­¦åé¦ˆçš„ä¼˜åŒ–ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.04495v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.04495.md)  |
| <span style='display: inline-block; width: 42px;'>05-07</span> | **Deception in Reinforced Autonomous Agents: The Unconventional Rabbit Hat Trick in Legislation**<br><sub>æœºæ„: Center for Responsible AI, IIT Madras, Princeton University  <br>è®ºæ–‡æœ‰æ•ˆåœ°å±•ç¤ºäº†ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„è‡ªæ²»ä»£ç†åœ¨ç›®æ ‡å¯¼å‘ç¯å¢ƒä¸­æ‰§è¡Œå¤æ‚ä»»åŠ¡ï¼ˆå¦‚ç«‹æ³•æ¸¸è¯´ï¼‰æ—¶çš„æ¬ºéª—èƒ½åŠ›ï¼Œå¹¶æå‡ºäº†æ£€æµ‹è¿™ç§æ¬ºéª—è¡Œä¸ºçš„æœ‰æ•ˆæ–¹æ³•ã€‚è¿™äº›å‘ç°ä¸ºAIåœ¨æ³•å¾‹å’Œé“å¾·æ–¹é¢çš„åº”ç”¨æä¾›äº†é‡è¦çš„è§è§£ï¼ŒåŒæ—¶ä¹Ÿä¸ºAIå®‰å…¨æä¾›äº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.04325v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.04325.md)  |
| <span style='display: inline-block; width: 42px;'>05-07</span> | **QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving**<br><sub>æœºæ„: MIT, NVIDIA<br>é€šè¿‡æ–°çš„é‡åŒ–ç®—æ³•å’Œç³»ç»Ÿè®¾è®¡ï¼ŒQServeæ˜¾è‘—æå‡äº†LLMåœ¨GPUä¸Šçš„æœåŠ¡æ•ˆç‡ï¼Œå®ç°äº†æˆæœ¬çš„å¤§å¹…åº¦é™ä½ï¼Œä¸ºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„éƒ¨ç½²æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.04532v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.04532.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/mit-han-lab/qserve)</div> |
| <span style='display: inline-block; width: 42px;'>05-06</span> | **MARE: Multi-Agents Collaboration Framework for Requirements Engineering**<br><sub>æœºæ„: Peking University<br>è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåˆ›æ–°çš„å¤šä»£ç†åˆä½œæ¡†æ¶ï¼ŒMAREï¼Œç”¨äºåœ¨æ•´ä¸ªéœ€æ±‚å·¥ç¨‹è¿‡ç¨‹ä¸­åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¹‹é—´çš„åˆä½œã€‚å®ƒé’ˆå¯¹REä¸­è‡ªåŠ¨åŒ–ä»»åŠ¡çš„å±€é™æ€§è¿›è¡Œäº†æ”¹è¿›ï¼Œå¹¶é€šè¿‡å¤§è§„æ¨¡å®éªŒçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒMAREåœ¨éœ€æ±‚å»ºæ¨¡å’Œè§„æ ¼ç”Ÿæˆæ–¹é¢ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.03256v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.03256.md)  |
| <span style='display: inline-block; width: 42px;'>05-06</span> | **Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning**<br><sub>æœºæ„: East China Normal University<br>RECIPEæ–¹æ³•é€šè¿‡è½¬æ¢çŸ¥è¯†é™ˆè¿°ä¸ºè¿ç»­æç¤ºç¬¦å¹¶ç»“åˆçŸ¥è¯†å“¨å…µæ¥åŠ¨æ€ç®¡ç†æ£€ç´¢è¿‡ç¨‹ï¼Œæœ‰æ•ˆæé«˜äº†LLMsåœ¨ç”Ÿå‘½å‘¨æœŸå­¦ä¹ åœºæ™¯ä¸­çš„ç¼–è¾‘æ•ˆç‡å’Œæ¨æ–­é€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹æ•´ä½“æ€§èƒ½ã€‚è¿™ç§æ–¹æ³•å…‹æœäº†ä»¥å‰æ–¹æ³•çš„ç¼ºç‚¹ï¼Œå¹¶åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸­è¡¨ç°å‡ºè‰²ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.03279v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.03279.md)  |
| <span style='display: inline-block; width: 42px;'>05-03</span> | **What matters when building vision-language models?**<br><sub>æœºæ„: Hugging Face, Sorbonne UniversitÃ©  <br>æœ¬æ–‡é€šè¿‡å¹¿æ³›çš„å®éªŒæ¢è®¨äº†å½±å“VLMsæ€§èƒ½çš„å…³é”®è®¾è®¡é€‰æ‹©ï¼Œæå‡ºäº†Idefics2è¿™ä¸€é«˜æ•ˆçš„åŸºç¡€è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå¹¶åœ¨å¤šä¸ªæ ‡å‡†æµ‹è¯•ä¸­è¯æ˜äº†å…¶ä¼˜è¶Šæ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.02246v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.02246.md)  |
| <span style='display: inline-block; width: 42px;'>05-02</span> | **How Can I Get It Right? Using GPT to Rephrase Incorrect Trainee Responses**<br><sub>æœºæ„: Carnegie Mellon University<br>è¯¥è®ºæ–‡ç ”ç©¶äº†åˆ©ç”¨GPT-4æ„å»ºä¸€ä¸ªè‡ªåŠ¨åŒ–åé¦ˆç³»ç»Ÿæ¥å¸®åŠ©ä¸€å¯¹ä¸€èŠ‚è¯¾ä¸­å¯¼å¸ˆçš„è®­ç»ƒï¼Œæ—¨åœ¨å‡è½»ä¼ ç»Ÿæä¾›ä¸ªæ€§åŒ–æ•™å­¦åé¦ˆçš„èµ„æºè´Ÿæ‹…ï¼ŒåŒæ—¶æä¾›é«˜è´¨é‡å’Œå…·ä½“æ€§çš„åé¦ˆï¼Œæ˜¯çŸ¥è¯†æ£€ç´¢ä¸è¯„ä¼°ç±»çš„ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00970v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.0097.md)  |
| <span style='display: inline-block; width: 42px;'>05-02</span> | **Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models**<br><sub>æœºæ„: KAIST AI, LG AI Research, Carnegie Mellon University<br>PROMETHEUS 2æ˜¯ä¸€ä¸ªæ–°å‹çš„å¼€æºè¯„ä¼°LMï¼Œèƒ½åœ¨ç›´æ¥è¯„ä¼°å’Œæˆå¯¹æ’åä¸¤ç§æ ¼å¼ä¸‹å·¥ä½œï¼Œå¹¶ä¸”åœ¨è‡ªå®šä¹‰è¯„ä»·æ ‡å‡†ä¸Šä¸äººç±»è¯„åˆ†å’Œä¸“æœ‰LMsçš„åˆ¤æ–­å¯†åˆ‡ç›¸å…³ã€‚è¯¥æ¨¡å‹é‡‡ç”¨æƒé‡åˆå¹¶çš„æ–¹å¼è®­ç»ƒï¼Œæ€§èƒ½æ˜¾è‘—è¶…è¿‡å…¶ä»–å¼€æºæ¨¡å‹å’ŒæŸäº›ä¸“æœ‰æ¨¡å‹ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.01535v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.01535.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/prometheus-eval/prometheus-eval)</div> |
| <span style='display: inline-block; width: 42px;'>05-01</span> | **A Careful Examination of Large Language Model Performance on Grade School Arithmetic**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00332v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.00332.md)  |
| <span style='display: inline-block; width: 42px;'>05-01</span> | **The Real, the Better: Aligning Large Language Models with Online Human Behaviors**<br><sub>æœºæ„: Baidu Inc.<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„å¤§å‹è¯­è¨€æ¨¡å‹å¯¹é½æ¡†æ¶RLHBï¼Œå®ƒé€šè¿‡åˆ©ç”¨çœŸå®çº¿ä¸Šäººç±»è¡Œä¸ºåˆ›æ–°æ€§åœ°å¯¹LLMsè¿›è¡Œè°ƒæ•´å’Œä¼˜åŒ–ï¼Œå…‹æœäº†ç°æœ‰æ–¹æ³•ä¸­çš„å±€é™æ€§ï¼Œå¹¶é€šè¿‡å®éªŒæœ‰æ•ˆåœ°éªŒè¯äº†å…¶æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00578v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.00578.md)  |
| <span style='display: inline-block; width: 42px;'>05-01</span> | **Can a Hallucinating Model help in Reducing Human "Hallucination"?**<br><sub>æœºæ„: Stanford University, UC Berkeley<br>æœ¬æ–‡æ¢è®¨äº†å¦‚ä½•ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¥æ£€æµ‹å’Œå¯¹æŠ—æ— æ ¹æ®ä¿¡å¿µï¼Œä»¥åŠåˆ©ç”¨LLMsä½œä¸ºä¸ªæ€§åŒ–çš„é”™è¯¯ä¿¡æ¯é©³æ–¥ä»£ç†ã€‚ç ”ç©¶è€…æå‡ºäº†è¯„ä¼°å¹¶åˆ©ç”¨LLMsåœ¨è¯†åˆ«é€»è¾‘é™·é˜±æ–¹é¢çš„èƒ½åŠ›ï¼Œå¹¶æŒ‘æˆ˜äººç±»æ— æ ¹æ®ä¿¡å¿µçš„æ–°æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00843v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.00843.md)  |
| <span style='display: inline-block; width: 42px;'>05-01</span> | **Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing with Llama-3**<br><sub>æœ¬ç ”ç©¶å¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹ç¼–è¾‘æŠ€æœ¯è¿›è¡Œäº†å®è¯åˆ†æï¼Œæ­ç¤ºäº†ä»¥å¾€æ–¹æ³•çš„æ½œåœ¨ä¸è¶³ï¼Œå¹¶ä¸ºæœªæ¥çš„æ¨¡å‹ç¼–è¾‘æ–¹æ³•æå‡ºäº†æ–°æ–¹å‘å’Œæ€è·¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00664v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.00664.md)  |
| <span style='display: inline-block; width: 42px;'>05-01</span> | **"I'm Not Sure, But...": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust**<br><sub>æœºæ„: Princeton University, Microsoft<br>è¯¥è®ºæ–‡é€šè¿‡å¤§è§„æ¨¡å®éªŒç ”ç©¶è¡¨æ˜ï¼ŒLLMsé€šè¿‡è‡ªç„¶è¯­è¨€æ¥è¡¨è¾¾ä¸ç¡®å®šæ€§ï¼Œå¯ä»¥å‡å°‘ç”¨æˆ·çš„è¿‡åº¦ä¾èµ–ï¼Œå¹¶æé«˜ä»»åŠ¡å¤„ç†çš„å‡†ç¡®åº¦ã€‚å°¤å…¶æ˜¯ç¬¬ä¸€äººç§°è¡¨è¾¾å½¢å¼å¯¹æé«˜ç”¨æˆ·çš„å‡†ç¡®æ€§æ•ˆæœæ˜¾è‘—ã€‚æ­¤å¤–ï¼Œè¿™é¡¹ç ”ç©¶è¿˜å¼ºè°ƒåœ¨å®é™…åº”ç”¨LLMsä¹‹å‰ï¼Œè¿›è¡Œç”¨æˆ·æµ‹è¯•ä»¥è°ƒæ•´ä¸ç¡®å®šæ€§çš„è¡¨è¾¾æ–¹å¼çš„é‡è¦æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00623v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.00623.md)  |

---

### 04æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Multi-hop Question Answering over Knowledge Graphs using Large Language Models**<br><sub>æœºæ„: Microsoft<br>è®ºæ–‡åœ¨å¤šè·³é—®ç­”ä»»åŠ¡ä¸­æå‡ºé’ˆå¯¹ä¸åŒçš„çŸ¥è¯†å›¾è°±æ•°æ®é›†é‡‡ç”¨ä¸åŒç­–ç•¥ï¼Œå±•ç¤ºäº†åˆ©ç”¨å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹åœ¨è¿™äº›å¤æ‚é—®ç­”ä»»åŠ¡ä¸­çš„å¼ºå¤§èƒ½åŠ›ã€‚é€šè¿‡å®éªŒï¼ŒéªŒè¯äº†æ‰€ææ–¹æ³•ç›¸æ¯”ç°æœ‰æŠ€æœ¯çš„ä¼˜åŠ¿ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19234v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19234.md)  |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Do Large Language Models Understand Conversational Implicature -- A case study with a chinese sitcom**<br><sub>æœºæ„: Shanghai Jiao Tong University<br>è¯¥ç ”ç©¶é€šè¿‡åˆ›å»ºä¸€ä¸ªæ–°çš„ä¸­æ–‡å¤šè½®å¯¹è¯æ•°æ®é›†SwordsmanImpè¯„ä¼°LLMsç†è§£è¨€å¤–ä¹‹æ„çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠå¤§é‡ä¸Šä¸‹æ–‡å’Œè½®æ¢çš„å¯¹è¯ä¸­ï¼Œå¹¶æ­ç¤ºäº†LLMsåœ¨ç†è§£å’Œè§£é‡Šéå­—é¢å«ä¹‰æ—¶çš„æŒ‘æˆ˜å’Œå±€é™ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19509v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19509.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/sjtu-compling/llm-pragmatics)</div> |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Iterative Reasoning Preference Optimization**<br><sub>æœºæ„: FAIR at Meta, New York University<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§è¿­ä»£æ¨ç†åå¥½ä¼˜åŒ–æ–¹æ³•ï¼Œé€šè¿‡åœ¨æ¨ç†ä»»åŠ¡ä¸Šåº”ç”¨åå¥½ä¼˜åŒ–ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹CoTæ¨ç†ï¼Œå¹¶é€šè¿‡åœ¨è¿­ä»£è®­ç»ƒä¸­å¼•å…¥NLLæŸå¤±é¡¹æ¥æå‡æ¨¡å‹æ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ•°æ¬¡è¿­ä»£åèƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨ç†æ€§èƒ½ï¼Œæœ€ç»ˆè¾¾åˆ°æ€§èƒ½é¥±å’Œã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19733v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19733.md)  |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Better & Faster Large Language Models via Multi-token Prediction**<br><sub>æœºæ„: FAIR at Meta<br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹çš„æ–¹æ³•ï¼Œé€šè¿‡é¢„æµ‹å¤šä¸ªæ ‡è®°è€Œä¸æ˜¯å•ä¸ªæ¥æé«˜æ ·æœ¬æ•ˆç‡ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•æå‡ç”Ÿæˆä»»åŠ¡ä¸­çš„æ€§èƒ½å¹¶åŠ å¿«æ¨ç†é€Ÿåº¦ã€‚å®éªŒè¯æ˜äº†è¿™ç§æ–¹æ³•åœ¨æå‡å¤§å‹æ¨¡å‹æ€§èƒ½å’Œæ¨ç†æ•ˆç‡æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19737v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19737.md)  |
| <span style='display: inline-block; width: 42px;'>04-29</span> | **Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models**<br><sub>æœºæ„: Cohere<br>è¯¥è®ºæ–‡å‘å±•äº†ä¸€ç§ä»¥æˆå‘˜æ¥è‡ªä¸åŒæ¨¡å‹å®¶æ—çš„å°å‹æ¨¡å‹ç»„ç»‡æˆçš„â€œè¯„å®¡å›¢â€æ¥è¯„ä¼°LLMç”Ÿæˆç‰©çš„æ–°æ–¹æ³•ï¼Œç§°ä¸ºPoLLï¼Œæ˜¾ç¤ºå‡ºåœ¨ä¸åŒä»»åŠ¡ä¸­çš„é€‚ç”¨æ€§ä»¥åŠæˆæœ¬æ•ˆç‡ï¼Œå‡å°‘äº†LLMsä½œä¸ºè¯„åˆ¤æ—¶å­˜åœ¨çš„åè§é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.18796v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.18796.md)  |
| <span style='display: inline-block; width: 42px;'>04-29</span> | **LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report**<br><sub>æœºæ„: Predibase<br>æœ¬æ–‡æå‡ºé€šè¿‡LoRAå¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œç»†åŒ–ï¼Œå¯ä»¥æ˜æ˜¾æå‡æ¨¡å‹çš„æ•´ä½“è¡¨ç°ï¼Œé™ä½åœ¨åˆ†ç±»ä»»åŠ¡ä¸­å‡ºç°çš„è¯¯å·®ï¼Œä¸”ä¸å¼€ç®±å³ç”¨çš„GPT-4å’ŒGPT-3.5ç›¸æ¯”ï¼Œæœ‰æ˜¾è‘—æé«˜ã€‚åŒæ—¶ï¼Œè®ºæ–‡è¿˜è€ƒè™‘äº†æˆæœ¬é™åˆ¶ï¼Œé€šè¿‡é™åˆ¶è¯„ä¼°æ ·æœ¬çš„æ•°é‡æ¥é™ä½ä½¿ç”¨LLM APIçš„è´¢åŠ¡è´Ÿæ‹…ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00732v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2405.00732.md)  |
| <span style='display: inline-block; width: 42px;'>04-26</span> | **When to Trust LLMs: Aligning Confidence with Response Quality**<br><sub>æœºæ„: Alibaba Group<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªé€šè¿‡å¼ºåŒ–å­¦ä¹ å¯¹é½ä¿¡å¿ƒå’Œå›ç­”è´¨é‡çš„æ–¹æ³•ï¼ˆCONQORDï¼‰ã€‚è¯¥æ–¹æ³•åœ¨æ²¡æœ‰å®¢è§‚å®é™…æ ‡å‡†çš„æƒ…å†µä¸‹é€šè¿‡è‡ªæˆ‘è¯„ä¼°æ¥ä¼˜åŒ–ä¿¡å¿ƒæ°´å¹³ï¼Œå¹¶èƒ½å¤Ÿå‡å°‘åè§ï¼Œæå‡äº†æ¨¡å‹é¢„æµ‹çš„å‡†ç¡®æ€§å’Œå¯¹é½æ€§ï¼Œä½†ä»éœ€å¯¹æ¯”ç»©æ•ˆæ›´é«˜çš„æ–¹æ³•è¿›è¡Œæ”¹è¿›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.17287v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.17287.md)  |
| <span style='display: inline-block; width: 42px;'>04-26</span> | **A Comprehensive Evaluation on Event Reasoning of Large Language Models**<br><sub>æœºæ„: Peking University, Advanced Institute of Big Data, Beihang University<br>æœ¬æ–‡é€šè¿‡å¼•å…¥ä¸€ä¸ªåä¸ºEV2çš„æ–°åŸºå‡†æµ‹è¯•æ¥å…¨é¢è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„äº‹ä»¶æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè™½ç„¶LLMsæ‹¥æœ‰äº‹ä»¶æ¨ç†èƒ½åŠ›ï¼Œä½†ä¸äººç±»åœ¨è¿ç”¨äº‹ä»¶æ¨¡å¼çŸ¥è¯†æ–¹é¢å¹¶ä¸ä¸€è‡´ï¼Œé€šè¿‡æä¾›æ˜ç¡®çš„æŒ‡å¯¼ï¼Œå¯ä»¥å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°ç†è§£å’Œæ‰§è¡Œäº‹ä»¶æ¨ç†ä»»åŠ¡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.17513v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.17513.md)  |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16621v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16621.md)  |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **Layer Skip: Enabling Early Exit Inference and Self-Speculative Decoding**<br><sub>æœºæ„: Meta, University of Toronto, Carnegie Mellon University<br>LayerSkipæ˜¯ä¸€ä¸ªæ–°é¢–çš„ç«¯åˆ°ç«¯è§£å†³æ–¹æ¡ˆï¼Œèƒ½å¤Ÿåœ¨ä¸ç‰ºç‰²å‡†ç¡®ç‡çš„æƒ…å†µä¸‹æ˜¾è‘—åŠ é€Ÿå¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œå…·æœ‰å®é™…åº”ç”¨ä»·å€¼å’Œæ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16710v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.1671.md)  |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **Continual Learning of Large Language Models: A Comprehensive Survey**<br><sub>æœºæ„: Rutgers University, Wuhan University, Huazhong University of Science and Technology<br>æœ¬ç»¼è¿°ä¸ºLLMsçš„æŒç»­å­¦ä¹ æä¾›äº†ä¸€ä¸ªå…¨é¢çš„è§†è§’ï¼Œç‰¹åˆ«å¼ºè°ƒäº†è¿ç»­é¢„è®­ç»ƒï¼ˆCPTï¼‰å’Œé¢†åŸŸè‡ªé€‚åº”é¢„è®­ç»ƒï¼ˆDAPï¼‰çš„ç ”ç©¶é¢†åŸŸã€‚å¼ºè°ƒç¤¾åŒºéœ€æ›´å¤šå…³æ³¨ï¼Œç‰¹åˆ«æ˜¯å¼€å‘å®ç”¨ã€æ˜“äºè·å–ä¸”å¹¿æ³›è®¤å¯çš„è¯„ä¼°åŸºå‡†æ–¹é¢ï¼Œä»¥åŠéœ€è¦é’ˆå¯¹æ–°å…´LLMså­¦ä¹ èŒƒå¼ç‰¹åˆ«è®¾è®¡çš„æ–¹æ³•è®ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16789v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16789.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Wang-ML-Lab/llm-continual-learning-survey)</div> |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites**<br><sub>æœºæ„: Shanghai AI Laboratory, SenseTime Research, Tsinghua University<br>InternVL 1.5æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¼€æºå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼Œè‡´åŠ›äºå¼¥è¡¥å¼€æºå’Œå•†ä¸šæ¨¡å‹åœ¨å¤šæ¨¡æ€ç†è§£æ–¹é¢çš„æ€§èƒ½å·®è·ã€‚è¯¥æ¨¡å‹çš„ä¼˜åŠ¿åŒ…æ‹¬æ”¹å–„è§†è§‰ç†è§£ã€å¤„ç†åŠ¨æ€é«˜åˆ†è¾¨ç‡å›¾åƒä»¥åŠé«˜è´¨é‡çš„åŒè¯­æ•°æ®é›†çš„ä½¿ç”¨ï¼Œè¿™äº›å®ƒåœ¨å¤šé¡¹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16821v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16821.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OpenGVLab/InternVL)</div> |
| <span style='display: inline-block; width: 42px;'>04-24</span> | **Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs**<br><sub>æœºæ„: Shanghai Jiao Tong University, UC San Diego, Duke University<br>æœ¬æ–‡ç« æ˜¯å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­Chain-of-X (CoX) æ–¹æ³•çš„è¯¦å°½è°ƒç ”ï¼Œç€é‡äºå°†Chain-of-Thought (CoT) çš„æ¦‚å¿µæ‰©å±•è‡³æ›´å¹¿æ³›çš„åº”ç”¨ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ½œåœ¨çš„å‘å±•æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.15676v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.15676.md)  |
| <span style='display: inline-block; width: 42px;'>04-24</span> | **From Local to Global: A Graph RAG Approach to Query-Focused Summarization**<br><sub>æœºæ„: Microsoft Research, Microsoft Strategic Missions and Technologies, Microsoft Office of the CTO<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†Graph RAGæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ä»¥å›¾è°±ç´¢å¼•å’ŒLLMç”Ÿæˆæ‘˜è¦ä¸ºåŸºç¡€çš„æŸ¥è¯¢èšç„¦æ‘˜è¦æŠ€æœ¯ï¼Œæ—¨åœ¨å¤„ç†å› è¯­æ–™é‡è¿‡å¤§è€Œè¶…å‡ºå¤§å‹è¯­è¨€æ¨¡å‹å¤„ç†èƒ½åŠ›çš„é—®é¢˜ã€‚é€šè¿‡ç¤¾åŒºæ£€æµ‹ç®—æ³•çš„å¸®åŠ©ï¼Œè¯¥æ–¹æ³•èƒ½åœ¨å¤„ç†å…¨å±€æ€§é—®é¢˜å¹¶å®ç°å¤§è§„æ¨¡æ–‡æœ¬åˆ†ææ–¹é¢å–å¾—æ˜¾è‘—æˆæ•ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16130v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.1613.md)  |
| <span style='display: inline-block; width: 42px;'>04-23</span> | **A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications**<br><sub>æœºæ„: Hong Kong Baptist University<br>æœ¬æ–‡æ˜¯ä¸€ä¸ªç»¼è¿°æ€§ç ”ç©¶ï¼Œä¸»è¦è°ƒæŸ¥äº†åœ¨å›¾æ•°æ®ä¸Šä½¿ç”¨çš„LLMsç ”ç©¶ï¼Œæ¢è®¨äº†LLMsåœ¨å›¾ä»»åŠ¡æ³›åŒ–æ–¹é¢çš„ä¼˜åŠ¿ï¼Œå¹¶æå‡ºäº†åœ¨è¯¥é¢†åŸŸè¿›è¡Œç ”ç©¶çš„æœªæ¥æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14809v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14809.md)  |
| <span style='display: inline-block; width: 42px;'>04-23</span> | **CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies**<br><sub>æœºæ„: Stanford University, IBM Research<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç”¨äºæ„å»ºæ–‡åŒ–çŸ¥è¯†åº“çš„é€šç”¨æµæ°´çº¿ï¼Œå¹¶ä½¿ç”¨è¯¥æµæ°´çº¿åˆ›å»ºäº†CultureBankï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«TikTokå’ŒRedditä¸Šæ–‡åŒ–æè¿°ç¬¦çš„çŸ¥è¯†åº“ã€‚è®ºæ–‡è¿˜é€šè¿‡è¿™ä¸ªçŸ¥è¯†åº“è¯„ä¼°äº†LLMsåœ¨æ–‡åŒ–æ„è¯†æ–¹é¢çš„è¡¨ç°ï¼Œå¹¶ç”¨äºè®­ç»ƒæ›´å…·æ–‡åŒ–æ„è¯†çš„è¯­è¨€æ¨¡å‹ï¼Œä»¥æ­¤ä¿ƒè¿›æœªæ¥è¯­è¨€æŠ€æœ¯çš„æ–‡åŒ–æ„è¯†å‘å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.15238v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.15238.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/SALT-NLP/CultureBank)</div> |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **LLMs Know What They Need: Leveraging a Missing Information Guided Framework to Empower Retrieval-Augmented Generation**<br><sub>æœºæ„: Meituan<br>æœ¬æ–‡æå‡ºçš„MIGRESæ¡†æ¶æ˜¯é€šè¿‡Exploiting LLMsè¯†åˆ«ç¼ºå¤±ä¿¡æ¯çš„èƒ½åŠ›æ¥å¢å¼ºRAGçš„èƒ½åŠ›ã€‚ç ”ç©¶ç»“æœè¯æ˜äº†MIGRESåœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šå…·æœ‰ä¼˜è¶Šæ€§ï¼Œåº”å¯¹äº†RAGåœ¨ç†è§£å¤æ‚æŸ¥è¯¢å’Œæ£€ç´¢ç›¸å…³æ–‡æ¡£æ–¹é¢çš„æŒ‘æˆ˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14043v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14043.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph**<br><sub>æœºæ„: University of California San Diego, Carnegie Mellon University, University of Pennsylvania<br>ç ”ç©¶è€…æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç”¨äºæ„å»ºç»†ç²’åº¦ä¸»å¼ ä¾èµ–å›¾(FLANå›¾)çš„ç®—æ³•ï¼Œè¯¥ç®—æ³•åœ¨å¤§è§„æ¨¡ä¸Šæ˜¾è‘—æ”¹å–„äº†ç°çŠ¶ï¼Œå¹¶å¯¹ç°ä»£LLMsåœ¨ä¸“åˆ©æ‰¹å‡†é¢„æµ‹ä¸Šçš„åº”ç”¨è¿›è¡Œäº†å¹¿æ³›å®éªŒå’Œåˆ†æï¼Œå‘ç°äº†LLMsçš„å±€é™æ€§ï¼Œå¹¶ä¸ºæœªæ¥LLMæ–¹æ¡ˆçš„å¼€å‘æä¾›äº†æœ‰ä»·å€¼çš„å‚è€ƒã€‚æºä»£ç å’Œæ•°æ®é›†å·²å…¬å¼€å‘å¸ƒä»¥ä¿ƒè¿›æœªæ¥çš„ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14372v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14372.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **A Survey on Efficient Inference for Large Language Models**<br><sub>æœºæ„: Tsinghua University<br>æœ¬æ–‡æä¾›äº†ä¸€ä¸ªå…¨é¢çš„ç»¼è¿°å…³äºæé«˜å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†æ•ˆç‡çš„æ–‡çŒ®ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªåŒ…å«æ•°æ®å±‚ã€æ¨¡å‹å±‚å’Œç³»ç»Ÿå±‚ä¼˜åŒ–çš„åˆ†ç±»æ³•ã€‚åŒæ—¶ï¼Œé€šè¿‡å®éªŒå¯¹å…³é”®æŠ€æœ¯è¿›è¡Œäº†é‡åŒ–æ¯”è¾ƒï¼ŒæŒ‡å‡ºäº†ç ”ç©¶çš„æœªæ¥æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14294v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14294.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **A Survey on Self-Evolution of Large Language Models**<br><sub>æœºæ„: Peking University, Alibaba Group, Nanyang Technological University<br>è¿™ç¯‡ç»¼è¿°æ–‡ç« æå‡ºå¹¶æ€»ç»“äº†LLMsçš„è‡ªæˆ‘è¿›åŒ–æ–¹æ³•ï¼Œä¸ºæ¨åŠ¨è‡ªæˆ‘è¿›åŒ–çš„ç ”ç©¶æä¾›äº†æ¦‚å¿µæ¡†æ¶å’Œæœªæ¥æ–¹å‘çš„è§è§£ï¼Œæ—¨åœ¨æ¨åŠ¨ä¸‹ä¸€ä»£è‡ªæˆ‘è¿›åŒ–LLMsçš„å‘å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14387v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14387.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **Information Re-Organization Improves Reasoning in Large Language Models**<br><sub>æœºæ„: Zhejiang University<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„ä¿¡æ¯é‡ç»„æ–¹æ³•ï¼ˆInfoREï¼‰ï¼Œé€šè¿‡é‡ç»„ä¸Šä¸‹æ–‡å†…å®¹æ¥æ­ç¤ºé€»è¾‘å…³ç³»ï¼Œä»è€Œå¢å¼ºLLMsçš„æ¨ç†èƒ½åŠ›ã€‚æ–¹æ³•åœ¨é›¶æ¬¡å°„å‡»è®¾ç½®ä¸‹å¯¹LLMsè¿›è¡Œä¸Šä¸‹æ–‡ç†è§£çš„å¤šè·³æ¨ç†ä»»åŠ¡æµ‹è¯•ï¼Œå–å¾—äº†æ˜¾è‘—æ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.13985v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.13985.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/hustcxx/InfoRE)</div> |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **Tree of Reviews: A Tree-based Dynamic Iterative Retrieval Framework for Multi-hop Question Answering**<br><sub>æœºæ„: Tencent Inc., Harbin Institute of Technology<br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¿­ä»£æ£€ç´¢æ¡†æ¶TORï¼Œå®ƒé‡‡ç”¨æ ‘å½¢ç»“æ„å‡å°‘é”™è¯¯ç´¯ç§¯ï¼Œå¹¶å¼•å…¥ä¼˜åŒ–ç­–ç•¥æé«˜æ£€ç´¢æ•ˆç‡å’Œè´¨é‡ã€‚åœ¨å®éªŒä¸­ï¼ŒTORæ¡†æ¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14464v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14464.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **SnapKV: LLM Knows What You are Looking for Before Generation**<br><sub>æœºæ„: University of Illinois Urbana-Champaign, Cohere, Princeton University<br>è¯¥æ–‡ç« ä»‹ç»äº†SnapKVï¼Œä¸€ç§é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å…³é”®å€¼ç¼“å­˜é—®é¢˜çš„æ–°æ–¹æ³•ã€‚SnapKVé€šè¿‡æ™ºèƒ½å‹ç¼©å’Œé€‰å–é‡è¦çš„KVä½ç½®ï¼Œæœ‰æ•ˆåœ°æå‡äº†é•¿æ–‡æœ¬å¤„ç†æ—¶çš„è§£ç é€Ÿåº¦å’Œå†…å­˜æ•ˆç‡ï¼Œå¹¶åœ¨ä¿æŒå‡†ç¡®æ€§çš„åŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14469v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14469.md)  |
| <span style='display: inline-block; width: 42px;'>04-21</span> | **AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs**<br><sub>æœºæ„: Meta AI (FAIR), Max-Planck-Institute for Intelligent Systems<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°å‹çš„LLMï¼Œåä¸ºAdvPrompterï¼Œå®ƒåˆ©ç”¨æ–°é¢–çš„ç®—æ³•ï¼Œæ— éœ€ç›®æ ‡LLMçš„æ¢¯åº¦ä¿¡æ¯ï¼Œè¿…é€Ÿç”Ÿæˆäººç±»å¯è¯»çš„æ•Œå¯¹æç¤ºï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆé€Ÿåº¦å¹¶ä¿æŒäº†æç¤ºçš„è¯­ä¹‰è¿è´¯æ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡AdvPrompterçš„è®­ç»ƒè¿˜èƒ½å¢å¼ºLLMé¢å¯¹è¶Šç‹±æ”»å‡»çš„ç¨³å¥æ€§ï¼Œè€Œä¸ç‰ºç‰²æ€§èƒ½è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16873v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16873.md)  |
| <span style='display: inline-block; width: 42px;'>04-19</span> | **Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?**<br><sub>æœºæ„: Nanyang Technological University, Princeton University, Salesforce Research<br>æœ¬è®ºæ–‡ç³»ç»Ÿåœ°è¯„ä¼°äº†LLMsè¿›è¡Œç±»æ¯”æ¨ç†çš„èƒ½åŠ›ï¼Œå¹¶æå‡ºäº†ä¸¤ç§å¯ä»¥åœ¨æ˜¾è‘—é™ä½æ¨ç†æˆæœ¬çš„åŒæ—¶è·å¾—æ›´å¥½æ€§èƒ½çš„æ–¹æ³•ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä¸ä»¥å‰è®¤ä¸ºç›¸å…³æ€§è‡³å…³é‡è¦çš„è§‚ç‚¹ç›¸åï¼Œè‡ªæˆ‘ç”Ÿæˆçš„æ— å…³ä¾‹å­åœ¨æŸäº›ä»»åŠ¡ä¸Šå¯ä»¥è¾¾åˆ°ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚å¸Œæœ›æœ¬ç ”ç©¶èƒ½åˆºæ¿€æ›´å¤šå…³äºè‡ªæˆ‘ç”Ÿæˆä¸Šä¸‹æ–‡è®¾è®¡çš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12728v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12728.md)  |
| <span style='display: inline-block; width: 42px;'>04-19</span> | **LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for Boosting Query Efficiency**<br><sub>æœºæ„: Nanyang Technological University, DAMO Academy Alibaba Group, Singapore University of Technology and Design<br>LLM-R2æ˜¯ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å¢å¼ºçš„æŸ¥è¯¢é‡å†™ç³»ç»Ÿï¼Œé€šè¿‡è‡ªåŠ¨é€‰æ‹©ä¸€ç»„ç»™å®šé‡å†™è§„åˆ™ä¸­çš„æœ‰æ•ˆè§„åˆ™ï¼Œæœ‰æ•ˆåœ°æå‡äº†æŸ¥è¯¢é‡å†™çš„æ‰§è¡Œæ•ˆç‡ï¼Œè§£å†³äº†ç›®å‰å…¶ä»–æ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†ä¼˜è¶Šçš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12872v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12872.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **EVIT: Event-Oriented Instruction Tuning for Event Reasoning**<br><sub>æœºæ„: Key Laboratory of High Confidence Software Technologies (PKU), MOE, China, School of Computer Science, Peking University, Advanced Institute of Big Data<br>EVITé€šè¿‡æå‡ºé¢å‘äº‹ä»¶çš„æŒ‡ä»¤è°ƒè°ï¼ˆEvent-Oriented Instruction Tuningï¼‰å’Œäº‹ä»¶å››å…ƒç»„çš„æ¦‚å¿µï¼Œè§£å†³äº†ç°æœ‰å°å‹åŸºäºæŒ‡ä»¤è°ƒè°æ¨¡å‹åœ¨äº‹ä»¶æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ä¸è¶³é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEVITåœ¨äº‹ä»¶æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11978v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11978.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences**<br><sub>æœºæ„: UC Berkeley<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªä¸äººç±»åå¥½ç›¸ä¸€è‡´çš„LLMè¾…åŠ©è¯„ä¼°ç•Œé¢EvalGenï¼Œé€šè¿‡æ··åˆä¸»åŠ¨å¼æ–¹æ³•è§£å†³äº†LLMç”Ÿæˆçš„è¯„ä¼°åŠŸèƒ½è¯„ä¼°è´¨é‡å—ä¿¡ä»»åº¦çš„é—®é¢˜ã€‚è®ºæ–‡è¿˜æ¢è®¨äº†ç”¨æˆ·å¦‚ä½•å®šä¹‰å’Œä½¿ç”¨è¯„ä¼°æ ‡å‡†çš„åŠ¨æ€æ€§ï¼Œä»¥åŠåœ¨å®é™…åº”ç”¨ä¸­æ‰€é¢ä¸´çš„æŒ‘æˆ˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12272v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12272.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing**<br><sub>è¯¥è®ºæ–‡ä»‹ç»äº†ä¸€ç§åä¸ºALPHALLMçš„æ–°å‹æ¡†æ¶ï¼Œé€šè¿‡è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ç»“åˆï¼Œå®ç°äº†LLMsçš„è‡ªæˆ‘æé«˜ï¼Œæ— éœ€é¢å¤–çš„æ³¨è§£æ•°æ®ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12253v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12253.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **Generating Diverse Criteria On-the-Fly to Improve Point-wise LLM Rankers**<br><sub>æœºæ„: Westlake University, Alibaba Group, Zhejiang University<br>è¯¥è®ºæ–‡æå‡ºäº†MCRankeræ¨¡å‹ï¼Œé€šè¿‡æ„å»ºè™šæ‹Ÿä¸“ä¸šè¯„æ³¨å›¢é˜Ÿå’Œç”Ÿæˆå¤šè§’åº¦è¯„ä¼°æ ‡å‡†ï¼Œæœ‰æ•ˆæå‡äº†LLMæ’åºå™¨çš„ä¸€è‡´æ€§ä¸å…¨é¢æ€§ï¼Œå¯å¹¿æ³›é€‚åº”äºå„ç±»æ•°æ®é›†ï¼Œæ”¹è¿›äº†æ’åºæ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11960v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.1196.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation**<br><sub>æœºæ„: Peking University, ByteDance Inc.<br>é€šè¿‡é’ˆå¯¹æ€§çš„ç¼“å­˜ç³»ç»Ÿè®¾è®¡å’Œä¸­é—´çŠ¶æ€å…±äº«ï¼ŒRAGCacheä¼˜åŒ–äº†RAGæµç¨‹çš„æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†å¤„ç†é€Ÿåº¦å¹¶å‡å°‘äº†è®¡ç®—èµ„æºçš„å¼€é”€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12457v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12457.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture**<br><sub>æœºæ„:  Beihang University, Beijing Information Science and Technology University<br>mABCæ˜¯ä¸€ç§åˆ›æ–°çš„æ¡†æ¶ï¼Œåˆ©ç”¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åŠå¤šä»£ç†åˆä½œï¼Œå¹¶ç”±åŒºå—é“¾å¯å‘å¼çš„å†³ç­–è¿‡ç¨‹ä¿ƒæˆï¼Œé’ˆå¯¹äº‘åŸç”ŸæŠ€æœ¯ä¸­å¾®æœåŠ¡æ¶æ„çš„æ ¹æœ¬åŸå› åˆ†æï¼ˆRCAï¼‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12135v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12135.md)  |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **Many-Shot In-Context Learning**<br><sub>æœºæ„: Google DeepMind<br>æœ¬è®ºæ–‡ä¸»è¦è´¡çŒ®åŒ…æ‹¬ç³»ç»Ÿè¯„ä¼°LLMåœ¨ä¸åŒè§„æ¨¡ä¸Šä¸‹æ–‡æ ·ä¾‹çš„æ€§èƒ½ï¼Œå¯¼å…¥reinforced ICLå’Œunsupervised ICLä»¥å‡å°‘æ ·ä¾‹ä¾èµ–ï¼Œå¹¶å‘ç°MS-ICLå¯ä»¥å…‹æœé¢„è®­ç»ƒåå·®å­¦ä¹ é«˜ç»´æ•°å€¼é¢„æµ‹ä»»åŠ¡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11018v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11018.md)  |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **Unifying Bias and Unfairness in Information Retrieval: A Survey of Challenges and Opportunities with Large Language Models**<br><sub>æœºæ„: Renmin University of China, Chinese Academy of Sciences, Huawei Technologies<br>è¿™ç¯‡ç»¼è¿°æ–‡ç« æä¾›äº†ä¸€ä¸ªæ–°é¢–çš„è§†è§’æ¥ç†è§£LLMså’ŒIRç³»ç»Ÿä¸­çš„åè§å’Œä¸å…¬å¹³ä¸ºåˆ†å¸ƒå¤±é…é—®é¢˜ï¼Œå¹¶å½’ç±»äº†å„ç§ç¼“è§£ç­–ç•¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11457v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11457.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/KID-22/LLM-IR-Bias-Fairness-Survey)</div> |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **AgentKit: Flow Engineering with Graphs, not Coding**<br><sub>æœºæ„: Carnegie Mellon University, NVIDIA, Microsoft<br>è®ºæ–‡å¼•å…¥äº†ä¸€ç§æ–°å‹çš„ LLM æç¤ºæ¡†æ¶ AgentKitï¼Œé’ˆå¯¹å¤šåŠŸèƒ½ä»£ç†é—®é¢˜ï¼Œé€šè¿‡æ¨¡å—åŒ–ç»„ä»¶å’Œç›´è§‚è®¾è®¡æ”¯æŒæ„å»ºå’Œå¾®è°ƒå¤æ‚çš„ä»£ç†æ€ç»´è¿‡ç¨‹ã€‚AgentKit æ˜¾ç¤ºå‡ºå®ç°å…ˆè¿›ä»£ç†èƒ½åŠ›å’Œé™ä½ç”¨æˆ·å‚ä¸é—¨æ§›çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11483v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11483.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/holmeswww/AgentKit)</div> |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **A Deep Dive into Large Language Models for Automated Bug Localization and Repair**<br><sub>æœºæ„: University of Virginia, Purdue University, Amazon Web Services<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºToggleçš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨tokenç²’åº¦çš„bugå®šä½å¹¶ä¿®å¤ï¼Œå…‹æœäº†ç°æœ‰è¡Œç²’åº¦æ–¹æ³•çš„å±€é™ï¼Œé€šè¿‡è¾“å…¥è®¾è®¡å’ŒLLMsçš„å¾®è°ƒï¼Œå¤§å¹…æå‡äº†é”™è¯¯ä¿®å¤çš„å‡†ç¡®æ€§ï¼Œå¹¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—ä¼˜å¼‚çš„è¡¨ç°ï¼Œä¸ºAPRé¢†åŸŸå¸¦æ¥æ–°çš„è¿›å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11595v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11595.md)  |
| <span style='display: inline-block; width: 42px;'>04-16</span> | **How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs' internal prior**<br><sub>æœºæ„: Stanford University<br>è®ºæ–‡é€šè¿‡åˆ†æåœ¨RAGç¯å¢ƒä¸‹LLMså†…éƒ¨çŸ¥è¯†ä¸æ£€ç´¢ä¿¡æ¯ä¹‹é—´çš„å¼ åŠ›ï¼Œå‘ç°äº†LLMså€¾å‘äºéµå¾ªRAGä¿¡æ¯çš„ç¨‹åº¦ä¸æ¨¡å‹åœ¨æ— ä¸Šä¸‹æ–‡æƒ…å†µä¸‹çš„å›ç­”ä¿¡å¿ƒæˆåæ¯”ã€‚ç ”ç©¶åŸºäºè·¨è¶…è¿‡1200ä¸ªé—®é¢˜çš„å…­ä¸ªé¢†åŸŸæ•°æ®é›†ï¼Œæ­ç¤ºäº†åœ¨æ¨¡å‹çš„é¢„è®­ç»ƒçŸ¥è¯†ä¸æ£€ç´¢åˆ°çš„ä¿¡æ¯ä¹‹é—´çš„å›ºæœ‰å†²çªã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10198v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.10198.md)  |
| <span style='display: inline-block; width: 42px;'>04-16</span> | **CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity**<br><sub>æœºæ„: Intel Labs<br>æœ¬æ–‡æå‡ºçš„CoTARæ–¹æ³•é’ˆå¯¹LLMsåœ¨é—®ç­”ä»»åŠ¡ä¸­å€¾å‘äºç”Ÿæˆä¸å‡†ç¡®å½’å› çš„é—®é¢˜ã€‚é€šè¿‡åœ¨è¾“å‡ºç”Ÿæˆå‰è¿›è¡Œæ¨ç†ï¼Œå¹¶åœ¨ä¸åŒçš„å½’å› ç²’åº¦çº§åˆ«ä¸Šå¼•å¯¼æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨ç­”æ¡ˆè´¨é‡å’Œå½’å› ç²¾ç¡®åº¦ä¸Šçš„è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10513v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.10513.md)  |
| <span style='display: inline-block; width: 42px;'>04-16</span> | **Self-playing Adversarial Language Game Enhances LLM Reasoning**<br><sub>æœºæ„: Tencent AI Lab<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºSPAGçš„æ–°å‹è®­ç»ƒæ–¹æ¡ˆï¼Œé€šè¿‡è‡ªæˆ‘å¯¹æŠ—æ€§è¯­è¨€æ¸¸æˆçš„è‡ªæˆ‘æ’­æ”¾ï¼Œæœ‰æ•ˆæå‡äº†LLMsçš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶ä¸”å…¶æ”¹è¿›æ˜¯å¯ä»¥é€šè¿‡è¿­ä»£è¿‡ç¨‹æŒç»­å¢å¼ºçš„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10642v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.10642.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Linear95/SPAG)</div> |
| <span style='display: inline-block; width: 42px;'>04-15</span> | **Learn Your Reference Model for Real Good Alignment**<br><sub>æœºæ„: Tinkoff<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºTrust Region DPO (TR-DPO) çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡äº¤äº’å¼åœ°æ›´æ–°å‚è€ƒç­–ç•¥çš„å‚æ•°ï¼Œæ˜¾è‘—æ”¹è¿›äº†è¯­è¨€æ¨¡å‹çš„å¯¹é½é—®é¢˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTR-DPOåœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šå‡ä¼˜äºDPOæ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹çš„å¤šå‚æ•°æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.09656v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.09656.md)  |
| <span style='display: inline-block; width: 42px;'>04-15</span> | **Compression Represents Intelligence Linearly**<br><sub>æœºæ„: The Hong Kong University of Science and Technology, Tencent<br>è¿™ç¯‡è®ºæ–‡é€šè¿‡å®è¯ç ”ç©¶ï¼Œè¯æ˜äº†LLMsåœ¨ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ä¸å®ƒä»¬çš„å‹ç¼©æ•ˆç‡ä¹‹é—´å­˜åœ¨ç€å‡ ä¹çº¿æ€§çš„ç›¸å…³æ€§ï¼Œä¸ºâ€œæ›´å¥½çš„å‹ç¼©èƒ½åŠ›è¡¨æ˜äº†æ›´é«˜çš„æ™ºèƒ½â€è¿™ä¸€é•¿æœŸä¿¡å¿µæä¾›äº†æ”¯æŒã€‚åŒæ—¶ï¼Œæå‡ºäº†ä½¿ç”¨å‹ç¼©æ•ˆç‡ä½œä¸ºè¯„ä¼°LLMsæ€§èƒ½çš„æ— ç›‘ç£åº¦é‡æ ‡å‡†çš„å»ºè®®ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.09937v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.09937.md)  |
| <span style='display: inline-block; width: 42px;'>04-14</span> | **Emerging Platforms Meet Emerging LLMs: A Year-Long Journey of Top-Down Development**<br><sub>æœ¬è®ºæ–‡çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å¦‚ä½•æ”¯æŒå’Œä¼˜åŒ–æ–°å…´è®¡ç®—å¹³å°ä¸‹çš„æœºå™¨å­¦ä¹ æ¨¡å‹éƒ¨ç½²ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ¡†æ¶TAPMLï¼Œæ—¨åœ¨é€šè¿‡é¡¶å±‚æ–¹æ³•å’Œé€šç”¨è¿è¡Œæ—¶ç¯å¢ƒä¿ƒè¿›æ¨¡å‹éƒ¨ç½²çš„å¹¿æ³›æ€§ã€ä¾¿åˆ©æ€§å’Œå¼ºå¤§æ€§ï¼Œæ–‡ä¸­æä¾›äº†å®é™…éƒ¨ç½²æ¡ˆä¾‹ä½œä¸ºå‘å±•MLç³»ç»Ÿçš„æ·±å…¥è§è§£å’Œæœ€ä½³å®è·µã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.09151v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.09151.md)  |
| <span style='display: inline-block; width: 42px;'>04-13</span> | **Intuition-aware Mixture-of-Rank-1-Experts for Parameter Efficient Finetuning**<br><sub>æœºæ„: Nanjing University, University of California<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹å¤šä»»åŠ¡å¾®è°ƒçš„æ¡†æ¶Intuition-MoR1Eï¼Œè¯¥æ¡†æ¶å€Ÿé‰´äººç±»è®¤çŸ¥ç¥ç»ç§‘å­¦åŸç†ï¼Œå¹¶åˆ©ç”¨æ’å1ä¸“å®¶å½¢å¼æ¥ç®¡ç†ç›´è§‰ï¼Œæ˜¾è‘—æé«˜äº†å‚æ•°æ•ˆç‡å’Œå¤šä»»åŠ¡å¾®è°ƒæ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.08985v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.08985.md)  |
| <span style='display: inline-block; width: 42px;'>04-12</span> | **Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length**<br><sub>æœºæ„: AI at Meta, University of Southern California, Carnegie Mellon University<br>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†MEGALODONï¼Œä¸€ä¸ªé«˜æ•ˆå¤„ç†æ— é™ä¸Šä¸‹æ–‡é•¿åº¦åºåˆ—çš„ç¥ç»ç½‘ç»œæ¶æ„ã€‚é€šè¿‡å¼•å…¥å¤šé¡¹åˆ›æ–°æŠ€æœ¯ï¼ŒMEGALODONåœ¨é•¿åºåˆ—æ¨¡å‹ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæ¯”Transformeræ›´é«˜çš„æ•ˆç‡å’Œæ•ˆèƒ½ï¼ŒåŒæ—¶åœ¨ä¸åŒè§„æ¨¡å’Œæ¨¡æ€çš„åŸºå‡†æµ‹è¯•ä¸­éƒ½å–å¾—äº†ç¨³å¥çš„æ”¹è¿›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.08801v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.08801.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/XuezheMax/megalodon)</div> |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **Decomposing Label Space, Format and Discrimination: Rethinking How LLMs Respond and Solve Tasks via In-Context Learning**<br><sub>æœºæ„: Nanyang Technological University<br>æœ¬æ–‡ç ”ç©¶äº†ICLåœ¨æå‡ä»»åŠ¡æ€§èƒ½æ–¹é¢çš„ç”Ÿæ•ˆæœºåˆ¶ï¼Œé€šè¿‡åˆ†è§£ICLçš„è´¡çŒ®å› ç´ ï¼Œå‘ç°ICLé€šè¿‡ç²¾ç»†è°ƒæ•´æ ‡ç­¾ç©ºé—´å’Œæ ¼å¼æ¥æ˜¾è‘—æå‡æ€§èƒ½ï¼ŒåŒæ—¶å¼ºè°ƒäº†é€‰æ‹©åˆé€‚æ¼”ç¤ºç¤ºä¾‹çš„é‡è¦æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07546v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07546.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **ChatGPT Can Predict the Future when it Tells Stories Set in the Future About the Past**<br><sub>æœºæ„: Baylor University<br>æœ¬ç ”ç©¶é€šè¿‡åˆ†æChatGPT-3.5å’ŒChatGPT-4çš„é¢„æµ‹èƒ½åŠ›ï¼Œæ­ç¤ºäº†LLMsåœ¨æ¨ç†æ–¹é¢çš„æ–°æ½œåŠ›ã€‚ç ”ç©¶è¯æ˜äº†â€œæœªæ¥å™äº‹â€æç¤ºèƒ½å¤Ÿæ˜¾è‘—æå‡é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œä¸ºLLMsåœ¨åˆ†æç¯å¢ƒä¸­çš„æ½œåœ¨åº”ç”¨æä¾›äº†æœ‰ç›Šè§è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07396v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07396.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **Rho-1: Not All Tokens Are What You Need**<br><sub>æœºæ„: Xiamen University, Tsinghua University, Microsoft<br>æœ¬æ–‡æå‡ºäº†RHO-1ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨é€‰æ‹©æ€§è¯­è¨€å»ºæ¨¡ï¼ˆSLMï¼‰çš„æ–°å‹è¯­è¨€æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨é¢„è®­ç»ƒä¸­ä¸“æ³¨äºå¯¹æœ‰ç”¨çš„ä»¤ç‰Œè¿›è¡Œè®­ç»ƒï¼Œè¿™ç§æ–¹æ³•åœ¨æ•°å­¦é¢†åŸŸçš„è¿ç»­é¢„è®­ç»ƒä¸­æ˜¾ç¤ºå‡ºå“è¶Šæ€§èƒ½ï¼Œèƒ½å¤Ÿæ›´å¿«åœ°è¾¾åˆ°åŸºçº¿æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨å°‘é‡ä»¤ç‰Œçš„æƒ…å†µä¸‹è¾¾åˆ°æœ€æ–°çš„çŠ¶æ€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07965v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07965.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments**<br><sub>æœºæ„: The University of Hong Kong, CMU, Salesforce Research<br>OSWORLDæä¾›äº†ä¸€ä¸ªæ–°çš„è¯„ä¼°ç¯å¢ƒï¼Œè§£å†³äº†ç°æœ‰åŸºå‡†æµ‹è¯•çš„å±€é™æ€§ï¼Œä¸ºå¼€å‘èƒ½åœ¨çœŸå®è®¡ç®—æœºç¯å¢ƒä¸­å®Œæˆå¼€æ”¾å¼ä»»åŠ¡çš„å¤šæ¨¡æ€ä»£ç†æä¾›äº†åŸºç¡€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07972v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07972.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback**<br><sub>æœºæ„: University of Central Florida, ByteDance Inc<br>ControlNet++é€šè¿‡ä¼˜åŒ–ç”Ÿæˆå›¾åƒä¸æ¡ä»¶æ§åˆ¶ä¹‹é—´çš„åƒç´ çº§ä¸€è‡´æ€§ï¼Œå¹¶é€šè¿‡é«˜æ•ˆçš„å¥–åŠ±å¾®è°ƒç­–ç•¥å‡å°‘äº†ä¸å›¾åƒé‡‡æ ·ç›¸å…³çš„æ—¶é—´å’Œå†…å­˜æˆæœ¬ï¼Œæ˜¾è‘—æ”¹å–„äº†åœ¨å¤šç§æ¡ä»¶æ§åˆ¶ä¸‹çš„å¯æ§æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07987v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07987.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **Interactive Prompt Debugging with Sequence Salience**<br><sub>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºåºåˆ—æ˜¾è‘—æ€§ï¼ˆSequence Salienceï¼‰çš„ç³»ç»Ÿï¼Œå®ƒæ‰©å±•äº†ç°æœ‰çš„è¾“å…¥æ˜¾è‘—æ€§ï¼ˆISï¼‰æ–¹æ³•ï¼Œä»¥æ”¯æŒå¤æ‚çš„LLMæç¤ºè°ƒè¯•ã€‚è¯¥å·¥å…·æä¾›å®æ—¶äº¤äº’å¼è°ƒè¯•ï¼Œå¹¶é™ä½äº†å®è·µè€…çš„è®¤çŸ¥è´Ÿè·ï¼Œæ”¯æŒæ ¹æ®æ˜¾è‘—æ€§ç»“æœå¿«é€Ÿè¿­ä»£æç¤ºï¼Œä¸å¼€å‘è€…çš„æ€ç»´æ¨¡å‹æ›´åŠ å¯¹é½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07498v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07498.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention**<br><sub>æœºæ„: Google<br>è¯¥ç ”ç©¶æå‡ºä¸€ç§å…¨æ–°çš„æ³¨æ„åŠ›æœºåˆ¶Infini-attentionï¼Œå®ƒé€šè¿‡å°†å‹ç¼©è®°å¿†ä¸æ ‡å‡†çš„ç‚¹ç§¯æ³¨æ„åŠ›ç›¸ç»“åˆï¼Œå¹¶åœ¨è®¾è®¡ä¸Šæ”¯æŒæ’æ‹”å¼çš„æŒç»­é¢„è®­ç»ƒå’Œé•¿ä¸Šä¸‹æ–‡è°ƒæ•´ï¼Œä½¿å¾—LLMsèƒ½ä»¥æœ‰ç•Œçš„å†…å­˜å’Œè®¡ç®—èµ„æºå¤„ç†æ— é™é•¿çš„ä¸Šä¸‹æ–‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07143v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07143.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **"We Need Structured Output": Towards User-centered Constraints on Large Language Model Output**<br><sub>æœºæ„: Google Research<br>æœ¬è®ºæ–‡æ¢ç´¢å¦‚ä½•ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¾“å‡ºå®ç°ç”¨æˆ·ä¸­å¿ƒçš„çº¦æŸï¼Œé€šè¿‡è°ƒæŸ¥è¡Œä¸šä¸“ä¸šäººå£«æ¥äº†è§£ä¸åŒåœºæ™¯å’Œéœ€æ±‚ã€‚é‡ç‚¹æ˜¯æé«˜å¼€å‘è€…åœ¨å¼€å‘ã€æµ‹è¯•å’Œæ•´åˆLLMè¿‡ç¨‹ä¸­çš„æ•ˆç‡ï¼Œå¹¶é€šè¿‡æ»¡è¶³ç‰¹å®šçš„è¾“å‡ºæ ¼å¼å’Œç”¨æˆ·ç•Œé¢è¦æ±‚æ¥å¢å¼ºæœ€ç»ˆç”¨æˆ·çš„ä½“éªŒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07362v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07362.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **Superposition Prompting: Improving and Accelerating Retrieval-Augmented Generation**<br><sub>æœºæ„: Apple, Cupertino, CA, USA<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æç¤ºæ–¹æ³•â€”â€”â€œè¶…çº§å åŠ æç¤ºâ€ï¼Œç”¨äºå¤„ç†å¤§å‹è¯­è¨€æ¨¡å‹å¤„ç†é•¿æ–‡æœ¬æ—¶é‡åˆ°çš„é—®é¢˜ï¼Œå¹¶åœ¨æ²¡æœ‰é¢å¤–è®­ç»ƒæˆ–å¾®è°ƒçš„æƒ…å†µä¸‹æ˜¾è‘—æé«˜äº†æ—¶é—´æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚è¿™ä¸€æ–¹æ³•åœ¨ä¼—å¤šé¢„è®­ç»ƒæ¨¡å‹ä¸Šå¾—åˆ°éªŒè¯ï¼Œå¹¶ä¸”ä½œè€…è®¡åˆ’å‘å¸ƒä¸€ä¸ªå¼€æºä»£ç å®ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06910v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.0691.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **Transferable and Efficient Non-Factual Content Detection via Probe Training with Offline Consistency Checking**<br><sub>æœºæ„: Renmin University of China, Tsinghua University<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§é€šè¿‡ç¦»çº¿è‡ªæˆ‘ä¸€è‡´æ€§æ£€æŸ¥è®­ç»ƒæ¢æµ‹æ¨¡å‹çš„æ–°æ–¹æ³•PINOSï¼Œæœ‰æ•ˆåœ°è§£å†³äº†ç°æœ‰çœŸå®æ€§æ£€æµ‹æ–¹æ³•çš„é™åˆ¶ã€‚PINOSæé«˜äº†è¿‡ç¨‹çš„è½¬ç§»èƒ½åŠ›å’Œæ•ˆç‡ï¼Œå¹¶ä¸”åœ¨çœŸå®æ€§æ£€æµ‹å’Œé—®ç­”åŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†è¶…è¶Šç°æœ‰æ–¹æ³•çš„ç»“æœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06742v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.06742.md)  |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **RULER: What's the Real Context Size of Your Long-Context Language Models?**<br><sub>æœºæ„: NVIDIA  <br>æœ¬è®ºæ–‡ä¸ºé•¿ä¸Šä¸‹æ–‡LMsæå‡ºäº†æ–°çš„è¯„ä¼°å·¥å…·RULERï¼Œå¹¶å¼€æºï¼Œç”¨äºæµ‹è¯•LMsåœ¨å¤æ‚ä»»åŠ¡å’Œé•¿ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ä¸Šçš„è¡¨ç°ï¼Œå¹¶åœ¨å„ç§æ¨¡å‹å’Œä»»åŠ¡å¤æ‚åº¦ä¸Šè¿›è¡Œäº†åˆ†æï¼Œæ¨åŠ¨äº†é•¿ä¸Šä¸‹æ–‡LMsçš„æœªæ¥ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06654v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.06654.md)  |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **Privacy Preserving Prompt Engineering: A Survey**<br><sub>æœºæ„: University of Arkansas<br>è¿™ç¯‡è°ƒç ”è®ºæ–‡ä¸ºäº†åœ¨ä½¿ç”¨LLMsè¿›è¡ŒICLå’Œä¸€èˆ¬æç¤ºçš„è¿‡ç¨‹ä¸­ä¿æŠ¤éšç§ï¼Œæä¾›äº†ä¸€ä¸ªå…³äºåœ¨è¿™ä¸€èŒƒç•´ä¸‹çš„éšç§ä¿æŠ¤æ–¹æ³•çš„ç³»ç»Ÿæ€§æ¦‚è¿°ï¼Œæœ‰åˆ©äºæ¨åŠ¨ç¤¾åŒºåœ¨éšç§ä¿æŠ¤æ–¹é¢çš„è¿›ä¸€æ­¥ç ”ç©¶å’Œæ¢ç´¢ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06001v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.06001.md)  |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **Event-enhanced Retrieval in Real-time Search**<br><sub>æœºæ„: Tencent Search, Platform and Content Group<br>EERæ˜¯ä¸€ç§æ–°å‹æ–¹æ³•ï¼Œé’ˆå¯¹å®æ—¶æœç´¢ä¸­çš„â€œè¯­ä¹‰æ¼‚ç§»â€é—®é¢˜ï¼Œé€šè¿‡æ”¹è¿›EBRæ¨¡å‹å’ŒåŠ å…¥å¯¹æ¯”å­¦ä¹ åŠäº‹ä»¶ä¸‰å…ƒç»„ç”Ÿæˆä»»åŠ¡æå‡æ£€ç´¢æ€§èƒ½ã€‚è¯¥æ–¹æ³•é€šè¿‡å®éªŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œå¹¶å¯èƒ½ä¸ºä¿¡æ¯æ£€ç´¢é¢†åŸŸæä¾›æ–°çš„è§†è§’ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05989v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05989.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/open-event-hub/Event-enhanced_Retrieval)</div> |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **THOUGHTSCULPT: Reasoning with Intermediate Revision and Search**<br><sub>æœºæ„: UC Berkeley<br>THOUGHTSCULPTä½œä¸ºä¸€ä¸ªåŸºäºå›¾çš„æ¡†æ¶ï¼Œé€šè¿‡å†…åµŒçš„è‡ªæˆ‘ä¿®æ­£æœºåˆ¶ï¼Œèƒ½å¤Ÿè®©LLMsåœ¨ç”Ÿæˆæ–°çš„æ€ç»´èŠ‚ç‚¹çš„åŒæ—¶è¿­ä»£åœ°æ”¹è¿›ä¹‹å‰çš„è¾“å‡ºï¼Œç‰¹åˆ«åœ¨éœ€è¦æŒç»­ä¿®æ­£å’Œä¿®æ”¹çš„ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05966v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05966.md)  |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **Evaluating Interventional Reasoning Capabilities of Large Language Models**<br><sub>æœºæ„: UniversitÃ© de MontrÃ©al, Google DeepMind, ServiceNow Research<br>æœ¬æ–‡å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å› æœæ¨ç†èƒ½åŠ›è¿›è¡Œäº†è¯„ä¼°ã€‚é€šè¿‡æå‡ºå¹²é¢„æ•ˆæœé¢„æµ‹ï¼Œå®ƒä¸»è¦æµ‹è¯•LLMsåœ¨å¹²é¢„å®éªŒåå¦‚ä½•æ›´æ–°è‡ªå·±å¯¹äº‹å®çš„ç†è§£ã€‚ç»“æœæ˜¾ç¤ºGPT-4åœ¨æŸäº›æ¡ä»¶ä¸‹èƒ½å¤Ÿå‡†ç¡®é¢„æµ‹å¹²é¢„æ•ˆæœï¼Œä½†æç¤ºè®¾è®¡çš„å¾®å°å˜åŒ–ä¼šæ˜¾è‘—å½±å“å…¶è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05545v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05545.md)  |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **Know When To Stop: A Study of Semantic Drift in Text Generation**<br><sub>æœºæ„: FAIR, Meta, Anthropic<br>æœ¬æ–‡ä¸ºç†è§£å’Œæµ‹é‡è¯­è¨€æ¨¡å‹åœ¨é•¿æ–‡æœ¬ç”Ÿæˆä¸­çš„è¯­ä¹‰æ¼‚ç§»ç°è±¡æä¾›äº†å·¥å…·ã€‚é€šè¿‡æ—©åœå’Œé‡é‡‡æ ·-é‡æ–°æ’åºç­‰æ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†äº‹å®å‡†ç¡®æ€§ï¼Œå¹¶ä¸ºå¦‚ä½•å¹³è¡¡ä¿¡æ¯é‡ä¸äº‹å®å‡†ç¡®æ€§æä¾›äº†å¯èƒ½çš„è§£å†³ç­–ç•¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05411v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05411.md)  |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding**<br><sub>æœºæ„: Alibaba Group, Zhejiang University<br>è¯¥è®ºæ–‡æˆåŠŸæå‡ºäº†LayoutLLMæ¨¡å‹åŠå…¶å¸ƒå±€æŒ‡å¯¼çš„è°ƒæ•´ç­–ç•¥ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹å¯¹æ–‡æ¡£å¸ƒå±€ä¿¡æ¯çš„ç†è§£å’Œåˆ©ç”¨ï¼Œå°¤å…¶åœ¨é›¶æ ·æœ¬æ–‡æ¡£ç†è§£ä»»åŠ¡ä¸Šè¡¨ç°å‡ºäº†å“è¶Šçš„æ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05225v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05225.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding)</div> |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **LLM-Augmented Retrieval: Enhancing Retrieval Models Through Language Models and Doc-Level Embedding**<br><sub>æœºæ„: Meta<br>è¯¥è®ºæ–‡æˆåŠŸæå‡ºå¹¶éªŒè¯äº†ä¸€ä¸ªå¢å¼ºå‹æ–‡æ¡£çº§åµŒå…¥çš„LLM-augmentedæ£€ç´¢æ¡†æ¶ï¼Œä¸ä»…é€šè¿‡ç”Ÿæˆåˆæˆçš„ç›¸å…³æŸ¥è¯¢å’Œæ ‡é¢˜å¢åŠ äº†æ–‡æ¡£åµŒå…¥çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè¿˜æ”¹è¿›äº†æ£€ç´¢æ¨¡å‹è®­ç»ƒçš„å…³é”®æ­¥éª¤ï¼Œä»è€Œæå‡æ£€ç´¢æ¨¡å‹çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05825v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05825.md)  |
| <span style='display: inline-block; width: 42px;'>04-07</span> | **Radial Networks: Dynamic Layer Routing for High-Performance Large Language Models**<br><sub>æœºæ„: Cornell University<br>æœ¬è®ºæ–‡æå‡ºäº†å¾„å‘ç½‘ç»œï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹ç¥ç»ç½‘ç»œç»“æ„ï¼Œé€šè¿‡åŠ¨æ€å±‚ç¨€ç–æ€§å’Œä¸€ä¸ªç»è¿‡è®­ç»ƒçš„è·¯ç”±æ¨¡å—æ¥å®ç°ä»¤ç‰Œçº§çš„å±‚é—´è·¯ç”±ã€‚è¿™ä¸ä»…æé«˜äº†æ¨¡å‹çš„æ€§èƒ½ï¼Œè¿˜æ˜¾è‘—é™ä½äº†è®¡ç®—å’ŒæœåŠ¡æˆæœ¬ï¼Œä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›ä¸€æ­¥æ‰©å±•æä¾›äº†å¯èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.04900v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.049.md)  |
| <span style='display: inline-block; width: 42px;'>04-07</span> | **Prompting Large Language Models for Zero-shot Essay Scoring via Multi-trait Specialization**<br><sub>æœºæ„: Peking University<br>è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé›¶æ ·æœ¬çš„å¤§å‹è¯­è¨€æ¨¡å‹ä½œæ–‡è¯„åˆ†æ¡†æ¶ï¼ˆMTSï¼‰ï¼Œé€šè¿‡å¤šè½®å¯¹è¯æ¥ä¸ºä½œæ–‡çš„ä¸åŒå†™ä½œç‰¹è´¨æ‰“åˆ†ï¼Œå¹¶é‡‡ç”¨æœ€å°-æœ€å¤§ç¼©æ”¾å’Œå¼‚å¸¸å€¼æˆªæ–­æœºåˆ¶æ¥å¾—åˆ°æœ€ç»ˆå¾—åˆ†ã€‚MTSåœ¨å‡†ç¡®åº¦ä¸Šæ˜¾è‘—ä¼˜äºç›´æ¥æç¤ºè¯„åˆ†æ–¹æ³•ï¼Œå¹¶åœ¨å°å‹åŒ–éƒ¨ç½²ä¸­ä¼˜äºChatGPTï¼Œæä¾›äº†ç›‘ç£å­¦ä¹ ä¹‹å¤–çš„é›¶æ ·æœ¬ä½œæ–‡è¯„åˆ†æ–¹æ¡ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.04941v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.04941.md)  |
| <span style='display: inline-block; width: 42px;'>04-04</span> | **Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences**<br><sub>æœºæ„: Microsoft Research<br>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†DNOâ€”â€”ä¸€ç§èƒ½å¤Ÿå°†å¯¹æ¯”å­¦ä¹ çš„ç®€æ´æ€§ä¸ä»ä¼˜åŒ–ä¸€èˆ¬æ€§åå¥½è€Œæ¥çš„ç†è®ºæ™®é€‚æ€§ç›¸ç»“åˆçš„ç®—æ³•ã€‚DNOåœ¨åè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹æ–¹é¢æ˜¾è‘—æå‡æ€§èƒ½ï¼Œå®ƒçš„æˆåŠŸå®è¯äº†é€šè¿‡ä¼˜åŒ–ä¸€èˆ¬åå¥½æ¥æŒ‡å¯¼æ¨¡å‹å­¦ä¹ ä¸äººç±»ä»·å€¼è§‚ä¿æŒä¸€è‡´æ˜¯å¯èƒ½çš„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.03715v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.03715.md)  |
| <span style='display: inline-block; width: 42px;'>04-04</span> | **ReFT: Representation Finetuning for Language Models**<br><sub>æœºæ„: Stanford University, Pr(Ai)2R Group<br>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„è¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•LoReFTï¼Œå®ƒåœ¨èµ„æºæ•ˆç‡å’Œæ¨¡å‹æ§åˆ¶èƒ½åŠ›æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰çš„å‚æ•°æœ‰æ•ˆè°ƒæ•´ï¼ˆPEFTsï¼‰æ–¹æ³•ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªNLPé¢†åŸŸçš„ä»»åŠ¡ä¸Šå®ç°äº†æ–°çš„æœ€ä½³æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒå°‘çš„å‚æ•°éœ€æ±‚å’Œè¾ƒé«˜çš„å¯è§£é‡Šæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.03592v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.03592.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/stanfordnlp/pyreft)</div> |
| <span style='display: inline-block; width: 42px;'>04-04</span> | **AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.03648v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.03648.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/THUDM/AutoWebGLM)</div> |
| <span style='display: inline-block; width: 42px;'>04-03</span> | **PromptRPA: Generating Robotic Process Automation on Smartphones from Textual Prompts**<br><sub>æœºæ„: Shanghai Jiao Tong University, CMU<br>æ–‡ç« ä»‹ç»äº†PromptRPAç³»ç»Ÿï¼Œè¿™æ˜¯ä¸€ä¸ªè§£å†³RPAåœ¨ç§»åŠ¨è®¾å¤‡ä¸Šåº”ç”¨å—é™çš„æœ‰æ•ˆæ–¹æ¡ˆã€‚é€šè¿‡åˆ©ç”¨å¤šä»£ç†æ¡†æ¶å’Œåœ¨çº¿æ•™ç¨‹ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿè§£é‡Šå„ç§æ–‡æœ¬æç¤ºï¼Œè§£å†³å¤§èŒƒå›´çš„RPAä»»åŠ¡ã€‚æ€§èƒ½è¯„ä¼°æ˜¾ç¤ºæˆåŠŸç‡æ˜¾è‘—æé«˜ï¼Œè¯æ˜äº†æ–‡æœ¬é©±åŠ¨æ§åˆ¶åœ¨RPAé¢†åŸŸçš„å¯è¡Œæ€§ï¼Œå¹¶å¼€è¾Ÿäº†åŠŸèƒ½å¢å¼ºå’Œé€‚ç”¨æ€§æ‰©å±•çš„æ–°æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02475v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.02475.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Long-context LLMs Struggle with Long In-context Learning**<br><sub>æœºæ„: University of Waterloo, Carnegie Mellon University<br>è¿™é¡¹ç ”ç©¶ä¸ºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹å¤„ç†é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡çš„èƒ½åŠ›æä¾›äº†ä¸€ä¸ªæ–°çš„åŸºå‡†â€”â€”LongICLBenchï¼Œå¹¶æ˜¾ç¤ºäº†éšç€ä»»åŠ¡éš¾åº¦å¢åŠ ï¼ŒLLMsçš„æ€§èƒ½æ™®éä¸‹é™ï¼Œå¹¶ä¸”æ¨¡å‹çš„é•¿ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›å—åˆ°æç¤ºä¸­æ ‡ç­¾ä½ç½®åˆ†å¸ƒçš„å½±å“ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02060v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.0206.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Advancing LLM Reasoning Generalists with Preference Trees**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02078v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.02078.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models**<br><sub>æœºæ„: Microsoft<br>è®ºæ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¦‚ä½•è¾…åŠ©è®¾è®¡è‡ªé€‚åº”æ¯”ç‰¹ç‡ï¼ˆABRï¼‰ç®—æ³•ï¼Œé€šè¿‡ç”Ÿæˆå¤šæ ·åŒ–çš„å€™é€‰ç®—æ³•ï¼Œå¹¶è¿ç”¨æ—©åœæœºåˆ¶åœ¨ç½‘ç»œæ¨¡æ‹Ÿå™¨ä¸­è¿›è¡Œæµ‹è¯•ï¼Œä»è€Œæœ‰æ•ˆåœ°ç­›é€‰å‡ºæœ€æœ‰æ•ˆçš„ç®—æ³•è®¾è®¡ã€‚è¯„ä¼°æ˜¾ç¤ºåœ¨ç‰¹å®šç½‘ç»œåœºæ™¯ä¸­ï¼Œåˆ©ç”¨LLMså¯ä»¥æ˜¾è‘—æé«˜ABRç®—æ³•çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01617v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01617.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Long-context LLMs Struggle with Long In-context Learning**<br><sub>æœºæ„: University of Waterloo, Carnegie Mellon University<br>è¿™ç¯‡æ–‡ç« æå‡ºäº†ä¸€ä¸ªæ–°çš„è¯„ä¼°åŸºå‡†ï¼ŒLongICLBenchï¼Œç”¨äºè¯„ä¼°LLMsåœ¨å¤„ç†é•¿è¾“å…¥ä»»åŠ¡æ—¶çš„æ€§èƒ½ï¼Œä»¥åŠLLMså¯¹è¾“å…¥åºåˆ—ä¸­å®ä¾‹ä½ç½®çš„æ•æ„Ÿæ€§ã€‚è¿™ä¸€å·¥ä½œæœ‰åŠ©äºæ›´å¥½åœ°ç†è§£å’Œæ”¹è¿›å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é•¿æ–‡æœ¬å¤„ç†æ–¹é¢çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02060v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.0206.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **CMAT: A Multi-Agent Collaboration Tuning Framework for Enhancing Small Language Models**<br><sub>æœºæ„: East China Jiaotong University, Guangdong University of Technology, University of Toronto<br>è¯¥è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®æ˜¯æå‡ºäº†CMATæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§åˆ›æ–°æ–¹æ³•ï¼Œå¯å®ç°å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå†…éƒ¨çš„åŠ¨æ€ã€å®æ—¶è®°å¿†æ›´æ–°ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§æ–°å‹çš„è§’è‰²æ‰®æ¼”æœºåˆ¶ï¼Œç”¨äºç²¾å‡†çš„ä»»åŠ¡åˆ†é…å’Œæå‡ä»£ç†é—´çš„é€šä¿¡ï¼Œä»¥æ­¤æ˜¾è‘—æé«˜æ•´ä½“æ€§èƒ½å’Œåˆä½œæ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01663v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01663.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Octopus v2: On-device language model for super agent**<br><sub>æœºæ„: Stanford University<br>è¿™ç¯‡è®ºæ–‡è§£å†³äº†è¾¹ç¼˜è®¾å¤‡ä¸ŠLLMçš„éƒ¨ç½²å’ŒåŠŸèƒ½è°ƒç”¨æ•ˆç‡é—®é¢˜ï¼Œé€šè¿‡å¼•å…¥ç‰¹æ®Šçš„è®­ç»ƒæ–¹æ³•å’Œå‡å°‘æ¨ç†æ—¶éœ€å¤„ç†çš„ä¸Šä¸‹æ–‡é‡ï¼Œæ˜¾è‘—æé«˜äº†åœ¨è®¾å¤‡ä¸Šè¿›è¡Œå‡½æ•°è°ƒç”¨çš„å‡†ç¡®ç‡å’Œé™ä½äº†å»¶è¿Ÿï¼Œå®éªŒç»“æœè¡¨æ˜å…¶å¯¹æå‡å‡½æ•°è°ƒç”¨ä»»åŠ¡çš„æ€§èƒ½å…·æœ‰æ˜¾è‘—å½±å“ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01744v3)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01744.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **LLM-RadJudge: Achieving Radiologist-Level Evaluation for X-Ray Report Generation**<br><sub>æœºæ„: Microsoft Research Asia<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ”¾å°„å­¦æŠ¥å‘Šè¯„ä»·æ–°æ¡†æ¶â€”â€”LLM-RadJudgeï¼Œèƒ½å¤Ÿæœ‰æ•ˆæé«˜æ”¾å°„å­¦æŠ¥å‘Šè¯„ä»·çš„ä¸´åºŠç›¸å…³æ€§å’Œä¸€è‡´æ€§ã€‚å¹¶é€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯å®ç°äº†å°å‹æ¨¡å‹çš„å¼€å‘ï¼Œæ—¢é™ä½äº†è¯„ä»·æˆæœ¬ä¹Ÿæé«˜äº†å¯è®¿é—®æ€§ï¼Œä¸ºæ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆç ”ç©¶å’Œå®é™…åº”ç”¨æä¾›äº†æœ‰åŠ›çš„æ”¯æ’‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.00998v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.00998.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **Prompt-prompted Mixture of Experts for Efficient LLM Generation**<br><sub>æœºæ„: CMU<br>GRIFFINæ˜¯ä¸€ä¸ªä¸éœ€è¦è®­ç»ƒçš„MoEç³»ç»Ÿï¼Œåˆ©ç”¨LLMså‰é¦ˆå—å†…çš„flockingç°è±¡åœ¨ä¸åŒçš„æ¿€æ´»å‡½æ•°ä¸‹æé«˜æ¨¡å‹æ•ˆç‡ï¼Œä¿æŒæ€§èƒ½çš„åŒæ—¶å‡å°‘äº†è®¡ç®—æˆæœ¬ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01365v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01365.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/hdong920/GRIFFIN)</div> |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **Efficiently Distilling LLMs for Edge Applications**<br><sub>æœºæ„: IBM Research  <br>æœ¬è®ºæ–‡æä¾›äº†ä¸€ç§æ–°çš„é’ˆå¯¹è¾¹ç¼˜è®¾å¤‡è¿›è¡ŒLLMsè’¸é¦çš„æ–¹æ³•ï¼Œå…è®¸LPFTåŒæ—¶æ˜¾è‘—å‡å°‘æ¨¡å‹å°ºå¯¸å’Œè®­ç»ƒæˆæœ¬ï¼Œå°¤å…¶æ˜¯ä¼˜åŒ–äº†è§£ç å™¨æ¨¡å‹çš„å‹ç¼©æŠµæŠ—å’Œè®­ç»ƒæ—¶é•¿ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01353v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01353.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **Mapping the Increasing Use of LLMs in Scientific Papers**<br><sub>æœºæ„: Stanford University, UC Santa Barbara<br>æœ¬æ–‡æ˜¯é¦–æ¬¡è¿›è¡Œçš„ï¼Œè·¨arXivã€bioRxivå’ŒNatureç»„åˆä¸Šå‘è¡¨çš„æ–‡ç« çš„ç³»ç»Ÿæ€§ã€å¤§è§„æ¨¡åˆ†æï¼Œé‡‡ç”¨çš„ç»Ÿè®¡ä¼°è®¡æ–¹æ³•å¯ä»¥åœ¨ç¾¤ä½“å±‚é¢ä¸Šæµ‹é‡LLMä¿®æ”¹å†…å®¹çš„æ™®åŠç¨‹åº¦ï¼Œä¸ºç†è§£LLMåœ¨ç§‘å­¦å†™ä½œä¸­çš„åº”ç”¨æä¾›äº†å®è´µçš„æ´å¯Ÿã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01268v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01268.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review**<br><sub>æœºæ„: University of Lyon, INSA Lyon, Infologic<br>æœ¬æ–‡æä¾›äº† AIOps é¢†åŸŸä¸­äº‹ä»¶ç®¡ç†çš„å…¨é¢æ–‡çŒ®å›é¡¾ï¼Œæ—¨åœ¨é€šè¿‡æä¾›ç»“æ„åŒ–çš„çŸ¥è¯†ã€ç¡®å®šçŸ¥è¯†ç©ºç™½å’Œä¸ºè¯¥é¢†åŸŸçš„æœªæ¥å‘å±•å¥ å®šåŸºç¡€ã€‚è®ºæ–‡å»ºç«‹äº† AIOps çš„ç»Ÿä¸€æœ¯è¯­å’Œåˆ†ç±»æ³•ï¼Œæ­ç¤ºäº†ç°æœ‰çš„æŒ‘æˆ˜ï¼Œå¹¶æä¾›äº†å…¬å¼€æ•°æ®é›†ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ–¹å‘å’ŒåŸºç¡€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01363v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01363.md)  |

---

### 03æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>03-28</span> | **sDPO: Don't Use Your Data All at Once**<br><sub>æ­¤è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„æ­¥éª¤åŒ–DPOï¼ˆsDPOï¼‰æ–¹æ³•ï¼Œé€šè¿‡åˆ†æ­¥éª¤åˆ©ç”¨åå¥½æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨å…ˆå‰æ­¥éª¤ä¸­çš„å¯¹é½æ¨¡å‹ä½œä¸ºå½“å‰æ­¥éª¤çš„å‚è€ƒæ¨¡å‹ï¼Œæœ‰æ•ˆæé«˜äº†æœ€ç»ˆæ¨¡å‹çš„æ€§èƒ½ä¸å¯¹é½åº¦ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.19270v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.1927.md)  |
| <span style='display: inline-block; width: 42px;'>03-28</span> | **Jamba: A Hybrid Transformer-Mamba Language Model**<br><sub>æœºæ„: AI21 Labs<br>Jambaæ˜¯åŸºäºæ··åˆTransformer-Mambaä½“ç³»ç»“æ„çš„æ–°å‹å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œçªç ´äº†å¤„ç†é•¿ä¸Šä¸‹æ–‡çš„é™åˆ¶ï¼Œå¹¶ä¸”é€šè¿‡åº”ç”¨ä¸“å®¶æ··åˆï¼ˆMoEï¼‰ç»„ä»¶æé«˜äº†æ¨¡å‹ååé‡ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒå°çš„å†…å­˜è¶³è¿¹ã€‚æ­¤æ¨¡å‹æ ‡å¿—ç€åœ¨å¤§å‹è¯­è¨€æ¨¡å‹é¢†åŸŸçš„ä¸€ä¸ªæ–°æ–¹å‘ï¼Œå¹¶å±•ç¤ºäº†é«˜æ•ˆè®­ç»ƒä¸å¼ºå¤§æ€§èƒ½ä¹‹é—´çš„å¯èƒ½å¹³è¡¡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.19887v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.19887.md)  |
| <span style='display: inline-block; width: 42px;'>03-27</span> | **BLADE: Enhancing Black-box Large Language Models with Small Domain-Specific Models**<br><sub>æœºæ„: DCST Tsinghua University, Beijing Institute of Technology, Huawei Cloud BU<br>è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ä¸ªæ–°æ¶æ„BLADEï¼Œå¯ä»¥é€šè¿‡å°å‹é¢†åŸŸç‰¹å®šæ¨¡å‹å¢å¼ºé»‘ç›’å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¹¶è§£å†³äº†å¤§å‹æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸåº”ç”¨ä¸­çš„çŸ¥è¯†ä¸è¶³é—®é¢˜ã€‚BLADEè¯æ˜äº†å…¶åœ¨æ€§èƒ½å’Œæˆæœ¬ä¸Šéƒ½æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.18365v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.18365.md)  |
| <span style='display: inline-block; width: 42px;'>03-27</span> | **Rejection Improves Reliability: Training LLMs to Refuse Unknown Questions Using RL from Knowledge Feedback**<br><sub>è¿™é¡¹å·¥ä½œé€šè¿‡æå‡ºRLKFæ¡†æ¶å¹¶å®šä¹‰äº†æ–°çš„æ¨¡å‹å¯é æ€§è¯„ä¼°æŒ‡æ ‡ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†LLMsçš„å¹»è§‰é—®é¢˜ï¼Œå¹¶æå‡äº†LLMsçš„è¯šå®åº¦å’Œå¯é æ€§ï¼Œæ˜¾ç¤ºå‡ºæ‰“é€ æ›´å€¼å¾—ä¿¡èµ–çš„AIç³»ç»Ÿçš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.18349v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.18349.md)  |
| <span style='display: inline-block; width: 42px;'>03-26</span> | **LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning**<br><sub>æœºæ„: The Hong Kong University of Science and Technology, University of Illinois Urbana-Champaign<br>è¿™ç¯‡è®ºæ–‡æå‡ºçš„LISAç­–ç•¥ï¼Œé€šè¿‡åˆ†å±‚æƒé‡é‡è¦æ€§é‡‡æ ·ï¼Œå®ç°äº†åœ¨ä¿æŒç±»ä¼¼äºLoRAçš„å†…å­˜æ•ˆç‡çš„åŒæ—¶ï¼Œæå‡äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„å¾®è°ƒæ•ˆç‡å’Œæ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.17919v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.17919.md)  |
| <span style='display: inline-block; width: 42px;'>03-26</span> | **COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning**<br><sub>æœºæ„: Shenzhen Institute of Advanced Technology, CAS; M-A-P; Institute of Automation, CAS<br>æœ¬æ–‡æå‡ºäº†COIG-CQIAæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹ä¸­æ–‡æŒ‡ä»¤è°ƒä¼˜çš„é«˜è´¨é‡æ•°æ®é›†ï¼Œèƒ½å¤Ÿä¿ƒè¿›ä¸äººç±»äº¤äº’çš„å¯¹é½ã€‚ç ”ç©¶å¼ºè°ƒäº†é«˜è´¨é‡æ•°æ®æºåœ¨æ¨¡å‹å¾®è°ƒä¸­çš„é‡è¦æ€§ï¼Œå¹¶é€šè¿‡å®éªŒå±•ç¤ºäº†æ•°æ®é›†åˆ›å»ºç­–ç•¥å’Œå¾®è°ƒæ–¹æ³•å¯¹æ¨¡å‹æ€§èƒ½çš„æ˜¾è‘—å½±å“ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.18058v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.18058.md)  |
| <span style='display: inline-block; width: 42px;'>03-26</span> | **The Unreasonable Ineffectiveness of the Deeper Layers**<br><sub>æœºæ„: Meta FAIR, UMD<br>æœ¬è®ºæ–‡é’ˆå¯¹æµè¡Œçš„å¼€æƒé‡é¢„è®­ç»ƒLLMsæå‡ºäº†ä¸€ç§ç®€å•çš„å±‚å‰ªæç­–ç•¥ï¼Œå¹¶å±•ç¤ºäº†åœ¨åˆ é™¤å¤§é‡å±‚åLLMså¯¹æ€§èƒ½å½±å“è¾ƒå°çš„å®è¯ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.17887v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.17887.md)  |
| <span style='display: inline-block; width: 42px;'>03-25</span> | **AIOS: LLM Agent Operating System**<br><sub>æœºæ„: Rutgers University  <br>AIOSä½œä¸ºä¸€ä¸ªLLMä»£ç†æ“ä½œç³»ç»Ÿï¼Œé€šè¿‡è®¾è®¡ç‰¹å®šçš„å†…æ ¸å’Œæ¨¡å—ï¼Œå…‹æœäº†ä¹‹å‰èµ„æºè°ƒåº¦å’Œä¸Šä¸‹æ–‡ç®¡ç†ç­‰é¢†åŸŸçš„æŒ‘æˆ˜ï¼Œä¸ºLLMä»£ç†çš„æ€§èƒ½å’Œæ•ˆç‡æä¾›äº†æ”¹è¿›ï¼Œä¸ºAIOSç”Ÿæ€ç³»ç»Ÿçš„æœªæ¥å‘å±•å’Œéƒ¨ç½²é“ºå¹³äº†é“è·¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.16971v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.16971.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/agiresearch/AIOS)</div> |
| <span style='display: inline-block; width: 42px;'>03-22</span> | **Can large language models explore in-context?**<br><sub>æœºæ„: Microsoft Research, Carnegie Mellon University<br>è¿™ç¯‡è®ºæ–‡è°ƒæŸ¥äº†å½“ä»£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½å¦åœ¨ä¸Šä¸‹æ–‡ä¸­ä»äº‹æ¢ç´¢çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨æ²¡æœ‰è®­ç»ƒå¹²é¢„çš„æƒ…å†µä¸‹ã€‚ç»è¿‡ä¸€ç³»åˆ—å®éªŒï¼Œä½œè€…å‘ç°åªæœ‰åœ¨ç‰¹å®šçš„é…ç½®ä¸‹LLMsæ‰èƒ½ç¨³å¥åœ°è¿›è¡Œæ¢ç´¢ã€‚ç ”ç©¶è¡¨æ˜ï¼Œæ²¡æœ‰é€‚å½“çš„æç¤ºè®¾è®¡ï¼Œå³ä½¿æ˜¯æœ€å…ˆè¿›çš„LLMsä¹Ÿå¯èƒ½æ— æ³•åœ¨æ›´å¤æ‚çš„ç¯å¢ƒä¸­è¿›è¡Œæ¢ç´¢ï¼Œè€Œåœ¨è¿™äº›ç¯å¢ƒä¸­å¤–éƒ¨æ€»ç»“å†å²å¯èƒ½æ˜¯ä¸€ä¸ªéå¹³å‡¡çš„ç®—æ³•è®¾è®¡é—®é¢˜ã€‚è¿™é¡¹å·¥ä½œæç¤ºäº†LLMså¯èƒ½éœ€è¦æœ‰é’ˆå¯¹æ€§çš„ç®—æ³•å¹²é¢„æ‰èƒ½åœ¨å¤æ‚ç¯å¢ƒä¸­æœ‰æ•ˆåœ°å·¥ä½œã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.15371v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.15371.md)  |
| <span style='display: inline-block; width: 42px;'>03-20</span> | **Chain-of-Interaction: Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts**<br><sub>æœºæ„: University of Memphis, San Francisco Veterans Affairs Health Care System, University of California San Francisco<br>æœ¬æ–‡é€šè¿‡å¼•å…¥äº’åŠ¨é“¾æç¤ºæ–¹æ³•ï¼Œæœ‰æ•ˆåœ°æå‡äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç†è§£ç²¾ç¥ç—…è¡Œä¸ºæ–¹é¢çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨åŠ¨æœºé¢è°ˆè¯­å¢ƒä¸‹çš„åº”ç”¨ã€‚é€šè¿‡ç»“æ„åŒ–çš„æç¤ºå’Œè¯„ä¼°æ–¹æ³•ï¼Œèƒ½å¤Ÿæ¨¡æ‹Ÿä¸“ä¸šå¿ƒç†æ²»ç–—äººå‘˜çš„æ€ç»´è¿‡ç¨‹ï¼Œå¯¹æ¨¡å‹è¿›è¡Œäº†æœ‰æ•ˆçš„åŸŸçŸ¥è¯†æ•™è‚²ï¼Œç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.13786v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.13786.md)  |
| <span style='display: inline-block; width: 42px;'>03-19</span> | **Towards Robots That Know When They Need Help: Affordance-Based Uncertainty for Large Language Model Planners**<br><sub>æœºæ„: University of Maryland  <br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•LAPï¼Œé€šè¿‡ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å’Œåœºæ™¯å¯ä»¥ä¾›æ€§æ¥å‡å°‘è§„åˆ’ä»»åŠ¡ä¸­çš„å¹»è§‰å¹¶å®ç°ä¸ç¡®å®šæ€§å¯¹é½ã€‚é€šè¿‡åœ¨æ¨¡æ‹Ÿå’Œç°å®ä¸–ç•Œæœºå™¨äººæ“ä½œä»»åŠ¡çš„å®éªŒä¸­è¡¨æ˜ï¼ŒLAPå¯ä»¥æ˜¾è‘—æé«˜æˆåŠŸç‡å¹¶å‡å°‘å¯¹äººç±»å¸®åŠ©çš„ä¾èµ–ï¼Œä»è€Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººé¢†åŸŸçš„è¿›æ­¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.13198v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.13198.md)  |
| <span style='display: inline-block; width: 42px;'>03-18</span> | **Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression**<br><sub>æœºæ„: University of Texas at Austin, Drexel University, MIT<br>æœ¬æ–‡é¦–æ¬¡å¯¹ç»è¿‡å‹ç¼©çš„LLMsåœ¨å¤šä¸ªä¿¡ä»»ç»´åº¦ä¸Šè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå¹¶æä¾›äº†å‹ç¼©æ—¶åŒæ—¶è€ƒè™‘æ•ˆç‡å’Œä¿¡ä»»åº¦çš„å®ç”¨å»ºè®®ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.15447v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.15447.md)  |
| <span style='display: inline-block; width: 42px;'>03-15</span> | **VideoAgent: Long-form Video Understanding with Large Language Model as Agent**<br><sub>æœºæ„: Stanford University<br>VideoAgenté€šè¿‡æ¨¡ä»¿äººç±»çš„è®¤çŸ¥è¿‡ç¨‹ï¼Œåœ¨é•¿è§†é¢‘ç†è§£æ–¹é¢è¿ˆå‡ºäº†é‡è¦çš„ä¸€æ­¥ï¼Œå¼ºè°ƒäº†åœ¨é•¿æ—¶é—´è·¨åº¦å†…å¯¹è§†è§‰ä¿¡æ¯è¿›è¡Œæ¨ç†çš„é‡è¦æ€§ã€‚æ­¤å·¥ä½œä¸ä»…ä¸ºé•¿è§†é¢‘ç†è§£è®¾ç«‹äº†æ–°çš„åŸºå‡†ï¼Œä¹Ÿä¸ºæœªæ¥è¯¥æ–¹å‘çš„ç ”ç©¶æä¾›äº†å¯ç¤ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.10517v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.10517.md)  |
| <span style='display: inline-block; width: 42px;'>03-15</span> | **Uni-SMART: Universal Science Multimodal Analysis and Research Transformer**<br><sub>æœºæ„: DP Technology, AI for Science Institute Beijing<br>Uni-SMART æ˜¯ä¸€æ¬¾åˆ›æ–°çš„æ¨¡å‹ï¼Œæ—¨åœ¨æ·±å…¥ç†è§£å¤šæ¨¡æ€ç§‘å­¦æ–‡çŒ®ï¼Œå®ƒåœ¨å¤šä¸ªé¢†åŸŸç›¸å¯¹äºå…¶ä»–é¡¶å°–æ–‡æœ¬ç„¦ç‚¹çš„ LLMs æ˜¾ç¤ºå‡ºäº†æ›´ä¼˜è¶Šçš„æ€§èƒ½ï¼Œå¹¶æœ‰æ½œåŠ›æ”¹å˜æˆ‘ä»¬ä¸ç§‘å­¦æ–‡çŒ®çš„äº’åŠ¨æ–¹å¼ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.10301v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.10301.md)  |
| <span style='display: inline-block; width: 42px;'>03-15</span> | **RAFT: Adapting Language Model to Domain Specific RAG**<br><sub>æœºæ„: UC Berkeley<br>æœ¬è®ºæ–‡æå‡ºçš„RAFTæ–¹æ³•é’ˆå¯¹è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸå†…ä»¥â€œå¼€å·â€æ¨¡å¼å›ç­”é—®é¢˜è¿›è¡Œäº†åˆ›æ–°ï¼Œå¼ºåŒ–äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œå¯¹å¹²æ‰°æ–‡æ¡£çš„æŠµæŠ—åŠ›ï¼ŒåŒæ—¶é€šè¿‡é“¾å¼æ¨ç†æ–¹å¼æ”¹è¿›äº†æ¨¡å‹ç”Ÿæˆè§£ç­”çš„å‡†ç¡®æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.10131v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.10131.md)  |
| <span style='display: inline-block; width: 42px;'>03-13</span> | **Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework**<br><sub>æœºæ„: ByteDance Research, University of Maryland College Park, Carnegie Mellon University<br>è¯¥è®ºæ–‡æˆåŠŸæå‡ºäº†ä¸€ä¸ªæ–°çš„å› æœå…³ç³»å¼•å¯¼çš„å»åè§æ¡†æ¶ï¼Œå¹¶é€šè¿‡å®è¯ç ”ç©¶éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œæ—¢å¯ä»¥æ•´åˆç°æœ‰çš„åŸºäºæç¤ºçš„å»åè§æ–¹æ³•ï¼Œä¹Ÿä¸ºè¯±å¯¼æ— åè§æ¨ç†æå‡ºäº†æ–°çš„é€”å¾„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.08743v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.08743.md)  |
| <span style='display: inline-block; width: 42px;'>03-13</span> | **Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments**<br><sub>æœºæ„: Nanjing University, Microsoft<br>Readiæ¡†æ¶æå‡ºäº†ä¸€ç§é«˜æ•ˆå¹¶çœŸå®åœ°åœ¨å¤§è§„æ¨¡ç»“æ„åŒ–ç¯å¢ƒä¸­è¿›è¡Œæ¨ç†çš„æ–¹æ³•ï¼Œå®ƒå……åˆ†å‘æŒ¥äº†LLMsçš„è§„åˆ’èƒ½åŠ›ï¼Œå¹¶é€šè¿‡åŠ¨æ€åé¦ˆä¼˜åŒ–æ¨ç†è·¯å¾„ï¼Œå®ç°äº†åœ¨å¤šè·³æ¨ç†ä»»åŠ¡ä¸­çš„æ˜¾è‘—æ”¹è¿›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.08593v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.08593.md)  |
| <span style='display: inline-block; width: 42px;'>03-13</span> | **Scaling Instructable Agents Across Many Simulated Worlds**<br><sub>æ­¤è®ºæ–‡æå‡ºçš„SIMAé¡¹ç›®æ—¨åœ¨åˆ›å»ºä¸€ä¸ªèƒ½å¤Ÿåœ¨å„ç§æ¨¡æ‹Ÿ3Dç¯å¢ƒä¸­æ ¹æ®ä»»æ„è¯­è¨€æŒ‡ä»¤è¿›è¡Œæ“ä½œçš„AIç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿçš„è®¾è®¡è‡´åŠ›äºè§£å†³åœ¨æ„ŸçŸ¥å’Œä½“åŒ–è¡ŒåŠ¨ä¸­å…·ä½“åŒ–è¯­è¨€çš„æŒ‘æˆ˜ï¼Œä»¥åŠåœ¨è®¸å¤šä¸åŒç¯å¢ƒä¸­å®ç°é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10179v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2404.10179.md)  |
| <span style='display: inline-block; width: 42px;'>03-12</span> | **Chronos: Learning the Language of Time Series**<br><sub>æœºæ„: Amazon Web Services, UC San Diego, University of Freiburg<br>Chronosä½œä¸ºä¸€ä¸ªé¢„è®­ç»ƒçš„æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹æ¡†æ¶ï¼Œåœ¨é›¶æ ·æœ¬å’Œæ ‡å‡†é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚å®ƒåˆ©ç”¨äº†æ•°æ®å¢å¼ºç­–ç•¥å’Œå…¬å…±æ•°æ®é›†çš„ä¼˜åŠ¿ï¼Œè¯å®äº†æ—¶é—´åºåˆ—é¢„æµ‹ä¸­è¯­è¨€æ¨¡å‹æ¶æ„é€šç”¨æ€§çš„æ½œåŠ›ï¼Œä¸ºå°†æ¥çš„æ—¶é—´åºåˆ—æ¨¡å‹æä¾›äº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.07815v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.07815.md)  |
| <span style='display: inline-block; width: 42px;'>03-11</span> | **RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback**<br><sub>æœºæ„: Zhejiang University, Southeast University, Massachusetts Institute of Technology<br>RA-ISFæ˜¯ä¸€ä¸ªåˆ›æ–°çš„æ£€ç´¢å¢å¼ºæ¡†æ¶ï¼Œé€šè¿‡è¿­ä»£é—®é¢˜åˆ†è§£å’Œä¸‰ä¸ªå­æ¨¡å—çš„è¿­ä»£å¤„ç†æ¥æé«˜LLMsçš„é—®é¢˜è§£å†³èƒ½åŠ›ï¼Œå¹¶æœ‰æ•ˆé™ä½ä¸ç›¸å…³æ–‡æœ¬çš„å¹²æ‰°ï¼Œæ˜¾è‘—æå‡çŸ¥è¯†æ£€ç´¢çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.06840v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.0684.md)  |
| <span style='display: inline-block; width: 42px;'>03-11</span> | **ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis**<br><sub>æœºæ„: Zhejiang University, Southeast University<br>è¯¥è®ºæ–‡é€šè¿‡æå‡ºä¸€ç§æ–°çš„æ¡†æ¶ERA-CoTï¼Œæœ‰æ•ˆå¼ºåŒ–äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚å®ä½“åœºæ™¯ä¸­çš„æ¨ç†å’Œé—®é¢˜å›ç­”èƒ½åŠ›ã€‚è¯¥æ–¹æ³•é€šè¿‡å¢å¼ºå¯¹å®ä½“å…³ç³»çš„ç†è§£ï¼Œå®ç°äº†æ˜¾è‘—æå‡æ¨¡å‹æ¨ç†å‡†ç¡®åº¦ï¼Œç‰¹åˆ«æ˜¯åœ¨CoTæ¨ç†è¿‡ç¨‹ä¸­ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.06932v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.06932.md)  |
| <span style='display: inline-block; width: 42px;'>03-11</span> | **Stealing Part of a Production Language Model**<br><sub>æœºæ„: Google DeepMind, ETH Zurich, University of Washington<br>æœ¬æ–‡æå‡ºäº†ä¸€é¡¹å¯¹ç”Ÿäº§è¯­è¨€æ¨¡å‹è¿›è¡Œæ¨¡å‹çªƒå–çš„æ–°æ”»å‡»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æå–Transformeræ¨¡å‹çš„æœ€åä¸€å±‚ï¼Œå¹¶èƒ½ç”¨äºè§£å¯†é»‘ç›’æ¨¡å‹çš„ç»†èŠ‚ä¿¡æ¯ã€å‚æ•°å’Œå°ºå¯¸ã€‚æ–‡ç« è¿˜è®¨è®ºäº†å¯èƒ½çš„é˜²å¾¡æªæ–½ï¼Œå¹¶æŒ‡å‡ºäº†ä¿®æ”¹APIä»¥é˜²æ­¢æœªæ¥æ­¤ç±»æ”»å‡»çš„å¿…è¦æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.06634v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.06634.md)  |
| <span style='display: inline-block; width: 42px;'>03-08</span> | **Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation**<br><sub>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†Adversarial Policy Optimization (AdvPO)ï¼Œå®ƒæ˜¯è§£å†³åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ä¸­å‡ºç°çš„å¥–åŠ±è¿‡ä¼˜åŒ–é—®é¢˜çš„æ–°æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸äººç±»åå¥½å¯¹é½çš„å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ã€‚AdvPOæœ‰æ•ˆåœ°åœ¨æ²¡æœ‰å¸¦æ¥é«˜é¢è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹ç¼“è§£äº†å¥–åŠ±è¿‡ä¼˜åŒ–ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.05171v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.05171.md)  |
| <span style='display: inline-block; width: 42px;'>03-08</span> | **Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering**<br><sub>æœºæ„: Gaoling School of Artificial Intelligence Renmin University of China, Nankai University, Beijing Academy of Artificial Intelligence<br>LLMQAæ˜¯ä¸€ä¸ªæ–°çš„é€šç”¨æ¡†æ¶æ¨¡å‹ï¼Œé€šè¿‡ç»“åˆæ£€ç´¢å’Œç”ŸæˆèŒƒå¼æœé›†æ›´é«˜è´¨é‡çš„è¯æ®ï¼Œå¹¶è®©LLMsåœ¨æ¡†æ¶ä¸­å‘æŒ¥å¤šé‡è§’è‰²ï¼Œæé«˜äº†å¼€æ”¾åŸŸé—®ç­”ç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½ï¼Œå®éªŒç»“æœä¹Ÿè¯æ˜äº†å…¶è¶…è¶Šç°æœ‰æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.05217v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.05217.md)  |
| <span style='display: inline-block; width: 42px;'>03-08</span> | **Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context**<br><sub>æœºæ„: Google<br>Gemini 1.5 Proåœ¨è®°å¿†ä¸æ¨ç†æµ·é‡é•¿ä¸Šä¸‹æ–‡ä¿¡æ¯çš„èƒ½åŠ›ä¸Šå–å¾—äº†æ˜¾è‘—çªç ´ï¼Œå°¤å…¶æ˜¯åœ¨è¶…é•¿æ–‡æœ¬ã€è§†é¢‘å’ŒéŸ³é¢‘å¤„ç†æ–¹é¢ã€‚è¯¥æ¨¡å‹ä¸ä»…åœ¨æ•ˆæœä¸Šä¼˜äºç°æœ‰æ¨¡å‹ï¼Œä¹Ÿåœ¨è®¡ç®—æ•ˆç‡ä¸Šæœ‰æ˜¾è‘—æé«˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.05530v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.0553.md)  |
| <span style='display: inline-block; width: 42px;'>03-07</span> | **Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference**<br><sub>æœºæ„: UC Berkeley, Stanford, UCSD<br>Chatbot Arenaæ˜¯ä¸€ä¸ªåŸºäºç”¨æˆ·åå¥½ï¼Œç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„å¼€æ”¾å¹³å°ã€‚å®ƒé€šè¿‡ä¼—åŒ…æ–¹å¼æ”¶é›†ç”¨æˆ·é—®é¢˜å¹¶è¿›è¡ŒåŒ¿ååŒ–çš„éšæœºåŒ–å¯¹å†³ï¼Œç”¨äºè¯„ä¼°LLMsçš„è¡¨ç°ï¼Œè§£å†³äº†ç°æœ‰é™æ€æ•°æ®é›†åŸºå‡†æµ‹è¯•çš„å±€é™æ€§ï¼Œå¹¶é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„ç»Ÿè®¡æ–¹æ³•ç¡®ä¿äº†è¯„ä¼°ç»“æœçš„å¯ä¿¡åº¦å’Œæ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.04132v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.04132.md)  |
| <span style='display: inline-block; width: 42px;'>03-07</span> | **Yi: Open Foundation Models by 01.AI**<br><sub>æœºæ„: 01.AI<br>è¯¥è®ºæ–‡æˆåŠŸåœ°æå‡ºäº†ä¸€ä¸ªåœ¨æ€§èƒ½å’Œæ•ˆç‡ä¸Šéƒ½å¯ä¸GPT-3.5ç›¸åª²ç¾çš„Yi-34Bæ¨¡å‹ï¼Œå¹¶è¯¦ç»†æè¿°äº†åœ¨å¤§å‹è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒåŠå…¶æŒ‡ä»¤å¾®è°ƒæ–¹é¢çš„åˆ›æ–°æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.04652v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.04652.md)  |
| <span style='display: inline-block; width: 42px;'>03-05</span> | **ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary**<br><sub>æœºæ„: Tsinghua University<br>ChatCiteç³»ç»Ÿæ˜¯ä¸ºäº†å…‹æœLLMåœ¨ç”Ÿæˆæ–‡çŒ®å›é¡¾æ—¶çš„æŒ‘æˆ˜è€Œè®¾è®¡çš„ï¼Œå®ƒé€šè¿‡ç‰¹å®šçš„æ¨¡å—ä½¿LLMä»£ç†å¯ä»¥æ›´æœ‰æ•ˆåœ°ç†è§£ã€æ±‡æ€»å’Œå¯¹æ¯”ä¸åŒçš„ç ”ç©¶å·¥ä½œï¼Œè¿›è€Œç”Ÿæˆæœ‰ç»„ç»‡ã€æœ‰æ¯”è¾ƒæ€§åˆ†æçš„æ–‡çŒ®å›é¡¾ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.02574v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.02574.md)  |
| <span style='display: inline-block; width: 42px;'>03-05</span> | **MathScale: Scaling Instruction Tuning for Mathematical Reasoning**<br><sub>æœºæ„: The Chinese University of Hong Kong Shenzhen, China; Microsoft Research Asia, Beijing, China; Shenzhen Research Institute of Big Data, Shenzhen, China<br>MathScaleæå‡ºäº†ä¸€ä¸ªå¯æ‰©å±•çš„æ–¹æ³•æ¥åˆ›å»ºé«˜è´¨é‡çš„æ•°å­¦æ¨ç†æ•°æ®ï¼Œé€šè¿‡æ„å»ºæ–°çš„è¯„ä¼°åŸºå‡†MWPBENCHå…¨é¢åœ°è¯„ä»·LLMsåœ¨æ•°å­¦æ¨ç†ä¸Šçš„èƒ½åŠ›ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹è§£å†³æ•°å­¦é—®é¢˜çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.02884v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.02884.md)  |
| <span style='display: inline-block; width: 42px;'>03-05</span> | **Design2Code: How Far Are We From Automating Front-End Engineering?**<br><sub>æœºæ„: Stanford University, Georgia Tech, Microsoft<br>æœ¬æ–‡é€šè¿‡å¯¹Design2Codeä»»åŠ¡çš„å½¢å¼åŒ–å’ŒåŸºå‡†æµ‹è¯•ï¼Œè¯„ä¼°äº†å½“å‰å¤šæ¨¡æ€LLMsåœ¨å°†è§†è§‰è®¾è®¡è½¬æ¢ä¸ºä»£ç çš„èƒ½åŠ›ï¼Œå¹¶å‘ç°GPT-4Vè¡¨ç°æœ€ä½³ï¼Œä¸ºè‡ªåŠ¨åŒ–å‰ç«¯å¼€å‘æä¾›äº†ä¸€ç§æ–°çš„èŒƒå¼ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.03163v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.03163.md)  |

---

### 02æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation**<br><sub>æœºæ„: Peking University<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºSEEDçš„é€‚åº”æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨é”™è¯¯é©±åŠ¨å­¦ä¹ æ¥ä½¿LLMsæ›´å°‘æ ·æœ¬åœ°é«˜æ•ˆå­¦ä¹ ï¼Œé’ˆå¯¹ä»£ç ç”Ÿæˆä»»åŠ¡å®ç°äº†æ›´ä½³çš„æ€§èƒ½å’Œæ³›åŒ–æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.00046v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2403.00046.md)  |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **Beyond Language Models: Byte Models are Digital World Simulators**<br><sub>æœºæ„: Microsoft Research Asia<br>è®ºæ–‡å±•ç°äº†bGPTåœ¨å¤„ç†æŒ‘æˆ˜æ€§çš„å­—èŠ‚çº§æ•°æ®æ¨¡æ‹Ÿä»»åŠ¡ä¸­çš„æ½œåŠ›ï¼Œç‰¹åˆ«å¼ºè°ƒäº†å…¶åœ¨è·¨æ¨¡æ€çŸ¥è¯†è½¬ç§»å’Œæ•°å­—ä¸–ç•Œæ¨¡æ‹Ÿæ–¹é¢çš„èƒ½åŠ›ã€‚è¿™æ­ç¤ºäº†å­—èŠ‚æ¨¡å‹åœ¨æ•°å­—åª’ä½“æ•°æ®å¤„ç†å’Œç†è§£ä¸Šçš„å¹¿æ³›é€‚ç”¨æ€§å’Œçµæ´»æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.19155v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.19155.md)  |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **StarCoder 2 and The Stack v2: The Next Generation**<br><sub>æœºæ„: ServiceNow, Hugging Face  <br>æœ¬è®ºæ–‡æå‡ºäº†The Stack v2å’ŒStarCoder2çš„å‘å±•è¿‡ç¨‹ï¼Œè¿™æ˜¯åŸºäºä»£ç å¤§è§„æ¨¡é¢„è®­ç»ƒå’ŒæŒ‡ä»¤å¾®è°ƒçš„ä¸€é¡¹å·¥ä½œã€‚ç ”ç©¶äººå‘˜é€šè¿‡æ•´åˆå¤šæ ·åŒ–æ•°æ®æºå’Œç»è¿‡ç²¾å¿ƒè®¾è®¡çš„è®­ç»ƒè¿‡ç¨‹ï¼Œæ˜¾è‘—æé«˜äº†ä»£ç LLMsçš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†ä½èµ„æºç¼–ç¨‹è¯­è¨€å’Œéœ€è¦ä»£ç æ¨ç†çš„ä»»åŠ¡ä¸Šã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.19173v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.19173.md)  |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **Resonance RoPE: Improving Context Length Generalization of Large Language Models**<br><sub>æœºæ„: 1DIRO UniversitÃ© de MontrÃ©al, Mila - Quebec AI Institute, Huawei Noahâ€™s Ark Lab<br>æœ¬è®ºæ–‡æå‡ºäº† Resonance Ropeï¼Œè¿™æ˜¯ä¸€ä¸ªæ”¹è¿›çš„æ¨¡å‹ï¼Œå®ƒåŸºäºå¯¹ RoPE ä½ç½®åµŒå…¥ç‰¹å¾æ³¢é•¿çš„åˆ†ææ¥æå‡æ¨¡å‹åœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶çš„æ€§èƒ½ã€‚å®ƒè¿˜å¼•å…¥äº† POSGEN åŸºå‡†æµ‹è¯•ï¼Œä»¥å¸®åŠ©ç ”ç©¶å’Œè¯„ä¼°ä½ç½®åµŒå…¥åœ¨é•¿æ–‡æœ¬ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.00071v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2403.00071.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits**<br><sub>æœºæ„: Microsoft, University of Chinese Academy of Sciences<br>è®ºæ–‡æå‡ºBitNet b1.58æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ä¸ª1.58æ¯”ç‰¹é‡åŒ–çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä¸ä¼ ç»Ÿçš„å®Œæ•´ç²¾åº¦LLMsåœ¨æ€§èƒ½ä¸Šå¯æ¯”ï¼Œè€Œä¸”æ›´é«˜æ•ˆã€æ›´èŠ‚çœèƒ½æºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17764v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17764.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions**<br><sub>æœºæ„: Alibaba Group  <br>EMO æ¡†æ¶é€šè¿‡ç›´æ¥çš„éŸ³é¢‘åˆ°è§†é¢‘åˆæˆæ–¹æ³•æé«˜äº†ç”Ÿæˆè§†é¢‘çš„çœŸå®æ„Ÿå’Œè¡¨ç°åŠ›ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œä¸ºè§†é¢‘åˆæˆé¢†åŸŸæä¾›äº†ä¸€ä¸ªé‡è¦çš„è¿›æ­¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17485v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17485.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method**<br><sub>æœºæ„: Google DeepMind<br>è¯¥è®ºæ–‡æä¾›äº†å¤§å‹è¯­è¨€æ¨¡å‹å¾®è°ƒé˜¶æ®µä¸åŒå› ç´ å¦‚æ•°æ®å¤§å°ã€æ¨¡å‹å¤§å°ä»¥åŠå¾®è°ƒæ–¹æ³•å¯¹æ¨¡å‹æ€§èƒ½å½±å“çš„æ·±å…¥æ´è§ï¼Œå®šä¹‰äº†ä¸€ç§æ–°çš„è¯„ä¼°æ¡†æ¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17193v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17193.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering**<br><sub>æœºæ„: Gaoling School of Artificial Intelligence Renmin University of China, School of Information Renmin University of China<br>è¯¥è®ºæ–‡æå‡ºäº†REARæ¡†æ¶ï¼Œé‡ç‚¹åœ¨äºé€šè¿‡ä¸ºLLMsåŠ å…¥æ–‡æ¡£ç›¸å…³æ€§è‡ªæˆ‘æ„è¯†æ¥å¢å¼ºå…¶åœ¨QAä»»åŠ¡ä¸­åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†çš„èƒ½åŠ›ï¼Œå¹¶è¯å®è¯¥æ¡†æ¶æœ‰æ•ˆåœ°è¶…è¶Šäº†å‰è¿°æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17497v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17497.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RUCAIBox/REAR)</div> |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization**<br><sub>æœºæ„: Zhejiang University, Institute of Software Chinese Academy of Sciences, Nanjing University of Posts and Telecommunications<br>Agent-Proæ˜¯ä¸€ä¸ªæ–°å‹çš„åŸºäºLLMçš„æ™ºèƒ½ä»£ç†ï¼Œèƒ½å¤Ÿé€šè¿‡æ”¿ç­–çº§åæ€å’Œä¼˜åŒ–åœ¨äº¤äº’ç¯å¢ƒä¸­å­¦ä¹ å’Œå‘å±•ç­–ç•¥ï¼Œè§£å†³äº†ç°æœ‰å·¥ä½œæ— æ³•é€šè¿‡äº¤äº’å­¦ä¹ å’Œé€‚åº”çš„é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17574v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17574.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models**<br><sub>æœºæ„: OpenAI<br>æœ¬æ–‡æ˜¯ä¸€ç¯‡å¯¹Soraâ€”â€”ä¸€ä¸ªå¤§å‹è§†è§‰æ¨¡å‹çš„ç»¼è¿°ã€‚è®ºæ–‡è®¨è®ºäº†Soraçš„æŠ€æœ¯ç‰¹å¾ã€åˆ›æ–°ç‚¹ã€ä»¥åŠå½“å‰åº”ç”¨é¢†åŸŸçš„å±€é™æ€§å’Œæœªæ¥å¯èƒ½çš„å‘å±•æœºä¼šã€‚Soraçš„èƒ½åŠ›åœ¨å¤šä¸ªç»´åº¦ä¸Šå±•ç°äº†å¤§å‹è§†è§‰æ¨¡å‹çš„è¿›æ­¥ï¼ŒåŒ…æ‹¬é•¿è§†é¢‘ç”Ÿæˆå’Œå¤šæ ·åŒ–è§†é¢‘æ ¼å¼çš„å¤„ç†ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17177v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17177.md)  |
| <span style='display: inline-block; width: 42px;'>02-26</span> | **LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments**<br><sub>ç ”ç©¶ä»‹ç»äº†LLMARENAåŸºå‡†ï¼Œç”¨ä»¥è¯„ä¼°LLMsæ™ºèƒ½ä½“åœ¨å¤æ‚å¤šä»£ç†ç¯å¢ƒä¸­çš„èƒ½åŠ›ï¼ŒæŒ‡å‡ºäº†å­˜åœ¨çš„é—®é¢˜å¹¶ä¿ƒè¿›äº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ï¼ŒåŒ…æ‹¬å¤šæ¨¡æ€åŠ¨æ€ç¯å¢ƒä¸­çš„èƒ½åŠ›åŠåˆ©ç”¨å¤–éƒ¨å·¥å…·çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16499v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16499.md)  |
| <span style='display: inline-block; width: 42px;'>02-26</span> | **Improving LLM-based Machine Translation with Systematic Self-Correction**<br><sub>æœºæ„: Zhejiang University, Tencent, Angelalign Technology Inc.<br>è®ºæ–‡æˆåŠŸæå‡ºäº†ç¬¬ä¸€ä¸ªåŸºäºLLMsçš„è‡ªæˆ‘çº æ­£ç¿»è¯‘æ¡†æ¶TERï¼Œå¹¶éªŒè¯äº†å…¶åœ¨å¤šç§è¯­è¨€å¯¹å’Œä¸åŒæ¨¡å‹é—´çš„ç¿»è¯‘è´¨é‡æ”¹è¿›æ•ˆæœã€‚å®ƒä¸ºæœºå™¨ç¿»è¯‘é¢†åŸŸå¸¦æ¥äº†æ–°çš„è§†è§’ï¼Œç‰¹åˆ«æ˜¯åœ¨è‡ªæˆ‘çº æ­£åœ¨é«˜èµ„æºã€ä½èµ„æºè¯­è¨€å’Œä¸åŒä¸­å¿ƒè¯­è¨€ä¹‹é—´ç¿»è¯‘çš„åº”ç”¨ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16379v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16379.md)  |
| <span style='display: inline-block; width: 42px;'>02-26</span> | **Do Large Language Models Latently Perform Multi-Hop Reasoning?**<br><sub>æœºæ„: Google DeepMind, UCL, Google Research<br>æœ¬æ–‡å¯¹LLMsæ˜¯å¦èƒ½å¤Ÿè¿›è¡Œæ½œåœ¨çš„å¤šè·³æ¨ç†è¿›è¡Œäº†ç ”ç©¶ï¼Œå¹¶é€šè¿‡å®éªŒæå‡ºäº†è¯„ä¼°LLMsæ½œåœ¨å¤šè·³æ¨ç†èƒ½åŠ›çš„æ–°æ–¹æ³•ã€‚ç ”ç©¶æç¤ºLLMså¯¹æŸäº›å…³ç³»ç±»å‹çš„æç¤ºæœ‰å¾ˆå¼ºçš„å¤šè·³æ¨ç†è¯æ®ï¼Œä½†è¿™ç§æ¨ç†è·¯å¾„çš„è¿ç”¨åœ¨ä¸åŒç±»å‹çš„æç¤ºä¸­è¡¨ç°å‡ºé«˜åº¦çš„æƒ…å¢ƒä¾èµ–æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16837v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16837.md)  |
| <span style='display: inline-block; width: 42px;'>02-25</span> | **ChatMusician: Understanding and Generating Music Intrinsically with LLM**<br><sub>æœºæ„: Hong Kong University of Science and Technology<br>æœ¬æ–‡é€šè¿‡åˆ›é€ é¦–ä¸ªé’ˆå¯¹è¯­è¨€æ¨¡å‹çš„éŸ³ä¹é¢„è®­ç»ƒæ•°æ®é›†å’Œè¯„ä¼°åŸºå‡†ï¼Œæå‡äº†LLMsåœ¨éŸ³ä¹ç†è§£å’Œç”Ÿæˆæ–¹é¢çš„è¡¨ç°ï¼Œå¹¶åœ¨è¿™ä¸€æœªè¢«æ·±å…¥ç ”ç©¶çš„é¢†åŸŸå–å¾—äº†å®è´¨æ€§è¿›å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16153v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16153.md)  |
| <span style='display: inline-block; width: 42px;'>02-23</span> | **Genie: Generative Interactive Environments**<br><sub>æœºæ„: Google DeepMind, University of British Columbia<br>Genieæ˜¯èƒ½å¤Ÿç”Ÿæˆæ–°è§†é¢‘å¹¶èƒ½é€šè¿‡ç”¨æˆ·è¾“å…¥æ§åˆ¶è§†é¢‘å†…å®¹çš„äº¤äº’ç¯å¢ƒæ¨¡å‹ï¼Œå¼¥è¡¥äº†ä¼ ç»Ÿè§†é¢‘ç”ŸæˆæŠ€æœ¯ä¸äº¤äº’ä½“éªŒä¹‹é—´çš„å·®è·ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.15391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.15391.md)  |
| <span style='display: inline-block; width: 42px;'>02-23</span> | **ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.15220v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.1522.md)  |
| <span style='display: inline-block; width: 42px;'>02-22</span> | **Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments**<br><sub>é€šè¿‡ä¸ºLLMsè®¾è®¡ç‰¹å®šçš„å·¥å…·å’Œæ¨ç†ç®—æ³•ï¼Œç ”ç©¶å¼€å‘äº†åä¸ºFUXIçš„æ–°æ¡†æ¶ï¼Œæœ‰æ•ˆæé«˜äº†LLMsåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œèƒ½</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14672v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14672.md)  |
| <span style='display: inline-block; width: 42px;'>02-22</span> | **CriticBench: Benchmarking LLMs for Critique-Correct Reasoning**<br><sub>æœºæ„: Tsinghua University, University of Hong Kong<br>è¯¥è®ºæ–‡é€šè¿‡CRITICBENCHè¯„ä¼°äº†LLMsçš„æ‰¹åˆ¤å’Œçº æ­£æ¨ç†èƒ½åŠ›ï¼Œå¹¶æ¢ç©¶äº†å½±å“è¿™äº›èƒ½åŠ›çš„å…³é”®å› å­ï¼Œæ—¨åœ¨ä¿ƒè¿›LLMsæ‰¹åˆ¤å’Œè‡ªæˆ‘æ”¹è¿›èƒ½åŠ›çš„åç»­ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14809v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14809.md)  |
| <span style='display: inline-block; width: 42px;'>02-22</span> | **OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14658v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14658.md)  |
| <span style='display: inline-block; width: 42px;'>02-21</span> | **AgentScope: A Flexible yet Robust Multi-Agent Platform**<br><sub>æœºæ„: Alibaba Group<br>AgentScopeæ˜¯ä¸€ä¸ªç”¨äºæ„å»ºå¤šä»£ç†åº”ç”¨çš„å¤šåŠŸèƒ½å¹³å°ï¼Œå¼ºè°ƒæ˜“ç”¨æ€§ä¸å¯å®šåˆ¶æ€§ï¼Œç‰¹åˆ«é€‚åˆä¸åŒæŠ€èƒ½æ°´å¹³çš„å¼€å‘è€…ä½¿ç”¨ã€‚é€šè¿‡å®ç°å®¹é”™å’Œæ”¯æŒå¤šæ¨¡æ€æ•°æ®å¤„ç†ï¼Œä»¥åŠä¼˜åŒ–åˆ†å¸ƒå¼æ“ä½œï¼ŒAgentScopeæ˜¾è‘—é™ä½äº†å¤šä»£ç†ç³»ç»Ÿå¼€å‘ä¸éƒ¨ç½²çš„éš¾åº¦ï¼Œé¼“åŠ±æ›´å¹¿æ³›çš„å‚ä¸å’Œåˆ›æ–°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14034v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14034.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/modelscope/agentscope)</div> |
| <span style='display: inline-block; width: 42px;'>02-21</span> | **User-LLM: Efficient LLM Contextualization with User Embeddings**<br><sub>USER-LLMæ˜¯ä¸€ä¸ªé€šè¿‡ç”¨æˆ·åµŒå…¥æ¥ä¸Šä¸‹æ–‡åŒ–LLMçš„æ¡†æ¶ã€‚å®ƒèƒ½æœ‰æ•ˆåœ°è§£å†³ç”¨æˆ·æ•°æ®çš„å¤æ‚æ€§å’Œé•¿åºåˆ—å¤„ç†çš„é—®é¢˜ï¼Œæå‡äº†LLMåœ¨ä¸ªæ€§åŒ–åº”ç”¨ä¸Šçš„æ•ˆèƒ½ï¼ŒåŒæ—¶ä¹Ÿä¿è¯äº†è®¡ç®—æ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.13598v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.13598.md)  |
| <span style='display: inline-block; width: 42px;'>02-20</span> | **Instruction-tuned Language Models are Better Knowledge Learners**<br><sub>æœºæ„: FAIR at Meta, Carnegie Mellon University, University of Washington<br>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºé¢„æŒ‡ä»¤å¾®è°ƒï¼ˆPITï¼‰çš„æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°æé«˜äº†LLMsä»æ–‡æ¡£ä¸­å¸æ”¶çŸ¥è¯†çš„èƒ½åŠ›ï¼Œè§£å†³äº†æ‰€è°“çš„å›°æƒ‘åº¦è¯…å’’é—®é¢˜ï¼Œå¹¶ä¸”åœ¨å¤šåŸŸçš„çŸ¥è¯†è·å–ä¸­ä¹Ÿå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.12847v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.12847.md)  |
| <span style='display: inline-block; width: 42px;'>02-20</span> | **TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization**<br><sub>æœºæ„: AWS AI Labs, The University of Texas at Austin, KAIST<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºTOFUEVALçš„æ–°å‹è¯„ä¼°åŸºå‡†ï¼Œé’ˆå¯¹LLMåœ¨ç”Ÿæˆè¯é¢˜ç„¦ç‚¹å¯¹è¯æ‘˜è¦æ—¶çš„äº‹å®ä¸€è‡´æ€§è¿›è¡Œäº†è¯„ä¼°ã€‚ç ”ç©¶å‘ç°ï¼Œä¸åŒå¤§å°çš„LLMåœ¨å¯¹è¯é¢†åŸŸç”Ÿæˆçš„æ‘˜è¦ä¸­å­˜åœ¨å¤§é‡äº‹å®é”™è¯¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.13249v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.13249.md)  |
| <span style='display: inline-block; width: 42px;'>02-19</span> | **AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling**<br><sub>æœºæ„: Fudan University, Multimodal Art Projection Research Community, Shanghai AI Laboratory<br>AnyGPT æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€æ¶æ„çš„è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡ç¦»æ•£åºåˆ—å»ºæ¨¡ï¼Œèƒ½å¤Ÿå®ç°ä¸åŒæ¨¡æ€é—´çš„æ— ç¼è½¬æ¢å’Œç»Ÿä¸€å¤„ç†ï¼Œæä¾›ä»»æ„åˆ°ä»»æ„æ¨¡æ€ä¹‹é—´çš„ç”Ÿæˆèƒ½åŠ›ï¼ŒåŒæ—¶ä¸éœ€è¦æ”¹å˜ç°æœ‰çš„ LLM æ¶æ„æˆ–è®­ç»ƒèŒƒå¼ã€‚è¯¥æ¨¡å‹é€šè¿‡åœ¨è¯­ä¹‰å’Œæ„ŸçŸ¥æ°´å¹³è¿›è¡Œå»ºæ¨¡ï¼Œèƒ½æœ‰æ•ˆå¤„ç†å’Œç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å†…å®¹ï¼Œå¹¶ä¸”ä¸ä¸“ä¸šæ¨¡å‹ç›¸æ¯”å…·æœ‰å¯æ¯”è¾ƒçš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.12226v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.12226.md)  |
| <span style='display: inline-block; width: 42px;'>02-16</span> | **Speculative Streaming: Fast LLM Inference without Auxiliary Models**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.11131v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.11131.md)  |
| <span style='display: inline-block; width: 42px;'>02-16</span> | **FinTral: A Family of GPT-4 Level Multimodal Financial Large Language Models**<br><sub>æœºæ„: The University of British Columbia & Invertible AI<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹è´¢åŠ¡åˆ†æä¼˜åŒ–çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¥—ä»¶FinTralã€‚é€šè¿‡ä¸ç°æœ‰æ¨¡å‹çš„å¯¹æ¯”ï¼Œå±•ç¤ºäº†å…¶åœ¨è´¢åŠ¡é¢†åŸŸå¤šä»»åŠ¡ç¯å¢ƒä¸‹çš„å…ˆè¿›æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†é›¶æ ·æœ¬ä»»åŠ¡å’Œå‡å°‘å¹»è§‰ç°è±¡æ–¹é¢çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.10986v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.10986.md)  |
| <span style='display: inline-block; width: 42px;'>02-16</span> | **SPAR: Personalized Content-Based Recommendation via Long Engagement Attention**<br><sub>æœºæ„: The University of British Columbia, Meta<br>SPARæ¡†æ¶å……åˆ†åˆ©ç”¨é•¿æœŸç”¨æˆ·äº’åŠ¨å†å²æ¥æå‡ä¸ªæ€§åŒ–å†…å®¹æ¨èçš„ç²¾åº¦ï¼Œå¹¶åœ¨å¤šé¡¹æ€§èƒ½æŒ‡æ ‡ä¸Šè¶…è¶Šç°æœ‰æŠ€æœ¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.10555v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.10555.md)  |
| <span style='display: inline-block; width: 42px;'>02-15</span> | **A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts**<br><sub>æœºæ„: Google DeepMind, Google Research<br>ReadAgent æ˜¯ä¸€ä¸ªå—äººç±»é˜…è¯»æ–¹å¼å¯å‘çš„LLMä»£ç†ç³»ç»Ÿï¼Œé€šè¿‡åˆ›å»ºæ‘˜è¦è®°å¿†å¹¶æ ¹æ®éœ€è¦æ£€ç´¢ä¿¡æ¯æ¥è§£å†³é•¿æ–‡æœ¬ä»»åŠ¡ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„è¡¨ç°å’Œä¼¸ç¼©æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.09727v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.09727.md)  |
| <span style='display: inline-block; width: 42px;'>02-15</span> | **How to Train Data-Efficient LLMs**<br><sub>æœºæ„: Google DeepMind, University of California San Diego, Texas A&M University<br>è®ºæ–‡æå‡ºçš„ASK-LLMå’ŒDENSITYæŠ€æœ¯ä¼˜åŒ–äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„æ•°æ®æ•ˆç‡ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹è®­ç»ƒçš„é€Ÿåº¦å’Œè´¨é‡ï¼Œå¹¶åœ¨èµ„æºé™åˆ¶ä¸‹è¡¨ç°å‡ºè‰²ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.09668v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.09668.md)  |
| <span style='display: inline-block; width: 42px;'>02-15</span> | **Chain-of-Thought Reasoning Without Prompting**<br><sub>æœºæ„: Google DeepMind<br>è¿™é¡¹å·¥ä½œæ­ç¤ºäº†é€šè¿‡æ”¹å˜è§£ç ç­–ç•¥ï¼Œå¯ä»¥æœ‰æ•ˆåœ°ä»é¢„è®­ç»ƒçš„LLMsä¸­è‡ªç„¶åœ°å¼•å‘æ¨ç†ï¼Œå¹¶ä¸”åœ¨é¢„è®­ç»ƒæ•°æ®ä¸­é¢‘ç¹å‡ºç°çš„ä»»åŠ¡ä¸ŠCoTè·¯å¾„æ›´å¸¸è§ã€‚æå‡ºçš„CoTè§£ç æ–¹æ³•æ— éœ€æ‰‹åŠ¨å¼•å¯¼ï¼Œå°±èƒ½æ˜¾è‘—æé«˜å„ç§æ¨ç†åŸºå‡†ä¸Šçš„æ¨¡å‹æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.10200v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.102.md)  |
| <span style='display: inline-block; width: 42px;'>02-14</span> | **Premise Order Matters in Reasoning with Large Language Models**<br><sub>æœºæ„: Google DeepMind<br>è¿™ç¯‡è®ºæ–‡å…³æ³¨äºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æ¨ç†ä»»åŠ¡æ—¶ï¼Œå‰æé¡ºåºçš„å½±å“ï¼Œå¹¶é€šè¿‡åˆ›å»ºR-GSMåŸºå‡†æµ‹è¯•æ¥è¯„ä¼°è¿™ä¸€ç°è±¡ã€‚ç ”ç©¶æ­ç¤ºäº†LLMså¯¹å‰æé¡ºåºæä¸ºæ•æ„Ÿï¼Œæ€§èƒ½å—é¡ºåºå½±å“æ˜¾è‘—ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.08939v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.08939.md)  |
| <span style='display: inline-block; width: 42px;'>02-09</span> | **InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning**<br><sub>æœºæ„: Shanghai AI Laboratory, Tsinghua University, Fudan University School of Computer Science<br>InternLM-Mathæ¨¡å‹æ˜¯ä¸€ç§åŸºäºLLMsçš„æ•°å­¦æ¨ç†å·¥å…·ï¼Œå®ƒæ•´åˆäº†å¤šç§èƒ½åŠ›å¹¶æä¾›äº†ç›‘ç£å­¦ä¹ ä»¥å¸®åŠ©æ¨¡å‹åœ¨å„ç§æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶å¼€æºå…¶ä»£ç å’Œæ•°æ®ã€‚è®ºæ–‡è¿˜æ¢è®¨äº†åˆ©ç”¨ç¨‹åºè¯­è¨€LEANåœ¨å¤šä»»åŠ¡å­¦ä¹ è®¾ç½®ä¸­è§£å†³æ•°å­¦é—®é¢˜çš„æ–°æ–¹æ³•ï¼Œå½°æ˜¾äº†LLMsåœ¨å½¢å¼åŒ–å’Œä»£ç è¾…åŠ©æ¨ç†ä¸­çš„æ½œèƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.06332v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.06332.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/InternLM/InternLM-Math)</div> |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **LimSim++: A Closed-Loop Platform for Deploying Multimodal LLMs in Autonomous Driving**<br><sub>æœºæ„: Shanghai Artificial Intelligence Laboratory, College of Control Science and Engineering Zhejiang University<br>LimSim++æ˜¯é¦–ä¸ªä¸“ä¸º(M)LLMæ”¯æŒçš„è‡ªåŠ¨é©¾é©¶è€Œå¼€å‘çš„å°é—­å¾ªç¯è¯„ä¼°å¹³å°ã€‚å®ƒè§£å†³äº†ç°æœ‰ä»¿çœŸå¹³å°çš„å±€é™æ€§ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†å…¶åœ¨å¤šç§å¤æ‚äº¤é€šåœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01246v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01246.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **Reasoning Capacity in Multi-Agent Systems: Limitations, Challenges and Human-Centered Solutions**<br><sub>æœºæ„: Megagon Labs, Carnegie Mellon University<br>æœ¬è®ºæ–‡æå‡ºäº†å¤šä»£ç†ç³»ç»Ÿä¸­çš„â€œæ¨ç†èƒ½åŠ›â€æ¦‚å¿µï¼Œä»¥æ”¹å–„ä¼˜åŒ–å’Œè¯„ä¼°ï¼Œå¹¶æ¢è®¨äº†åˆ©ç”¨äººç±»åé¦ˆå¢å¼ºç³»ç»Ÿæ¨ç†èƒ½åŠ›çš„å¯èƒ½æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01108v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01108.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback**<br><sub>æœºæ„: Tsinghua University, Ant Group<br>AMORæ¡†æ¶ç»¼åˆäº†åŸºäºæœ‰é™çŠ¶æ€æœºï¼ˆFSMï¼‰çš„æ¨ç†é€»è¾‘å’Œè¿‡ç¨‹åé¦ˆæœºåˆ¶ï¼Œå±•ç¤ºäº†åŸºäºå¼€æºLLMçš„çŸ¥è¯†ä»£ç†å¦‚ä½•é€šè¿‡äººç±»ç›‘ç£å®ç°æ¨ç†å’Œé€‚åº”æ€§ï¼Œæé«˜äº†æ¨¡å‹åœ¨å®ŒæˆçŸ¥è¯†å¯†é›†ä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01469v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01469.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **K-Level Reasoning with Large Language Models**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01521v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01521.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **MAGDi: Structured Distillation of Multi-Agent Interaction Graphs Improves Reasoning in Smaller Language Models**<br><sub>æœºæ„: UNC Chapel Hill.<br>æœ¬è®ºæ–‡ä»‹ç»äº†åä¸ºMAGDIçš„æ–°æ–¹æ³•ï¼Œå®ƒé€šè¿‡ç»“æ„åŒ–è’¸é¦æ–¹å¼å°†å¤šLLMä¹‹é—´çš„æ¨ç†äº¤äº’è’¸é¦åˆ°æ›´å°çš„æ¨¡å‹ä¸­ï¼Œæ˜¾è‘—æå‡å°æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶é™ä½äº†æˆæœ¬ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01620v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.0162.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **Don't Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration**<br><sub>æœºæ„: University of Washington, University of California Berkeley, The Hong Kong University of Science and Technology<br>æœ¬æ–‡å…³æ³¨çš„æ˜¯å¦‚ä½•åœ¨å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä¸­è¯†åˆ«çŸ¥è¯†å·®è·å¹¶åœ¨å¿…è¦æ—¶æ”¾å¼ƒå›ç­”é—®é¢˜ã€‚ç ”ç©¶æå‡ºäº†ä¸¤ç§åŸºäºå¤šLLMåˆä½œçš„æ–°æ–¹æ³•ï¼Œé€šè¿‡å¯¹æ¯”å®éªŒæ˜¾ç¤ºå®ƒä»¬èƒ½æœ‰æ•ˆæé«˜LLMsæ”¾å¼ƒç”Ÿæˆä½ä¿¡å¿ƒè¾“å‡ºçš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.00367v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.00367.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **HR-MultiWOZ: A Task Oriented Dialogue (TOD) Dataset for HR LLM Agent**<br><sub>æœºæ„: Amazon, University of Milano-Bicocca<br>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªæ–°çš„é’ˆå¯¹äººåŠ›èµ„æºé¢†åŸŸçš„å¤§è¯­è¨€æ¨¡å‹ä»£ç†ï¼ˆHR LLM Agentï¼‰ä»»åŠ¡çš„å¯¹è¯æ•°æ®é›†ï¼ŒHR-MultiWOZã€‚å®ƒä¸ä»…è§£å†³äº†å½“å‰åœ¨æ„å»ºå’Œè¯„ä¼°HRé¢†åŸŸLLMä»£ç†æ—¶ç¼ºä¹é«˜è´¨é‡è®­ç»ƒæ•°æ®é›†çš„é—®é¢˜ï¼Œè¿˜æä¾›äº†ä¸€ä¸ªç»æµé«˜æ•ˆçš„æ•°æ®é›†ç”Ÿæˆæ–¹æ³•ï¼Œä¸ºåŒé¢†åŸŸä¸­çš„å…¶ä»–ç ”ç©¶æä¾›äº†å®è´µçš„èµ„æºå’Œå‚è€ƒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01018v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01018.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing**<br><sub>æœºæ„: Nanyang Technological University, Institute for Infocomm Research A*STAR, Salesforce Research<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„ç¦»çº¿è®­ç»ƒæ¡†æ¶ï¼Œä¸“æ³¨äºæ”¹è¿›å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æ—¶çš„å¯é æ€§å’Œç²¾ç¡®æ€§ï¼Œé€šè¿‡æ”¶é›†è½¨è¿¹å’ŒåŸºäºç»“æœç›‘ç£çš„ç›´æ¥åå¥½ä¼˜åŒ–ï¼Œæ— éœ€æ•™å¸ˆæ¨¡å‹æˆ–äººç±»æ ‡æ³¨ã€‚åœ¨ä¸¤ä¸ªé€»è¾‘æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„ç»“æœè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.00658v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.00658.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **Can Large Language Models Understand Context?**<br><sub>æœºæ„: Georgetown University, Apple<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªä¸Šä¸‹æ–‡ç†è§£åŸºå‡†ï¼Œç”¨ä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ã€‚è¯¥åŸºå‡†æ¶µç›–äº†å¯¹æ–‡æ¡£å’Œå¯¹è¯åŸºç¡€ä¸Šä¸‹æ–‡ç†è§£çš„è¦ç´ ï¼Œé€šè¿‡åˆ›æ–°çš„æµ‹è¯•æ–¹æ³•å’Œå®éªŒåˆ†æå±•ç¤ºäº†LLMsåœ¨ä¸Šä¸‹æ–‡ç†è§£æ–¹é¢çš„èƒ½åŠ›å’Œå±€é™æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.00858v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.00858.md)  |

---

### 01æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>01-31</span> | **LongAlign: A Recipe for Long Context Alignment of Large Language Models**<br><sub>æœºæ„: Tsinghua University, Zhipu.AI<br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„é•¿ä¸Šä¸‹æ–‡å¯¹é½é…æ–¹LongAlignï¼Œé€šè¿‡æ„å»ºé•¿æŒ‡ä»¤æ•°æ®é›†ã€é‡‡ç”¨æ–°çš„è®­ç»ƒç­–ç•¥å¹¶å¼•å…¥è¯„ä¼°åŸºå‡†æ¥æé«˜LLMså¤„ç†é•¿ä¸Šä¸‹æ–‡çš„èƒ½åŠ›ï¼Œä¸”ä»£ç ã€æ•°æ®å’Œé•¿å¯¹é½çš„æ¨¡å‹å·²å¼€æºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.18058v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.18058.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/THUDM/LongAlign)</div> |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Incoherent Probability Judgments in Large Language Models**<br><sub>æœºæ„: Princeton University<br>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å½¢æˆæ¦‚ç‡åˆ¤æ–­æ–¹é¢çš„è¿è´¯æ€§é—®é¢˜ï¼Œå¹¶å‘ç°è¿™äº›æ¨¡å‹åœ¨è¯¥é¢†åŸŸè¡¨ç°å‡ºçš„åå·®ä¸äººç±»è®¤çŸ¥ä¸­çš„ç³»ç»Ÿæ€§åå·®ç›¸ä¼¼ã€‚é€šè¿‡åº”ç”¨æ¦‚ç‡æ’ç­‰å¼å’Œé‡å¤åˆ¤æ–­çš„æ–¹æ³•ï¼Œç ”ç©¶äººå‘˜é‡åŒ–äº†è¿™äº›åˆ¤æ–­çš„ä¸è¿è´¯æ€§ã€‚ç ”ç©¶è¿˜æå‡ºäº†ä¸€ä¸ªå‡è®¾ï¼Œå³LLMsåœ¨åšå‡ºæ¦‚ç‡åˆ¤æ–­æ—¶çš„äººç±»æ ·åå·®å¯èƒ½æºè‡ªå®ƒä»¬é‡‡ç”¨çš„è‡ªå›å½’è®­ç»ƒç›®æ ‡ï¼Œè¿™ä¸€å‡è®¾å¾—åˆ°äº†ä»¥è´å¶æ–¯å–æ ·å™¨æ¨¡å‹å’ŒLLMsä¸­çš„è‡ªå›å½’è¿‡ç¨‹ä¹‹é—´æ½œåœ¨è”ç³»ä¸ºåŸºç¡€çš„æ”¯æŒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16646v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16646.md)  |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Recovering Mental Representations from Large Language Models with Markov Chain Monte Carlo**<br><sub>æœºæ„: Princeton University, University of Warwick<br>æœ¬æ–‡é€šè¿‡å°† LLMs æ•´åˆåˆ°é‡‡æ ·ç®—æ³•ä¸­ï¼Œå¹¶è¿ç”¨ç›´æ¥é‡‡æ ·ä¸ MCMC çš„æ–¹å¼æå–å¿ƒç†è¡¨å¾ï¼Œæœ‰æ•ˆæå‡äº†æ•ˆç‡å’Œæ€§èƒ½ï¼Œå¹¶æ¢ç´¢äº†ç”¨ LLM è¿›è¡Œè´å¶æ–¯æ¨æ–­çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16657v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16657.md)  |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate**<br><sub>æœºæ„: Shanghai Jiao Tong University, Carnegie Mellon University, Shanghai Artificial Intelligence Laboratory<br>SCALEEVAL æ˜¯ä¸€ç§æ–°å‹çš„å…ƒè¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°LLMsä½œä¸ºè¯„ä¼°è€…çš„å¯é æ€§å’Œæ•ˆç‡ã€‚é€šè¿‡åˆ©ç”¨LLMä»£ç†é—´çš„è¾©è®ºå’Œæœ€å°åŒ–çš„äººç±»ç›‘ç£ï¼Œè¯¥æ¡†æ¶åœ¨è¯„ä¼°ä¸­å¼•å…¥çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ï¼Œå¹¶åœ¨å®éªŒä¸­æ˜¾ç¤ºå‡ºä¸çº¯äººå·¥è¯„ä¼°é«˜åº¦ä¸€è‡´çš„ç»“æœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16788v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16788.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/GAIR-NLP/scaleeval)</div> |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Efficient Tool Use with Chain-of-Abstraction Reasoning**<br><sub>æœºæ„: Meta<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„é“¾å¼æŠ½è±¡æ¨ç†æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°æå‡äº†LLMsä½¿ç”¨å¤–éƒ¨å·¥å…·çš„èƒ½åŠ›ï¼Œå¹¶åŠ é€Ÿäº†æ¨ç†è¿‡ç¨‹ã€‚å®éªŒç»“æœè¯æ˜äº†å…¶åœ¨å¤šæ­¥éª¤æ¨ç†ä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§å’Œé«˜æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.17464v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.17464.md)  |
| <span style='display: inline-block; width: 42px;'>01-29</span> | **SelectLLM: Can LLMs Select Important Instructions to Annotate?**<br><sub>æœºæ„: University of Minnesota, Carnegie Mellon University<br>è¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ä¸ªåˆ©ç”¨LLMsé€‰æ‹©æœªæ ‡è®°çš„é«˜è´¨é‡æŒ‡ä»¤çš„æ–°æ–¹æ³•SELECTLLMï¼Œé€šè¿‡æŒ‘æˆ˜ä¼ ç»Ÿçš„é€‰æ‹©ç®—æ³•å¹¶åœ¨ä¿æŒæ•°æ®é›†çš„å…¨å±€ç»“æ„çš„åŒæ—¶æå‡é€‰æ‹©æ•ˆæœã€‚å®éªŒç»“æœæ˜¾ç¤ºäº†å…¶åœ¨æŒ‡ä»¤è°ƒæ•´åŸºå‡†æµ‹è¯•ä¸Šçš„ä¼˜è¶Šæ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16553v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16553.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/minnesotanlp/select-llm)</div> |
| <span style='display: inline-block; width: 42px;'>01-29</span> | **Beyond Direct Diagnosis: LLM-based Multi-Specialist Agent Consultation for Automatic Diagnosis**<br><sub>æœºæ„: Harbin Institute of Technology<br>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºLLMçš„è‡ªåŠ¨è¯Šæ–­æ–¹æ³•â€”â€”å¤šä¸“å®¶æ™ºèƒ½ä»£ç†å’¨è¯¢æ¨¡å‹ï¼ˆAMSCï¼‰ï¼Œå®ƒèƒ½æ›´å¥½åœ°æ¨¡æ‹Ÿç°å®ä¸–ç•Œä¸­çš„è¯Šæ–­æµç¨‹ï¼Œå¹¶é€šè¿‡é›†æˆå¤šä¸ªä¸“å®¶ä»£ç†çš„é¢„æµ‹æ¥æå‡è¯Šæ–­çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16107v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16107.md)  |
| <span style='display: inline-block; width: 42px;'>01-29</span> | **LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning**<br><sub>æœºæ„: Nanyang Technological University<br>LLM4Vulnæ˜¯ä¸€ä¸ªåˆ›æ–°çš„æ¡†æ¶ï¼Œå®ƒé€šè¿‡æä¾›æ¼æ´çŸ¥è¯†çš„å‘é‡æ•°æ®åº“ã€è°ƒç”¨å·¥å…·çš„åŠŸèƒ½ã€å®šåˆ¶çš„CoTæç¤ºæ–¹æ¡ˆä»¥åŠä½¿ç”¨ç²¾é€šæŒ‡ä»¤çš„æ¨¡å‹æ¥ç»“æ„åŒ–è¾“å‡ºï¼Œæ˜¾è‘—æé«˜äº†LLMsåœ¨ä»£ç æ¼æ´åˆ†æä¸­çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16185v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16185.md)  |
| <span style='display: inline-block; width: 42px;'>01-28</span> | **PRE: A Peer Review Based Large Language Model Evaluator**<br><sub>è¿™ç¯‡è®ºæ–‡æå‡ºçš„PREæ¨¡å‹é€šè¿‡æ¨¡æ‹Ÿå­¦æœ¯ç•Œçš„åŒè¡Œè¯„å®¡æœºåˆ¶ï¼Œæä¾›äº†ä¸€ç§å…¨æ–°çš„è‡ªåŠ¨è¯„ä¼°LLMçš„æ¡†æ¶ï¼Œå®ƒæ˜¾è‘—é™ä½äº†æˆæœ¬ï¼Œå¹¶ä¸”å…·æœ‰æ›´é«˜çš„é€šç”¨æ€§å’Œå¯é æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.15641v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.15641.md)  |
| <span style='display: inline-block; width: 42px;'>01-27</span> | **MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries**<br><sub>æœºæ„: Hong Kong University of Science and Technology<br>è¿™ç¯‡è®ºæ–‡å¼€å‘äº†MultiHop-RAGæ•°æ®é›†ï¼Œä»¥è¯„ä¼°å’Œæ”¹å–„ç°å­˜çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿåœ¨å¤„ç†éœ€è¦å¤šæ­¥æ£€ç´¢å’Œæ¨ç†çš„æŸ¥è¯¢ä¸Šçš„ä¸è¶³ã€‚ç ”ç©¶è¿˜æä¾›äº†ä¸€ç³»åˆ—å®éªŒç»“æœï¼Œæ­ç¤ºäº†ç›®å‰RAGç³»ç»Ÿåœ¨æ­¤ç±»ä»»åŠ¡ä¸Šçš„å±€é™æ€§ï¼Œå¹¶å…¬å¼€äº†æ•°æ®é›†æ¨åŠ¨è¿›ä¸€æ­¥çš„ç ”ç©¶å’Œå¼€å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.15391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.15391.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/yixuantt/MultiHop-RAG)</div> |
| <span style='display: inline-block; width: 42px;'>01-26</span> | **EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty**<br><sub>æœºæ„: Peking University, Microsoft Research, University of Waterloo<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªåä¸ºEAGLEçš„æ–°æ¡†æ¶ï¼Œä»¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡ªå›å½’è§£ç çš„é€Ÿåº¦ï¼ŒåŒæ—¶ä¿è¯ç”Ÿæˆæ–‡æœ¬ä¸åŸå§‹LLMsçš„æ–‡æœ¬åˆ†å¸ƒä¸€è‡´ã€‚EAGLEé€šè¿‡æ”¹è¿›æ¨æµ‹æ€§é‡‡æ ·æ–¹æ³•ï¼Œåœ¨å‡å°‘æ—¶é—´å¼€é”€å’Œæé«˜è‰ç¨¿çš„æ¥å—ç‡æ–¹é¢å–å¾—äº†æ˜¾è‘—æˆæ•ˆï¼Œå¯¹æ¯”Lookaheadå’ŒMedusaå®ç°äº†æ›´å¿«çš„åŠ é€Ÿæ•ˆæœï¼Œå¹¶ä¸”è®­ç»ƒæˆæœ¬ä½ï¼Œæ˜“äºéƒ¨ç½²ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.15077v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.15077.md)  |
| <span style='display: inline-block; width: 42px;'>01-25</span> | **Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning**<br><sub>æœºæ„: Columbia University, Microsoft Research, University of California Berkeley<br>EC-Finetuningæ–¹æ³•æˆåŠŸåœ°æé«˜äº†LLMsç”Ÿæˆè§£é‡Šçš„ä¸€è‡´æ€§ï¼Œå¹¶ä¸”å¯ä»¥æ¨å¹¿åˆ°æœªè§è¿‡çš„æ•°æ®é›†ï¼Œè¡¨ç°å‡ºå¾®è°ƒæ•°æ®é›†ä¸Š10.0%å’Œåˆ†å¸ƒå¤–æ•°æ®é›†ä¸Š4.5%çš„è§£é‡Šä¸€è‡´æ€§ç›¸å¯¹æ”¹å–„ï¼ŒåŒæ—¶ä¹Ÿé€‚åº¦æå‡äº†é¢„æµ‹å‡†ç¡®åº¦ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13986v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13986.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/yandachen/explanation-consistency-finetuning)</div> |
| <span style='display: inline-block; width: 42px;'>01-25</span> | **ConstraintChecker: A Plugin for Large Language Models to Reason on Commonsense Knowledge Bases**<br><sub>æœºæ„: HKUST<br>ConstraintCheckeræ˜¯ä¸€ä¸ªèƒ½æœ‰æ•ˆæå‡LLMsåœ¨CSKBæ¨ç†ä»»åŠ¡ä¸­æ€§èƒ½çš„ç‹¬ç«‹æ’ä»¶å·¥å…·ã€‚é€šè¿‡æä¾›å’Œæ£€æŸ¥æ˜¾å¼çº¦æŸçš„æ–¹å¼ï¼Œå®ƒèƒ½å¤Ÿå¸®åŠ©LLMsåœ¨æ¨ç†ä¸­å–å¾—æ›´å¥½çš„è¡¨ç°ï¼Œä¸”åœ¨ç»è¿‡éªŒè¯åçš„æŒ‡æ ‡ä¸Šè¶…è¿‡äº†å…¶ä»–çš„æç¤ºæŠ€æœ¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.14003v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.14003.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/HKUST-KnowComp/ConstraintChecker)</div> |
| <span style='display: inline-block; width: 42px;'>01-25</span> | **True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning**<br><sub>æœºæ„: Nanyang Technological University, Zhejiang University<br>TWOSOMEæ¡†æ¶é€šè¿‡å¼ºåŒ–å­¦ä¹ æ¥æœ‰æ•ˆåœ°å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸ä½“ç°ç¯å¢ƒå¯¹é½ï¼Œæé«˜äº†æ ·æœ¬æ•ˆç‡å’Œä»»åŠ¡æ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶ä¿ç•™äº†LLMsçš„åŸå§‹åŠŸèƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.14151v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.14151.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents**<br><sub>æœºæ„: The University of Hong Kong, Zhejiang University, Shanghai Jiao Tong University<br>ç ”ç©¶äººå‘˜æå‡ºäº†ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯• AGENTBOARDï¼Œä¸“é—¨è¯„ä¼°å…·æœ‰å¤šè½®äº¤äº’èƒ½åŠ›çš„å¤§è¯­è¨€æ¨¡å‹ä»£ç†ï¼Œå®ƒæä¾›äº†ç»†ç²’åº¦çš„è¿›å±•ç‡å’Œäº¤äº’å¼åˆ†æå·¥å…·ï¼Œä»¥å¢è¿›å¯¹ LLM ä»£ç†æ€§èƒ½çš„æ·±å…¥ç†è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13178v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13178.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **Can AI Assistants Know What They Don't Know?**<br><sub>æœºæ„: Fudan University, Shanghai Artificial Intelligence Laboratory<br>è¿™ç¯‡è®ºæ–‡é‡ç‚¹æ¢ç©¶äº†AIåŠ©æ‰‹è¯†åˆ«è‡ªå·±çŸ¥è¯†è¾¹ç•Œçš„èƒ½åŠ›ï¼Œå¹¶é€šè¿‡æ„å»ºIdkæ•°æ®é›†å¹¶å¯¹åŠ©æ‰‹è°ƒæ•´ï¼Œå®ç°äº†è®©AIåŠ©æ‰‹è¯†åˆ«å¹¶æ‰¿è®¤ä¸çŸ¥é“çš„é—®é¢˜ï¼Œä»¥å‡å°‘å›ç­”ä¸­çš„äº‹å®é”™è¯¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13275v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13275.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **MM-LLMs: Recent Advances in MultiModal Large Language Models**<br><sub>æœºæ„: Tencent AI Lab, Kyoto University, Mohamed Bin Zayed University of Artificial Intelligence<br>æœ¬æ–‡æ˜¯ä¸€é¡¹å…³äºMM-LLMsçš„ç»¼åˆæ€§è°ƒç ”ï¼Œæ—¨åœ¨è¿›ä¸€æ­¥æ¨åŠ¨MM-LLMsé¢†åŸŸçš„ç ”ç©¶å·¥ä½œã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13601v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13601.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **Consistency Guided Knowledge Retrieval and Denoising in LLMs for Zero-shot Document-level Relation Triplet Extraction**<br><sub>æœºæ„: Nanjing University of Science and Technology, Northeastern University, Singapore Institute of Technology<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE)æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡ä»LLMsä¸­æ£€ç´¢å’Œå»å™ªçŸ¥è¯†ç”Ÿæˆå¸¦æ ‡ç­¾çš„æ•°æ®ï¼Œå¹¶é€šè¿‡ä¸€ç³»åˆ—æ–°æ–¹æ³•æ˜¾è‘—æé«˜äº†æ–‡æ¡£çº§å…³ç³»ä¸‰å…ƒç»„æŠ½å–çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13598v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13598.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption**<br><sub>æœºæ„: Tsinghua University, Zhongguancun Laboratory, XinJiang University<br>è®ºæ–‡æå‡ºçš„CGPEæ¡†æ¶èƒ½æœ‰æ•ˆæ”¯æŒLLMsåœ¨é—®ç­”ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œé€šè¿‡çº¿ç´¢å¼•å¯¼çš„è·¯å¾„æ¢ç´¢æœºåˆ¶ï¼Œé™ä½äº†å¯¹LLMsèƒ½åŠ›çš„è¦æ±‚ï¼Œå¹¶æ˜¾è‘—å‡å°‘äº†è®¡ç®—èµ„æºæ¶ˆè€—ï¼Œå¯¹è®¡ç®—èµ„æºæœ‰é™çš„ä¸ªäººå’Œç»„ç»‡å…·æœ‰é‡è¦å®é™…æ„ä¹‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13444v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13444.md)  |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment**<br><sub>æœºæ„: Alibaba Inc.<br>è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºDITTOçš„è‡ªå¯¹é½æ–¹æ³•ï¼Œèƒ½å¤Ÿé€šè¿‡çŸ¥è¯†å¢å¼ºå’Œå¯¹è¯æ¨¡æ‹Ÿå¢å¼ºLLMsçš„è§’è‰²æ‰®æ¼”èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå®ƒæä¾›äº†ä¸€ç§å®¢è§‚ã€å¯å¤åˆ¶ã€å¯è§£é‡Šä¸”é«˜æ•ˆçš„è§’è‰²æ‰®æ¼”è¯„ä¼°æ–¹æ³•ï¼Œå¹¶é€šè¿‡è·¨ç›‘ç£çš„å®éªŒäº†è§£è§’è‰²æ‰®æ¼”çš„åˆ†è§£ï¼Œä¸ºLLMsæ„å»ºè§’è‰²æ‰®æ¼”åŠŸèƒ½æä¾›äº†æ·±å…¥çš„ç†è§£å’Œè§è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12474v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12474.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OFA-Sys/Ditto)</div> |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning**<br><sub>æœºæ„: Samsung R&D Institute India - Bangalore<br>KAM-CoTæ˜¯ä¸€ä¸ªå¤šæ¨¡æ€CoTæ¨ç†æ¡†æ¶ï¼Œæ•´åˆäº†CoTæ¨ç†ã€çŸ¥è¯†å›¾è°±å’Œå¤šç§æ¨¡æ€ã€‚å®ƒåœ¨å…·æœ‰è¾ƒå°‘å¯è®­ç»ƒå‚æ•°çš„æƒ…å†µä¸‹ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œå±•ç°å‡ºå“è¶Šçš„æ€§èƒ½å’Œæˆæœ¬æ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12863v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12863.md)  |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **CCA: Collaborative Competitive Agents for Image Editing**<br><sub>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šä¸ªå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æ–°å‹ç”Ÿæˆæ¨¡å‹CCAï¼Œèƒ½å¤Ÿå¤„ç†å¤æ‚çš„å›¾åƒç¼–è¾‘ä»»åŠ¡å¹¶æå‡ç»“æœçš„è´¨é‡å’Œé²æ£’æ€§ã€‚é€šè¿‡é¼“åŠ±ä»£ç†çš„åä½œç«äº‰ï¼Œæ¨¡å‹å±•ç¤ºå‡ºä¼˜äºä¼ ç»Ÿæ–¹æ³•çš„èƒ½åŠ›ï¼Œå°¤å…¶åœ¨ç®¡ç†å¤æ‚ä»»åŠ¡å’Œä»ä¸­é—´æ­¥éª¤ä¸­å­¦ä¹ ä»¥æ”¹è¿›ç»“æœæ–¹é¢ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13011v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13011.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/TiankaiHang/CCA)</div> |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents**<br><sub>æœºæ„: Google DeepMind<br>æœ¬è®ºæ–‡æè¿°äº†ä¸€ä¸ªåä¸ºAutoRTçš„ç³»ç»Ÿï¼Œå®ƒåˆ©ç”¨å¤§å‹åŸºç¡€æ¨¡å‹æ§åˆ¶çœŸå®ä¸–ç•Œä¸­çš„æœºå™¨äººï¼Œä½¿å®ƒä»¬èƒ½å¤Ÿè‡ªåŠ¨å¯¼èˆªå¹¶æ‰§è¡Œä»»åŠ¡ã€‚è¿™æ ‡å¿—ç€ç¬¬ä¸€æ¬¡å®ç°LLMæ§åˆ¶çš„æœºå™¨äººåœ¨çœŸå®ç¯å¢ƒä¸­è¿›è¡Œè‡ªåŠ¨æ“ä½œã€æå‡ºç›®æ ‡å¹¶å®ç°è¿™äº›ç›®æ ‡ã€‚é€šè¿‡AutoRTæ”¶é›†åˆ°çš„æ•°æ®ä¸ä»…å¤šæ ·åŒ–ä¸”èƒ½å¤Ÿæé«˜æœºå™¨äººå­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶ä¸”å¯ä»¥ä¸äººç±»åå¥½ä¿æŒä¸€è‡´ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12963v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12963.md)  |
| <span style='display: inline-block; width: 42px;'>01-22</span> | **Improving Small Language Models' Mathematical Reasoning via Mix Thoughts Distillation**<br><sub>æœºæ„: Institute of Information Engineering, Chinese Academy of Sciences<br>è¿™ç¯‡è®ºæ–‡é€šè¿‡ä»‹ç»EoTDå’ŒMTDï¼Œè¡¨æ˜äº†å¯ä»¥å°†LLMsçš„æ•°å­¦æ¨ç†èƒ½åŠ›è½¬åŒ–ç»™å‚æ•°æ•°é‡å°‘äºä¸€åäº¿ä¸ªçš„SLMsã€‚é€šè¿‡å®éªŒéªŒè¯äº†è¿™äº›æ–¹æ³•ä¸ä»…ä¿ç•™äº†SLMsçš„æ¨ç†èƒ½åŠ›ï¼Œè¿˜åœ¨ä¸€å®šç¨‹åº¦ä¸Šæå‡äº†è¯¥èƒ½åŠ›ï¼Œä½¿SLMsåœ¨æ¨ç†ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å¥½æ°´å¹³ã€‚è¿™ä¸€è¿›å±•å¯¹äºåœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­æ¨å¹¿SLMsçš„åº”ç”¨æ‰“å¼€äº†å¤§é—¨ï¼Œå¹¶ç¼©å°äº†å¯¹å¼ºå¤§æ¨ç†æ¨¡å‹éœ€æ±‚ä¸è®¡ç®—èµ„æºé™åˆ¶ä¹‹é—´çš„å·®è·ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.11864v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.11864.md)  |
| <span style='display: inline-block; width: 42px;'>01-22</span> | **PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety**<br><sub>æœºæ„: Shanghai Artificial Intelligence Laboratory, Dalian University of Technology<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå®‰å…¨æ€§çš„ç»¼åˆæ€§æ¡†æ¶PsySafeï¼Œè¯¥æ¡†æ¶ç»“åˆäº†å¿ƒç†å±‚é¢çš„æ”»å‡»ã€é˜²å¾¡ä¸è¯„ä¼°æ–¹æ³•ã€‚ç ”ç©¶çš„å®éªŒç»“æœæœ‰åŠ©äºæ›´æ·±å…¥åœ°ç†è§£å’Œç ”ç©¶å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.11880v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.1188.md)  |
| <span style='display: inline-block; width: 42px;'>01-22</span> | **CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation**<br><sub>æœºæ„: Stanford University, Stability AI  <br>æœ¬è®ºæ–‡è‡´åŠ›äºè§£å†³åœ¨è‡ªåŠ¨åŒ–èƒ¸éƒ¨Xå…‰è§£é‡Šæ–¹é¢å­˜åœ¨çš„æŒ‘æˆ˜ï¼Œé€šè¿‡å¼•å…¥ä¸“ä¸ºCXRè§£é‡Šè®¾è®¡çš„å¤§å‹æ•°æ®é›†ã€å¼€å‘äº†æ–°çš„åŸºç¡€æ¨¡å‹ä»¥åŠåˆ›å»ºäº†ä¸€ä¸ªå…¨é¢çš„è¯„ä¼°åŸºå‡†ï¼Œå®ç°äº†åœ¨åŒ»å­¦æˆåƒé¢†åŸŸçš„åº”ç”¨ï¼Œå¹¶è¯æ˜äº†åœ¨å¤šé¡¹è¯„ä¼°ä»»åŠ¡ä¸­CheXagentçš„æ€§èƒ½ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚åŒæ—¶ä¹Ÿå¯¹æ¨¡å‹ä¸­å¯èƒ½å­˜åœ¨çš„åå·®è¿›è¡Œäº†æ£€æŸ¥ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶å’Œåº”ç”¨æä¾›äº†é‡è¦å‚è€ƒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12208v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12208.md)  |
| <span style='display: inline-block; width: 42px;'>01-21</span> | **Interactive AI with Retrieval-Augmented Generation for Next Generation Networking**<br><sub>æœºæ„: Nanyang Technological University, Guangdong University of Technology, Institute for Infocomm Research, Agency for Science Technology and Research<br>æœ¬æ–‡ç ”ç©¶äº†å°†äº¤äº’å¼AI (IAI) é›†æˆåˆ°ä¸‹ä¸€ä»£ç½‘ç»œä¸­çš„å¯èƒ½æ€§ï¼Œé‡‡ç”¨äº†æ£€ç´¢å¢å¼ºå‹ç”Ÿæˆï¼ˆRAGï¼‰å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥æå‡å†³ç­–èƒ½åŠ›ï¼Œå¹¶é€šè¿‡çœŸå®ç½‘ç»œä¼˜åŒ–çš„æ¡ˆä¾‹ç ”ç©¶è¯æ˜äº†æå‡ºæ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.11391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.11391.md)  |
| <span style='display: inline-block; width: 42px;'>01-20</span> | **BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models**<br><sub>æœºæ„: University of Illinois Urbana-Champaign, University of Washington, Western Washington University<br>æœ¬æ–‡æå‡ºäº†BadChainï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹é‡‡ç”¨COTæç¤ºçš„LLMsçš„åé—¨æ”»å‡»ï¼Œä¸ä»…ä¸éœ€è¦è®¿é—®è®­ç»ƒæ•°æ®é›†æˆ–æ¨¡å‹å‚æ•°ï¼Œè€Œä¸”è®¡ç®—å¼€é”€ä½ã€‚è¯¥æ–¹æ³•æœ‰æ•ˆåœ°æ­ç¤ºäº†COTæç¤ºä¸‹LLMsçš„å®‰å…¨æ¼æ´ï¼Œå¼ºè°ƒäº†è¿›è¡Œåé—¨æ”»å‡»å’Œè®¾è®¡æœ‰æ•ˆé˜²å¾¡çš„é‡è¦æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12242v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12242.md)  |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning**<br><sub>æœºæ„: MIT<br>è®ºæ–‡å±•ç¤ºäº†é€šè¿‡Wandaå‰ªææ–¹æ³•ï¼Œæ— éœ€å¾®è°ƒè€Œæå‡LLMsä»å¯¹é½å®‰å…¨æ€§æ–¹é¢æŠµå¾¡â€œè¶Šç‹±â€æ”»å‡»çš„èƒ½åŠ›ï¼Œå¹¶é€šè¿‡æ„å»ºç‰¹å®šçš„æ•°æ®é›†å’Œè¯„ä¼°ä½“ç³»éªŒè¯æ¨¡å‹è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10862v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10862.md)  |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Tool-LMM: A Large Multi-Modal Model for Tool Agent Learning**<br><sub>æœºæ„: ShanghaiTech University, Meituan, UniDT<br>Tool-LMMä¸ºé¦–ä¸ªè‡´åŠ›äºè®­ç»ƒå¤§å‹å¤šæ¨¡æ€æ¨¡å‹ä»¥å­¦ä¹ å·¥å…·ä»£ç†çš„ç³»ç»Ÿï¼Œåˆ›æ–°åœ°æ•´åˆäº†å¤šæ¨¡æ€è¾“å…¥ä¸å¤–éƒ¨å·¥å…·çš„æ­£ç¡®é€‰æ‹©ï¼Œå…‹æœäº†æ–‡æœ¬æ¨¡ç³Šå¸¦æ¥çš„é—®é¢˜ï¼Œå±•ç°äº†åœ¨å¤šæ¨¡æ€æŒ‡ä»¤ä¸‹è‡ªåŠ¨é€‰æ‹©åˆé€‚å·¥å…·çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10727v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10727.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Tool-LMM/Tool-LMM)</div> |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Mitigating Hallucinations of Large Language Models via Knowledge Consistent Alignment**<br><sub>æœºæ„: Sun Yat-sen University, Tencent AI Lab<br>è¿™ç¯‡è®ºæ–‡å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„KCAæ–¹æ³•ï¼Œé€šè¿‡å‡å°‘å¤–éƒ¨çŸ¥è¯†å’Œå†…åœ¨çŸ¥è¯†ä¹‹é—´çš„ä¸ä¸€è‡´æ€§ï¼Œä»è€Œå‡è½»LLMsåœ¨æ ¡å‡†è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å¹»è§‰ã€‚ç ”ç©¶æä¾›äº†æœªæ¥ç ”ç©¶çš„å‡ ä¸ªè§è§£ï¼Œå°¤å…¶æ˜¯KCAæ–¹æ³•åœ¨å¤šç§åœºæ™¯ä¸‹çš„å‡ºè‰²è¡¨ç°ï¼Œä»¥åŠå…¶ç®€å•æ€§ä¸æœ‰æ•ˆæ€§çš„ç»“åˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10768v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10768.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/fanqiwan/KCA)</div> |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads**<br><sub>æœºæ„: Princeton University, Together AI, University of Illinois Urbana-Champaign<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªåä¸ºMedusaçš„LLMæ¨ç†åŠ é€Ÿæ¡†æ¶ï¼Œé€šè¿‡å¢åŠ é¢å¤–çš„è§£ç å¤´å¹¶ç”¨æ ‘å½¢æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¹¶è¡Œç”Ÿæˆå¤šä¸ªtokenï¼Œæœ‰æ•ˆå‡å°‘è§£ç æ­¥éª¤æ•°é‡ï¼Œå®ç°äº†å¯¹å¤§æ¨¡å‹æ¨ç†é€Ÿåº¦çš„æ˜¾è‘—æå‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10774v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10774.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **ChatQA: Building GPT-4 Level Conversational QA Models**<br><sub>æœºæ„: NVIDIA<br>ChatQAæ¨¡å‹é€šè¿‡ä¸¤é˜¶æ®µçš„æŒ‡ä»¤å¾®è°ƒç­–ç•¥æ˜¾è‘—æ”¹è¿›äº†å¤šè½®å¯¹è¯å¼é—®ç­”çš„æ•ˆæœï¼Œå°¤å…¶æ˜¯åœ¨ä¸Šä¸‹æ–‡ç†è§£å’Œä¿¡æ¯æ£€ç´¢æ–¹é¢ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10225v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10225.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **Self-Rewarding Language Models**<br><sub>æœºæ„: Meta, NYU  <br>æœ¬æ–‡æå‡ºäº†è‡ªå¥–åŠ±è¯­è¨€æ¨¡å‹ï¼ˆSelf-Rewarding Language Modelsï¼‰ï¼Œæ—¨åœ¨é€šè¿‡è‡ªæˆ‘è®­ç»ƒæ¥é¿å…äººç±»åå¥½æ•°æ®çš„ç“¶é¢ˆï¼Œå¹¶æé«˜æ¨¡å‹çš„è‡ªå¥–åŠ±å’Œæ‰§è¡ŒæŒ‡ä»¤çš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹è¡¨ç°å‡ºè‰²ï¼Œæœ‰æœ›æˆä¸ºè¿ç»­è‡ªæˆ‘æ”¹è¿›æ¨¡å‹çš„å¼€å±±ä¹‹ä½œã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10020v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.1002.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and Visual Question Generation**<br><sub>æœºæ„: The University of Tokyo, RIKEN<br>è¿™é¡¹ç ”ç©¶é€šè¿‡åˆ›æ–°åœ°æ•´åˆä¸€ä¸ªæ˜¾æ€§çš„æ¨ç†è¿‡ç¨‹å’Œç”Ÿæˆé—®é¢˜çš„èƒ½åŠ›åˆ°LMMä¸­ï¼Œä»¥ä¿ƒè¿›æ¨¡å‹è¿›è¡Œæ›´å¯é çš„æ¨ç†ã€‚åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†å¹¶åˆ©ç”¨å®ƒå¯¹æ¨¡å‹è¿›è¡ŒåŸ¹è®­ï¼Œä¸ºä»ŠåLMMçš„è¿›æ­¥è®¾å®šäº†å…ˆä¾‹ï¼Œå¹¶é€šè¿‡è¿™ç§æ–¹å¼ä½¿æ¨¡å‹åœ¨é¢ä¸´ä¸ç¡®å®šæ€§æ—¶èƒ½ç”Ÿæˆæ˜¾æ€§æ¨ç†æ­¥éª¤å’Œæé—®ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10005v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10005.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **A Fast, Performant, Secure Distributed Training Framework For Large Language Model**<br><sub>æœºæ„: Ant Group China<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºæ¨¡å‹åˆ‡ç‰‡çš„å®‰å…¨åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ï¼Œèƒ½åœ¨ä¿è¯æ¨¡å‹è®­ç»ƒç²¾åº¦å’Œé«˜æ•ˆç‡çš„åŒæ—¶ï¼Œè§£å†³äº†æœåŠ¡ç«¯å’Œå®¢æˆ·ç«¯çš„æ¨¡å‹å‚æ•°åŠæ•°æ®æ³„éœ²é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.09796v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.09796.md)  |
| <span style='display: inline-block; width: 42px;'>01-17</span> | **ReFT: Reasoning with Reinforced Fine-Tuning**<br><sub>æœºæ„: ByteDance Research<br>ReFTé€šè¿‡åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–éå¯å¾®ç›®æ ‡ï¼Œæ˜¾è‘—æé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•°å­¦é—®é¢˜æ±‚è§£ä»»åŠ¡ä¸­çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚å®ƒè¶…è¶Šäº†ä¼ ç»Ÿçš„ç›‘ç£å¼å­¦ä¹ æ–¹æ³•ï¼Œå±•ç°äº†åœ¨æ›´å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08967v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08967.md)  |
| <span style='display: inline-block; width: 42px;'>01-17</span> | **LLMs for Relational Reasoning: How Far are We?**<br><sub>æœºæ„: Continental-NTU Corporate Lab, Nanyang Technological University, Singapore<br>æœ¬è®ºæ–‡ä¸»è¦æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å…³ç³»æ¨ç†æ–¹é¢çš„èƒ½åŠ›å’Œå±€é™æ€§ã€‚é€šè¿‡å…¨é¢çš„è¯„ä¼°ï¼ŒåŒ…æ‹¬æ–°æå‡ºçš„æµ‹è¯•æ–¹æ³•å’Œè¯„ä¼°æ¨¡å—ï¼Œå‘ç°LLMsè™½ç„¶åœ¨æŸäº›å…³ç³»æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°ä¸é”™ï¼Œä½†ä¸ä¸“é—¨ä¸ºé€»è¾‘æ¨ç†è®¾è®¡çš„æ¨¡å‹ç›¸æ¯”ï¼Œå…¶æ€§èƒ½ç›¸å¯¹è¾ƒå·®ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.09042v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.09042.md)  |
| <span style='display: inline-block; width: 42px;'>01-17</span> | **Vlogger: Make Your Dream A Vlog**<br><sub>æœºæ„: Shanghai Jiao Tong University, Shanghai AI Laboratory, Shenzhen Institute of Advanced Technology Chinese Academy of Sciences<br>æœ¬è®ºæ–‡é€šè¿‡ä»‹ç»Vloggerç³»ç»Ÿï¼Œå±•ç¤ºäº†ä¸€ä¸ªåˆ›æ–°çš„åŠæ³•å°†LLMsåº”ç”¨äºè§†é¢‘åšå®¢çš„ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä»è€Œå…‹æœäº†ç”Ÿæˆåˆ†é’Ÿçº§è¿è´¯è§†é¢‘å†…å®¹çš„æŒ‘æˆ˜ï¼Œå¹¶å–å¾—äº†ä¼˜å¼‚çš„å®éªŒç»“æœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.09414v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.09414.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/zhuangshaobin/Vlogger)</div> |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **SpecGen: Automated Generation of Formal Program Specifications via Large Language Models**<br><sub>æœºæ„: Nanjing University, Nanyang Technological University, Singapore Management University<br>è®ºæ–‡æå‡ºäº† SpecGenï¼Œä¸€ä¸ªç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹å’Œå¯å‘å¼é€‰æ‹©ç­–ç•¥çš„ç¨‹åºå½¢å¼åŒ–è§„èŒƒè‡ªåŠ¨ç”ŸæˆæŠ€æœ¯ã€‚é€šè¿‡æ¯”è¾ƒä¸ç°æœ‰å·¥å…·å’Œçº¯ LLM æ–¹æ³•ï¼ŒSpecGen è¡¨ç°å‡ºæ›´é«˜æ•ˆå’Œå‡†ç¡®çš„ç”Ÿæˆè§„èŒƒçš„èƒ½åŠ›ï¼Œå¹¶ä¸”æå‡ºäº†æ•°æ®é›†ä¿ƒè¿›åç»­ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08807v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08807.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture**<br><sub>æœºæ„: Microsoft<br>æœ¬æ–‡ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å†œä¸šæ•°æ®ä¸Šç”Ÿæˆé—®ç­”å¯¹çš„æ€§èƒ½ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ–°çš„ç”Ÿæˆç®¡é“ï¼Œæœ‰æ•ˆåœ°ä½¿ç”¨äº†RAGå’Œå¾®è°ƒæŠ€æœ¯å¢å¼ºLLMçš„åº”ç”¨åœºæ™¯ï¼Œæ‹“å±•äº†LLMåœ¨ç‰¹å®šè¡Œä¸šçš„åº”ç”¨æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08406v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08406.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible Pipeline**<br><sub>æœºæ„: Alibaba Group  <br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„æ•°å­¦æ¨ç†æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ä¸Pythonä»£ç è§£é‡Šå™¨ç›¸ç»“åˆï¼Œé€šè¿‡æ”¹è¿›æ•°æ®é›†å¹¶å®æ–½ç‰¹å®šå¾®è°ƒæµç¨‹æ˜¾è‘—æé«˜äº†LLMåœ¨æ•°å­¦é—®é¢˜æ±‚è§£ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08190v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0819.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **Salute the Classic: Revisiting Challenges of Machine Translation in the Age of Large Language Models**<br><sub>æœºæ„: Tencent AI Lab<br>æœ¬æ–‡æ·±å…¥åˆ†æäº†LLMsåœ¨æœºå™¨ç¿»è¯‘ä»»åŠ¡ä¸­é¢†åŸŸä¸åŒ¹é…é—®é¢˜ï¼Œå¹¶å®éªŒäº†ä¸åŒæ•°é‡çš„å¹³è¡Œæ•°æ®å¯¹LLMsç¿»è¯‘èƒ½åŠ›çš„å½±å“ï¼Œå±•ç°å‡ºLLMsåœ¨å¤„ç†è¿™äº›æŒ‘æˆ˜ä¸­çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08350v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0835.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/pangjh3/LLM4MT)</div> |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language Models**<br><sub>æœºæ„:  Zhejiang University<br>DoraemonGPTæ˜¯ä¸€ä¸ªLLMé©±åŠ¨çš„æ™ºèƒ½ä½“ï¼Œé€šè¿‡ç¬¦å·è®°å¿†å’Œå·¥å…·é›†æ¥ç†è§£å¹¶è§£ç­”æ¶‰åŠåŠ¨æ€è§†é¢‘çš„å¤æ‚é—®é¢˜ã€‚å…¶é‡‡ç”¨äº†MCTSè§„åˆ’å™¨ä¼˜åŒ–å›ç­”çš„ç”Ÿæˆè¿‡ç¨‹ï¼Œèƒ½å¤Ÿåœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­å¤„ç†æ›´ä¸ºå¤æ‚çš„ä»»åŠ¡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08392v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08392.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation**<br><sub>æœºæ„: Johns Hopkins University, Microsoft<br>æœ¬è®ºæ–‡æå‡ºäº†CPOï¼Œä¸€ä¸ªæ–°çš„LLMå¾®è°ƒæ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†SFTåœ¨æœºå™¨ç¿»è¯‘ä»»åŠ¡ä¸­å­˜åœ¨çš„ç“¶é¢ˆï¼Œå®ç°äº†åœ¨èµ„æºæ¶ˆè€—æå°‘çš„æƒ…å†µä¸‹æ˜¾è‘—æå‡ä¸­ç­‰è§„æ¨¡LLMç¿»è¯‘æ¨¡å‹çš„æ€§èƒ½ï¼Œæœ€ç»ˆä¸æœ€å…ˆè¿›çš„çŠ¶æ€è‰ºæœ¯ç¿»è¯‘ç³»ç»Ÿé½å¤´å¹¶è¿›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08417v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08417.md)  |
| <span style='display: inline-block; width: 42px;'>01-15</span> | **MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of Large Language Models**<br><sub>æœºæ„: Microsoft Research India<br>è¿™ç¯‡è®ºæ–‡ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€ä»»åŠ¡ä¸Šé€šè¿‡å‚æ•°é«˜æ•ˆå¾®è°ƒåçš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½èµ„æºè¯­è¨€å’Œè‹±è¯­ä»»åŠ¡ä¸Šã€‚ç ”ç©¶å±•ç¤ºäº†PEFTçš„æ½œåŠ›ï¼ŒåŒæ—¶æŒ‡å‡ºäº†æœªæ¥å·¥ä½œçš„ä¸€äº›å¯èƒ½æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07598v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07598.md)  |
| <span style='display: inline-block; width: 42px;'>01-15</span> | **The What, Why, and How of Context Length Extension Techniques in Large Language Models -- A Detailed Survey**<br><sub>æœºæ„: Technology Innovation Institute UAE, Islamic University of Technology Bangladesh, Stanford University, Amazon GenAI, AI Institute University of South Carolina<br>æœ¬è®ºæ–‡æ˜¯å…³äºLLMsä¸Šä¸‹æ–‡é•¿åº¦æ‰©å±•æŠ€æœ¯çš„è¯¦ç»†è°ƒç ”ã€‚å®ƒä¸ºç ”ç©¶äººå‘˜æä¾›äº†è¯¥é¢†åŸŸçš„ç°æœ‰ç­–ç•¥å’ŒæŒ‘æˆ˜çš„æœ‰ç»„ç»‡æ¦‚è§ˆï¼Œå¹¶é¼“åŠ±äº†å¯¹æœªæ¥å‘å±•çš„è®¨è®ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07872v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07872.md)  |
| <span style='display: inline-block; width: 42px;'>01-15</span> | **A Study on Large Language Models' Limitations in Multiple-Choice Question Answering**<br><sub>æœºæ„: David R. Cheriton School of Computer Science<br>è¯¥è®ºæ–‡é’ˆå¯¹LLMsåœ¨MCQä»»åŠ¡ä¸­çš„é™åˆ¶è¿›è¡Œäº†ç ”ç©¶ï¼ŒæŒ‡å‡ºå¤šæ•°æ¨¡å‹åœ¨æ­¤ç±»ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚è®ºæ–‡è¿˜å‘ç°æ¨¡å‹çš„å›ç­”å¾€å¾€ä¾èµ–äºé€‰é¡¹é¡ºåºï¼Œå¹¶æå‡ºäº†æœ‰æ•ˆçš„è¯„ä¼°æ–¹æ³•æ¥æ’é™¤è¿™äº›åè§ã€‚è®ºæ–‡æ¨èåœ¨ä½¿ç”¨MCQè¯„ä¼°LLMsæ—¶è¦æ ¼å¤–å°å¿ƒï¼Œå¹¶æµ‹è¯•æ¨¡å‹æ˜¯å¦çœŸæ­£ç†è§£äº†ä»»åŠ¡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07955v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07955.md)  |
| <span style='display: inline-block; width: 42px;'>01-14</span> | **Small LLMs Are Weak Tool Learners: A Multi-LLM Agent**<br><sub>æœºæ„: Sun Yat-sen University, Alibaba Group<br>ç ”ç©¶è¡¨æ˜å°å‹LLMåœ¨ä½œä¸ºå·¥å…·å­¦ä¹ è€…æ–¹é¢è¾ƒä¸ºè–„å¼±ï¼Œé€šè¿‡å¼•å…¥Î±-UMiå¤šLLMæ¡†æ¶æ¥æ„å»ºæ€§èƒ½æ›´ä¼˜çš„LLMä»£ç†ï¼Œæå‡ºäº†å¿…è¦çš„åŒé˜¶æ®µå¾®è°ƒç­–ç•¥ï¼Œå¹¶æ·±å…¥åˆ†æäº†æ•°æ®è§„æ¨¡æ³•åˆ™ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07324v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07324.md)  |
| <span style='display: inline-block; width: 42px;'>01-13</span> | **Bridging the Preference Gap between Retrievers and LLMs**<br><sub>æœ¬è®ºæ–‡ä»‹ç»äº†BGMæ¡†æ¶ä»¥è§£å†³æ£€ç´¢å™¨å’ŒLLMsä¹‹é—´çš„"åå¥½å·®"é—®é¢˜ï¼Œé€šè¿‡ä¸€ä¸ªåºåˆ—åˆ°åºåˆ—ï¼ˆseq2seqï¼‰çš„æ¡¥æ¨¡å‹ç»“åˆSLå’ŒRLçš„è®­ç»ƒæ–¹æ¡ˆï¼Œä¼˜åŒ–äº†æ£€ç´¢ä¿¡æ¯ä»¥æ»¡è¶³LLMsçš„åå¥½ï¼Œæ”¹è¿›äº†å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡çš„è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06954v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06954.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **TestSpark: IntelliJ IDEA's Ultimate Test Generation Companion**<br><sub>æœºæ„: JetBrains Research, Delft University of Technology<br>è®ºæ–‡æå‡ºäº†TestSparkæ’ä»¶ï¼Œå®ƒç»“åˆäº†åŸºäºæœç´¢çš„è½¯ä»¶æµ‹è¯•ç”Ÿæˆå’ŒåŸºäºè¯­è¨€æ¨¡å‹çš„æµ‹è¯•ç”Ÿæˆæ–¹æ³•ï¼Œåœ¨IntelliJ IDEAä¸­æé«˜äº†å•å…ƒæµ‹è¯•çš„ç”Ÿæˆå’Œé›†æˆæ•ˆç‡ï¼ŒåŒæ—¶è§£å†³äº†LLMç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å¯ç¼–è¯‘æ€§çš„é—®é¢˜ã€‚æ’ä»¶çš„å¼€æºç‰¹æ€§ä½¿å…¶æˆä¸ºè¿æ¥è½¯ä»¶å¼€å‘è€…å’Œç ”ç©¶è€…çš„æ¡¥æ¢ï¼Œæœ‰åŠ©äºæµ‹è¯•ç”ŸæˆæŠ€æœ¯çš„å®ç”¨æ€§è¿›æ­¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06580v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0658.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/JetBrains-Research/TestSpark)</div> |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs**<br><sub>æœºæ„: Virginia Tech, Renmin University of China, UC Davis<br>æœ¬è®ºæ–‡æå‡ºäº†å°†LLMsè§†ä¸ºå…·å¤‡ç±»äººæ²Ÿé€šèƒ½åŠ›çš„å®ä½“ï¼Œåˆ©ç”¨äº†ä¸€ä¸ªæ–°çš„è§†è§’æ¥ç ”ç©¶AIå®‰å…¨é—®é¢˜ã€‚é€šè¿‡å°†åå¤šå¹´çš„ç¤¾ä¼šç§‘å­¦ç ”ç©¶åº”ç”¨äºAIå®‰å…¨ï¼Œåˆ¶å®šäº†ä¸€ä¸ªè¯´æœæŠ€å·§åˆ†ç±»æ³•ï¼Œå¹¶é€šè¿‡åˆ›å»ºçš„å·¥å…·è‡ªåŠ¨ç”Ÿæˆäº†å¯¹æŠ—æ€§æç¤ºã€‚ç»“æœè¡¨æ˜ï¼Œè¯´æœæŠ€å·§å¯ä»¥æœ‰æ•ˆåœ°å¢å¼ºæœ‰é£é™©è¡Œä¸ºè¢«LLMsæ‰§è¡Œçš„å¯èƒ½æ€§ï¼ŒåŒæ—¶æ­ç¤ºäº†å½“å‰é˜²å¾¡æ‰‹æ®µåœ¨åº”å¯¹è¿™ç±»ç­–ç•¥æ—¶çš„ä¸è¶³ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06373v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06373.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **From Automation to Augmentation: Large Language Models Elevating Essay Scoring Landscape**<br><sub>æœºæ„: Tsinghua University, University of Maryland, Beijing Xicheng Educational Research Institute  <br>æœ¬æ–‡çš„ç ”ç©¶å±•ç°äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•™è‚²é¢†åŸŸä¸­ï¼Œç‰¹åˆ«æ˜¯åœ¨AESç³»ç»Ÿä¸­çš„æ½œåŠ›ã€‚LLMsä¸ä»…èƒ½å¤Ÿè‡ªåŠ¨åŒ–è¯„åˆ†è¿‡ç¨‹ï¼Œè¿˜èƒ½å¤Ÿé€šè¿‡ç”Ÿæˆåé¦ˆæ¥å¢å¼ºäººç±»è¯„åˆ†è€…çš„è¡¨ç°ã€‚è¿™ä¸ä»…æ˜¯æŠ€æœ¯ä¸Šçš„è¿›æ­¥ï¼Œæ›´ä¸ºæœªæ¥çš„äººå·¥æ™ºèƒ½è¾…åŠ©æ•™è‚²å’Œäººå·¥æ™ºèƒ½ä¸äººç±»çš„é«˜æ•ˆåä½œæä¾›äº†å®è´µè§è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06431v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06431.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **Kun: Answer Polishment for Chinese Self-Alignment with Instruction Back-Translation**<br><sub>æœºæ„: Tianyu Zheng, Shuyue Guo, Xingwei Qu, Jiawei Guo, Weixu Zhang, Xinrun Du, Chenghua Lin, Wenhao Huang, Wenhu Chen, Jie Fu, Ge Zhang<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†Kunç­–ç•¥ï¼Œè§£å†³äº†ä¸­æ–‡å¤§å‹è¯­è¨€æ¨¡å‹æŒ‡ä»¤å¾®è°ƒä¸­å­˜åœ¨çš„æ•°æ®ä¸€è‡´æ€§é—®é¢˜ï¼Œé€šè¿‡APè¿‡ç¨‹å’Œæ–°çš„æ•°æ®ç”Ÿæˆæ–¹æ³•ï¼Œå‡å°‘äº†å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒKunç­–ç•¥åœ¨åˆ›å»ºé«˜è´¨é‡æ•°æ®é›†æ–¹é¢å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06477v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06477.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Zheng0428/COIG-Kun)</div> |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **Teaching Code LLMs to Use Autocompletion Tools in Repository-Level Code Generation**<br><sub>æœºæ„: Nanyang Technological University, Fudan University<br>è¯¥è®ºæ–‡æˆåŠŸæå‡ºäº†ä¸€ç§æ–°æ–¹æ³•TOOLGENï¼Œé€šè¿‡é›†æˆè‡ªåŠ¨å®Œæˆå·¥å…·åˆ°ä»“åº“çº§ä»£ç ç”Ÿæˆä¸­çš„LLMsï¼Œè§£å†³äº†ä¾èµ–æ€§é—®é¢˜ï¼Œæé«˜äº†ä»£ç ç”Ÿæˆçš„è´¨é‡å’ŒæˆåŠŸç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06391.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models**<br><sub>æœºæ„: University of Washington Seattle, University of Wisconsin-Madison, Stanford University<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªå®éªŒè®¾è®¡æ¡†æ¶ï¼Œä¸ºäº†æé«˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç›‘ç£å¼å¾®è°ƒï¼ˆSFTï¼‰è¿‡ç¨‹ä¸­çš„æ ‡ç­¾æ•ˆç‡ã€‚å®ƒå±•ç¤ºäº†å®éªŒè®¾è®¡æŠ€æœ¯å¯ä»¥åœ¨ç»´æŒä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œå¤§å¹…æé«˜æ ‡ç­¾æ•ˆç‡ï¼Œåœ¨ä¸€äº›ä»»åŠ¡ä¸­ä¸éšæœºé‡‡æ ·ç›¸æ¯”èŠ‚çœäº†50%çš„æ³¨é‡Šæˆæœ¬ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06692v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06692.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **APAR: LLMs Can Do Auto-Parallel Auto-Regressive Decoding**<br><sub>æœºæ„: Tsinghua University, Zhipu AI<br>é€šè¿‡å®æ–½APARï¼Œè¯¥ç ”ç©¶æˆåŠŸæé«˜äº†LLMsåœ¨å†…å­˜å—é™åœºæ™¯å’Œé«˜ååç‡åœºæ™¯ä¸‹çš„è§£ç æ•ˆç‡å’Œç”Ÿæˆé€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆè´¨é‡ï¼Œä¸ºå¤§è¯­è¨€æ¨¡å‹çš„éƒ¨ç½²æä¾›äº†ä¸€ç§æ–°çš„é«˜æ•ˆç­–ç•¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06761v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06761.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **LLM-as-a-Coauthor: The Challenges of Detecting LLM-Human Mixcase**<br><sub>æœºæ„: LAIR Lab Lehigh University, Huazhong University of Science and Technology  <br>æœ¬æ–‡å®šä¹‰äº†æ··åˆåœºæ™¯ä¸­çš„æ··åˆæ–‡æœ¬ï¼ˆmixcaseï¼‰ï¼Œæ„å»ºäº†MIXSETæ•°æ®é›†ï¼Œå¹¶æå‡ºäº†é€šå‘è§£å†³æ··åˆæ–‡æœ¬æ£€æµ‹é—®é¢˜çš„è§è§£å’Œæ–¹å‘ã€‚ç ”ç©¶å‘ç°ï¼Œç°æœ‰çš„æ£€æµ‹å™¨åœ¨è¯†åˆ«æ··åˆæ–‡æœ¬æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œè¿™æå‡ºäº†åˆ¶å®šæ›´ç»†ç²’åº¦æ£€æµ‹å™¨çš„ç´§è¿«éœ€æ±‚ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05952v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05952.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Dongping-Chen/MixSet)</div> |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems**<br><sub>æœºæ„: Zhongguancun Laboratory, Tsinghua University, Institute of Information Engineering Chinese Academy of Sciences<br>æœ¬æ–‡ä¸ºå¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿä¸­çš„é£é™©åˆ†ç±»ã€ç¼“è§£æªæ–½ä»¥åŠè¯„ä¼°æ ‡å‡†æä¾›äº†å…¨é¢çš„æ¦‚è¿°ï¼Œæå‡ºäº†ä¸€ä¸ªæ–°çš„ç³»ç»ŸåŒ–åˆ†ç±»æ¡†æ¶ï¼Œå¸®åŠ©å¼€å‘è€…æ›´å…¨é¢åœ°ç†è§£å’Œå¤„ç†LLMç³»ç»Ÿçš„æ½œåœ¨é£é™©ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05778v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05778.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Improving Large Language Models via Fine-grained Reinforcement Learning with Minimum Editing Constraint**<br><sub>æœºæ„: Gaoling School of Artificial Intelligence, Renmin University of China; School of Information, Renmin University of China; Kuaishou Technology, Beijing China.<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„RLæ–¹æ³•ï¼Œåä¸ºRLMECï¼Œé€šè¿‡ç”Ÿæˆå¼å¥–åŠ±æ¨¡å‹å’Œæœ€å°ç¼–è¾‘æœºåˆ¶ï¼Œä½¿å¤§å‹è¯­è¨€æ¨¡å‹åœ¨RLè®­ç»ƒè¿‡ç¨‹ä¸­å®ç°æ›´ç²¾ç»†çš„ç›‘ç£å’Œè®­ç»ƒçš„ç¨³å®šæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06081v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06081.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RUCAIBox/RLMEC)</div> |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction**<br><sub>æœºæ„: Fudan University, Microsoft Research Asia, Zhejiang University<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºEASYTOOLçš„æ–¹æ³•ï¼Œå¯ä»¥é€šè¿‡ç®€åŒ–å’Œç»Ÿä¸€å·¥å…·æ–‡æ¡£çš„æŒ‡ä»¤æ¥æé«˜LLMåŸºç¡€ä»£ç†åœ¨å·¥å…·ä½¿ç”¨æ–¹é¢çš„è¡¨ç°ï¼Œè§£å†³äº†ç°æœ‰å·¥å…·ä½¿ç”¨ä¸­çš„ä¸ä¸€è‡´æ€§ã€å†—ä½™æ€§å’Œä¸å®Œæ•´æ€§é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06201v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06201.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/microsoft/JARVIS)</div> |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models**<br><sub>æœºæ„: Johns Hopkins University<br>æ­¤ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡ä½¿ç”¨ç®€æ´çš„æ€ç»´é“¾æç¤ºï¼ˆCCoTï¼‰ï¼Œåœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å¯ä»¥å¤§å¹…å‡å°‘æ–‡æœ¬è¾“å‡ºçš„é•¿åº¦ï¼Œè€Œä¸ä¼šå½±å“è§£å†³é—®é¢˜çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05618v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05618.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Chain of History: Learning and Forecasting with LLMs for Temporal Knowledge Graph Completion**<br><sub>æœºæ„: Tsinghua Shenzhen International Graduate School Tsinghua University, School of Computer Science Peking University, Baidu Inc.<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæ—¶é—´çŸ¥è¯†å›¾è°±å®Œæˆçš„æ–¹æ³•ï¼Œé€šè¿‡é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•å’Œç»“åˆç»“æ„ä¿¡æ¯çš„å†å²æ•°æ®å¢å¼ºï¼Œæé«˜äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œæ€§èƒ½ã€‚å®éªŒæ˜¾ç¤ºè¯¥æ–¹æ³•æœ‰æ•ˆåœ°æå‡äº†æ—¶é—´çŸ¥è¯†å›¾è°±é¢„æµ‹çš„ç²¾åº¦ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06072v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06072.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Evidence to Generate (E2G): A Single-agent Two-step Prompting for Context Grounded and Retrieval Augmented Reasoning**<br><sub>æœºæ„: Qatar Computing Research Institute <br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„ã€ç”¨äºæ”¹å–„LLMsåœ¨ä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›çš„å•ä»£ç†åŒæ­¥æç¤ºæ¡†æ¶â€”â€”Evidence to Generate (E2G)ã€‚é€šè¿‡è¦æ±‚LLMsåœ¨ç”Ÿæˆç­”æ¡ˆçš„åŒæ—¶æä¾›è¯æ®ä¸è§£é‡Šï¼ŒE2Gèƒ½å¤Ÿå‡å°‘é”™è¯¯æ¨ç†å¹¶æé«˜æ¨¡å‹åœ¨å¤„ç†å„ç§æ¨ç†ä»»åŠ¡æ—¶çš„å‡†ç¡®åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒE2Gæ–¹æ³•åœ¨å¤šä¸ªæƒ…å¢ƒå¯†é›†å‹è¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°å‡ºè¾ƒCoTæ›´å¥½çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05787v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05787.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models**<br><sub>æœºæ„: Google Research, Tel Aviv University<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºPatchscopesçš„æ¡†æ¶ï¼Œæä¾›äº†ä¸€ç§æ–°çš„æ–¹æ³•å»è§£é‡Šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰éšè—è¡¨ç¤ºä¸­ç¼–ç çš„ä¿¡æ¯ï¼Œå¹¶ä¸”èƒ½å¤Ÿçº æ­£å¤šæ­¥æ¨ç†é”™è¯¯ã€‚Patchscopesä½œä¸ºä¸€ç§é€šç”¨çš„å¯é…ç½®æ¡†æ¶ï¼Œä¸ä»…ç»Ÿä¸€äº†ç°æœ‰çš„è§£é‡Šå·¥å…·ï¼Œå¹¶è§£å†³äº†å®ƒä»¬è‡ªèº«çš„ä¸€äº›ä¸è¶³ï¼ŒåŒæ—¶ä¹Ÿå¼€è¾Ÿäº†æ–°çš„ç ”ç©¶å’Œåº”ç”¨å¯èƒ½æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06102v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06102.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **TOFU: A Task of Fictitious Unlearning for LLMs**<br><sub>æœºæ„: Carnegie Mellon University<br>æ–‡ç« ä¸ºLLMé—å¿˜é—®é¢˜æä¾›äº†æ–°çš„æ•°æ®é›†å’Œè¯„ä¼°æœºåˆ¶ï¼ŒTOFUä»»åŠ¡å±•ç¤ºäº†ç°æœ‰é—å¿˜æŠ€æœ¯çš„ä¸è¶³ï¼Œé¼“åŠ±äº†ç›¸ç»§è€Œæ¥çš„æ”¹è¿›å’Œç ”ç©¶å·¥ä½œã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06121v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06121.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **CASA: Causality-driven Argument Sufficiency Assessment**<br><sub>æœºæ„: Peking University<br>æœ¬è®ºæ–‡ä»‹ç»äº†ä¸€ä¸ªåŸºäºLLMsçš„é›¶æ ·æœ¬å› æœé©±åŠ¨è®ºè¯å……åˆ†æ€§è¯„ä¼°æ¡†æ¶ï¼ˆCASAï¼‰ï¼ŒæˆåŠŸåº”å¯¹äº†æ— è§‚æµ‹æ•°æ®ä¸‹è®ºè¯å……åˆ†æ€§é‡åŒ–å’Œå¹²é¢„çš„éš¾é¢˜ï¼Œå¹¶åœ¨å®é™…åº”ç”¨ä¸­å±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05249v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05249.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/xxxiaol/CASA)</div> |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Attendre: Wait To Attend By Retrieval With Evicted Queries in Memory-Based Transformers for Long Context Processing**<br><sub>æœºæ„: Google Research<br>è®ºæ–‡æˆåŠŸåœ°æå‡ºäº†ä¸€ä¸ªæ–°çš„åŸºäºå†…å­˜çš„è½¬æ¢å™¨æ–¹æ³•ï¼Œé€šè¿‡å­˜å‚¨é©±é€ç­–ç•¥å’ŒATTENDREå±‚ï¼Œæœ‰æ•ˆåœ°å‡å°‘å†…å­˜éœ€æ±‚å¹¶æ”¯æŒåŒå‘æ³¨æ„åŠ›ï¼Œåœ¨é•¿åºåˆ—å¤„ç†ä¸Šè¡¨ç°å‡ºä¸ä¼ ç»Ÿæ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04881v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04881.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks**<br><sub>InfiAgent-DABenchæä¾›äº†ä¸€ä¸ªæ–°é¢–çš„è¯„ä¼°åŸºå‡†ï¼Œè¿™ä¸ä»…æœ‰åŠ©äºè¡¡é‡æ™ºèƒ½ä»£ç†åœ¨æ•°æ®åˆ†æä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¹Ÿæ˜¯æ¢ç´¢å¦‚ä½•æ”¹è¿›å’Œä¼˜åŒ–LLMåœ¨è¿™ä¸€ç‰¹å®šé¢†åŸŸåº”ç”¨çš„é‡è¦ä¸€æ­¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05507v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05507.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/InfiAgent/InfiAgent)</div> |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security**<br><sub>æœºæ„: Tsinghua University, Xiaomi AI Lab<br>è¯¥è®ºæ–‡ä½œä¸ºä¸€é¡¹è°ƒç ”å·¥ä½œï¼Œä»‹ç»äº†ä¸ªäººLLMä»£ç†çš„ç°çŠ¶ã€æŒ‘æˆ˜å’Œæœªæ¥è¶‹åŠ¿ï¼Œå¹¶æå‡ºäº†ä¸€ç§é€šç”¨çš„ç³»ç»Ÿæ¶æ„å’Œæ™ºèƒ½æ°´å¹³å®šä¹‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05459v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05459.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Prompting Large Language Models for Recommender Systems: A Comprehensive Framework and Empirical Analysis**<br><sub>æœºæ„: Renmin University of China, Beijing Key Laboratory of Big Data Management and Analysis Methods, Meituan Group<br>è¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ä¸ªåä¸ºProLLM4Recçš„æ¡†æ¶ï¼Œç³»ç»Ÿåœ°åˆ†æäº†åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä½œä¸ºæ¨èç³»ç»Ÿçš„åŸºç¡€æ¨¡å‹ï¼Œå¹¶é€šè¿‡å®éªŒæµ‹è¯•äº†ä¸åŒæƒ…å†µä¸‹å¯¹LLMsçš„å½±å“ã€‚é€šè¿‡å®è¯åˆ†æï¼Œæ€»ç»“äº†å¯¹æœªæ¥ç ”ç©¶çš„å¯å‘æ€§å‘ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04997v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04997.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk**<br><sub>æœºæ„: AWS AI Labs<br>è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡ªæˆ‘å¯¹è¯ç”Ÿæˆè®­ç»ƒæ•°æ®çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æœ‰æ½œåŠ›æ”¹è¿›ä»»åŠ¡å¯¼å‘å¯¹è¯ä»£ç†çš„æ€§èƒ½ã€‚å°½ç®¡å­˜åœ¨ä¸€äº›é™åˆ¶ï¼Œç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå½“é€‰æ‹©é«˜è´¨é‡å¯¹è¯ä½œä¸ºè®­ç»ƒæ•°æ®æ—¶ï¼Œå¯ä»¥æœ‰æ•ˆæé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚è¿™è¯æ˜äº†åœ¨æ­£ç¡®çš„è®¾ç½®ä¸‹ï¼Œé€šè¿‡è‡ªæˆ‘ç”Ÿæˆæ•°æ®è¿›è¡Œå¾®è°ƒçš„è¯­è¨€æ¨¡å‹ç¡®å®æœ‰æ½œåŠ›å®ç°è‡ªæˆ‘æ”¹è¿›ï¼Œå¹¶æˆä¸ºæ›´å¥½çš„ä»»åŠ¡å¯¼å‘å¯¹è¯ä»£ç†ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05033v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05033.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **AUTOACT: Automatic Agent Learning from Scratch via Self-Planning**<br><sub>æœºæ„: Zhejiang University, Alibaba Group<br>è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåä¸ºAUTOACTçš„æ¡†æ¶ï¼Œå®ƒé€šè¿‡è‡ªæˆ‘æŒ‡å¯¼å’Œè‡ªæˆ‘è§„åˆ’å®ç°è¯­è¨€ä»£ç†çš„è‡ªåŠ¨å­¦ä¹ ï¼Œä»¥åº”å¯¹ä»é›¶å¼€å§‹å­¦ä¹ æ–°ä»»åŠ¡çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºæœ‰æ•ˆçš„æ•°æ®æ‰©å……æ–¹æ³•å’Œé«˜æ•ˆç‡çš„è‡ªåŠ¨ä»£ç†å­¦ä¹ è¿‡ç¨‹ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05268v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05268.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/zjunlp/AutoAct)</div> |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Leveraging Print Debugging to Improve Code Generation in Large Language Models**<br><sub>æœºæ„: Zhejiang University, ByteDance<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨print debuggingæ–¹æ³•æŒ‡å¯¼LLMsè¿›è¡Œä»£ç ç”Ÿæˆå’Œè°ƒè¯•çš„æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨Leetcodeé—®é¢˜é›†ä¸ŠéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨ç®€å•å’Œä¸­ç­‰éš¾åº¦çš„é—®é¢˜ä¸Šã€‚å°½ç®¡åœ¨é«˜éš¾åº¦é—®é¢˜ä¸Šæ•ˆæœæœ‰é™ï¼Œä½†è¿™é¡¹å·¥ä½œä»ç„¶æ˜¯LLMsåœ¨ä»£ç è°ƒè¯•æ–¹é¢çš„ä¸€ä¸ªé‡è¦è¿›æ­¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05319v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05319.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Large Language Models for Robotics: Opportunities, Challenges, and Perspectives**<br><sub>æœºæ„: Northwestern Polytechnical University, University of Georgia, Shaanxi Normal University<br>è®ºæ–‡æå‡ºçš„å¤šæ¨¡æ€GPT-4Væ¡†æ¶ï¼Œç»“åˆè‡ªç„¶è¯­è¨€å¤„ç†å’Œè§†è§‰æ„ŸçŸ¥ï¼Œæœ‰æœ›è§£å†³LLMsåœ¨æœºå™¨äººä»»åŠ¡è§„åˆ’ä¸­é¢å¯¹çš„æŒ‘æˆ˜ã€‚è¿™å¯¹äºç†è§£å’Œå®ç°æ›´é«˜çº§åˆ«çš„äººæœºäº¤äº’å’Œäººå·¥æ™ºèƒ½çš„æœªæ¥å…·æœ‰é‡è¦æ„ä¹‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04334v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04334.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Agent Alignment in Evolving Social Norms**<br><sub>æœºæ„: Fudan University<br>æ­¤è®ºæ–‡æå‡ºäº†ä¸€ä¸ªEvoluationaryAgentæ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å’Œå¢å¼ºå¤§å‹æ™ºèƒ½ä»£ç†åœ¨åŠ¨æ€æŒç»­å˜åŒ–çš„ç¤¾ä¼šè§„èŒƒä¸­çš„è‡ªé€‚åº”æ€§å’Œä¸€è‡´æ€§ã€‚ç ”ç©¶å¼ºè°ƒäº†ä»£ç†åœ¨è¿›åŒ–ä¸­ä¸ç¤¾ä¼šè§„èŒƒå¯¹é½çš„é‡è¦æ€§ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†æ¨¡å‹çš„å¯è¡Œæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04620v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0462.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **The Critique of Critique**<br><sub>æœºæ„: The Hong Kong Polytechnic University, Shanghai Jiao Tong University, Shanghai Artificial Intelligence Laboratory<br>METACRITIQUEæ˜¯é¦–ä¸ªé’ˆå¯¹è‡ªç„¶è¯­è¨€æ‰¹åˆ¤è¿›è¡Œè¯„ä»·çš„æ¡†æ¶ï¼Œå…¶é€šè¿‡ç²¾ç¡®åº¦å’Œå¬å›ç‡çš„åŸåˆ™è¯„ä¼°æ‰¹åˆ¤çš„è´¨é‡ï¼Œå¹¶å®ç°äº†é«˜åº¦çš„å¯è§£é‡Šæ€§å’Œé€æ˜æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04518v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04518.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/GAIR-NLP/MetaCritique)</div> |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search**<br><sub>æœºæ„: Nanyang Technological University Singapore<br>ReCoåˆ©ç”¨LLMsé‡å†™ä»£ç åº“ä¸­çš„ä»£ç ï¼Œé€šè¿‡é£æ ¼è§„èŒƒåŒ–æ˜¾è‘—æé«˜äº†ä»£ç æœç´¢çš„å‡†ç¡®æ€§ï¼Œå¹¶é€šè¿‡æ–°çš„è¯„ä»·æŒ‡æ ‡CSSimé‡åŒ–äº†é£æ ¼çš„å·®å¼‚ï¼Œæ¨åŠ¨äº†ä»£ç æ ·å¼æ ‡å‡†åŒ–çš„ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04514v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04514.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding**<br><sub>æœºæ„: University of California San Diego, Google Cloud AI Research, Google Research<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåˆ›æ–°çš„CHAIN-OF-TABLEæ¡†æ¶ï¼Œé€šè¿‡å°†è¡¨æ ¼æ•°æ®æ˜¾å¼åœ°ç”¨äºæ¨ç†é“¾ï¼ŒåŠ¨æ€åœ°è§„åˆ’å¹¶æ›´æ–°æ“ä½œè¿‡ç¨‹ï¼Œä»è€Œæé«˜äº†LLMsåœ¨åŸºäºè¡¨æ ¼çš„æ¨ç†ä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04398v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04398.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs**<br><sub>æœºæ„: Zhejiang University, Ant Group<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºARALLMçš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†ç±»æ¯”æ¨ç†å’Œå¤šä»»åŠ¡æ¨¡å‹æç‚¼ï¼Œæœ‰æ•ˆä¿ƒè¿›äº†å¤§å‹è¯­è¨€æ¨¡å‹ä»è‡ªç„¶è¯­è¨€ä¸­ç†è§£å¹¶è½¬æ¢ä¸ºç»“æ„åŒ–çš„é€»è¾‘è¯­è¨€çš„èƒ½åŠ›ã€‚é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œéä¸“ä¸šè¥é”€äººå‘˜èƒ½å¤Ÿåˆ©ç”¨è‡ªç„¶è¯­è¨€æ¥é€‰æ‹©ç›®æ ‡ç”¨æˆ·ï¼Œæœ‰æœ›æ”¹å˜ç”¨æˆ·å®šä½å®è·µã€‚è¿™ç§èƒ½åŠ›çš„æå‡ï¼Œä¸ä»…åœ¨è¥é”€åœºæ™¯ä¸­æœ‰å®é™…çš„åº”ç”¨ä»·å€¼ï¼ŒåŒæ—¶ä¹Ÿä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„åŠŸèƒ½æ€§å’Œå®ç”¨æ€§åšå‡ºäº†æœ‰ç›Šçš„æ¢ç´¢ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04319v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04319.md)  |
| <span style='display: inline-block; width: 42px;'>01-08</span> | **MARG: Multi-Agent Review Generation for Scientific Papers**<br><sub>æœºæ„: Northwestern University, The Hebrew University of Jerusalem, Allen Institute for AI<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåˆ›æ–°çš„å¤šä»£ç†è¯„è®ºç”Ÿæˆæ–¹æ³•ï¼ˆMARGï¼‰ï¼Œå¯ä»¥è·¨è¶ŠåŸºç¡€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å¤§å°é™åˆ¶ï¼Œç”Ÿæˆé«˜è´¨é‡çš„ç§‘å­¦è®ºæ–‡åŒè¡Œè¯„å®¡åé¦ˆã€‚é€šè¿‡ç”¨æˆ·ç ”ç©¶å’Œè‡ªåŠ¨åŒ–åº¦é‡ï¼ŒMARGçš„åé¦ˆè´¨é‡å¯¹æ¯”åŸºçº¿æœ‰æ˜¾è‘—æé«˜ï¼Œç”Ÿæˆçš„æœ‰ç”¨è¯„è®ºæ•°é‡æé«˜äº†2.2å€ï¼ŒåŒæ—¶ç”Ÿæˆäº†æ›´åŠ å…·ä½“çš„è¯„è®ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04259v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04259.md)  |
| <span style='display: inline-block; width: 42px;'>01-08</span> | **TTMs: Fast Multi-level Tiny Time Mixers for Improved Zero-shot and Few-shot Forecasting of Multivariate Time Series**<br><sub>æœºæ„: IBM Research<br>TTMå±•ç¤ºäº†ä¸“é—¨é’ˆå¯¹å¤šæ ·åŒ–æ—¶é—´åºåˆ—æ•°æ®è®­ç»ƒçš„å°å‹é¢„è®­ç»ƒæ¨¡å‹åœ¨å¤šå˜é‡æ—¶é—´åºåˆ—é›¶/å°‘æ ·æœ¬é¢„æµ‹ä¸­çš„é«˜æ•ˆæ€§å’Œè½¬ç§»å­¦ä¹ èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03955v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03955.md)  |
| <span style='display: inline-block; width: 42px;'>01-08</span> | **SpeechAgents: Human-Communication Simulation with Multi-Modal Multi-Agent Systems**<br><sub>æœºæ„: Fudan University<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šä»£ç†ç³»ç»Ÿâ€”â€”SpeechAgentsï¼Œå…¶èƒ½æ¨¡æ‹ŸåŒ…å«å¤šè¾¾ 25 åä»£ç†äººçš„äººç±»äº¤æµåœºæ™¯ï¼Œå¹¶å±•ç°å‡ºå“è¶Šçš„å¯æ‰©å±•æ€§ã€‚é€šè¿‡ä½¿ç”¨å¤šæ¨¡æ€ä¿¡å·ä½œä¸ºä»£ç†é—´äº¤æµçš„åª’ä»‹ï¼Œç³»ç»Ÿä¸ä»…å¯ä»¥æ¨¡æ‹Ÿå…·æœ‰æ­£ç¡®å†…å®¹ã€çœŸå®èŠ‚å¥å’Œä¸°å¯Œæƒ…æ„Ÿçš„å¯¹è¯ï¼Œè€Œä¸”è¿˜èƒ½åº”ç”¨äºå¦‚æˆå‰§åˆ›ä½œå’Œæœ‰å£°å°è¯´ç”Ÿæˆç­‰ä»»åŠ¡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03945v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03945.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **Grimoire is All You Need for Enhancing Large Language Models**<br><sub>æœºæ„: Beihang University, Renmin University of China<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºSLEICLçš„æ–¹æ³•ï¼Œé€šè¿‡å¼ºè¯­è¨€æ¨¡å‹å­¦ä¹ ç¤ºä¾‹æŠ€èƒ½å¹¶å°†å…¶è½¬ç§»ç»™å¼±è¯­è¨€æ¨¡å‹ï¼Œæ˜¾è‘—æé«˜äº†å¼±æ¨¡å‹çš„ICLèƒ½åŠ›ã€‚é€šè¿‡å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå±•ç°äº†è¯¥æŠ€æœ¯åœ¨å¢å¼ºå¼±è¯­è¨€æ¨¡å‹ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›æ–¹é¢çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03385v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03385.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **ChatGPT for Conversational Recommendation: Refining Recommendations by Reprompting with Feedback**<br><sub>æœºæ„: University of Louisville, Microsoft<br>è¯¥è®ºæ–‡æ¢ç´¢äº†ChatGPTä½œä¸ºå¯¹è¯æ¨èç³»ç»Ÿçš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡æ„å»ºå›´ç»•ChatGPTçš„æµç¨‹ï¼Œæ¨¡æ‹Ÿç”¨æˆ·å®é™…ä½¿ç”¨æƒ…æ™¯ï¼Œå¹¶å¯¹æµè¡Œåè§è¿›è¡Œäº†ç ”ç©¶å’Œç¼“è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03605v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03605.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects**<br><sub>æœºæ„: The Chinese University of Hong Kong, DeepWisdom, Peking University<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç”¨äºæŒ‡å¯¼æœªæ¥ç ”ç©¶ä¸å¼€å‘çš„åŸºäºLLMçš„æ™ºèƒ½ä»£ç†ç³»ç»Ÿçš„æ¡†æ¶ï¼Œå¹¶æ¢è®¨äº†æé«˜å®ƒä»¬çš„è®¡åˆ’èƒ½åŠ›å’Œå¤šæ¨¡æ€ä¿¡æ¯å¤„ç†èƒ½åŠ›çš„ä¸åŒæ–¹æ³•ï¼Œä»¥åŠå¦‚ä½•è§£å†³LLMä»£ç†æ‰€é¢ä¸´çš„æŒ‘æˆ˜ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›äº†æ¸…æ™°çš„æŒ‡å—ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03428v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03428.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon**<br><sub>æœºæ„: Beijing Academy of Artificial Intelligence, Renmin University of China, Nankai University<br>è¿™ç¯‡æ–‡ç« ä»‹ç»äº†æ¿€æ´»ä¿¡æ ‡è¿™ä¸€èƒ½å¤Ÿæ‰©å±•å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦çš„æ–°æŠ€æœ¯ï¼Œä½¿å¾—æ¨¡å‹èƒ½åœ¨æœ‰é™ä¸Šä¸‹æ–‡çª—å£å†…æ„ŸçŸ¥æ›´å¹¿çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŒæ—¶ä¿ç•™å¯¹çŸ­ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å¤„ç†èƒ½åŠ›ã€‚æ¿€æ´»ä¿¡æ ‡ä»£è¡¨äº†ä¸€ç§æœ‰æ•ˆã€é«˜æ•ˆã€å…¼å®¹ä¸”è®­ç»ƒæˆæœ¬ä½çš„æ–¹æ³•ï¼Œæ¥æ‰©å±•LLMsçš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03462v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03462.md)  |
| <span style='display: inline-block; width: 42px;'>01-06</span> | **CogGPT: Unleashing the Power of Cognitive Dynamics on Large Language Models**<br><sub>æœºæ„: Harbin Institute of Technology, Kuaishou Technology<br>CogGPTé€šè¿‡å¼•å…¥è¿­ä»£è®¤çŸ¥æœºåˆ¶å’Œè®°å¿†ä¿æŒç³»ç»Ÿï¼Œæœ‰æ•ˆåœ°è§£å†³äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨¡ä»¿äººç±»è®¤çŸ¥åŠ¨æ€æ–¹é¢çš„æŒ‘æˆ˜ï¼Œå±•ç¤ºäº†åœ¨è¿ç»­ä¿¡æ¯å¤„ç†ä¸­çš„ä¼˜ç§€è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08438v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08438.md)  |
| <span style='display: inline-block; width: 42px;'>01-06</span> | **Quartet Logic: A Four-Step Reasoning (QLFR) framework for advancing Short Text Classification**<br><sub>æœºæ„: Aerospace Information Research Institute Chinese Academy of Sciences, Key Laboratory of Target Cognition and Application Technology, University of Chinese Academy of Sciences<br>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹çŸ­æ–‡æœ¬åˆ†ç±»ä»»åŠ¡çš„Quartet Logic: A Four-Step Reasoning (QLFR)æ¡†æ¶ï¼Œä»¥åŠä¸€ä¸ªCoTé©±åŠ¨çš„å¤šä»»åŠ¡å­¦ä¹ ï¼ˆQLFR-CMLï¼‰æ–¹æ³•ï¼Œè¿™ä¸¤è€…éƒ½é€šè¿‡å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†é“¾æ¥è§£å†³STCé¢†åŸŸä¸­çš„æŒ‘æˆ˜ã€‚å®éªŒç»“æœè¯æ˜äº†è¿™äº›æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03158v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03158.md)  |
| <span style='display: inline-block; width: 42px;'>01-06</span> | **The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models**<br><sub>æœºæ„: Renmin University of China, UniversitÃ© de MontrÃ©al<br>æœ¬è®ºæ–‡é€šè¿‡ç³»ç»Ÿæ€§å®è¯ç ”ç©¶ï¼Œæ·±å…¥äº†è§£å¹¶æ¢ç´¢å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰é—®é¢˜ï¼Œè¯†åˆ«äº†å¹»è§‰çš„æ¥æºã€æ£€æµ‹æ–¹æ³•å’Œå‡è½»ç­–ç•¥ï¼Œå¹¶æå‡ºäº†æ–°çš„åŸºå‡†HaluEval 2.0å’Œç®€å•æœ‰æ•ˆçš„å¹»è§‰æ£€æµ‹æ¡†æ¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03205v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03205.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RUCAIBox/HaluEval-2.0)</div> |
| <span style='display: inline-block; width: 42px;'>01-05</span> | **From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models**<br><sub>æœºæ„: Beike Inc.<br>æœ¬è®ºæ–‡ä»‹ç»äº†RAISEæ¡†æ¶ï¼Œé€šè¿‡å¢å¼ºè®°å¿†ç³»ç»Ÿå’Œç»“æ„åŒ–çš„ä»£ç†æ„å»ºè¿‡ç¨‹ï¼Œæé«˜äº†LLMsåœ¨å¤šè½®å¯¹è¯ä¸­çš„è¡¨ç°ï¼Œå°¤å…¶æ˜¯åœ¨æˆ¿åœ°äº§é”€å”®æƒ…å¢ƒä¸­ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02777v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02777.md)  |
| <span style='display: inline-block; width: 42px;'>01-05</span> | **Infinite-LLM: Efficient LLM Service for Long Context with DistAttention and Distributed KVCache**<br><sub>æœºæ„: Alibaba Group, Shanghai Jiao Tong University<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªæœ‰æ•ˆæ”¯æŒé•¿ä¸Šä¸‹æ–‡è¯­è¨€æ¨¡å‹äº‘æœåŠ¡çš„ç³»ç»Ÿï¼Œé€šè¿‡åˆ†å¸ƒå¼ç®—æ³•DistAttentionï¼Œä¼˜åŒ–äº†æ³¨æ„åŠ›æ¨¡å—çš„å¤„ç†å’Œå­˜å‚¨ï¼Œå¹¶é€šè¿‡DistKV-LLMæœåŠ¡ç³»ç»Ÿè¿›è¡Œç®¡ç†å’Œåè°ƒï¼Œå®ç°äº†åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­å¯¹èµ„æºçš„é«˜æ•ˆåˆ†é…å’Œç®¡ç†ï¼ŒéªŒè¯äº†å…¶åœ¨æ€§èƒ½ä¸Šçš„æ˜æ˜¾æé«˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02669v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02669.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers**<br><sub>æœºæ„: Bytedance Inc.<br>æœ¬è®ºæ–‡æå‡ºäº†é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸä»»åŠ¡ä¸­æ·±åº¦ä¸å‡†ç¡®æ€§æå‡çš„æ–¹æ³•â€”â€”ICE-GRTã€‚é€šè¿‡ç»“åˆäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ŒICE-GRT åœ¨ä¸ç‰ºç‰²ä¸€èˆ¬æ€§èƒ½çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†ç‰¹å®šé¢†åŸŸçš„èƒ½åŠ›ï¼Œå¹¶åœ¨å¤šé¡¹è¯„ä¼°ä»»åŠ¡ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02072v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02072.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives**<br><sub>æœºæ„: Zhejiang University, OPPO Research Institute<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºâ€œè‡ªæˆ‘å¯¹æ¯”â€çš„æ–°ç­–ç•¥ï¼Œç”¨äºæ”¹å–„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨åæ€å’Œè‡ªæˆ‘ä¿®æ­£è¿‡ç¨‹ä¸­å­˜åœ¨çš„å›ºæ‰§å’Œä¸ä¸€è‡´é—®é¢˜ï¼Œé€šè¿‡åˆ›å»ºå¤šæ ·åŒ–è§£å†³æ–¹æ¡ˆè§†è§’ï¼Œå¯¹æ¯”ä¸åŒè§£å†³æ–¹æ¡ˆçš„å·®å¼‚ï¼Œå¹¶å°†å·®å¼‚æ€»ç»“ä¸ºæ£€æŸ¥æ¸…å•ï¼Œè¿›è€Œæå‡äº†LLMçš„åæ€è´¨é‡ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†è¯¥ç­–ç•¥çš„æ•ˆæœå’Œå¹¿æ³›é€‚ç”¨æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02009v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02009.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **SPEER: Sentence-Level Planning of Long Clinical Summa