<h2 align='center'>llm-paper-daily æ—¥å¸¸è®ºæ–‡ç²¾é€‰</h2>
<div align='center'>

[![Status](https://img.shields.io/badge/status-Update_06.18_10:08-success.svg)]() [![ç®€ä½“ä¸­æ–‡ badge](https://img.shields.io/badge/%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87-Simplified%20Chinese-blue)](./README.md) [![English badge](https://img.shields.io/badge/%E8%8B%B1%E6%96%87-English-blue)](./README_en.md) 

</div>

æ¬¢è¿æ¥åˆ° **llm-paper-daily**! è¿™æ˜¯ä¸€ä¸ªè·å–æœ€æ–°ç ”ç©¶è®ºæ–‡çš„æ¯æ—¥æ›´æ–°å’Œåˆ†ç±»çš„å¹³å°ã€‚å¸Œæœ›ä¸ºçˆ±å¥½è€…æä¾› LLM ç ”ç©¶çš„å‰æ²¿èµ„è®¯ï¼Œè®©æ‚¨æ›´è½»æ¾åœ°äº†è§£è¯¥é¢†åŸŸçš„æœ€æ–°å‘å±•ã€‚

ğŸ“š **æ¯æ—¥æ›´æ–°:** ä»“åº“æ¯å¤©ä¼šå¸¦æ¥æœ€æ–°çš„ LLM ç ”ç©¶ï¼Œå¹¶é™„æœ‰arxivåœ°å€ã€ç›¸å…³ git ä»“åº“å’ŒåŸºäº GPT-4 çš„ç®€å•æ€»ç»“

ğŸ’ **åˆ†ç±»æ‘˜è¦:** å°†æ¯ç¯‡è®ºæ–‡åˆ†ç±»åˆ°å¦‚æ¨ç†ã€ä»£ç†ã€æ£€ç´¢ã€åº”ç”¨ã€é¢„è®­ç»ƒä¸æŒ‡ä»¤å¾®è°ƒç­‰ä¸åŒéƒ¨åˆ†ï¼Œå¸®åŠ©æ‚¨èƒ½è½»æ¾å¯¼èˆªå¹¶å‘ç°ç›¸å…³çš„ç ”ç©¶

ğŸŒˆ **äº¤æµå­¦ä¹ :** æœ€è¿‘å‡†å¤‡æ‹‰ä¸€ä¸ªè®¨è®ºå°ç»„æ–¹ä¾¿å¤§å®¶äº¤æµå’Œäº’ç›¸å­¦ä¹ ã€‚
æ¬¢è¿å¯¹å¤§æ¨¡å‹è½åœ°ã€è®ºæ–‡ç­‰ç­‰æ–¹é¢æœ‰å…´è¶£çš„å°ä¼™ä¼´åŠ å…¥ğŸ™Œ 

<img src='./images/qrcode.JPG' width=15%  alt=/>

## ç›®å½•
- [æœ€æ–°è®ºæ–‡(å«æ€»ç»“)](#æœ€æ–°è®ºæ–‡)
- [åˆ†ç±»](#åˆ†ç±»)
  - [ğŸ’¡ Reasoning](CATEGORIES.md#Reasoning)
  - [ğŸ¤– Agent](CATEGORIES.md#Agent)
  - [ğŸ¦‰ Knowledge and Retrieval](CATEGORIES.md#Knowledge-and-Retrieval)
  - [ğŸ‘©â€ğŸ« Alignment and Hallucination](CATEGORIES.md#Alignment-and-Hallucination)
  - [ğŸ¨ Application](CATEGORIES.md#Application)
  - [ğŸ“ Pre-training and Instruction Fine-tuning](CATEGORIES.md#Pre-training-and-Instruction-Fine-tuning)
  - [ğŸ“„ Survey](CATEGORIES.md#Survey)
<details>
  <summary>æŸ¥çœ‹æ›´æ–°æ–‡ç«  &nbsp;&nbsp;<sub>æ›´æ–°æ—¶é—´: 06æœˆ18æ—¥ 10:08</sub></summary>
<br>

- Test of Time: A Benchmark for Evaluating LLMs on Temporal Reasoning 
- Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing 
</details>

## æœ€æ–°è®ºæ–‡
### 06æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>06-13</span> | **Test of Time: A Benchmark for Evaluating LLMs on Temporal Reasoning**<br><sub>æœºæ„: Google Research, Google DeepMind, Google<br>æœ¬æ–‡å¼•å…¥äº†ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯• ToTï¼Œé€šè¿‡åˆæˆæ•°æ®é›†å’Œä¼—åŒ…ä»»åŠ¡ï¼Œå…¨é¢è¯„ä¼°äº†LLMsåœ¨å„ç§æƒ…å¢ƒä¸­å¯¹æ—¶é—´æ¨ç†èƒ½åŠ›çš„è¡¨ç°ï¼ŒåŒæ—¶æ­ç¤ºäº†è¿™äº›æ¨¡å‹åœ¨æ—¶é—´æ¨ç†æ–¹é¢çš„ä¼˜åŠ¿å’Œä¸è¶³ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.09170v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.0917.md)  |
| <span style='display: inline-block; width: 42px;'>06-12</span> | **Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing**<br><sub>æœºæ„: University of Washington, Allen Institute for AI<br>æœ¬æ–‡æå‡ºäº†MAGPIEï¼Œä¸€ä¸ªè‡ªåˆæˆæ–¹æ³•ç”Ÿæˆå¤§è§„æ¨¡çš„é«˜è´¨é‡å¯¹é½æ•°æ®ï¼Œè¯¥æ–¹æ³•ä¸ä¾èµ–äºäººçš„å‚ä¸æˆ–æç¤ºå·¥ç¨‹ã€‚å®éªŒè¯æ˜ï¼Œä½¿ç”¨MAGPIEå¾®è°ƒçš„æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†ä¸Šå‡æ˜¾ç¤ºå‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†LLMsåœ¨è‡ªåŠ¨æ•°æ®ç”Ÿæˆå’Œå¯¹é½æ–¹é¢çš„æ½œèƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.08464v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.08464.md)  |
| <span style='display: inline-block; width: 42px;'>06-12</span> | **Designing a Dashboard for Transparency and Control of Conversational AI**<br><sub>æœºæ„: Harvard University, Google Research<br>è¿™ç¯‡è®ºæ–‡è‡´åŠ›äºå¢åŠ LLMsåœ¨å¯¹è¯AIç³»ç»Ÿä¸­çš„é€æ˜åº¦ï¼Œå¹¶é€šè¿‡è®¾è®¡ä¸€ä¸ªå¯è§†åŒ–çš„ç”¨æˆ·ç•Œé¢â€”ä¸€ä¸ªä¸èŠå¤©æœºå™¨äººæ¥å£ç›¸é…å¥—çš„çœ‹æ¿â€”å®ç°äº†è¿™ä¸€ç‚¹ã€‚ç”¨æˆ·èƒ½å¤Ÿå®æ—¶çœ‹åˆ°ç³»ç»Ÿçš„å†…éƒ¨ç”¨æˆ·æ¨¡å‹ï¼Œå¹¶å¯ä»¥é€šè¿‡ç•Œé¢æ›´æ”¹è¿™äº›æ¨¡å‹ã€‚åŸºäºç”¨æˆ·åé¦ˆï¼Œçœ‹æ¿è¿˜æœ‰åŠ©äºæ­éœ²å¹¶ä¸”å¯¹æŠ—æ¨¡å‹çš„åè§è¡Œä¸ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.07882v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.07882.md)  |
| <span style='display: inline-block; width: 42px;'>06-12</span> | **TasTe: Teaching Large Language Models to Translate through Self-Reflection**<br><sub>æœºæ„: Harbin Institute of Technology, Tencent Inc<br>æœ¬æ–‡æå‡ºçš„TASTEæ¡†æ¶é€šè¿‡è‡ªæˆ‘åæ€è¿‡ç¨‹æå‡äº†LLMsçš„æœºå™¨ç¿»è¯‘èƒ½åŠ›ï¼Œå®ƒä»£è¡¨äº†åˆ©ç”¨LLMsç¿»è¯‘æ½œåŠ›çš„ä¸€ç§æ–°æ–¹æ³•ï¼Œä¸ºç†è§£å’Œåˆ©ç”¨LLMsçš„å¤æ‚æ¨ç†å’Œè¯­è¨€å»ºæ¨¡èƒ½åŠ›æ ‘ç«‹äº†æ–°çš„å…¸èŒƒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.08434v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.08434.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/YutongWang1216/ReflectionLLMMT)</div> |
| <span style='display: inline-block; width: 42px;'>06-11</span> | **Needle In A Multimodal Haystack**<br><sub>æœºæ„: OpenGVLab, Shanghai AI Laboratory, Fudan University<br>è¯¥è®ºæ–‡æå‡ºäº†MM-NIAHï¼Œé¦–ä¸ªé•¿ç¯‡å¤šæ¨¡æ€æ–‡ä»¶ç†è§£çš„è¯„ä¼°åŸºå‡†ï¼Œæ—¨åœ¨è€ƒéªŒå’Œæå‡MLLMsçš„æ€§èƒ½ã€‚é€šè¿‡ä¸åŒçš„è¯„ä¼°ä»»åŠ¡ï¼Œè®ºæ–‡æŒ‡å‡ºäº†ç°æœ‰MLLMsåœ¨é•¿ç¯‡å¤šæ¨¡æ€æ–‡æ¡£ç†è§£æ–¹é¢çš„å±€é™å’ŒæŒ‘æˆ˜ã€‚è¿›ä¸€æ­¥çš„ï¼Œè¯¥åŸºå‡†ä¸ºMLLMsçš„é•¿ç¯‡å¤šæ¨¡æ€æ–‡æ¡£ç†è§£ç ”ç©¶æä¾›äº†æœ‰æ•ˆçš„å¹³å°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.07230v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.0723.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OpenGVLab/MM-NIAH)</div> |
| <span style='display: inline-block; width: 42px;'>06-10</span> | **Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-Teaching**<br><sub>æœºæ„: The Chinese University of Hong Kong, Tencent AI Lab, Centre for Perceptual and Interactive Intelligence<br>è®ºæ–‡é€šè¿‡å¼•å…¥SELF-TUNINGï¼Œæå‡ºäº†ä¸€ç§æ”¹è¿›LLMé€šè¿‡è‡ªæˆ‘æ•™å­¦è·å–çŸ¥è¯†èƒ½åŠ›çš„æ¡†æ¶ï¼Œå¹¶é€šè¿‡Wiki-Newpages-QAæ•°æ®é›†åœ¨å¤šä¸ªå…³é”®çŸ¥è¯†è·å–ä»»åŠ¡ä¸ŠéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.06326v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.06326.md)  |
| <span style='display: inline-block; width: 42px;'>06-10</span> | **Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies**<br><sub>æœºæ„: Duke University, AWS AI Labs<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªè€ƒè™‘è®¡ç®—é¢„ç®—çš„LLMæ¨ç†ç­–ç•¥è¯„ä¼°æ¡†æ¶ï¼Œå¹¶å±•ç¤ºäº†ç®€å•ç­–ç•¥åœ¨åŒç­‰è®¡ç®—èµ„æºä¸‹å¯è¶…è¶Šå¤æ‚ç­–ç•¥çš„èƒ½åŠ›ã€‚é€šè¿‡æ­ç¤ºè‡ªæˆ‘è¯„ä¼°çš„é‡è¦æ€§ï¼Œä¸ºæ›´åŠ é«˜æ•ˆçš„é¢„ç®—åˆ©ç”¨å’Œæ›´æœ‰æ•ˆç­–ç•¥çš„å¼€å‘å¥ å®šäº†åŸºç¡€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.06461v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.06461.md)  |
| <span style='display: inline-block; width: 42px;'>06-10</span> | **Transforming Wearable Data into Health Insights using Large Language Model Agents**<br><sub>æœºæ„: Google LLC<br>æœ¬è®ºæ–‡é€šè¿‡ä»‹ç»€åä¸ºPHIAçš„å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ç³»ç»Ÿï¼ŒæˆåŠŸåœ°å°†å¯ç©¿æˆ´è®¾å¤‡æ•°æ®è½¬åŒ–ä¸ºä¸ªäººå¥åº·æ´å¯Ÿã€‚PHIAç»“åˆäº†ä»£ç ç”Ÿæˆå’Œä¿¡æ¯æ£€ç´¢å·¥å…·ï¼Œæœ‰æ•ˆè§£å†³äº†ä»å¤§é‡å¥åº·æ•°æ®ä¸­æ´¾ç”Ÿä¸ªæ€§åŒ–å¥åº·æŒ‡å¯¼çš„æŒ‘æˆ˜ã€‚é€šè¿‡å¹¿æ³›çš„äººå·¥å’Œè‡ªåŠ¨åŒ–è¯„ä¼°ï¼Œè¯æ˜äº†è¿™ç§æ–¹æ³•åœ¨å¤„ç†å®é™…å¥åº·é—®é¢˜ä¸Šçš„å‡†ç¡®æ€§å’Œåº”ç”¨å¯èƒ½æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.06464v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.06464.md)  |
| <span style='display: inline-block; width: 42px;'>06-10</span> | **Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning**<br><sub>æœºæ„: University of Washington, MetaAI, Allen Institute for AI<br>HUSKYæ˜¯é¦–ä¸ªç»Ÿä¸€ã€å¼€æºçš„å¤šæ­¥æ¨ç†è¯­è¨€ä»£ç†ï¼Œè§£å†³äº†æˆæœ¬é«˜å’Œæ‰©å±•å›°éš¾çš„é—®é¢˜ï¼Œä¸”åœ¨å¤šä»»åŠ¡ç¯å¢ƒä¸­å–å¾—ä¼˜å¼‚è¡¨ç°ï¼Œå±•ç°äº†å¼€æºè¯­è¨€ä»£ç†çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.06469v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.06469.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/agent-husky/Husky-v1)</div> |
| <span style='display: inline-block; width: 42px;'>06-09</span> | **Do LLMs Exhibit Human-Like Reasoning? Evaluating Theory of Mind in LLMs for Open-Ended Responses**<br><sub>æœºæ„: University of Washington, University of Washington - Bothell<br>æœ¬ç ”ç©¶å¼ºè°ƒäº† LLM åœ¨ç¤¾äº¤æ¨ç†æ–¹é¢çš„ä¸è¶³ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•é€šè¿‡æ•´åˆäººç±»çš„æ„å›¾å’Œæƒ…ç»ªæ¥å¢å¼ºå…¶æœ‰æ•ˆæ€§ã€‚ç ”ç©¶ç»“æœå‡¸æ˜¾äº† LLM ç†è§£äººç±»å¿ƒç†çŠ¶æ€å¹¶åœ¨å¼€æ”¾å¼é—®é¢˜ä¸­è¿›è¡Œç¤¾äº¤æ¨ç†çš„éœ€æ±‚ï¼Œæ ‡æ˜äº†æœªæ¥å‘å±•çš„å…³é”®é¢†åŸŸã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.05659v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.05659.md)  |
| <span style='display: inline-block; width: 42px;'>06-07</span> | **WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild**<br><sub>WILDBENCH ä½œä¸ºä¸€ä¸ªè¯„ä»·åŸºå‡†ï¼Œæä¾›äº†ä¸€ä¸ªç»“åˆäº†çœŸå®ç”¨æˆ·ä»»åŠ¡æŒ‘æˆ˜ã€è‡ªåŠ¨åŒ–æŒ‡æ ‡å’Œè§£é‡Šæ€§æ¸…å•çš„è¯„ä»·æ¡†æ¶ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°å’ŒåŒºåˆ«å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.04770v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.0477.md)  |
| <span style='display: inline-block; width: 42px;'>06-07</span> | **Mixture-of-Agents Enhances Large Language Model Capabilities**<br><sub>æœºæ„: Duke University, Together AI, University of Chicago<br>è¿™ç¯‡è®ºæ–‡é€šè¿‡æå‡ºMixture-of-Agents (MoA) æ–¹æ³•ï¼Œå±•ç¤ºäº†å¦‚ä½•é€šè¿‡ç»“åˆå¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹çš„é›†ä½“ä¸“é•¿æ¥å¢å¼ºå®ƒä»¬åœ¨ç†è§£å’Œç”Ÿæˆè‡ªç„¶è¯­è¨€æ–¹é¢çš„èƒ½åŠ›ã€‚ä½œè€…é€šè¿‡å®éªŒéªŒè¯äº†è¿™ç§æ–¹æ³•å¯ä»¥æ˜¾è‘—æé«˜æ¨¡å‹çš„è¡¨ç°ï¼Œå¹¶åœ¨å¤šä¸ªç«äº‰åŠ›å¾ˆå¼ºçš„åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€æ–°çš„æœ€ä½³æˆç»©ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.04692v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.04692.md)  |
| <span style='display: inline-block; width: 42px;'>06-06</span> | **Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models**<br><sub>æœºæ„: Peking University, UC Berkeley, Stanford University<br>BoTé€šè¿‡ä¸ºLLMsæä¾›ä¸€ä¸ªå­˜å‚¨é«˜å±‚æ¬¡æ€ç»´æ¨¡æ¿çš„meta-bufferï¼Œå¢å¼ºäº†æ¨ç†çš„å‡†ç¡®æ€§ã€æ•ˆç‡å’Œé²æ£’æ€§ï¼Œå…‹æœäº†ç°æœ‰æ–¹æ³•çš„é™åˆ¶ï¼Œå¹¶å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.04271v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.04271.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/YangLing0818/buffer-of-thought-llm)</div> |
| <span style='display: inline-block; width: 42px;'>06-06</span> | **FastGAS: Fast Graph-based Annotation Selection for In-Context Learning**<br><sub>æœºæ„: Department of ECE, University of Virginia<br>è®ºæ–‡æå‡ºçš„FastGASæ–¹æ³•åœ¨é€‰æ‹©ICLå®ä¾‹æ—¶ï¼Œä¸ä»…èƒ½æé«˜å¤šæ ·æ€§å’Œä»£è¡¨æ€§ï¼ŒåŒæ—¶è¿˜æ˜¾è‘—å‡å°‘äº†æ‰€éœ€çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚å®éªŒç»“æœéªŒè¯äº†å…¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„æ•ˆèƒ½å’Œæ•ˆç‡ï¼Œè¯æ˜äº†å…¶ä½œä¸ºä¸€ç§æœ‰æ•ˆçš„å®ä¾‹é€‰æ‹©æ–¹æ³•çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.03730v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.0373.md)  |
| <span style='display: inline-block; width: 42px;'>06-04</span> | **Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models**<br><sub>æœºæ„: Zhejiang University, School of Engineering (Westlake University), Shanghai AI Laboratory<br>æ–‡ç« æå‡ºäº†ä¸€ç§æ–°é¢–çš„åä½œæ–¹æ³•ä»¥è§£å†³è·¨æ–‡æ¡£äº‹ä»¶å…±æŒ‡æ¶ˆè§£ä»»åŠ¡ã€‚é€šè¿‡å°†LLMsçš„æ™®éèƒ½åŠ›ä¸ä»»åŠ¡ç‰¹å®šçš„SLMsç»“åˆï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.02148v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.02148.md)  |
| <span style='display: inline-block; width: 42px;'>06-04</span> | **To Believe or Not to Believe Your LLM**<br><sub>æœºæ„: Google DeepMind<br>æœ¬è®ºæ–‡é‡ç‚¹ç ”ç©´å¹¶æå‡ºäº†ä¸€ä¸ªæ–°çš„ä¿¡æ¯è®ºåº¦é‡æ–¹æ³•ä»¥åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­é‡åŒ–ä¸ç¡®å®šæ€§ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹LLMsç”Ÿæˆå“åº”æ—¶çš„å¹»è§‰ç°è±¡ã€‚è¿™é¡¹ç ”ç©¶ä¸ºå¦‚ä½•è¯†åˆ«å’Œå¤„ç†LLMsä¸­çš„å¹»è§‰æä¾›äº†æ–°çš„ç†è§£å’Œè§£å†³æ–¹æ¡ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.02543v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.02543.md)  |
| <span style='display: inline-block; width: 42px;'>06-03</span> | **Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration**<br><sub>æœºæ„: Beijing Jiaotong University, Alibaba Group<br>Mobile-Agent-v2æ˜¯ä¸€ä¸ªå¤šä»£ç†æ¶æ„ï¼Œèƒ½æœ‰æ•ˆè§£å†³ç§»åŠ¨è®¾å¤‡æ“ä½œä»»åŠ¡ä¸­çš„å¯¼èˆªæŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯ä»»åŠ¡è¿›å±•å’Œç„¦ç‚¹å†…å®¹çš„å¯¼èˆªé—®é¢˜ã€‚é€šè¿‡å¼•å…¥ä¸‰ä¸ªä¸“é—¨çš„ä»£ç†è§’è‰²ï¼Œç›¸è¾ƒäºä¼ ç»Ÿçš„å•ä»£ç†æ¶æ„ï¼Œæ˜¾è‘—æé«˜äº†ä»»åŠ¡å®Œæˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.01014v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.01014.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/X-PLUG/MobileAgent)</div> |
| <span style='display: inline-block; width: 42px;'>06-03</span> | **Self-Improving Robust Preference Optimization**<br><sub>æœºæ„: Cohere<br>SRPOé€šè¿‡åœ¨ç†è®ºä¸Šåˆç†çš„ç¦»çº¿RLHFæ¡†æ¶å†…è¡¨ç°å‡ºå¯¹ä»»åŠ¡å˜åŒ–çš„å¼ºå¤§é²æ£’æ€§ï¼ŒæˆåŠŸåœ°è§£å†³äº†ä¾èµ–ç‰¹å®šä»»åŠ¡çš„é—®é¢˜ï¼Œå¹¶é€šè¿‡éå¯¹æŠ—æ€§ç¦»çº¿æŸå¤±çš„ä¼˜åŒ–æä¾›äº†æ›´ç®€å•çš„è®­ç»ƒå’Œéƒ¨ç½²è¿‡ç¨‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºSRPOåœ¨åŒ…æ‹¬OODè®¾ç½®åœ¨å†…çš„å„ç§ç¯å¢ƒä¸‹ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2406.01660v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-06/2406.0166.md)  |

---

### 05æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>05-31</span> | **Preemptive Answer "Attacks" on Chain-of-Thought Reasoning**<br><sub>æœºæ„: Tsinghua University<br>è®ºæ–‡ç ”ç©¶äº†é¢„å…ˆç­”æ¡ˆå¯¹LLMsæ¨ç†èƒ½åŠ›çš„è´Ÿé¢å½±å“ï¼Œå¹¶æå‡ºäº†å‡è½»å…¶å½±å“çš„ç­–ç•¥ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™äº›ç­–ç•¥ä¸èƒ½å®Œå…¨æŠµæ¶ˆé¢„å…ˆç­”æ¡ˆçš„å½±å“ï¼Œæç¤ºéœ€è¦è¿›ä¸€æ­¥å¢å¼ºCoTçš„é²æ£’æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.20902v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.20902.md)  |
| <span style='display: inline-block; width: 42px;'>05-31</span> | **Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality**<br><sub>æœºæ„: Princeton University, Carnegie Mellon University<br>æœ¬è®ºæ–‡å±•ç¤ºäº†ä¸€ä¸ªå…¨æ–°çš„çŠ¶æ€ç©ºé—´å¯¹å¶æ€§ï¼ˆSSDï¼‰æ¡†æ¶ï¼Œè¿æ¥äº†ç»“æ„åŒ–çš„çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰å’Œæ³¨æ„åŠ›æœºåˆ¶å˜ä½“ã€‚è®ºæ–‡çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬å°†åŸæœ¬é’ˆå¯¹Transformersçš„ç®—æ³•å’Œç³»ç»Ÿä¼˜åŒ–åº”ç”¨åˆ°SSMsä¸Šï¼Œä»¥åŠå¼€å‘äº†ä¸€ç§æ–°çš„SSDç®—æ³•ï¼Œæœ‰æ•ˆæé«˜äº†æ¨¡å‹è®­ç»ƒå’Œæ¨ç†çš„æ•ˆç‡ã€‚Mamba-2æ¶æ„ä½œä¸ºæœ€ç»ˆäº§å“ï¼Œå®ç°äº†ç†æƒ³çš„æ€§èƒ½è¡¨ç°ï¼Œä¸ºæœªæ¥çš„æ·±åº¦å­¦ä¹ æ¨¡å‹è®¾è®¡å’Œä¼˜åŒ–æä¾›äº†æ–°çš„æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.21060v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.2106.md)  |
| <span style='display: inline-block; width: 42px;'>05-30</span> | **Jina CLIP: Your CLIP Model Is Also Your Text Retriever**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.20204v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.20204.md)  |
| <span style='display: inline-block; width: 42px;'>05-30</span> | **Similarity is Not All You Need: Endowing Retrieval Augmented Generation with Multi Layered Thoughts**<br><sub>æœºæ„: Ant Group<br>METRAGæå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡å®ç”¨æ€§å’Œç´§å‡‘æ€§æ€ç»´æ¥è§£å†³ç°æœ‰æ¨¡å‹çš„å±€é™æ€§ï¼Œå¹¶åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæ›´å¥½çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.19893v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.19893.md)  |
| <span style='display: inline-block; width: 42px;'>05-29</span> | **MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.19327v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.19327.md)  |
| <span style='display: inline-block; width: 42px;'>05-29</span> | **LLMs achieve adult human performance on higher-order theory of mind tasks**<br><sub>æœºæ„: Google Research, Google DeepMind, Johns Hopkins University Applied Physics Lab<br>æœ¬è®ºæ–‡å±•ç¤ºäº†LLMsåœ¨é«˜é˜¶ç†è®ºå¿ƒæ™ºï¼ˆToMï¼‰ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯è¯æ˜äº†æŸäº›æ¨¡å‹å¦‚GPT-4èƒ½å¤Ÿåœ¨æŸäº›ä»»åŠ¡ä¸Šè¾¾åˆ°æˆäººæ°´å¹³çš„è¡¨ç°ã€‚é€šè¿‡å¼•å…¥åŸºäºçœŸå®äººç±»æˆäººåŸºå‡†çš„æ–°è¯„æµ‹æŒ‡æ ‡ï¼Œæœ¬ç ”ç©¶æœ‰åŠ©äºæ­ç¤ºå’Œç†è§£LLMsåœ¨å¤æ‚ç¤¾äº¤äº’åŠ¨ä¸­çš„æ½œåŠ›ä¸é™åˆ¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.18870v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.1887.md)  |
| <span style='display: inline-block; width: 42px;'>05-28</span> | **RealitySummary: On-Demand Mixed Reality Document Enhancement using Large Language Models**<br><sub>æœºæ„: University of Calgary<br>æ­¤è®ºæ–‡ä»‹ç»äº†RealitySummaryç³»ç»Ÿï¼Œå®ƒç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹å’Œæ··åˆç°å®æŠ€æœ¯ï¼Œæä¾›äº†ä¸€ä¸ªå³æ—¶çš„é˜…è¯»è¾…åŠ©å·¥å…·ï¼Œå¹¶ä¸”å±•ç°äº†è¿™ç§æŠ€æœ¯åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›å’Œç¡®ç«‹äº†æœªæ¥ç ”ç©¶çš„æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.18620v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.1862.md)  |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models**<br><sub>æœºæ„: The Ohio State University, Stanford University<br>HippoRAGæ˜¯ä¸€ä¸ªå—äººç±»è®°å¿†ç³»ç»Ÿå¯å‘çš„æ–°å‹æ£€ç´¢æ¡†æ¶ï¼Œè§£å†³äº†ä¼ ç»ŸLLMsåœ¨é•¿æœŸè®°å¿†å’ŒçŸ¥è¯†æ•´åˆæ–¹é¢çš„ä¸è¶³ã€‚é€šè¿‡æ¨¡æ‹Ÿäººè„‘ç»“æ„å’Œè¿ä½œæœºåˆ¶ï¼ŒHippoRAGæœ‰æ•ˆåœ°æå‡äº†LLMså¤„ç†å¤æ‚çŸ¥è¯†æ•´åˆä»»åŠ¡çš„èƒ½åŠ›ï¼Œå¹¶ä¸”åœ¨æ•ˆç‡å’Œæ€§èƒ½ä¸Šå‡è¶…è¶Šç°æœ‰æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14831v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14831.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OSU-NLP-Group/HippoRAG)</div> |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **Agent Planning with World Knowledge Model**<br><sub>æœºæ„: Zhejiang University, Zhejiang University - Ant Group Joint Laboratory of Knowledge Graph, National University of Singapore, Alibaba Group<br>æœ¬è®ºæ–‡é€šè¿‡åˆ›å»ºä¸€ä¸ªå‚æ•°åŒ–çš„ä¸–ç•ŒçŸ¥è¯†æ¨¡å‹ (WKM)ï¼Œæ¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ‰§è¡Œäº¤äº’å¼è§„åˆ’ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚è¿™ä¸ªæ¨¡å‹ä½¿ç”¨äº†æ¥è‡ªä¸“å®¶å’Œæ¢ç´¢æ€§è½¨è¿¹çš„çŸ¥è¯†ï¼Œå¹¶é€šè¿‡åœ¨ä»¿çœŸç¯å¢ƒä¸­ä¸å¤šç§å¼ºåŸºå‡†è¿›è¡Œæ¯”è¾ƒï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œå¹¶å¤„ç†äº†ç”Ÿæˆå¹»è§†åŠ¨ä½œå’Œç›²ç›®è¯•é”™çš„é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14205v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14205.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/zjunlp/WKM)</div> |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration**<br><sub>æœºæ„: Tsinghua University, Northwestern Polytechnical University, Shanghai AI Laboratory<br>æœ¬æ–‡é’ˆå¯¹å¤šä»£ç†åˆä½œä»»åŠ¡ä¸­LLMsçš„æœ‰æ•ˆè§„åˆ’æå‡ºäº†ReAdæ¡†æ¶ï¼Œè¯æ˜äº†å…¶é™ä½äº¤äº’æ¬¡æ•°å¹¶æé«˜æˆåŠŸç‡çš„èƒ½åŠ›ï¼Œä¸ºLLMsåœ¨å¤šä»£ç†ç³»ç»Ÿä¸­çš„åº”ç”¨å¥ å®šäº†åŸºç¡€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14314v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14314.md)  |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **RaFe: Ranking Feedback Improves Query Rewriting for RAG**<br><sub>æœºæ„: Zhejiang University, Alibaba Group, Nanjing University<br>RaFeæ˜¯ä¸€ä¸ªæ–°é¢–çš„æŸ¥è¯¢é‡å†™æ¡†æ¶ï¼Œåˆ©ç”¨é‡æ’åºå™¨åé¦ˆæ¥è®­ç»ƒæ¨¡å‹ï¼Œæ— éœ€æ³¨é‡Šï¼Œæ”¯æŒç¦»çº¿å’Œåœ¨çº¿åé¦ˆè®­ç»ƒï¼Œå…·æœ‰è‰¯å¥½çš„æ™®é€‚æ€§å’Œæœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14431v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14431.md)  |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **RefChecker: Reference-based Fine-grained Hallucination Checker and Benchmark for Large Language Models**<br><sub>æœºæ„: Amazon AWS AI, Shanghai AI Lab, Shanghai Jiaotong University<br>REFCHECKERæ˜¯ä¸€ä¸ªç”¨äºæ£€æµ‹LLMsä¸­ç»†ç²’åº¦å¹»è§‰å¹¶è¿›è¡ŒåŸºå‡†æµ‹è¯•çš„æ¡†æ¶ã€‚å…¶é€šè¿‡ä½¿ç”¨claim-tripletsï¼Œèƒ½åœ¨ç»†ç²’åº¦ä¸Šæ£€æµ‹å¹¶éªŒè¯å›åº”ä¸­çš„äº‹å®ä¸€è‡´æ€§ï¼Œæ˜¾è‘—æé«˜äº†æ£€æµ‹çš„ç²¾åº¦å’Œä¸äººç±»åˆ¤æ–­çš„ä¸€è‡´æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14486v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14486.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/amazon-science/RefChecker)</div> |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **PerLLM: Personalized Inference Scheduling with Edge-Cloud Collaboration for Diverse LLM Services**<br><sub>æœºæ„: Institute of Computing Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences<br>æœ¬è®ºæ–‡æå‡ºäº†PerLLMæ¡†æ¶ï¼Œé€šè¿‡è¾¹ç¼˜-äº‘åä½œæ¥å¤„ç†å¤§é‡æ¨ç†æœåŠ¡ï¼Œä¸ä»…ä¼˜åŒ–äº†æœåŠ¡è°ƒåº¦å’Œèµ„æºåˆ†é…ï¼Œè¿˜æ˜¾è‘—æé«˜äº†ååé‡å¹¶é™ä½äº†èƒ½æºæˆæœ¬ï¼Œå…·æœ‰çªå‡ºçš„åº”ç”¨ä»·å€¼ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14636v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14636.md)  |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **AGILE: A Novel Framework of LLM Agents**<br><sub>æœºæ„: ByteDance Research, University of Science and Technology of China, Shanghai Jiao Tong University<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°å‹çš„LLMä»£ç†æ¡†æ¶AGILEï¼Œå®ƒé€šè¿‡æ•´åˆä¸åŒçš„ç»„ä»¶ï¼Œå¹¶é‡‡ç”¨å¼ºåŒ–å­¦ä¹ æ¥å®ç°ç«¯åˆ°ç«¯çš„è®­ç»ƒã€‚è¯¥æ¡†æ¶åœ¨å¤æ‚çš„é—®ç­”ä»»åŠ¡ä¸­å±•ç°å‡ºè¾ƒä¼ ç»ŸLLMç‹¬ç«‹ä½¿ç”¨æ›´ä¼˜çš„æ€§èƒ½ï¼Œå¹¶è¯æ˜äº†ç»„ä»¶æ•´åˆå’Œç«¯åˆ°ç«¯ä¼˜åŒ–çš„æœ‰æ•ˆæ€§ã€‚æ•°æ®é›†å’Œä»£ç å·²å…¬å¼€å‘å¸ƒï¼Œä»¥ä¿ƒè¿›ç›¸å…³é¢†åŸŸçš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.14751v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.14751.md)  |
| <span style='display: inline-block; width: 42px;'>05-21</span> | **G-DIG: Towards Gradient-based DIverse and hiGh-quality Instruction Data Selection for Machine Translation**<br><sub>æœºæ„: ByteDance Research<br>è¯¥è®ºæ–‡ä¸ºè§£å†³LLMsåœ¨æœºå™¨ç¿»è¯‘ä¸­æŒ‡ä»¤å¾®è°ƒæ•°æ®çš„å¤šæ ·æ€§å’Œè´¨é‡é—®é¢˜ï¼Œæå‡ºäº†åŸºäºæ¢¯åº¦çš„æ•°æ®é€‰æ‹©æ–¹æ³•G-DIGï¼Œé€šè¿‡å®éªŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.12915v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.12915.md)  |
| <span style='display: inline-block; width: 42px;'>05-21</span> | **SmartFlow: Robotic Process Automation using LLMs**<br><sub>æœºæ„: TCS Research<br>SmartFlowæ˜¯ä¸€ä¸ªåŸºäºAIçš„RPAç³»ç»Ÿï¼Œå®ƒæ•´åˆäº†æ·±åº¦å­¦ä¹ çš„è§†è§‰ç†è§£ä¸LLMsï¼Œèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆå¯¼èˆªå·¥ä½œæµå¹¶è‡ªä¸»æ‰§è¡Œç”¨æˆ·æŒ‡æ´¾çš„ä»»åŠ¡ï¼Œå±•ç¤ºäº†å…¶åœ¨é€‚åº”GUIå˜åŒ–å’Œå¤„ç†å¤æ‚ä»»åŠ¡ä¸Šçš„é«˜æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.12842v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.12842.md)  |
| <span style='display: inline-block; width: 42px;'>05-20</span> | **Octo: An Open-Source Generalist Robot Policy**<br><sub>æœºæ„: UC Berkeley, Stanford<br>è®ºæ–‡ä»‹ç»äº†Octoï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå˜æ¢å™¨çš„ç­–ç•¥ï¼Œå¯¹å¤šæ ·åŒ–çš„æœºå™¨äººä»»åŠ¡æä¾›å¼€æºçš„è§£å†³æ–¹æ¡ˆï¼Œèƒ½é€šè¿‡å¾®è°ƒé€‚åº”æ–°çš„è§‚æµ‹å’ŒåŠ¨ä½œç©ºé—´ã€‚å®ƒåœ¨å¤šä¸ªæœºå™¨äººå¹³å°ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå¹¶é€šè¿‡å®Œå…¨å¼€æ”¾çš„æºç é¼“åŠ±å¹¿æ³›åº”ç”¨å’Œè¿›ä¸€æ­¥å‘å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.12213v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.12213.md)  |
| <span style='display: inline-block; width: 42px;'>05-20</span> | **xFinder: Robust and Pinpoint Answer Extraction for Large Language Models**<br><sub>æœºæ„: Institute for Advanced Algorithms Research, Shanghai,Renmin University of China<br>è¿™ç¯‡æ–‡ç« çš„é‡ç‚¹æ˜¯æå‡ºä¸€ä¸ªåä¸ºxFinderçš„æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜ä»LLMsè¾“å‡ºä¸­æå–å…³é”®ç­”æ¡ˆçš„å‡†ç¡®åº¦ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•æ— æ³•æ»¡è¶³çš„é¢†åŸŸéœ€æ±‚ï¼Œä¸ºLLMsè¯„ä¼°æä¾›äº†æ›´å¯é çš„æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.11874v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.11874.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/IAAR-Shanghai/xFinder)</div> |
| <span style='display: inline-block; width: 42px;'>05-20</span> | **OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework**<br><sub>æœºæ„: OpenLLMAI Team, ByteDance Inc., Netease Fuxi AI Lab<br>OpenRLHFæ˜¯ä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œå®ƒä½¿å¾—åœ¨70äº¿ä»¥ä¸Šå‚æ•°æ¨¡å‹ä¸Šå®ç°å…¨å°ºåº¦RLHFè®­ç»ƒæˆä¸ºå¯èƒ½ã€‚å®ƒé€šè¿‡Rayåˆ†å¸ƒå¼è®¡ç®—æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨vLLMä¼˜åŒ–æ•ˆç‡ï¼ŒåŒæ—¶å®ç°äº†å¤šç§å¯¹é½ç®—æ³•ï¼Œå¹¶ä¸HuggingFaceåº“æ— ç¼æ•´åˆï¼Œä»è€Œæä¾›å³å¼€å³ç”¨çš„ç”¨æˆ·ä½“éªŒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.11143v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.11143.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OpenLLMAI/OpenRLHF)</div> |
| <span style='display: inline-block; width: 42px;'>05-20</span> | **Multiple-Choice Questions are Efficient and Robust LLM Evaluators**<br><sub>æœºæ„: Shanghai Jiao Tong University<br>è¯¥ç ”ç©¶æˆåŠŸå°†å¸¸è§„çš„å¼€æ”¾å¼ç”Ÿæˆé—®é¢˜è½¬æ¢ä¸ºå¤šé¡¹é€‰æ‹©æ ¼å¼ï¼Œä»¥æé«˜LLMsçš„è¯„ä¼°æ•ˆç‡å’Œå‡†ç¡®åº¦ã€‚è¿™ä¸€æ–¹æ³•åœ¨é˜²æ­¢æ— æ•ˆç­”æ¡ˆçš„å½±å“ã€æé«˜è¯„ä¼°æ•ˆç‡æ–¹é¢å–å¾—äº†çªç ´ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.11966v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.11966.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Geralt-Targaryen/MC-Evaluation)</div> |
| <span style='display: inline-block; width: 42px;'>05-19</span> | **Your Transformer is Secretly Linear**<br><sub>æœºæ„: AIRI, Skoltech, SberAI<br>è¿™é¡¹ç ”ç©¶å±•ç¤ºäº†å˜å‹å™¨ç¼–ç å±‚ä¹‹é—´å¯èƒ½å­˜åœ¨é«˜åº¦çš„çº¿æ€§åŠ¨æ€ï¼Œè¿™ä¸€å‘ç°æ¨ç¿»äº†å˜å‹å™¨ä¸­çº¿æ€§å’Œéçº¿æ€§æ“ä½œçš„ä¼ ç»Ÿç†è§£ï¼Œå¹¶å‘ç°å¯ä»¥åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„æƒ…å†µä¸‹è¿›è¡Œæ¨¡å‹ä¿®æ”¹ä»¥æé«˜æ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.12250v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.1225.md)  |
| <span style='display: inline-block; width: 42px;'>05-17</span> | **Prompt Exploration with Prompt Regression**<br><sub>æœºæ„: Carnegie Mellon University, Massachusetts Institute of Technology, University of Michigan<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶PEPRï¼Œç”¨äºé¢„æµ‹LLMsä¸­æç¤ºå…ƒç´ ç»„åˆçš„å½±å“ï¼Œå¹¶é€‰æ‹©æœ€é€‚ç”¨äºç‰¹å®šä»»åŠ¡çš„æç¤ºã€‚è¯¥æ¡†æ¶ä¸ä»…æå‡ºäº†åˆ›æ–°æ€§çš„è§£å†³æ–¹æ¡ˆï¼Œè¿˜é€šè¿‡åœ¨å¤šä¸ªæ•°æ®é›†å’Œä»»åŠ¡ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.11083v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.11083.md)  |
| <span style='display: inline-block; width: 42px;'>05-16</span> | **Thinking Fair and Slow: On the Efficacy of Structured Prompts for Debiasing Language Models**<br><sub>æœºæ„: BITS Pilani, MDSR Labs, Adobe, IIT Guhawati, National University of Singapore<br>è¿™é¡¹ç ”ç©¶å¼€å‘å¹¶è¯„ä¼°äº†ä¸€ä¸ªé’ˆå¯¹ç«¯åˆ°ç«¯ç”¨æˆ·çš„è¿­ä»£æ¶ˆåæ¡†æ¶ï¼Œè¯¥æ¡†æ¶æä¾›äº†ä¸€ç§éè®­ç»ƒå‹çš„æ¶ˆé™¤LLMsåè§çš„æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•ä½¿ç”¨å¤æ‚çš„promptingç­–ç•¥åœ¨ä¸å‡å°‘ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½çš„å‰æä¸‹æ˜¾è‘—é™ä½äº†è¾“å‡ºçš„å¹³å‡åè§åº¦ï¼Œå¹¶ä¸ºæœªæ¥ç ”ç©¶LLMsçš„prompt-basedæ¶ˆåæ–¹æ³•é“ºå¹³äº†é“è·¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.10431v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.10431.md)  |
| <span style='display: inline-block; width: 42px;'>05-16</span> | **SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation**<br><sub>æœºæ„: Amazon, The University of Texas at Austin<br>SYNTHESIZRRæ˜¯ä¸€ç§æ–°æ–¹æ³•ï¼Œé€šè¿‡æ£€ç´¢å¢å¼ºä¸ºæ•™å¸ˆ-å­¦ç”Ÿè’¸é¦çš„ç¤ºä¾‹åˆæˆé›†æˆäº†è·å–ä¿¡æ¯ã€‚ç ”ç©¶è¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒSYNTHESIZRRç”Ÿæˆçš„æ•°æ®åœ¨å†…åœ¨æ•°æ®å¤šæ ·æ€§å’Œä¸‹æ¸¸ä»»åŠ¡å‡†ç¡®æ€§æ–¹é¢è¡¨ç°æ›´ä½³ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.10040v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.1004.md)  |
| <span style='display: inline-block; width: 42px;'>05-16</span> | **SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation**<br><sub>æœºæ„: Amazon, The University of Texas at Austin<br>SYNTHESIZRRé€šè¿‡æ£€ç´¢å¢å¼ºè§£å†³äº†è¿‡å»åˆæˆæ•°æ®çš„å¤šæ ·æ€§ä¸è¶³å’Œä¸äººç±»æ–‡æœ¬ç›¸å¼‚çš„é—®é¢˜ï¼Œé€šè¿‡æ£€ç´¢ä¸åŒæ–‡æ¡£å’Œå†…å®¹ï¼Œç”Ÿæˆçš„æ ·æœ¬å…·æœ‰æ›´é«˜çš„å¤šæ ·æ€§å’Œæ›´æ¥è¿‘äººç±»æ–‡æœ¬çš„é£æ ¼ï¼Œè¿™æ”¹å–„äº†è’¸é¦æ¨¡å‹çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.10040v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.1004.md)  |
| <span style='display: inline-block; width: 42px;'>05-16</span> | **MarkLLM: An Open-Source Toolkit for LLM Watermarking**<br><sub>æœºæ„: Tsinghua University, Shanghai Jiao Tong University, The University of Sydney<br>MARKLLMä¸ºç ”ç©¶äººå‘˜å’Œå…¬ä¼—æä¾›ä¸€ä¸ªæ˜“äºè®¿é—®å’Œä½¿ç”¨çš„å®éªŒå¹³å°ï¼Œæ—¨åœ¨æé«˜LLMæ°´å°æŠ€æœ¯çš„æ™®åŠåº¦å’Œå‚ä¸åº¦ï¼Œæ¨åŠ¨ç ”ç©¶å’Œåº”ç”¨è¿›ä¸€æ­¥å‘å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.10051v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.10051.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/THU-BPM/MarkLLM)</div> |
| <span style='display: inline-block; width: 42px;'>05-16</span> | **Listen Again and Choose the Right Answer: A New Paradigm for Automatic Speech Recognition with Large Language Models**<br><sub>æœºæ„: Nanyang Technological University, University of Science and Technology of China, University of Aberdeen<br>æœ¬è®ºæ–‡æˆåŠŸæå‡ºå¹¶éªŒè¯äº†ç»“åˆå¤šæ¨¡æ€LLMçš„æ–°ASRé”™è¯¯ä¿®æ­£èŒƒå¼ï¼Œä¸ä»…è§£å†³äº†æºè¯­éŸ³å¿½è§†å’Œè¾“å…¥å†—ä½™çš„é—®é¢˜ï¼Œè¿˜åœ¨å®é™…åº”ç”¨ä¸­å–å¾—äº†æ˜¾è‘—æ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.10025v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.10025.md)  |
| <span style='display: inline-block; width: 42px;'>05-15</span> | **ALPINE: Unveiling the Planning Capability of Autoregressive Learning in Language Models**<br><sub>æœºæ„: Microsoft Research Asia, Harvard University, Peking University<br>ALPINEé¡¹ç›®è€ƒå¯Ÿäº†è‡ªå›å½’å­¦ä¹ å¦‚ä½•ä½¿Transformerå…·å¤‡ç½‘ç»œä¸­çš„è§„åˆ’èƒ½åŠ›ï¼Œå¹¶æ­ç¤ºäº†åœ¨æ‰§è¡Œè·¯å¾„å¯»æ‰¾ä»»åŠ¡ä¸­Transformerçš„è¡¨ç°èƒ½åŠ›åŠå…¶å±€é™æ€§ï¼Œä¸ºæˆ‘ä»¬ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å…¶ä»–ç›¸å…³é¢†åŸŸçš„ä¸€èˆ¬è§„åˆ’èƒ½åŠ›æä¾›äº†æ–°è§è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.09220v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.0922.md)  |
| <span style='display: inline-block; width: 42px;'>05-15</span> | **LoRA Learns Less and Forgets Less**<br><sub>æœºæ„: Columbia University, Databricks<br>LoRAè™½ç„¶åœ¨ç›®æ ‡ä»»åŠ¡çš„å­¦ä¹ æ•ˆç‡å’Œç²¾ç¡®åº¦æ–¹é¢é€šå¸¸ä¸å¦‚å…¨å‚æ•°å¾®è°ƒï¼Œä½†åœ¨ä¿æŒæºä»»åŠ¡æ€§èƒ½æ–¹é¢å±•ç°äº†æ›´å¥½çš„è¡¨ç°å’Œæ›´å¼ºçš„æ­£åˆ™åŒ–èƒ½åŠ›ã€‚æ ¹æ®æœ¬æ–‡ç ”ç©¶ï¼Œå¯¹ä½¿ç”¨LoRAåšå¾®è°ƒæ—¶çš„æœ€ä½³å®è·µåšå‡ºäº†å»ºè®®ï¼Œå°¤å…¶æ³¨æ„åˆ°å­¦ä¹ ç‡ã€ç›®æ ‡æ¨¡å—é€‰æ‹©å’Œæ‰°åŠ¨çš„ç§©ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.09673v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.09673.md)  |
| <span style='display: inline-block; width: 42px;'>05-14</span> | **Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Intent Resolution in LLMs**<br><sub>æœºæ„: Carnegie Mellon University, Allen Institute for AI  <br>æœ¬ç ”ç©¶é€šè¿‡å¼•å…¥ä¸€ä¸ªå…¨æ–°çš„ç”Ÿæˆæ€§è¯„ä¼°æ¡†æ¶ï¼Œæ¢ç´¢äº†LLMsåœ¨ç†è§£å’Œç”Ÿæˆä¸æ„å›¾å¯¹é½çš„å›åº”æ–¹é¢çš„æ½œåŠ›å’ŒæŒ‘æˆ˜ï¼Œæ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨è¯­ç”¨ç†è§£æ–¹é¢çš„ä¸è¶³ï¼Œå¹¶æŒ‡å‡ºäº†æœªæ¥æå‡æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.08760v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.0876.md)  |
| <span style='display: inline-block; width: 42px;'>05-13</span> | **RLHF Workflow: From Reward Modeling to Online RLHF**<br><sub>æœºæ„: Salesforce AI Research, University of Illinois Urbana-Champaign  <br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå®Œæ•´çš„åœ¨çº¿è¿­ä»£ RLHF å·¥ä½œæµç¨‹ï¼Œä¸ä»…ç†è®ºä¸Šåˆ›æ–°ï¼Œè¿˜é€šè¿‡è¯¦ç»†çš„å®è·µå®ç°æŒ‡å—æä¾›äº†å®é™…åº”ç”¨çš„æ¡†æ¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.07863v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.07863.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RLHFlow/RLHF-Reward-Modeling)</div> |
| <span style='display: inline-block; width: 42px;'>05-13</span> | **DoLLM: How Large Language Models Understanding Network Flow Data to Detect Carpet Bombing DDoS**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.07638v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.07638.md)  |
| <span style='display: inline-block; width: 42px;'>05-10</span> | **A Survey on RAG Meets LLMs: Towards Retrieval-Augmented Large Language Models**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.06211v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.06211.md)  |
| <span style='display: inline-block; width: 42px;'>05-10</span> | **UniDM: A Unified Framework for Data Manipulation with Large Language Models**<br><sub>æœºæ„: Alibaba Group, University of Science and Technology of China<br>UniDMæ˜¯ä¸€ä¸ªåˆ›æ–°çš„ç»Ÿä¸€æ•°æ®æ“ä½œæ¡†æ¶ï¼Œé€šè¿‡æœ‰æ•ˆçš„æç¤ºè®¾è®¡ä¸æ­¥éª¤åˆ†è§£ï¼Œæ˜¾è‘—æé«˜äº†å¤„ç†å¤šç§æ•°æ®ä»»åŠ¡çš„æ•ˆç‡å’Œè´¨é‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.06510v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.0651.md)  |
| <span style='display: inline-block; width: 42px;'>05-10</span> | **Automatic Generation of Model and Data Cards: A Step Towards Responsible AI**<br><sub>æœºæ„: CMU, MPI, ETH ZÃ¼rich<br>è®ºæ–‡æˆåŠŸå¼€å‘äº†ä¸€ç§ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è‡ªåŠ¨åŒ–ç”Ÿæˆæœºå™¨å­¦ä¹ æ¨¡å‹å¡ç‰‡å’Œæ•°æ®å¡ç‰‡çš„æ–¹æ³•ï¼Œå¹¶é€šè¿‡åˆ›å»ºç›¸åº”çš„æ•°æ®é›†å’Œè¯„ä¼°æœºåˆ¶ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆæ–‡æ¡£çš„è´¨é‡å’Œæ ‡å‡†åŒ–ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.06258v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.06258.md)  |
| <span style='display: inline-block; width: 42px;'>05-10</span> | **Mitigating Hallucinations in Large Language Models via Self-Refinement-Enhanced Knowledge Retrieval**<br><sub>æœºæ„: Imperial College London, Huawei<br>è¿™é¡¹å·¥ä½œé€šè¿‡ä¸€ä¸ªæ–°çš„è‡ªæˆ‘å®Œå–„å¢å¼ºçš„çŸ¥è¯†å›¾è°±æ£€ç´¢æ–¹æ³•æœ‰æ•ˆåœ°å‡å°‘äº†å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰ç°è±¡ï¼Œå°¤å…¶æé«˜äº†åœ¨åŒ»ç–—é¢†åŸŸä¸­çš„åº”ç”¨å®æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.06545v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.06545.md)  |
| <span style='display: inline-block; width: 42px;'>05-10</span> | **Value Augmented Sampling for Language Model Alignment and Personalization**<br><sub>VASä¸ºLLMçš„é€‚é…å’Œä¸ªæ€§åŒ–æä¾›äº†ä¸€ä¸ªé«˜æ•ˆä¸”å¼ºå¤§çš„æ–¹æ³•ã€‚å®ƒå…‹æœäº†ç°æœ‰RLç®—æ³•çš„ä¸ç¨³å®šæ€§ï¼Œå®ç°äº†é«˜æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡çš„åŒé‡ä¼˜åŠ¿ï¼ŒåŒæ—¶æ”¯æŒé»‘ç›’æ¨¡å‹çš„é€‚åº”ï¼Œä¸ºæœªæ¥çš„LLMä¸ªæ€§åŒ–å’Œå¯¹é½å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.06639v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.06639.md)  |
| <span style='display: inline-block; width: 42px;'>05-09</span> | **LLMPot: Automated LLM-based Industrial Protocol and Physical Process Emulation for ICS Honeypots**<br><sub>æœºæ„: New York University Abu Dhabi  <br>LLMPotæ˜¯ä¸€ç§åˆ›æ–°çš„ICSç½‘ç»œå®‰å…¨é˜²å¾¡å·¥å…·ï¼Œå…¶åˆ©ç”¨LLMçš„èƒ½åŠ›ï¼Œé€šè¿‡è‡ªåŠ¨åŒ–ç”Ÿæˆä¸åè®®å’Œç‰©ç†è¿‡ç¨‹ç´§å¯†ç›¸å…³çš„å“åº”ï¼Œæ˜¾è‘—æé«˜äº†èœœç½çš„å®ç”¨æ€§å’Œæ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05999v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05999.md)  |
| <span style='display: inline-block; width: 42px;'>05-09</span> | **Exploring the Potential of Human-LLM Synergy in Advancing Qualitative Analysis: A Case Study on Mental-Illness Stigma**<br><sub>CHALETæ–¹æ³•æ¡†æ¶å±•ç¤ºäº†äººç±»-LLM åä½œåœ¨å®šæ€§ç ”ç©¶ä¸­çš„å·¨å¤§æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨æ·±åŒ–ç†è§£å’Œæ´è§ç”Ÿæˆæ–¹é¢ï¼Œä¸ºæœªæ¥çš„HCIå’Œå®šæ€§åˆ†æç ”ç©¶æä¾›äº†æ–°æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05758v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05758.md)  |
| <span style='display: inline-block; width: 42px;'>05-09</span> | **An Automatic Prompt Generation System for Tabular Data Tasks**<br><sub>æœ¬è®ºæ–‡æˆåŠŸå¼€å‘äº†ä¸€ä¸ªæ—¢é€‚åº”å¤šç§LLMsåˆæ— éœ€å¹¿æ³›è®­ç»ƒçš„è‡ªåŠ¨æç¤ºç”Ÿæˆç³»ç»Ÿï¼Œé€šè¿‡ä¸¤ç§åˆ›æ–°æ–¹æ³•æ˜¾è‘—æé«˜äº†å¤„ç†è¡¨æ ¼æ•°æ®ä»»åŠ¡çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05618v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05618.md)  |
| <span style='display: inline-block; width: 42px;'>05-09</span> | **Can large language models understand uncommon meanings of common words?**<br><sub>æœºæ„: Tsinghua University, Chinese Academy of Science<br>æœ¬ç ”ç©¶é€šè¿‡å»ºç«‹æ–°çš„è¯„ä¼°ä½“ç³»å’Œæ•°æ®é›†ï¼Œæ­ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç†è§£å¸¸è§è¯æ±‡çš„ç½•è§å«ä¹‰æ–¹é¢å­˜åœ¨çš„é‡å¤§ä¸è¶³ï¼Œä¸ºæé«˜æ¨¡å‹çš„NLUèƒ½åŠ›æä¾›äº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05741v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05741.md)  |
| <span style='display: inline-block; width: 42px;'>05-08</span> | **"They are uncultured": Unveiling Covert Harms and Social Threats in LLM Generated Conversations**<br><sub>æœºæ„: University of Washington, MBZUAI<br>è¿™é¡¹ç ”ç©¶é€šè¿‡åˆ›æ–°çš„CHASTè¯„ä¼°ä½“ç³»ï¼Œæ­ç¤ºäº†LLMsåœ¨å¤„ç†æ¶µç›–å¹¿æ³›æ–‡åŒ–å’Œèº«ä»½çš„å¤æ‚ç¤¾ä¼šäº’åŠ¨ä¸­å¯èƒ½å¯¼è‡´çš„æ½œåœ¨ä¼¤å®³ï¼Œå¼ºè°ƒäº†åœ¨éƒ¨ç½²è¿™äº›æ¨¡å‹ä¹‹å‰è¿›è¡Œå½»åº•çš„åè§å®¡è®¡çš„å¿…è¦æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05378v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05378.md)  |
| <span style='display: inline-block; width: 42px;'>05-08</span> | **Air Gap: Protecting Privacy-Conscious Conversational Agents**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05175v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05175.md)  |
| <span style='display: inline-block; width: 42px;'>05-08</span> | **ADELIE: Aligning Large Language Models on Information Extraction**<br><sub>æœºæ„: Tsinghua University<br>æœ¬æ–‡æå‡ºçš„ADELIEæ¨¡å‹æœ‰æ•ˆåœ°è§£å†³äº†LLMåœ¨ä¿¡æ¯æå–ä»»åŠ¡ä¸­çš„å¯¹é½é—®é¢˜ï¼Œå¹¶é€šè¿‡åˆ›æ–°çš„æ•°æ®é›†å’Œè®­ç»ƒæ–¹æ³•æå‡äº†æ¨¡å‹åœ¨è¿™äº›ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼ŒåŒæ—¶ç»´æŠ¤äº†è‰¯å¥½çš„é€šç”¨èƒ½åŠ›ï¼Œä¸ºæœªæ¥ç›¸å…³ç ”ç©¶æä¾›äº†æœ‰ä»·å€¼çš„è§è§£å’ŒåŸºç¡€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.05008v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.05008.md)  |
| <span style='display: inline-block; width: 42px;'>05-07</span> | **Toward In-Context Teaching: Adapting Examples to Students' Misconceptions**<br><sub>æœºæ„: MIT CSAIL  <br>æœ¬è®ºæ–‡æˆåŠŸå±•ç¤ºäº†åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œé€‚åº”æ€§æ•™å­¦çš„æ½œåŠ›ï¼Œå¹¶é€šè¿‡ATOMæ¨¡å‹å®ç°äº†å¯¹å­¦ç”Ÿè¯¯è§£çš„æœ‰æ•ˆè¯†åˆ«å’Œæ•™å­¦åé¦ˆçš„ä¼˜åŒ–ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.04495v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.04495.md)  |
| <span style='display: inline-block; width: 42px;'>05-07</span> | **QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving**<br><sub>æœºæ„: MIT, NVIDIA<br>é€šè¿‡æ–°çš„é‡åŒ–ç®—æ³•å’Œç³»ç»Ÿè®¾è®¡ï¼ŒQServeæ˜¾è‘—æå‡äº†LLMåœ¨GPUä¸Šçš„æœåŠ¡æ•ˆç‡ï¼Œå®ç°äº†æˆæœ¬çš„å¤§å¹…åº¦é™ä½ï¼Œä¸ºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„éƒ¨ç½²æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.04532v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.04532.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/mit-han-lab/qserve)</div> |
| <span style='display: inline-block; width: 42px;'>05-07</span> | **Deception in Reinforced Autonomous Agents: The Unconventional Rabbit Hat Trick in Legislation**<br><sub>æœºæ„: Center for Responsible AI, IIT Madras, Princeton University  <br>è®ºæ–‡æœ‰æ•ˆåœ°å±•ç¤ºäº†ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„è‡ªæ²»ä»£ç†åœ¨ç›®æ ‡å¯¼å‘ç¯å¢ƒä¸­æ‰§è¡Œå¤æ‚ä»»åŠ¡ï¼ˆå¦‚ç«‹æ³•æ¸¸è¯´ï¼‰æ—¶çš„æ¬ºéª—èƒ½åŠ›ï¼Œå¹¶æå‡ºäº†æ£€æµ‹è¿™ç§æ¬ºéª—è¡Œä¸ºçš„æœ‰æ•ˆæ–¹æ³•ã€‚è¿™äº›å‘ç°ä¸ºAIåœ¨æ³•å¾‹å’Œé“å¾·æ–¹é¢çš„åº”ç”¨æä¾›äº†é‡è¦çš„è§è§£ï¼ŒåŒæ—¶ä¹Ÿä¸ºAIå®‰å…¨æä¾›äº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.04325v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.04325.md)  |
| <span style='display: inline-block; width: 42px;'>05-07</span> | **Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application**<br><sub>æœºæ„: Kuaishou Technology, Southeast University<br>æœ¬è®ºæ–‡æˆåŠŸåœ°å°†å¤§å‹è¯­è¨€æ¨¡å‹çš„å¼€æ”¾ä¸–ç•ŒçŸ¥è¯†åº”ç”¨äºæ¨èç³»ç»Ÿï¼Œé€šè¿‡ä¸€ä¸ªåˆ›æ–°çš„åŒå¡”ç»“æ„è§£å†³äº†å®é™…åº”ç”¨ä¸­çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œä¸ºæå‡æ¨èç³»ç»Ÿçš„æ€§èƒ½æä¾›äº†æ–°çš„æ€è·¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.03988v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.03988.md)  |
| <span style='display: inline-block; width: 42px;'>05-06</span> | **MARE: Multi-Agents Collaboration Framework for Requirements Engineering**<br><sub>æœºæ„: Peking University<br>è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåˆ›æ–°çš„å¤šä»£ç†åˆä½œæ¡†æ¶ï¼ŒMAREï¼Œç”¨äºåœ¨æ•´ä¸ªéœ€æ±‚å·¥ç¨‹è¿‡ç¨‹ä¸­åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¹‹é—´çš„åˆä½œã€‚å®ƒé’ˆå¯¹REä¸­è‡ªåŠ¨åŒ–ä»»åŠ¡çš„å±€é™æ€§è¿›è¡Œäº†æ”¹è¿›ï¼Œå¹¶é€šè¿‡å¤§è§„æ¨¡å®éªŒçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒMAREåœ¨éœ€æ±‚å»ºæ¨¡å’Œè§„æ ¼ç”Ÿæˆæ–¹é¢ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.03256v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.03256.md)  |
| <span style='display: inline-block; width: 42px;'>05-06</span> | **Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning**<br><sub>æœºæ„: East China Normal University<br>RECIPEæ–¹æ³•é€šè¿‡è½¬æ¢çŸ¥è¯†é™ˆè¿°ä¸ºè¿ç»­æç¤ºç¬¦å¹¶ç»“åˆçŸ¥è¯†å“¨å…µæ¥åŠ¨æ€ç®¡ç†æ£€ç´¢è¿‡ç¨‹ï¼Œæœ‰æ•ˆæé«˜äº†LLMsåœ¨ç”Ÿå‘½å‘¨æœŸå­¦ä¹ åœºæ™¯ä¸­çš„ç¼–è¾‘æ•ˆç‡å’Œæ¨æ–­é€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹æ•´ä½“æ€§èƒ½ã€‚è¿™ç§æ–¹æ³•å…‹æœäº†ä»¥å‰æ–¹æ³•çš„ç¼ºç‚¹ï¼Œå¹¶åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸­è¡¨ç°å‡ºè‰²ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.03279v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.03279.md)  |
| <span style='display: inline-block; width: 42px;'>05-03</span> | **What matters when building vision-language models?**<br><sub>æœºæ„: Hugging Face, Sorbonne UniversitÃ©  <br>æœ¬æ–‡é€šè¿‡å¹¿æ³›çš„å®éªŒæ¢è®¨äº†å½±å“VLMsæ€§èƒ½çš„å…³é”®è®¾è®¡é€‰æ‹©ï¼Œæå‡ºäº†Idefics2è¿™ä¸€é«˜æ•ˆçš„åŸºç¡€è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå¹¶åœ¨å¤šä¸ªæ ‡å‡†æµ‹è¯•ä¸­è¯æ˜äº†å…¶ä¼˜è¶Šæ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.02246v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.02246.md)  |
| <span style='display: inline-block; width: 42px;'>05-02</span> | **Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models**<br><sub>æœºæ„: KAIST AI, LG AI Research, Carnegie Mellon University<br>PROMETHEUS 2æ˜¯ä¸€ä¸ªæ–°å‹çš„å¼€æºè¯„ä¼°LMï¼Œèƒ½åœ¨ç›´æ¥è¯„ä¼°å’Œæˆå¯¹æ’åä¸¤ç§æ ¼å¼ä¸‹å·¥ä½œï¼Œå¹¶ä¸”åœ¨è‡ªå®šä¹‰è¯„ä»·æ ‡å‡†ä¸Šä¸äººç±»è¯„åˆ†å’Œä¸“æœ‰LMsçš„åˆ¤æ–­å¯†åˆ‡ç›¸å…³ã€‚è¯¥æ¨¡å‹é‡‡ç”¨æƒé‡åˆå¹¶çš„æ–¹å¼è®­ç»ƒï¼Œæ€§èƒ½æ˜¾è‘—è¶…è¿‡å…¶ä»–å¼€æºæ¨¡å‹å’ŒæŸäº›ä¸“æœ‰æ¨¡å‹ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.01535v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.01535.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/prometheus-eval/prometheus-eval)</div> |
| <span style='display: inline-block; width: 42px;'>05-02</span> | **How Can I Get It Right? Using GPT to Rephrase Incorrect Trainee Responses**<br><sub>æœºæ„: Carnegie Mellon University<br>è¯¥è®ºæ–‡ç ”ç©¶äº†åˆ©ç”¨GPT-4æ„å»ºä¸€ä¸ªè‡ªåŠ¨åŒ–åé¦ˆç³»ç»Ÿæ¥å¸®åŠ©ä¸€å¯¹ä¸€èŠ‚è¯¾ä¸­å¯¼å¸ˆçš„è®­ç»ƒï¼Œæ—¨åœ¨å‡è½»ä¼ ç»Ÿæä¾›ä¸ªæ€§åŒ–æ•™å­¦åé¦ˆçš„èµ„æºè´Ÿæ‹…ï¼ŒåŒæ—¶æä¾›é«˜è´¨é‡å’Œå…·ä½“æ€§çš„åé¦ˆï¼Œæ˜¯çŸ¥è¯†æ£€ç´¢ä¸è¯„ä¼°ç±»çš„ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00970v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.0097.md)  |
| <span style='display: inline-block; width: 42px;'>05-01</span> | **"I'm Not Sure, But...": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust**<br><sub>æœºæ„: Princeton University, Microsoft<br>è¯¥è®ºæ–‡é€šè¿‡å¤§è§„æ¨¡å®éªŒç ”ç©¶è¡¨æ˜ï¼ŒLLMsé€šè¿‡è‡ªç„¶è¯­è¨€æ¥è¡¨è¾¾ä¸ç¡®å®šæ€§ï¼Œå¯ä»¥å‡å°‘ç”¨æˆ·çš„è¿‡åº¦ä¾èµ–ï¼Œå¹¶æé«˜ä»»åŠ¡å¤„ç†çš„å‡†ç¡®åº¦ã€‚å°¤å…¶æ˜¯ç¬¬ä¸€äººç§°è¡¨è¾¾å½¢å¼å¯¹æé«˜ç”¨æˆ·çš„å‡†ç¡®æ€§æ•ˆæœæ˜¾è‘—ã€‚æ­¤å¤–ï¼Œè¿™é¡¹ç ”ç©¶è¿˜å¼ºè°ƒåœ¨å®é™…åº”ç”¨LLMsä¹‹å‰ï¼Œè¿›è¡Œç”¨æˆ·æµ‹è¯•ä»¥è°ƒæ•´ä¸ç¡®å®šæ€§çš„è¡¨è¾¾æ–¹å¼çš„é‡è¦æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00623v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.00623.md)  |
| <span style='display: inline-block; width: 42px;'>05-01</span> | **The Real, the Better: Aligning Large Language Models with Online Human Behaviors**<br><sub>æœºæ„: Baidu Inc.<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„å¤§å‹è¯­è¨€æ¨¡å‹å¯¹é½æ¡†æ¶RLHBï¼Œå®ƒé€šè¿‡åˆ©ç”¨çœŸå®çº¿ä¸Šäººç±»è¡Œä¸ºåˆ›æ–°æ€§åœ°å¯¹LLMsè¿›è¡Œè°ƒæ•´å’Œä¼˜åŒ–ï¼Œå…‹æœäº†ç°æœ‰æ–¹æ³•ä¸­çš„å±€é™æ€§ï¼Œå¹¶é€šè¿‡å®éªŒæœ‰æ•ˆåœ°éªŒè¯äº†å…¶æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00578v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.00578.md)  |
| <span style='display: inline-block; width: 42px;'>05-01</span> | **A Careful Examination of Large Language Model Performance on Grade School Arithmetic**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00332v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.00332.md)  |
| <span style='display: inline-block; width: 42px;'>05-01</span> | **Can a Hallucinating Model help in Reducing Human "Hallucination"?**<br><sub>æœºæ„: Stanford University, UC Berkeley<br>æœ¬æ–‡æ¢è®¨äº†å¦‚ä½•ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¥æ£€æµ‹å’Œå¯¹æŠ—æ— æ ¹æ®ä¿¡å¿µï¼Œä»¥åŠåˆ©ç”¨LLMsä½œä¸ºä¸ªæ€§åŒ–çš„é”™è¯¯ä¿¡æ¯é©³æ–¥ä»£ç†ã€‚ç ”ç©¶è€…æå‡ºäº†è¯„ä¼°å¹¶åˆ©ç”¨LLMsåœ¨è¯†åˆ«é€»è¾‘é™·é˜±æ–¹é¢çš„èƒ½åŠ›ï¼Œå¹¶æŒ‘æˆ˜äººç±»æ— æ ¹æ®ä¿¡å¿µçš„æ–°æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00843v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.00843.md)  |
| <span style='display: inline-block; width: 42px;'>05-01</span> | **Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing with Llama-3**<br><sub>æœ¬ç ”ç©¶å¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹ç¼–è¾‘æŠ€æœ¯è¿›è¡Œäº†å®è¯åˆ†æï¼Œæ­ç¤ºäº†ä»¥å¾€æ–¹æ³•çš„æ½œåœ¨ä¸è¶³ï¼Œå¹¶ä¸ºæœªæ¥çš„æ¨¡å‹ç¼–è¾‘æ–¹æ³•æå‡ºäº†æ–°æ–¹å‘å’Œæ€è·¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00664v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-05/2405.00664.md)  |

---

### 04æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Iterative Reasoning Preference Optimization**<br><sub>æœºæ„: FAIR at Meta, New York University<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§è¿­ä»£æ¨ç†åå¥½ä¼˜åŒ–æ–¹æ³•ï¼Œé€šè¿‡åœ¨æ¨ç†ä»»åŠ¡ä¸Šåº”ç”¨åå¥½ä¼˜åŒ–ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹CoTæ¨ç†ï¼Œå¹¶é€šè¿‡åœ¨è¿­ä»£è®­ç»ƒä¸­å¼•å…¥NLLæŸå¤±é¡¹æ¥æå‡æ¨¡å‹æ€§èƒ½ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ•°æ¬¡è¿­ä»£åèƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨ç†æ€§èƒ½ï¼Œæœ€ç»ˆè¾¾åˆ°æ€§èƒ½é¥±å’Œã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19733v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19733.md)  |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Multi-hop Question Answering over Knowledge Graphs using Large Language Models**<br><sub>æœºæ„: Microsoft<br>è®ºæ–‡åœ¨å¤šè·³é—®ç­”ä»»åŠ¡ä¸­æå‡ºé’ˆå¯¹ä¸åŒçš„çŸ¥è¯†å›¾è°±æ•°æ®é›†é‡‡ç”¨ä¸åŒç­–ç•¥ï¼Œå±•ç¤ºäº†åˆ©ç”¨å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹åœ¨è¿™äº›å¤æ‚é—®ç­”ä»»åŠ¡ä¸­çš„å¼ºå¤§èƒ½åŠ›ã€‚é€šè¿‡å®éªŒï¼ŒéªŒè¯äº†æ‰€ææ–¹æ³•ç›¸æ¯”ç°æœ‰æŠ€æœ¯çš„ä¼˜åŠ¿ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19234v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19234.md)  |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Better & Faster Large Language Models via Multi-token Prediction**<br><sub>æœºæ„: FAIR at Meta<br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹çš„æ–¹æ³•ï¼Œé€šè¿‡é¢„æµ‹å¤šä¸ªæ ‡è®°è€Œä¸æ˜¯å•ä¸ªæ¥æé«˜æ ·æœ¬æ•ˆç‡ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•æå‡ç”Ÿæˆä»»åŠ¡ä¸­çš„æ€§èƒ½å¹¶åŠ å¿«æ¨ç†é€Ÿåº¦ã€‚å®éªŒè¯æ˜äº†è¿™ç§æ–¹æ³•åœ¨æå‡å¤§å‹æ¨¡å‹æ€§èƒ½å’Œæ¨ç†æ•ˆç‡æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19737v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19737.md)  |
| <span style='display: inline-block; width: 42px;'>04-30</span> | **Do Large Language Models Understand Conversational Implicature -- A case study with a chinese sitcom**<br><sub>æœºæ„: Shanghai Jiao Tong University<br>è¯¥ç ”ç©¶é€šè¿‡åˆ›å»ºä¸€ä¸ªæ–°çš„ä¸­æ–‡å¤šè½®å¯¹è¯æ•°æ®é›†SwordsmanImpè¯„ä¼°LLMsç†è§£è¨€å¤–ä¹‹æ„çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠå¤§é‡ä¸Šä¸‹æ–‡å’Œè½®æ¢çš„å¯¹è¯ä¸­ï¼Œå¹¶æ­ç¤ºäº†LLMsåœ¨ç†è§£å’Œè§£é‡Šéå­—é¢å«ä¹‰æ—¶çš„æŒ‘æˆ˜å’Œå±€é™ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.19509v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.19509.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/sjtu-compling/llm-pragmatics)</div> |
| <span style='display: inline-block; width: 42px;'>04-29</span> | **Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models**<br><sub>æœºæ„: Cohere<br>è¯¥è®ºæ–‡å‘å±•äº†ä¸€ç§ä»¥æˆå‘˜æ¥è‡ªä¸åŒæ¨¡å‹å®¶æ—çš„å°å‹æ¨¡å‹ç»„ç»‡æˆçš„â€œè¯„å®¡å›¢â€æ¥è¯„ä¼°LLMç”Ÿæˆç‰©çš„æ–°æ–¹æ³•ï¼Œç§°ä¸ºPoLLï¼Œæ˜¾ç¤ºå‡ºåœ¨ä¸åŒä»»åŠ¡ä¸­çš„é€‚ç”¨æ€§ä»¥åŠæˆæœ¬æ•ˆç‡ï¼Œå‡å°‘äº†LLMsä½œä¸ºè¯„åˆ¤æ—¶å­˜åœ¨çš„åè§é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.18796v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.18796.md)  |
| <span style='display: inline-block; width: 42px;'>04-29</span> | **LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report**<br><sub>æœºæ„: Predibase<br>æœ¬æ–‡æå‡ºé€šè¿‡LoRAå¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œç»†åŒ–ï¼Œå¯ä»¥æ˜æ˜¾æå‡æ¨¡å‹çš„æ•´ä½“è¡¨ç°ï¼Œé™ä½åœ¨åˆ†ç±»ä»»åŠ¡ä¸­å‡ºç°çš„è¯¯å·®ï¼Œä¸”ä¸å¼€ç®±å³ç”¨çš„GPT-4å’ŒGPT-3.5ç›¸æ¯”ï¼Œæœ‰æ˜¾è‘—æé«˜ã€‚åŒæ—¶ï¼Œè®ºæ–‡è¿˜è€ƒè™‘äº†æˆæœ¬é™åˆ¶ï¼Œé€šè¿‡é™åˆ¶è¯„ä¼°æ ·æœ¬çš„æ•°é‡æ¥é™ä½ä½¿ç”¨LLM APIçš„è´¢åŠ¡è´Ÿæ‹…ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2405.00732v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2405.00732.md)  |
| <span style='display: inline-block; width: 42px;'>04-26</span> | **When to Trust LLMs: Aligning Confidence with Response Quality**<br><sub>æœºæ„: Alibaba Group<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªé€šè¿‡å¼ºåŒ–å­¦ä¹ å¯¹é½ä¿¡å¿ƒå’Œå›ç­”è´¨é‡çš„æ–¹æ³•ï¼ˆCONQORDï¼‰ã€‚è¯¥æ–¹æ³•åœ¨æ²¡æœ‰å®¢è§‚å®é™…æ ‡å‡†çš„æƒ…å†µä¸‹é€šè¿‡è‡ªæˆ‘è¯„ä¼°æ¥ä¼˜åŒ–ä¿¡å¿ƒæ°´å¹³ï¼Œå¹¶èƒ½å¤Ÿå‡å°‘åè§ï¼Œæå‡äº†æ¨¡å‹é¢„æµ‹çš„å‡†ç¡®æ€§å’Œå¯¹é½æ€§ï¼Œä½†ä»éœ€å¯¹æ¯”ç»©æ•ˆæ›´é«˜çš„æ–¹æ³•è¿›è¡Œæ”¹è¿›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.17287v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.17287.md)  |
| <span style='display: inline-block; width: 42px;'>04-26</span> | **A Comprehensive Evaluation on Event Reasoning of Large Language Models**<br><sub>æœºæ„: Peking University, Advanced Institute of Big Data, Beihang University<br>æœ¬æ–‡é€šè¿‡å¼•å…¥ä¸€ä¸ªåä¸ºEV2çš„æ–°åŸºå‡†æµ‹è¯•æ¥å…¨é¢è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„äº‹ä»¶æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè™½ç„¶LLMsæ‹¥æœ‰äº‹ä»¶æ¨ç†èƒ½åŠ›ï¼Œä½†ä¸äººç±»åœ¨è¿ç”¨äº‹ä»¶æ¨¡å¼çŸ¥è¯†æ–¹é¢å¹¶ä¸ä¸€è‡´ï¼Œé€šè¿‡æä¾›æ˜ç¡®çš„æŒ‡å¯¼ï¼Œå¯ä»¥å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°ç†è§£å’Œæ‰§è¡Œäº‹ä»¶æ¨ç†ä»»åŠ¡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.17513v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.17513.md)  |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16621v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16621.md)  |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **Layer Skip: Enabling Early Exit Inference and Self-Speculative Decoding**<br><sub>æœºæ„: Meta, University of Toronto, Carnegie Mellon University<br>LayerSkipæ˜¯ä¸€ä¸ªæ–°é¢–çš„ç«¯åˆ°ç«¯è§£å†³æ–¹æ¡ˆï¼Œèƒ½å¤Ÿåœ¨ä¸ç‰ºç‰²å‡†ç¡®ç‡çš„æƒ…å†µä¸‹æ˜¾è‘—åŠ é€Ÿå¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œå…·æœ‰å®é™…åº”ç”¨ä»·å€¼å’Œæ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16710v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.1671.md)  |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **Continual Learning of Large Language Models: A Comprehensive Survey**<br><sub>æœºæ„: Rutgers University, Wuhan University, Huazhong University of Science and Technology<br>æœ¬ç»¼è¿°ä¸ºLLMsçš„æŒç»­å­¦ä¹ æä¾›äº†ä¸€ä¸ªå…¨é¢çš„è§†è§’ï¼Œç‰¹åˆ«å¼ºè°ƒäº†è¿ç»­é¢„è®­ç»ƒï¼ˆCPTï¼‰å’Œé¢†åŸŸè‡ªé€‚åº”é¢„è®­ç»ƒï¼ˆDAPï¼‰çš„ç ”ç©¶é¢†åŸŸã€‚å¼ºè°ƒç¤¾åŒºéœ€æ›´å¤šå…³æ³¨ï¼Œç‰¹åˆ«æ˜¯å¼€å‘å®ç”¨ã€æ˜“äºè·å–ä¸”å¹¿æ³›è®¤å¯çš„è¯„ä¼°åŸºå‡†æ–¹é¢ï¼Œä»¥åŠéœ€è¦é’ˆå¯¹æ–°å…´LLMså­¦ä¹ èŒƒå¼ç‰¹åˆ«è®¾è®¡çš„æ–¹æ³•è®ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16789v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16789.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Wang-ML-Lab/llm-continual-learning-survey)</div> |
| <span style='display: inline-block; width: 42px;'>04-25</span> | **How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites**<br><sub>æœºæ„: Shanghai AI Laboratory, SenseTime Research, Tsinghua University<br>InternVL 1.5æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¼€æºå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼Œè‡´åŠ›äºå¼¥è¡¥å¼€æºå’Œå•†ä¸šæ¨¡å‹åœ¨å¤šæ¨¡æ€ç†è§£æ–¹é¢çš„æ€§èƒ½å·®è·ã€‚è¯¥æ¨¡å‹çš„ä¼˜åŠ¿åŒ…æ‹¬æ”¹å–„è§†è§‰ç†è§£ã€å¤„ç†åŠ¨æ€é«˜åˆ†è¾¨ç‡å›¾åƒä»¥åŠé«˜è´¨é‡çš„åŒè¯­æ•°æ®é›†çš„ä½¿ç”¨ï¼Œè¿™äº›å®ƒåœ¨å¤šé¡¹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16821v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16821.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OpenGVLab/InternVL)</div> |
| <span style='display: inline-block; width: 42px;'>04-24</span> | **Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs**<br><sub>æœºæ„: Shanghai Jiao Tong University, UC San Diego, Duke University<br>æœ¬æ–‡ç« æ˜¯å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­Chain-of-X (CoX) æ–¹æ³•çš„è¯¦å°½è°ƒç ”ï¼Œç€é‡äºå°†Chain-of-Thought (CoT) çš„æ¦‚å¿µæ‰©å±•è‡³æ›´å¹¿æ³›çš„åº”ç”¨ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ½œåœ¨çš„å‘å±•æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.15676v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.15676.md)  |
| <span style='display: inline-block; width: 42px;'>04-24</span> | **From Local to Global: A Graph RAG Approach to Query-Focused Summarization**<br><sub>æœºæ„: Microsoft Research, Microsoft Strategic Missions and Technologies, Microsoft Office of the CTO<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†Graph RAGæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ä»¥å›¾è°±ç´¢å¼•å’ŒLLMç”Ÿæˆæ‘˜è¦ä¸ºåŸºç¡€çš„æŸ¥è¯¢èšç„¦æ‘˜è¦æŠ€æœ¯ï¼Œæ—¨åœ¨å¤„ç†å› è¯­æ–™é‡è¿‡å¤§è€Œè¶…å‡ºå¤§å‹è¯­è¨€æ¨¡å‹å¤„ç†èƒ½åŠ›çš„é—®é¢˜ã€‚é€šè¿‡ç¤¾åŒºæ£€æµ‹ç®—æ³•çš„å¸®åŠ©ï¼Œè¯¥æ–¹æ³•èƒ½åœ¨å¤„ç†å…¨å±€æ€§é—®é¢˜å¹¶å®ç°å¤§è§„æ¨¡æ–‡æœ¬åˆ†ææ–¹é¢å–å¾—æ˜¾è‘—æˆæ•ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16130v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.1613.md)  |
| <span style='display: inline-block; width: 42px;'>04-23</span> | **A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications**<br><sub>æœºæ„: Hong Kong Baptist University<br>æœ¬æ–‡æ˜¯ä¸€ä¸ªç»¼è¿°æ€§ç ”ç©¶ï¼Œä¸»è¦è°ƒæŸ¥äº†åœ¨å›¾æ•°æ®ä¸Šä½¿ç”¨çš„LLMsç ”ç©¶ï¼Œæ¢è®¨äº†LLMsåœ¨å›¾ä»»åŠ¡æ³›åŒ–æ–¹é¢çš„ä¼˜åŠ¿ï¼Œå¹¶æå‡ºäº†åœ¨è¯¥é¢†åŸŸè¿›è¡Œç ”ç©¶çš„æœªæ¥æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14809v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14809.md)  |
| <span style='display: inline-block; width: 42px;'>04-23</span> | **CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies**<br><sub>æœºæ„: Stanford University, IBM Research<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç”¨äºæ„å»ºæ–‡åŒ–çŸ¥è¯†åº“çš„é€šç”¨æµæ°´çº¿ï¼Œå¹¶ä½¿ç”¨è¯¥æµæ°´çº¿åˆ›å»ºäº†CultureBankï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«TikTokå’ŒRedditä¸Šæ–‡åŒ–æè¿°ç¬¦çš„çŸ¥è¯†åº“ã€‚è®ºæ–‡è¿˜é€šè¿‡è¿™ä¸ªçŸ¥è¯†åº“è¯„ä¼°äº†LLMsåœ¨æ–‡åŒ–æ„è¯†æ–¹é¢çš„è¡¨ç°ï¼Œå¹¶ç”¨äºè®­ç»ƒæ›´å…·æ–‡åŒ–æ„è¯†çš„è¯­è¨€æ¨¡å‹ï¼Œä»¥æ­¤ä¿ƒè¿›æœªæ¥è¯­è¨€æŠ€æœ¯çš„æ–‡åŒ–æ„è¯†å‘å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.15238v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.15238.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/SALT-NLP/CultureBank)</div> |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **A Survey on Self-Evolution of Large Language Models**<br><sub>æœºæ„: Peking University, Alibaba Group, Nanyang Technological University<br>è¿™ç¯‡ç»¼è¿°æ–‡ç« æå‡ºå¹¶æ€»ç»“äº†LLMsçš„è‡ªæˆ‘è¿›åŒ–æ–¹æ³•ï¼Œä¸ºæ¨åŠ¨è‡ªæˆ‘è¿›åŒ–çš„ç ”ç©¶æä¾›äº†æ¦‚å¿µæ¡†æ¶å’Œæœªæ¥æ–¹å‘çš„è§è§£ï¼Œæ—¨åœ¨æ¨åŠ¨ä¸‹ä¸€ä»£è‡ªæˆ‘è¿›åŒ–LLMsçš„å‘å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14387v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14387.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph**<br><sub>æœºæ„: University of California San Diego, Carnegie Mellon University, University of Pennsylvania<br>ç ”ç©¶è€…æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç”¨äºæ„å»ºç»†ç²’åº¦ä¸»å¼ ä¾èµ–å›¾(FLANå›¾)çš„ç®—æ³•ï¼Œè¯¥ç®—æ³•åœ¨å¤§è§„æ¨¡ä¸Šæ˜¾è‘—æ”¹å–„äº†ç°çŠ¶ï¼Œå¹¶å¯¹ç°ä»£LLMsåœ¨ä¸“åˆ©æ‰¹å‡†é¢„æµ‹ä¸Šçš„åº”ç”¨è¿›è¡Œäº†å¹¿æ³›å®éªŒå’Œåˆ†æï¼Œå‘ç°äº†LLMsçš„å±€é™æ€§ï¼Œå¹¶ä¸ºæœªæ¥LLMæ–¹æ¡ˆçš„å¼€å‘æä¾›äº†æœ‰ä»·å€¼çš„å‚è€ƒã€‚æºä»£ç å’Œæ•°æ®é›†å·²å…¬å¼€å‘å¸ƒä»¥ä¿ƒè¿›æœªæ¥çš„ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14372v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14372.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **Information Re-Organization Improves Reasoning in Large Language Models**<br><sub>æœºæ„: Zhejiang University<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„ä¿¡æ¯é‡ç»„æ–¹æ³•ï¼ˆInfoREï¼‰ï¼Œé€šè¿‡é‡ç»„ä¸Šä¸‹æ–‡å†…å®¹æ¥æ­ç¤ºé€»è¾‘å…³ç³»ï¼Œä»è€Œå¢å¼ºLLMsçš„æ¨ç†èƒ½åŠ›ã€‚æ–¹æ³•åœ¨é›¶æ¬¡å°„å‡»è®¾ç½®ä¸‹å¯¹LLMsè¿›è¡Œä¸Šä¸‹æ–‡ç†è§£çš„å¤šè·³æ¨ç†ä»»åŠ¡æµ‹è¯•ï¼Œå–å¾—äº†æ˜¾è‘—æ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.13985v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.13985.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/hustcxx/InfoRE)</div> |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **A Survey on Efficient Inference for Large Language Models**<br><sub>æœºæ„: Tsinghua University<br>æœ¬æ–‡æä¾›äº†ä¸€ä¸ªå…¨é¢çš„ç»¼è¿°å…³äºæé«˜å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†æ•ˆç‡çš„æ–‡çŒ®ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªåŒ…å«æ•°æ®å±‚ã€æ¨¡å‹å±‚å’Œç³»ç»Ÿå±‚ä¼˜åŒ–çš„åˆ†ç±»æ³•ã€‚åŒæ—¶ï¼Œé€šè¿‡å®éªŒå¯¹å…³é”®æŠ€æœ¯è¿›è¡Œäº†é‡åŒ–æ¯”è¾ƒï¼ŒæŒ‡å‡ºäº†ç ”ç©¶çš„æœªæ¥æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14294v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14294.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **SnapKV: LLM Knows What You are Looking for Before Generation**<br><sub>æœºæ„: University of Illinois Urbana-Champaign, Cohere, Princeton University<br>è¯¥æ–‡ç« ä»‹ç»äº†SnapKVï¼Œä¸€ç§é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å…³é”®å€¼ç¼“å­˜é—®é¢˜çš„æ–°æ–¹æ³•ã€‚SnapKVé€šè¿‡æ™ºèƒ½å‹ç¼©å’Œé€‰å–é‡è¦çš„KVä½ç½®ï¼Œæœ‰æ•ˆåœ°æå‡äº†é•¿æ–‡æœ¬å¤„ç†æ—¶çš„è§£ç é€Ÿåº¦å’Œå†…å­˜æ•ˆç‡ï¼Œå¹¶åœ¨ä¿æŒå‡†ç¡®æ€§çš„åŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14469v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14469.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **LLMs Know What They Need: Leveraging a Missing Information Guided Framework to Empower Retrieval-Augmented Generation**<br><sub>æœºæ„: Meituan<br>æœ¬æ–‡æå‡ºçš„MIGRESæ¡†æ¶æ˜¯é€šè¿‡Exploiting LLMsè¯†åˆ«ç¼ºå¤±ä¿¡æ¯çš„èƒ½åŠ›æ¥å¢å¼ºRAGçš„èƒ½åŠ›ã€‚ç ”ç©¶ç»“æœè¯æ˜äº†MIGRESåœ¨å¤šä¸ªå…¬å…±æ•°æ®é›†ä¸Šå…·æœ‰ä¼˜è¶Šæ€§ï¼Œåº”å¯¹äº†RAGåœ¨ç†è§£å¤æ‚æŸ¥è¯¢å’Œæ£€ç´¢ç›¸å…³æ–‡æ¡£æ–¹é¢çš„æŒ‘æˆ˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14043v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14043.md)  |
| <span style='display: inline-block; width: 42px;'>04-22</span> | **Tree of Reviews: A Tree-based Dynamic Iterative Retrieval Framework for Multi-hop Question Answering**<br><sub>æœºæ„: Tencent Inc., Harbin Institute of Technology<br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¿­ä»£æ£€ç´¢æ¡†æ¶TORï¼Œå®ƒé‡‡ç”¨æ ‘å½¢ç»“æ„å‡å°‘é”™è¯¯ç´¯ç§¯ï¼Œå¹¶å¼•å…¥ä¼˜åŒ–ç­–ç•¥æé«˜æ£€ç´¢æ•ˆç‡å’Œè´¨é‡ã€‚åœ¨å®éªŒä¸­ï¼ŒTORæ¡†æ¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.14464v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.14464.md)  |
| <span style='display: inline-block; width: 42px;'>04-21</span> | **AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs**<br><sub>æœºæ„: Meta AI (FAIR), Max-Planck-Institute for Intelligent Systems<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°å‹çš„LLMï¼Œåä¸ºAdvPrompterï¼Œå®ƒåˆ©ç”¨æ–°é¢–çš„ç®—æ³•ï¼Œæ— éœ€ç›®æ ‡LLMçš„æ¢¯åº¦ä¿¡æ¯ï¼Œè¿…é€Ÿç”Ÿæˆäººç±»å¯è¯»çš„æ•Œå¯¹æç¤ºï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆé€Ÿåº¦å¹¶ä¿æŒäº†æç¤ºçš„è¯­ä¹‰è¿è´¯æ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡AdvPrompterçš„è®­ç»ƒè¿˜èƒ½å¢å¼ºLLMé¢å¯¹è¶Šç‹±æ”»å‡»çš„ç¨³å¥æ€§ï¼Œè€Œä¸ç‰ºç‰²æ€§èƒ½è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.16873v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.16873.md)  |
| <span style='display: inline-block; width: 42px;'>04-19</span> | **Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?**<br><sub>æœºæ„: Nanyang Technological University, Princeton University, Salesforce Research<br>æœ¬è®ºæ–‡ç³»ç»Ÿåœ°è¯„ä¼°äº†LLMsè¿›è¡Œç±»æ¯”æ¨ç†çš„èƒ½åŠ›ï¼Œå¹¶æå‡ºäº†ä¸¤ç§å¯ä»¥åœ¨æ˜¾è‘—é™ä½æ¨ç†æˆæœ¬çš„åŒæ—¶è·å¾—æ›´å¥½æ€§èƒ½çš„æ–¹æ³•ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä¸ä»¥å‰è®¤ä¸ºç›¸å…³æ€§è‡³å…³é‡è¦çš„è§‚ç‚¹ç›¸åï¼Œè‡ªæˆ‘ç”Ÿæˆçš„æ— å…³ä¾‹å­åœ¨æŸäº›ä»»åŠ¡ä¸Šå¯ä»¥è¾¾åˆ°ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚å¸Œæœ›æœ¬ç ”ç©¶èƒ½åˆºæ¿€æ›´å¤šå…³äºè‡ªæˆ‘ç”Ÿæˆä¸Šä¸‹æ–‡è®¾è®¡çš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12728v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12728.md)  |
| <span style='display: inline-block; width: 42px;'>04-19</span> | **LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for Boosting Query Efficiency**<br><sub>æœºæ„: Nanyang Technological University, DAMO Academy Alibaba Group, Singapore University of Technology and Design<br>LLM-R2æ˜¯ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å¢å¼ºçš„æŸ¥è¯¢é‡å†™ç³»ç»Ÿï¼Œé€šè¿‡è‡ªåŠ¨é€‰æ‹©ä¸€ç»„ç»™å®šé‡å†™è§„åˆ™ä¸­çš„æœ‰æ•ˆè§„åˆ™ï¼Œæœ‰æ•ˆåœ°æå‡äº†æŸ¥è¯¢é‡å†™çš„æ‰§è¡Œæ•ˆç‡ï¼Œè§£å†³äº†ç›®å‰å…¶ä»–æ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†ä¼˜è¶Šçš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12872v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12872.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **Generating Diverse Criteria On-the-Fly to Improve Point-wise LLM Rankers**<br><sub>æœºæ„: Westlake University, Alibaba Group, Zhejiang University<br>è¯¥è®ºæ–‡æå‡ºäº†MCRankeræ¨¡å‹ï¼Œé€šè¿‡æ„å»ºè™šæ‹Ÿä¸“ä¸šè¯„æ³¨å›¢é˜Ÿå’Œç”Ÿæˆå¤šè§’åº¦è¯„ä¼°æ ‡å‡†ï¼Œæœ‰æ•ˆæå‡äº†LLMæ’åºå™¨çš„ä¸€è‡´æ€§ä¸å…¨é¢æ€§ï¼Œå¯å¹¿æ³›é€‚åº”äºå„ç±»æ•°æ®é›†ï¼Œæ”¹è¿›äº†æ’åºæ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11960v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.1196.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing**<br><sub>è¯¥è®ºæ–‡ä»‹ç»äº†ä¸€ç§åä¸ºALPHALLMçš„æ–°å‹æ¡†æ¶ï¼Œé€šè¿‡è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ç»“åˆï¼Œå®ç°äº†LLMsçš„è‡ªæˆ‘æé«˜ï¼Œæ— éœ€é¢å¤–çš„æ³¨è§£æ•°æ®ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12253v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12253.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **EVIT: Event-Oriented Instruction Tuning for Event Reasoning**<br><sub>æœºæ„: Key Laboratory of High Confidence Software Technologies (PKU), MOE, China, School of Computer Science, Peking University, Advanced Institute of Big Data<br>EVITé€šè¿‡æå‡ºé¢å‘äº‹ä»¶çš„æŒ‡ä»¤è°ƒè°ï¼ˆEvent-Oriented Instruction Tuningï¼‰å’Œäº‹ä»¶å››å…ƒç»„çš„æ¦‚å¿µï¼Œè§£å†³äº†ç°æœ‰å°å‹åŸºäºæŒ‡ä»¤è°ƒè°æ¨¡å‹åœ¨äº‹ä»¶æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ä¸è¶³é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEVITåœ¨äº‹ä»¶æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11978v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11978.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences**<br><sub>æœºæ„: UC Berkeley<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªä¸äººç±»åå¥½ç›¸ä¸€è‡´çš„LLMè¾…åŠ©è¯„ä¼°ç•Œé¢EvalGenï¼Œé€šè¿‡æ··åˆä¸»åŠ¨å¼æ–¹æ³•è§£å†³äº†LLMç”Ÿæˆçš„è¯„ä¼°åŠŸèƒ½è¯„ä¼°è´¨é‡å—ä¿¡ä»»åº¦çš„é—®é¢˜ã€‚è®ºæ–‡è¿˜æ¢è®¨äº†ç”¨æˆ·å¦‚ä½•å®šä¹‰å’Œä½¿ç”¨è¯„ä¼°æ ‡å‡†çš„åŠ¨æ€æ€§ï¼Œä»¥åŠåœ¨å®é™…åº”ç”¨ä¸­æ‰€é¢ä¸´çš„æŒ‘æˆ˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12272v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12272.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation**<br><sub>æœºæ„: Peking University, ByteDance Inc.<br>é€šè¿‡é’ˆå¯¹æ€§çš„ç¼“å­˜ç³»ç»Ÿè®¾è®¡å’Œä¸­é—´çŠ¶æ€å…±äº«ï¼ŒRAGCacheä¼˜åŒ–äº†RAGæµç¨‹çš„æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†å¤„ç†é€Ÿåº¦å¹¶å‡å°‘äº†è®¡ç®—èµ„æºçš„å¼€é”€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12457v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12457.md)  |
| <span style='display: inline-block; width: 42px;'>04-18</span> | **mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture**<br><sub>æœºæ„:  Beihang University, Beijing Information Science and Technology University<br>mABCæ˜¯ä¸€ç§åˆ›æ–°çš„æ¡†æ¶ï¼Œåˆ©ç”¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åŠå¤šä»£ç†åˆä½œï¼Œå¹¶ç”±åŒºå—é“¾å¯å‘å¼çš„å†³ç­–è¿‡ç¨‹ä¿ƒæˆï¼Œé’ˆå¯¹äº‘åŸç”ŸæŠ€æœ¯ä¸­å¾®æœåŠ¡æ¶æ„çš„æ ¹æœ¬åŸå› åˆ†æï¼ˆRCAï¼‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.12135v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.12135.md)  |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **Many-Shot In-Context Learning**<br><sub>æœºæ„: Google DeepMind<br>æœ¬è®ºæ–‡ä¸»è¦è´¡çŒ®åŒ…æ‹¬ç³»ç»Ÿè¯„ä¼°LLMåœ¨ä¸åŒè§„æ¨¡ä¸Šä¸‹æ–‡æ ·ä¾‹çš„æ€§èƒ½ï¼Œå¯¼å…¥reinforced ICLå’Œunsupervised ICLä»¥å‡å°‘æ ·ä¾‹ä¾èµ–ï¼Œå¹¶å‘ç°MS-ICLå¯ä»¥å…‹æœé¢„è®­ç»ƒåå·®å­¦ä¹ é«˜ç»´æ•°å€¼é¢„æµ‹ä»»åŠ¡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11018v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11018.md)  |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **Unifying Bias and Unfairness in Information Retrieval: A Survey of Challenges and Opportunities with Large Language Models**<br><sub>æœºæ„: Renmin University of China, Chinese Academy of Sciences, Huawei Technologies<br>è¿™ç¯‡ç»¼è¿°æ–‡ç« æä¾›äº†ä¸€ä¸ªæ–°é¢–çš„è§†è§’æ¥ç†è§£LLMså’ŒIRç³»ç»Ÿä¸­çš„åè§å’Œä¸å…¬å¹³ä¸ºåˆ†å¸ƒå¤±é…é—®é¢˜ï¼Œå¹¶å½’ç±»äº†å„ç§ç¼“è§£ç­–ç•¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11457v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11457.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/KID-22/LLM-IR-Bias-Fairness-Survey)</div> |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **AgentKit: Flow Engineering with Graphs, not Coding**<br><sub>æœºæ„: Carnegie Mellon University, NVIDIA, Microsoft<br>è®ºæ–‡å¼•å…¥äº†ä¸€ç§æ–°å‹çš„ LLM æç¤ºæ¡†æ¶ AgentKitï¼Œé’ˆå¯¹å¤šåŠŸèƒ½ä»£ç†é—®é¢˜ï¼Œé€šè¿‡æ¨¡å—åŒ–ç»„ä»¶å’Œç›´è§‚è®¾è®¡æ”¯æŒæ„å»ºå’Œå¾®è°ƒå¤æ‚çš„ä»£ç†æ€ç»´è¿‡ç¨‹ã€‚AgentKit æ˜¾ç¤ºå‡ºå®ç°å…ˆè¿›ä»£ç†èƒ½åŠ›å’Œé™ä½ç”¨æˆ·å‚ä¸é—¨æ§›çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11483v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11483.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/holmeswww/AgentKit)</div> |
| <span style='display: inline-block; width: 42px;'>04-17</span> | **A Deep Dive into Large Language Models for Automated Bug Localization and Repair**<br><sub>æœºæ„: University of Virginia, Purdue University, Amazon Web Services<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºToggleçš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨tokenç²’åº¦çš„bugå®šä½å¹¶ä¿®å¤ï¼Œå…‹æœäº†ç°æœ‰è¡Œç²’åº¦æ–¹æ³•çš„å±€é™ï¼Œé€šè¿‡è¾“å…¥è®¾è®¡å’ŒLLMsçš„å¾®è°ƒï¼Œå¤§å¹…æå‡äº†é”™è¯¯ä¿®å¤çš„å‡†ç¡®æ€§ï¼Œå¹¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—ä¼˜å¼‚çš„è¡¨ç°ï¼Œä¸ºAPRé¢†åŸŸå¸¦æ¥æ–°çš„è¿›å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.11595v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.11595.md)  |
| <span style='display: inline-block; width: 42px;'>04-16</span> | **How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs' internal prior**<br><sub>æœºæ„: Stanford University<br>è®ºæ–‡é€šè¿‡åˆ†æåœ¨RAGç¯å¢ƒä¸‹LLMså†…éƒ¨çŸ¥è¯†ä¸æ£€ç´¢ä¿¡æ¯ä¹‹é—´çš„å¼ åŠ›ï¼Œå‘ç°äº†LLMså€¾å‘äºéµå¾ªRAGä¿¡æ¯çš„ç¨‹åº¦ä¸æ¨¡å‹åœ¨æ— ä¸Šä¸‹æ–‡æƒ…å†µä¸‹çš„å›ç­”ä¿¡å¿ƒæˆåæ¯”ã€‚ç ”ç©¶åŸºäºè·¨è¶…è¿‡1200ä¸ªé—®é¢˜çš„å…­ä¸ªé¢†åŸŸæ•°æ®é›†ï¼Œæ­ç¤ºäº†åœ¨æ¨¡å‹çš„é¢„è®­ç»ƒçŸ¥è¯†ä¸æ£€ç´¢åˆ°çš„ä¿¡æ¯ä¹‹é—´çš„å›ºæœ‰å†²çªã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10198v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.10198.md)  |
| <span style='display: inline-block; width: 42px;'>04-16</span> | **CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity**<br><sub>æœºæ„: Intel Labs<br>æœ¬æ–‡æå‡ºçš„CoTARæ–¹æ³•é’ˆå¯¹LLMsåœ¨é—®ç­”ä»»åŠ¡ä¸­å€¾å‘äºç”Ÿæˆä¸å‡†ç¡®å½’å› çš„é—®é¢˜ã€‚é€šè¿‡åœ¨è¾“å‡ºç”Ÿæˆå‰è¿›è¡Œæ¨ç†ï¼Œå¹¶åœ¨ä¸åŒçš„å½’å› ç²’åº¦çº§åˆ«ä¸Šå¼•å¯¼æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨ç­”æ¡ˆè´¨é‡å’Œå½’å› ç²¾ç¡®åº¦ä¸Šçš„è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10513v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.10513.md)  |
| <span style='display: inline-block; width: 42px;'>04-16</span> | **Self-playing Adversarial Language Game Enhances LLM Reasoning**<br><sub>æœºæ„: Tencent AI Lab<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºSPAGçš„æ–°å‹è®­ç»ƒæ–¹æ¡ˆï¼Œé€šè¿‡è‡ªæˆ‘å¯¹æŠ—æ€§è¯­è¨€æ¸¸æˆçš„è‡ªæˆ‘æ’­æ”¾ï¼Œæœ‰æ•ˆæå‡äº†LLMsçš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶ä¸”å…¶æ”¹è¿›æ˜¯å¯ä»¥é€šè¿‡è¿­ä»£è¿‡ç¨‹æŒç»­å¢å¼ºçš„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10642v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.10642.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Linear95/SPAG)</div> |
| <span style='display: inline-block; width: 42px;'>04-15</span> | **Compression Represents Intelligence Linearly**<br><sub>æœºæ„: The Hong Kong University of Science and Technology, Tencent<br>è¿™ç¯‡è®ºæ–‡é€šè¿‡å®è¯ç ”ç©¶ï¼Œè¯æ˜äº†LLMsåœ¨ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ä¸å®ƒä»¬çš„å‹ç¼©æ•ˆç‡ä¹‹é—´å­˜åœ¨ç€å‡ ä¹çº¿æ€§çš„ç›¸å…³æ€§ï¼Œä¸ºâ€œæ›´å¥½çš„å‹ç¼©èƒ½åŠ›è¡¨æ˜äº†æ›´é«˜çš„æ™ºèƒ½â€è¿™ä¸€é•¿æœŸä¿¡å¿µæä¾›äº†æ”¯æŒã€‚åŒæ—¶ï¼Œæå‡ºäº†ä½¿ç”¨å‹ç¼©æ•ˆç‡ä½œä¸ºè¯„ä¼°LLMsæ€§èƒ½çš„æ— ç›‘ç£åº¦é‡æ ‡å‡†çš„å»ºè®®ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.09937v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.09937.md)  |
| <span style='display: inline-block; width: 42px;'>04-15</span> | **Learn Your Reference Model for Real Good Alignment**<br><sub>æœºæ„: Tinkoff<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºTrust Region DPO (TR-DPO) çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡äº¤äº’å¼åœ°æ›´æ–°å‚è€ƒç­–ç•¥çš„å‚æ•°ï¼Œæ˜¾è‘—æ”¹è¿›äº†è¯­è¨€æ¨¡å‹çš„å¯¹é½é—®é¢˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTR-DPOåœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šå‡ä¼˜äºDPOæ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹çš„å¤šå‚æ•°æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.09656v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.09656.md)  |
| <span style='display: inline-block; width: 42px;'>04-14</span> | **Emerging Platforms Meet Emerging LLMs: A Year-Long Journey of Top-Down Development**<br><sub>æœ¬è®ºæ–‡çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å¦‚ä½•æ”¯æŒå’Œä¼˜åŒ–æ–°å…´è®¡ç®—å¹³å°ä¸‹çš„æœºå™¨å­¦ä¹ æ¨¡å‹éƒ¨ç½²ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ¡†æ¶TAPMLï¼Œæ—¨åœ¨é€šè¿‡é¡¶å±‚æ–¹æ³•å’Œé€šç”¨è¿è¡Œæ—¶ç¯å¢ƒä¿ƒè¿›æ¨¡å‹éƒ¨ç½²çš„å¹¿æ³›æ€§ã€ä¾¿åˆ©æ€§å’Œå¼ºå¤§æ€§ï¼Œæ–‡ä¸­æä¾›äº†å®é™…éƒ¨ç½²æ¡ˆä¾‹ä½œä¸ºå‘å±•MLç³»ç»Ÿçš„æ·±å…¥è§è§£å’Œæœ€ä½³å®è·µã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.09151v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.09151.md)  |
| <span style='display: inline-block; width: 42px;'>04-13</span> | **Intuition-aware Mixture-of-Rank-1-Experts for Parameter Efficient Finetuning**<br><sub>æœºæ„: Nanjing University, University of California<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹å¤šä»»åŠ¡å¾®è°ƒçš„æ¡†æ¶Intuition-MoR1Eï¼Œè¯¥æ¡†æ¶å€Ÿé‰´äººç±»è®¤çŸ¥ç¥ç»ç§‘å­¦åŸç†ï¼Œå¹¶åˆ©ç”¨æ’å1ä¸“å®¶å½¢å¼æ¥ç®¡ç†ç›´è§‰ï¼Œæ˜¾è‘—æé«˜äº†å‚æ•°æ•ˆç‡å’Œå¤šä»»åŠ¡å¾®è°ƒæ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.08985v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.08985.md)  |
| <span style='display: inline-block; width: 42px;'>04-12</span> | **Megalodon: Efficient LLM Pretraining and Inference with Unlimited Context Length**<br><sub>æœºæ„: AI at Meta, University of Southern California, Carnegie Mellon University<br>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†MEGALODONï¼Œä¸€ä¸ªé«˜æ•ˆå¤„ç†æ— é™ä¸Šä¸‹æ–‡é•¿åº¦åºåˆ—çš„ç¥ç»ç½‘ç»œæ¶æ„ã€‚é€šè¿‡å¼•å…¥å¤šé¡¹åˆ›æ–°æŠ€æœ¯ï¼ŒMEGALODONåœ¨é•¿åºåˆ—æ¨¡å‹ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºæ¯”Transformeræ›´é«˜çš„æ•ˆç‡å’Œæ•ˆèƒ½ï¼ŒåŒæ—¶åœ¨ä¸åŒè§„æ¨¡å’Œæ¨¡æ€çš„åŸºå‡†æµ‹è¯•ä¸­éƒ½å–å¾—äº†ç¨³å¥çš„æ”¹è¿›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.08801v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.08801.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/XuezheMax/megalodon)</div> |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **ChatGPT Can Predict the Future when it Tells Stories Set in the Future About the Past**<br><sub>æœºæ„: Baylor University<br>æœ¬ç ”ç©¶é€šè¿‡åˆ†æChatGPT-3.5å’ŒChatGPT-4çš„é¢„æµ‹èƒ½åŠ›ï¼Œæ­ç¤ºäº†LLMsåœ¨æ¨ç†æ–¹é¢çš„æ–°æ½œåŠ›ã€‚ç ”ç©¶è¯æ˜äº†â€œæœªæ¥å™äº‹â€æç¤ºèƒ½å¤Ÿæ˜¾è‘—æå‡é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œä¸ºLLMsåœ¨åˆ†æç¯å¢ƒä¸­çš„æ½œåœ¨åº”ç”¨æä¾›äº†æœ‰ç›Šè§è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07396v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07396.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **Decomposing Label Space, Format and Discrimination: Rethinking How LLMs Respond and Solve Tasks via In-Context Learning**<br><sub>æœºæ„: Nanyang Technological University<br>æœ¬æ–‡ç ”ç©¶äº†ICLåœ¨æå‡ä»»åŠ¡æ€§èƒ½æ–¹é¢çš„ç”Ÿæ•ˆæœºåˆ¶ï¼Œé€šè¿‡åˆ†è§£ICLçš„è´¡çŒ®å› ç´ ï¼Œå‘ç°ICLé€šè¿‡ç²¾ç»†è°ƒæ•´æ ‡ç­¾ç©ºé—´å’Œæ ¼å¼æ¥æ˜¾è‘—æå‡æ€§èƒ½ï¼ŒåŒæ—¶å¼ºè°ƒäº†é€‰æ‹©åˆé€‚æ¼”ç¤ºç¤ºä¾‹çš„é‡è¦æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07546v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07546.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **Interactive Prompt Debugging with Sequence Salience**<br><sub>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºåºåˆ—æ˜¾è‘—æ€§ï¼ˆSequence Salienceï¼‰çš„ç³»ç»Ÿï¼Œå®ƒæ‰©å±•äº†ç°æœ‰çš„è¾“å…¥æ˜¾è‘—æ€§ï¼ˆISï¼‰æ–¹æ³•ï¼Œä»¥æ”¯æŒå¤æ‚çš„LLMæç¤ºè°ƒè¯•ã€‚è¯¥å·¥å…·æä¾›å®æ—¶äº¤äº’å¼è°ƒè¯•ï¼Œå¹¶é™ä½äº†å®è·µè€…çš„è®¤çŸ¥è´Ÿè·ï¼Œæ”¯æŒæ ¹æ®æ˜¾è‘—æ€§ç»“æœå¿«é€Ÿè¿­ä»£æç¤ºï¼Œä¸å¼€å‘è€…çš„æ€ç»´æ¨¡å‹æ›´åŠ å¯¹é½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07498v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07498.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **ControlNet++: Improving Conditional Controls with Efficient Consistency Feedback**<br><sub>æœºæ„: University of Central Florida, ByteDance Inc<br>ControlNet++é€šè¿‡ä¼˜åŒ–ç”Ÿæˆå›¾åƒä¸æ¡ä»¶æ§åˆ¶ä¹‹é—´çš„åƒç´ çº§ä¸€è‡´æ€§ï¼Œå¹¶é€šè¿‡é«˜æ•ˆçš„å¥–åŠ±å¾®è°ƒç­–ç•¥å‡å°‘äº†ä¸å›¾åƒé‡‡æ ·ç›¸å…³çš„æ—¶é—´å’Œå†…å­˜æˆæœ¬ï¼Œæ˜¾è‘—æ”¹å–„äº†åœ¨å¤šç§æ¡ä»¶æ§åˆ¶ä¸‹çš„å¯æ§æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07987v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07987.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments**<br><sub>æœºæ„: The University of Hong Kong, CMU, Salesforce Research<br>OSWORLDæä¾›äº†ä¸€ä¸ªæ–°çš„è¯„ä¼°ç¯å¢ƒï¼Œè§£å†³äº†ç°æœ‰åŸºå‡†æµ‹è¯•çš„å±€é™æ€§ï¼Œä¸ºå¼€å‘èƒ½åœ¨çœŸå®è®¡ç®—æœºç¯å¢ƒä¸­å®Œæˆå¼€æ”¾å¼ä»»åŠ¡çš„å¤šæ¨¡æ€ä»£ç†æä¾›äº†åŸºç¡€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07972v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07972.md)  |
| <span style='display: inline-block; width: 42px;'>04-11</span> | **Rho-1: Not All Tokens Are What You Need**<br><sub>æœºæ„: Xiamen University, Tsinghua University, Microsoft<br>æœ¬æ–‡æå‡ºäº†RHO-1ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨é€‰æ‹©æ€§è¯­è¨€å»ºæ¨¡ï¼ˆSLMï¼‰çš„æ–°å‹è¯­è¨€æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨é¢„è®­ç»ƒä¸­ä¸“æ³¨äºå¯¹æœ‰ç”¨çš„ä»¤ç‰Œè¿›è¡Œè®­ç»ƒï¼Œè¿™ç§æ–¹æ³•åœ¨æ•°å­¦é¢†åŸŸçš„è¿ç»­é¢„è®­ç»ƒä¸­æ˜¾ç¤ºå‡ºå“è¶Šæ€§èƒ½ï¼Œèƒ½å¤Ÿæ›´å¿«åœ°è¾¾åˆ°åŸºçº¿æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨å°‘é‡ä»¤ç‰Œçš„æƒ…å†µä¸‹è¾¾åˆ°æœ€æ–°çš„çŠ¶æ€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07965v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07965.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **"We Need Structured Output": Towards User-centered Constraints on Large Language Model Output**<br><sub>æœºæ„: Google Research<br>æœ¬è®ºæ–‡æ¢ç´¢å¦‚ä½•ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¾“å‡ºå®ç°ç”¨æˆ·ä¸­å¿ƒçš„çº¦æŸï¼Œé€šè¿‡è°ƒæŸ¥è¡Œä¸šä¸“ä¸šäººå£«æ¥äº†è§£ä¸åŒåœºæ™¯å’Œéœ€æ±‚ã€‚é‡ç‚¹æ˜¯æé«˜å¼€å‘è€…åœ¨å¼€å‘ã€æµ‹è¯•å’Œæ•´åˆLLMè¿‡ç¨‹ä¸­çš„æ•ˆç‡ï¼Œå¹¶é€šè¿‡æ»¡è¶³ç‰¹å®šçš„è¾“å‡ºæ ¼å¼å’Œç”¨æˆ·ç•Œé¢è¦æ±‚æ¥å¢å¼ºæœ€ç»ˆç”¨æˆ·çš„ä½“éªŒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07362v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07362.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **Transferable and Efficient Non-Factual Content Detection via Probe Training with Offline Consistency Checking**<br><sub>æœºæ„: Renmin University of China, Tsinghua University<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§é€šè¿‡ç¦»çº¿è‡ªæˆ‘ä¸€è‡´æ€§æ£€æŸ¥è®­ç»ƒæ¢æµ‹æ¨¡å‹çš„æ–°æ–¹æ³•PINOSï¼Œæœ‰æ•ˆåœ°è§£å†³äº†ç°æœ‰çœŸå®æ€§æ£€æµ‹æ–¹æ³•çš„é™åˆ¶ã€‚PINOSæé«˜äº†è¿‡ç¨‹çš„è½¬ç§»èƒ½åŠ›å’Œæ•ˆç‡ï¼Œå¹¶ä¸”åœ¨çœŸå®æ€§æ£€æµ‹å’Œé—®ç­”åŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†è¶…è¶Šç°æœ‰æ–¹æ³•çš„ç»“æœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06742v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.06742.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **Superposition Prompting: Improving and Accelerating Retrieval-Augmented Generation**<br><sub>æœºæ„: Apple, Cupertino, CA, USA<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æç¤ºæ–¹æ³•â€”â€”â€œè¶…çº§å åŠ æç¤ºâ€ï¼Œç”¨äºå¤„ç†å¤§å‹è¯­è¨€æ¨¡å‹å¤„ç†é•¿æ–‡æœ¬æ—¶é‡åˆ°çš„é—®é¢˜ï¼Œå¹¶åœ¨æ²¡æœ‰é¢å¤–è®­ç»ƒæˆ–å¾®è°ƒçš„æƒ…å†µä¸‹æ˜¾è‘—æé«˜äº†æ—¶é—´æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚è¿™ä¸€æ–¹æ³•åœ¨ä¼—å¤šé¢„è®­ç»ƒæ¨¡å‹ä¸Šå¾—åˆ°éªŒè¯ï¼Œå¹¶ä¸”ä½œè€…è®¡åˆ’å‘å¸ƒä¸€ä¸ªå¼€æºä»£ç å®ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06910v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.0691.md)  |
| <span style='display: inline-block; width: 42px;'>04-10</span> | **Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention**<br><sub>æœºæ„: Google<br>è¯¥ç ”ç©¶æå‡ºä¸€ç§å…¨æ–°çš„æ³¨æ„åŠ›æœºåˆ¶Infini-attentionï¼Œå®ƒé€šè¿‡å°†å‹ç¼©è®°å¿†ä¸æ ‡å‡†çš„ç‚¹ç§¯æ³¨æ„åŠ›ç›¸ç»“åˆï¼Œå¹¶åœ¨è®¾è®¡ä¸Šæ”¯æŒæ’æ‹”å¼çš„æŒç»­é¢„è®­ç»ƒå’Œé•¿ä¸Šä¸‹æ–‡è°ƒæ•´ï¼Œä½¿å¾—LLMsèƒ½ä»¥æœ‰ç•Œçš„å†…å­˜å’Œè®¡ç®—èµ„æºå¤„ç†æ— é™é•¿çš„ä¸Šä¸‹æ–‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.07143v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.07143.md)  |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **THOUGHTSCULPT: Reasoning with Intermediate Revision and Search**<br><sub>æœºæ„: UC Berkeley<br>THOUGHTSCULPTä½œä¸ºä¸€ä¸ªåŸºäºå›¾çš„æ¡†æ¶ï¼Œé€šè¿‡å†…åµŒçš„è‡ªæˆ‘ä¿®æ­£æœºåˆ¶ï¼Œèƒ½å¤Ÿè®©LLMsåœ¨ç”Ÿæˆæ–°çš„æ€ç»´èŠ‚ç‚¹çš„åŒæ—¶è¿­ä»£åœ°æ”¹è¿›ä¹‹å‰çš„è¾“å‡ºï¼Œç‰¹åˆ«åœ¨éœ€è¦æŒç»­ä¿®æ­£å’Œä¿®æ”¹çš„ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05966v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05966.md)  |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **Event-enhanced Retrieval in Real-time Search**<br><sub>æœºæ„: Tencent Search, Platform and Content Group<br>EERæ˜¯ä¸€ç§æ–°å‹æ–¹æ³•ï¼Œé’ˆå¯¹å®æ—¶æœç´¢ä¸­çš„â€œè¯­ä¹‰æ¼‚ç§»â€é—®é¢˜ï¼Œé€šè¿‡æ”¹è¿›EBRæ¨¡å‹å’ŒåŠ å…¥å¯¹æ¯”å­¦ä¹ åŠäº‹ä»¶ä¸‰å…ƒç»„ç”Ÿæˆä»»åŠ¡æå‡æ£€ç´¢æ€§èƒ½ã€‚è¯¥æ–¹æ³•é€šè¿‡å®éªŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œå¹¶å¯èƒ½ä¸ºä¿¡æ¯æ£€ç´¢é¢†åŸŸæä¾›æ–°çš„è§†è§’ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05989v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05989.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/open-event-hub/Event-enhanced_Retrieval)</div> |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **RULER: What's the Real Context Size of Your Long-Context Language Models?**<br><sub>æœºæ„: NVIDIA  <br>æœ¬è®ºæ–‡ä¸ºé•¿ä¸Šä¸‹æ–‡LMsæå‡ºäº†æ–°çš„è¯„ä¼°å·¥å…·RULERï¼Œå¹¶å¼€æºï¼Œç”¨äºæµ‹è¯•LMsåœ¨å¤æ‚ä»»åŠ¡å’Œé•¿ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ä¸Šçš„è¡¨ç°ï¼Œå¹¶åœ¨å„ç§æ¨¡å‹å’Œä»»åŠ¡å¤æ‚åº¦ä¸Šè¿›è¡Œäº†åˆ†æï¼Œæ¨åŠ¨äº†é•¿ä¸Šä¸‹æ–‡LMsçš„æœªæ¥ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06654v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.06654.md)  |
| <span style='display: inline-block; width: 42px;'>04-09</span> | **Privacy Preserving Prompt Engineering: A Survey**<br><sub>æœºæ„: University of Arkansas<br>è¿™ç¯‡è°ƒç ”è®ºæ–‡ä¸ºäº†åœ¨ä½¿ç”¨LLMsè¿›è¡ŒICLå’Œä¸€èˆ¬æç¤ºçš„è¿‡ç¨‹ä¸­ä¿æŠ¤éšç§ï¼Œæä¾›äº†ä¸€ä¸ªå…³äºåœ¨è¿™ä¸€èŒƒç•´ä¸‹çš„éšç§ä¿æŠ¤æ–¹æ³•çš„ç³»ç»Ÿæ€§æ¦‚è¿°ï¼Œæœ‰åˆ©äºæ¨åŠ¨ç¤¾åŒºåœ¨éšç§ä¿æŠ¤æ–¹é¢çš„è¿›ä¸€æ­¥ç ”ç©¶å’Œæ¢ç´¢ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.06001v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.06001.md)  |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **Evaluating Interventional Reasoning Capabilities of Large Language Models**<br><sub>æœºæ„: UniversitÃ© de MontrÃ©al, Google DeepMind, ServiceNow Research<br>æœ¬æ–‡å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å› æœæ¨ç†èƒ½åŠ›è¿›è¡Œäº†è¯„ä¼°ã€‚é€šè¿‡æå‡ºå¹²é¢„æ•ˆæœé¢„æµ‹ï¼Œå®ƒä¸»è¦æµ‹è¯•LLMsåœ¨å¹²é¢„å®éªŒåå¦‚ä½•æ›´æ–°è‡ªå·±å¯¹äº‹å®çš„ç†è§£ã€‚ç»“æœæ˜¾ç¤ºGPT-4åœ¨æŸäº›æ¡ä»¶ä¸‹èƒ½å¤Ÿå‡†ç¡®é¢„æµ‹å¹²é¢„æ•ˆæœï¼Œä½†æç¤ºè®¾è®¡çš„å¾®å°å˜åŒ–ä¼šæ˜¾è‘—å½±å“å…¶è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05545v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05545.md)  |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **Know When To Stop: A Study of Semantic Drift in Text Generation**<br><sub>æœºæ„: FAIR, Meta, Anthropic<br>æœ¬æ–‡ä¸ºç†è§£å’Œæµ‹é‡è¯­è¨€æ¨¡å‹åœ¨é•¿æ–‡æœ¬ç”Ÿæˆä¸­çš„è¯­ä¹‰æ¼‚ç§»ç°è±¡æä¾›äº†å·¥å…·ã€‚é€šè¿‡æ—©åœå’Œé‡é‡‡æ ·-é‡æ–°æ’åºç­‰æ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†äº‹å®å‡†ç¡®æ€§ï¼Œå¹¶ä¸ºå¦‚ä½•å¹³è¡¡ä¿¡æ¯é‡ä¸äº‹å®å‡†ç¡®æ€§æä¾›äº†å¯èƒ½çš„è§£å†³ç­–ç•¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05411v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05411.md)  |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding**<br><sub>æœºæ„: Alibaba Group, Zhejiang University<br>è¯¥è®ºæ–‡æˆåŠŸæå‡ºäº†LayoutLLMæ¨¡å‹åŠå…¶å¸ƒå±€æŒ‡å¯¼çš„è°ƒæ•´ç­–ç•¥ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹å¯¹æ–‡æ¡£å¸ƒå±€ä¿¡æ¯çš„ç†è§£å’Œåˆ©ç”¨ï¼Œå°¤å…¶åœ¨é›¶æ ·æœ¬æ–‡æ¡£ç†è§£ä»»åŠ¡ä¸Šè¡¨ç°å‡ºäº†å“è¶Šçš„æ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05225v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05225.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding)</div> |
| <span style='display: inline-block; width: 42px;'>04-08</span> | **LLM-Augmented Retrieval: Enhancing Retrieval Models Through Language Models and Doc-Level Embedding**<br><sub>æœºæ„: Meta<br>è¯¥è®ºæ–‡æˆåŠŸæå‡ºå¹¶éªŒè¯äº†ä¸€ä¸ªå¢å¼ºå‹æ–‡æ¡£çº§åµŒå…¥çš„LLM-augmentedæ£€ç´¢æ¡†æ¶ï¼Œä¸ä»…é€šè¿‡ç”Ÿæˆåˆæˆçš„ç›¸å…³æŸ¥è¯¢å’Œæ ‡é¢˜å¢åŠ äº†æ–‡æ¡£åµŒå…¥çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè¿˜æ”¹è¿›äº†æ£€ç´¢æ¨¡å‹è®­ç»ƒçš„å…³é”®æ­¥éª¤ï¼Œä»è€Œæå‡æ£€ç´¢æ¨¡å‹çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.05825v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.05825.md)  |
| <span style='display: inline-block; width: 42px;'>04-07</span> | **Prompting Large Language Models for Zero-shot Essay Scoring via Multi-trait Specialization**<br><sub>æœºæ„: Peking University<br>è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé›¶æ ·æœ¬çš„å¤§å‹è¯­è¨€æ¨¡å‹ä½œæ–‡è¯„åˆ†æ¡†æ¶ï¼ˆMTSï¼‰ï¼Œé€šè¿‡å¤šè½®å¯¹è¯æ¥ä¸ºä½œæ–‡çš„ä¸åŒå†™ä½œç‰¹è´¨æ‰“åˆ†ï¼Œå¹¶é‡‡ç”¨æœ€å°-æœ€å¤§ç¼©æ”¾å’Œå¼‚å¸¸å€¼æˆªæ–­æœºåˆ¶æ¥å¾—åˆ°æœ€ç»ˆå¾—åˆ†ã€‚MTSåœ¨å‡†ç¡®åº¦ä¸Šæ˜¾è‘—ä¼˜äºç›´æ¥æç¤ºè¯„åˆ†æ–¹æ³•ï¼Œå¹¶åœ¨å°å‹åŒ–éƒ¨ç½²ä¸­ä¼˜äºChatGPTï¼Œæä¾›äº†ç›‘ç£å­¦ä¹ ä¹‹å¤–çš„é›¶æ ·æœ¬ä½œæ–‡è¯„åˆ†æ–¹æ¡ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.04941v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.04941.md)  |
| <span style='display: inline-block; width: 42px;'>04-07</span> | **Radial Networks: Dynamic Layer Routing for High-Performance Large Language Models**<br><sub>æœºæ„: Cornell University<br>æœ¬è®ºæ–‡æå‡ºäº†å¾„å‘ç½‘ç»œï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹ç¥ç»ç½‘ç»œç»“æ„ï¼Œé€šè¿‡åŠ¨æ€å±‚ç¨€ç–æ€§å’Œä¸€ä¸ªç»è¿‡è®­ç»ƒçš„è·¯ç”±æ¨¡å—æ¥å®ç°ä»¤ç‰Œçº§çš„å±‚é—´è·¯ç”±ã€‚è¿™ä¸ä»…æé«˜äº†æ¨¡å‹çš„æ€§èƒ½ï¼Œè¿˜æ˜¾è‘—é™ä½äº†è®¡ç®—å’ŒæœåŠ¡æˆæœ¬ï¼Œä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„è¿›ä¸€æ­¥æ‰©å±•æä¾›äº†å¯èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.04900v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.049.md)  |
| <span style='display: inline-block; width: 42px;'>04-04</span> | **Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences**<br><sub>æœºæ„: Microsoft Research<br>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†DNOâ€”â€”ä¸€ç§èƒ½å¤Ÿå°†å¯¹æ¯”å­¦ä¹ çš„ç®€æ´æ€§ä¸ä»ä¼˜åŒ–ä¸€èˆ¬æ€§åå¥½è€Œæ¥çš„ç†è®ºæ™®é€‚æ€§ç›¸ç»“åˆçš„ç®—æ³•ã€‚DNOåœ¨åè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹æ–¹é¢æ˜¾è‘—æå‡æ€§èƒ½ï¼Œå®ƒçš„æˆåŠŸå®è¯äº†é€šè¿‡ä¼˜åŒ–ä¸€èˆ¬åå¥½æ¥æŒ‡å¯¼æ¨¡å‹å­¦ä¹ ä¸äººç±»ä»·å€¼è§‚ä¿æŒä¸€è‡´æ˜¯å¯èƒ½çš„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.03715v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.03715.md)  |
| <span style='display: inline-block; width: 42px;'>04-04</span> | **AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.03648v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.03648.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/THUDM/AutoWebGLM)</div> |
| <span style='display: inline-block; width: 42px;'>04-04</span> | **ReFT: Representation Finetuning for Language Models**<br><sub>æœºæ„: Stanford University, Pr(Ai)2R Group<br>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„è¯­è¨€æ¨¡å‹å¾®è°ƒæ–¹æ³•LoReFTï¼Œå®ƒåœ¨èµ„æºæ•ˆç‡å’Œæ¨¡å‹æ§åˆ¶èƒ½åŠ›æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰çš„å‚æ•°æœ‰æ•ˆè°ƒæ•´ï¼ˆPEFTsï¼‰æ–¹æ³•ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªNLPé¢†åŸŸçš„ä»»åŠ¡ä¸Šå®ç°äº†æ–°çš„æœ€ä½³æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒå°‘çš„å‚æ•°éœ€æ±‚å’Œè¾ƒé«˜çš„å¯è§£é‡Šæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.03592v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.03592.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/stanfordnlp/pyreft)</div> |
| <span style='display: inline-block; width: 42px;'>04-03</span> | **PromptRPA: Generating Robotic Process Automation on Smartphones from Textual Prompts**<br><sub>æœºæ„: Shanghai Jiao Tong University, CMU<br>æ–‡ç« ä»‹ç»äº†PromptRPAç³»ç»Ÿï¼Œè¿™æ˜¯ä¸€ä¸ªè§£å†³RPAåœ¨ç§»åŠ¨è®¾å¤‡ä¸Šåº”ç”¨å—é™çš„æœ‰æ•ˆæ–¹æ¡ˆã€‚é€šè¿‡åˆ©ç”¨å¤šä»£ç†æ¡†æ¶å’Œåœ¨çº¿æ•™ç¨‹ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿè§£é‡Šå„ç§æ–‡æœ¬æç¤ºï¼Œè§£å†³å¤§èŒƒå›´çš„RPAä»»åŠ¡ã€‚æ€§èƒ½è¯„ä¼°æ˜¾ç¤ºæˆåŠŸç‡æ˜¾è‘—æé«˜ï¼Œè¯æ˜äº†æ–‡æœ¬é©±åŠ¨æ§åˆ¶åœ¨RPAé¢†åŸŸçš„å¯è¡Œæ€§ï¼Œå¹¶å¼€è¾Ÿäº†åŠŸèƒ½å¢å¼ºå’Œé€‚ç”¨æ€§æ‰©å±•çš„æ–°æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02475v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.02475.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Long-context LLMs Struggle with Long In-context Learning**<br><sub>æœºæ„: University of Waterloo, Carnegie Mellon University<br>è¿™ç¯‡æ–‡ç« æå‡ºäº†ä¸€ä¸ªæ–°çš„è¯„ä¼°åŸºå‡†ï¼ŒLongICLBenchï¼Œç”¨äºè¯„ä¼°LLMsåœ¨å¤„ç†é•¿è¾“å…¥ä»»åŠ¡æ—¶çš„æ€§èƒ½ï¼Œä»¥åŠLLMså¯¹è¾“å…¥åºåˆ—ä¸­å®ä¾‹ä½ç½®çš„æ•æ„Ÿæ€§ã€‚è¿™ä¸€å·¥ä½œæœ‰åŠ©äºæ›´å¥½åœ°ç†è§£å’Œæ”¹è¿›å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é•¿æ–‡æœ¬å¤„ç†æ–¹é¢çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02060v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.0206.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models**<br><sub>æœºæ„: Microsoft<br>è®ºæ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¦‚ä½•è¾…åŠ©è®¾è®¡è‡ªé€‚åº”æ¯”ç‰¹ç‡ï¼ˆABRï¼‰ç®—æ³•ï¼Œé€šè¿‡ç”Ÿæˆå¤šæ ·åŒ–çš„å€™é€‰ç®—æ³•ï¼Œå¹¶è¿ç”¨æ—©åœæœºåˆ¶åœ¨ç½‘ç»œæ¨¡æ‹Ÿå™¨ä¸­è¿›è¡Œæµ‹è¯•ï¼Œä»è€Œæœ‰æ•ˆåœ°ç­›é€‰å‡ºæœ€æœ‰æ•ˆçš„ç®—æ³•è®¾è®¡ã€‚è¯„ä¼°æ˜¾ç¤ºåœ¨ç‰¹å®šç½‘ç»œåœºæ™¯ä¸­ï¼Œåˆ©ç”¨LLMså¯ä»¥æ˜¾è‘—æé«˜ABRç®—æ³•çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01617v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01617.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Octopus v2: On-device language model for super agent**<br><sub>æœºæ„: Stanford University<br>è¿™ç¯‡è®ºæ–‡è§£å†³äº†è¾¹ç¼˜è®¾å¤‡ä¸ŠLLMçš„éƒ¨ç½²å’ŒåŠŸèƒ½è°ƒç”¨æ•ˆç‡é—®é¢˜ï¼Œé€šè¿‡å¼•å…¥ç‰¹æ®Šçš„è®­ç»ƒæ–¹æ³•å’Œå‡å°‘æ¨ç†æ—¶éœ€å¤„ç†çš„ä¸Šä¸‹æ–‡é‡ï¼Œæ˜¾è‘—æé«˜äº†åœ¨è®¾å¤‡ä¸Šè¿›è¡Œå‡½æ•°è°ƒç”¨çš„å‡†ç¡®ç‡å’Œé™ä½äº†å»¶è¿Ÿï¼Œå®éªŒç»“æœè¡¨æ˜å…¶å¯¹æå‡å‡½æ•°è°ƒç”¨ä»»åŠ¡çš„æ€§èƒ½å…·æœ‰æ˜¾è‘—å½±å“ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01744v3)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01744.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Long-context LLMs Struggle with Long In-context Learning**<br><sub>æœºæ„: University of Waterloo, Carnegie Mellon University<br>è¿™é¡¹ç ”ç©¶ä¸ºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹å¤„ç†é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡çš„èƒ½åŠ›æä¾›äº†ä¸€ä¸ªæ–°çš„åŸºå‡†â€”â€”LongICLBenchï¼Œå¹¶æ˜¾ç¤ºäº†éšç€ä»»åŠ¡éš¾åº¦å¢åŠ ï¼ŒLLMsçš„æ€§èƒ½æ™®éä¸‹é™ï¼Œå¹¶ä¸”æ¨¡å‹çš„é•¿ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›å—åˆ°æç¤ºä¸­æ ‡ç­¾ä½ç½®åˆ†å¸ƒçš„å½±å“ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02060v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.0206.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **Advancing LLM Reasoning Generalists with Preference Trees**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.02078v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.02078.md)  |
| <span style='display: inline-block; width: 42px;'>04-02</span> | **CMAT: A Multi-Agent Collaboration Tuning Framework for Enhancing Small Language Models**<br><sub>æœºæ„: East China Jiaotong University, Guangdong University of Technology, University of Toronto<br>è¯¥è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®æ˜¯æå‡ºäº†CMATæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§åˆ›æ–°æ–¹æ³•ï¼Œå¯å®ç°å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå†…éƒ¨çš„åŠ¨æ€ã€å®æ—¶è®°å¿†æ›´æ–°ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§æ–°å‹çš„è§’è‰²æ‰®æ¼”æœºåˆ¶ï¼Œç”¨äºç²¾å‡†çš„ä»»åŠ¡åˆ†é…å’Œæå‡ä»£ç†é—´çš„é€šä¿¡ï¼Œä»¥æ­¤æ˜¾è‘—æé«˜æ•´ä½“æ€§èƒ½å’Œåˆä½œæ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01663v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01663.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review**<br><sub>æœºæ„: University of Lyon, INSA Lyon, Infologic<br>æœ¬æ–‡æä¾›äº† AIOps é¢†åŸŸä¸­äº‹ä»¶ç®¡ç†çš„å…¨é¢æ–‡çŒ®å›é¡¾ï¼Œæ—¨åœ¨é€šè¿‡æä¾›ç»“æ„åŒ–çš„çŸ¥è¯†ã€ç¡®å®šçŸ¥è¯†ç©ºç™½å’Œä¸ºè¯¥é¢†åŸŸçš„æœªæ¥å‘å±•å¥ å®šåŸºç¡€ã€‚è®ºæ–‡å»ºç«‹äº† AIOps çš„ç»Ÿä¸€æœ¯è¯­å’Œåˆ†ç±»æ³•ï¼Œæ­ç¤ºäº†ç°æœ‰çš„æŒ‘æˆ˜ï¼Œå¹¶æä¾›äº†å…¬å¼€æ•°æ®é›†ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ–¹å‘å’ŒåŸºç¡€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01363v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01363.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **LLM-RadJudge: Achieving Radiologist-Level Evaluation for X-Ray Report Generation**<br><sub>æœºæ„: Microsoft Research Asia<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ”¾å°„å­¦æŠ¥å‘Šè¯„ä»·æ–°æ¡†æ¶â€”â€”LLM-RadJudgeï¼Œèƒ½å¤Ÿæœ‰æ•ˆæé«˜æ”¾å°„å­¦æŠ¥å‘Šè¯„ä»·çš„ä¸´åºŠç›¸å…³æ€§å’Œä¸€è‡´æ€§ã€‚å¹¶é€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯å®ç°äº†å°å‹æ¨¡å‹çš„å¼€å‘ï¼Œæ—¢é™ä½äº†è¯„ä»·æˆæœ¬ä¹Ÿæé«˜äº†å¯è®¿é—®æ€§ï¼Œä¸ºæ”¾å°„å­¦æŠ¥å‘Šç”Ÿæˆç ”ç©¶å’Œå®é™…åº”ç”¨æä¾›äº†æœ‰åŠ›çš„æ”¯æ’‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.00998v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.00998.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **Mapping the Increasing Use of LLMs in Scientific Papers**<br><sub>æœºæ„: Stanford University, UC Santa Barbara<br>æœ¬æ–‡æ˜¯é¦–æ¬¡è¿›è¡Œçš„ï¼Œè·¨arXivã€bioRxivå’ŒNatureç»„åˆä¸Šå‘è¡¨çš„æ–‡ç« çš„ç³»ç»Ÿæ€§ã€å¤§è§„æ¨¡åˆ†æï¼Œé‡‡ç”¨çš„ç»Ÿè®¡ä¼°è®¡æ–¹æ³•å¯ä»¥åœ¨ç¾¤ä½“å±‚é¢ä¸Šæµ‹é‡LLMä¿®æ”¹å†…å®¹çš„æ™®åŠç¨‹åº¦ï¼Œä¸ºç†è§£LLMåœ¨ç§‘å­¦å†™ä½œä¸­çš„åº”ç”¨æä¾›äº†å®è´µçš„æ´å¯Ÿã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01268v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01268.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **Efficiently Distilling LLMs for Edge Applications**<br><sub>æœºæ„: IBM Research  <br>æœ¬è®ºæ–‡æä¾›äº†ä¸€ç§æ–°çš„é’ˆå¯¹è¾¹ç¼˜è®¾å¤‡è¿›è¡ŒLLMsè’¸é¦çš„æ–¹æ³•ï¼Œå…è®¸LPFTåŒæ—¶æ˜¾è‘—å‡å°‘æ¨¡å‹å°ºå¯¸å’Œè®­ç»ƒæˆæœ¬ï¼Œå°¤å…¶æ˜¯ä¼˜åŒ–äº†è§£ç å™¨æ¨¡å‹çš„å‹ç¼©æŠµæŠ—å’Œè®­ç»ƒæ—¶é•¿ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01353v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01353.md)  |
| <span style='display: inline-block; width: 42px;'>04-01</span> | **Prompt-prompted Mixture of Experts for Efficient LLM Generation**<br><sub>æœºæ„: CMU<br>GRIFFINæ˜¯ä¸€ä¸ªä¸éœ€è¦è®­ç»ƒçš„MoEç³»ç»Ÿï¼Œåˆ©ç”¨LLMså‰é¦ˆå—å†…çš„flockingç°è±¡åœ¨ä¸åŒçš„æ¿€æ´»å‡½æ•°ä¸‹æé«˜æ¨¡å‹æ•ˆç‡ï¼Œä¿æŒæ€§èƒ½çš„åŒæ—¶å‡å°‘äº†è®¡ç®—æˆæœ¬ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.01365v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-04/2404.01365.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/hdong920/GRIFFIN)</div> |

---

### 03æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>03-28</span> | **Jamba: A Hybrid Transformer-Mamba Language Model**<br><sub>æœºæ„: AI21 Labs<br>Jambaæ˜¯åŸºäºæ··åˆTransformer-Mambaä½“ç³»ç»“æ„çš„æ–°å‹å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œçªç ´äº†å¤„ç†é•¿ä¸Šä¸‹æ–‡çš„é™åˆ¶ï¼Œå¹¶ä¸”é€šè¿‡åº”ç”¨ä¸“å®¶æ··åˆï¼ˆMoEï¼‰ç»„ä»¶æé«˜äº†æ¨¡å‹ååé‡ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒå°çš„å†…å­˜è¶³è¿¹ã€‚æ­¤æ¨¡å‹æ ‡å¿—ç€åœ¨å¤§å‹è¯­è¨€æ¨¡å‹é¢†åŸŸçš„ä¸€ä¸ªæ–°æ–¹å‘ï¼Œå¹¶å±•ç¤ºäº†é«˜æ•ˆè®­ç»ƒä¸å¼ºå¤§æ€§èƒ½ä¹‹é—´çš„å¯èƒ½å¹³è¡¡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.19887v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.19887.md)  |
| <span style='display: inline-block; width: 42px;'>03-28</span> | **sDPO: Don't Use Your Data All at Once**<br><sub>æ­¤è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„æ­¥éª¤åŒ–DPOï¼ˆsDPOï¼‰æ–¹æ³•ï¼Œé€šè¿‡åˆ†æ­¥éª¤åˆ©ç”¨åå¥½æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨å…ˆå‰æ­¥éª¤ä¸­çš„å¯¹é½æ¨¡å‹ä½œä¸ºå½“å‰æ­¥éª¤çš„å‚è€ƒæ¨¡å‹ï¼Œæœ‰æ•ˆæé«˜äº†æœ€ç»ˆæ¨¡å‹çš„æ€§èƒ½ä¸å¯¹é½åº¦ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.19270v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.1927.md)  |
| <span style='display: inline-block; width: 42px;'>03-27</span> | **BLADE: Enhancing Black-box Large Language Models with Small Domain-Specific Models**<br><sub>æœºæ„: DCST Tsinghua University, Beijing Institute of Technology, Huawei Cloud BU<br>è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ä¸ªæ–°æ¶æ„BLADEï¼Œå¯ä»¥é€šè¿‡å°å‹é¢†åŸŸç‰¹å®šæ¨¡å‹å¢å¼ºé»‘ç›’å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¹¶è§£å†³äº†å¤§å‹æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸåº”ç”¨ä¸­çš„çŸ¥è¯†ä¸è¶³é—®é¢˜ã€‚BLADEè¯æ˜äº†å…¶åœ¨æ€§èƒ½å’Œæˆæœ¬ä¸Šéƒ½æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.18365v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.18365.md)  |
| <span style='display: inline-block; width: 42px;'>03-27</span> | **Rejection Improves Reliability: Training LLMs to Refuse Unknown Questions Using RL from Knowledge Feedback**<br><sub>è¿™é¡¹å·¥ä½œé€šè¿‡æå‡ºRLKFæ¡†æ¶å¹¶å®šä¹‰äº†æ–°çš„æ¨¡å‹å¯é æ€§è¯„ä¼°æŒ‡æ ‡ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†LLMsçš„å¹»è§‰é—®é¢˜ï¼Œå¹¶æå‡äº†LLMsçš„è¯šå®åº¦å’Œå¯é æ€§ï¼Œæ˜¾ç¤ºå‡ºæ‰“é€ æ›´å€¼å¾—ä¿¡èµ–çš„AIç³»ç»Ÿçš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.18349v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.18349.md)  |
| <span style='display: inline-block; width: 42px;'>03-26</span> | **COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning**<br><sub>æœºæ„: Shenzhen Institute of Advanced Technology, CAS; M-A-P; Institute of Automation, CAS<br>æœ¬æ–‡æå‡ºäº†COIG-CQIAæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹ä¸­æ–‡æŒ‡ä»¤è°ƒä¼˜çš„é«˜è´¨é‡æ•°æ®é›†ï¼Œèƒ½å¤Ÿä¿ƒè¿›ä¸äººç±»äº¤äº’çš„å¯¹é½ã€‚ç ”ç©¶å¼ºè°ƒäº†é«˜è´¨é‡æ•°æ®æºåœ¨æ¨¡å‹å¾®è°ƒä¸­çš„é‡è¦æ€§ï¼Œå¹¶é€šè¿‡å®éªŒå±•ç¤ºäº†æ•°æ®é›†åˆ›å»ºç­–ç•¥å’Œå¾®è°ƒæ–¹æ³•å¯¹æ¨¡å‹æ€§èƒ½çš„æ˜¾è‘—å½±å“ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.18058v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.18058.md)  |
| <span style='display: inline-block; width: 42px;'>03-26</span> | **LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning**<br><sub>æœºæ„: The Hong Kong University of Science and Technology, University of Illinois Urbana-Champaign<br>è¿™ç¯‡è®ºæ–‡æå‡ºçš„LISAç­–ç•¥ï¼Œé€šè¿‡åˆ†å±‚æƒé‡é‡è¦æ€§é‡‡æ ·ï¼Œå®ç°äº†åœ¨ä¿æŒç±»ä¼¼äºLoRAçš„å†…å­˜æ•ˆç‡çš„åŒæ—¶ï¼Œæå‡äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„å¾®è°ƒæ•ˆç‡å’Œæ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.17919v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.17919.md)  |
| <span style='display: inline-block; width: 42px;'>03-26</span> | **The Unreasonable Ineffectiveness of the Deeper Layers**<br><sub>æœºæ„: Meta FAIR, UMD<br>æœ¬è®ºæ–‡é’ˆå¯¹æµè¡Œçš„å¼€æƒé‡é¢„è®­ç»ƒLLMsæå‡ºäº†ä¸€ç§ç®€å•çš„å±‚å‰ªæç­–ç•¥ï¼Œå¹¶å±•ç¤ºäº†åœ¨åˆ é™¤å¤§é‡å±‚åLLMså¯¹æ€§èƒ½å½±å“è¾ƒå°çš„å®è¯ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.17887v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.17887.md)  |
| <span style='display: inline-block; width: 42px;'>03-25</span> | **AIOS: LLM Agent Operating System**<br><sub>æœºæ„: Rutgers University  <br>AIOSä½œä¸ºä¸€ä¸ªLLMä»£ç†æ“ä½œç³»ç»Ÿï¼Œé€šè¿‡è®¾è®¡ç‰¹å®šçš„å†…æ ¸å’Œæ¨¡å—ï¼Œå…‹æœäº†ä¹‹å‰èµ„æºè°ƒåº¦å’Œä¸Šä¸‹æ–‡ç®¡ç†ç­‰é¢†åŸŸçš„æŒ‘æˆ˜ï¼Œä¸ºLLMä»£ç†çš„æ€§èƒ½å’Œæ•ˆç‡æä¾›äº†æ”¹è¿›ï¼Œä¸ºAIOSç”Ÿæ€ç³»ç»Ÿçš„æœªæ¥å‘å±•å’Œéƒ¨ç½²é“ºå¹³äº†é“è·¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.16971v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.16971.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/agiresearch/AIOS)</div> |
| <span style='display: inline-block; width: 42px;'>03-22</span> | **Can large language models explore in-context?**<br><sub>æœºæ„: Microsoft Research, Carnegie Mellon University<br>è¿™ç¯‡è®ºæ–‡è°ƒæŸ¥äº†å½“ä»£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½å¦åœ¨ä¸Šä¸‹æ–‡ä¸­ä»äº‹æ¢ç´¢çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨æ²¡æœ‰è®­ç»ƒå¹²é¢„çš„æƒ…å†µä¸‹ã€‚ç»è¿‡ä¸€ç³»åˆ—å®éªŒï¼Œä½œè€…å‘ç°åªæœ‰åœ¨ç‰¹å®šçš„é…ç½®ä¸‹LLMsæ‰èƒ½ç¨³å¥åœ°è¿›è¡Œæ¢ç´¢ã€‚ç ”ç©¶è¡¨æ˜ï¼Œæ²¡æœ‰é€‚å½“çš„æç¤ºè®¾è®¡ï¼Œå³ä½¿æ˜¯æœ€å…ˆè¿›çš„LLMsä¹Ÿå¯èƒ½æ— æ³•åœ¨æ›´å¤æ‚çš„ç¯å¢ƒä¸­è¿›è¡Œæ¢ç´¢ï¼Œè€Œåœ¨è¿™äº›ç¯å¢ƒä¸­å¤–éƒ¨æ€»ç»“å†å²å¯èƒ½æ˜¯ä¸€ä¸ªéå¹³å‡¡çš„ç®—æ³•è®¾è®¡é—®é¢˜ã€‚è¿™é¡¹å·¥ä½œæç¤ºäº†LLMså¯èƒ½éœ€è¦æœ‰é’ˆå¯¹æ€§çš„ç®—æ³•å¹²é¢„æ‰èƒ½åœ¨å¤æ‚ç¯å¢ƒä¸­æœ‰æ•ˆåœ°å·¥ä½œã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.15371v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.15371.md)  |
| <span style='display: inline-block; width: 42px;'>03-20</span> | **Chain-of-Interaction: Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts**<br><sub>æœºæ„: University of Memphis, San Francisco Veterans Affairs Health Care System, University of California San Francisco<br>æœ¬æ–‡é€šè¿‡å¼•å…¥äº’åŠ¨é“¾æç¤ºæ–¹æ³•ï¼Œæœ‰æ•ˆåœ°æå‡äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç†è§£ç²¾ç¥ç—…è¡Œä¸ºæ–¹é¢çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨åŠ¨æœºé¢è°ˆè¯­å¢ƒä¸‹çš„åº”ç”¨ã€‚é€šè¿‡ç»“æ„åŒ–çš„æç¤ºå’Œè¯„ä¼°æ–¹æ³•ï¼Œèƒ½å¤Ÿæ¨¡æ‹Ÿä¸“ä¸šå¿ƒç†æ²»ç–—äººå‘˜çš„æ€ç»´è¿‡ç¨‹ï¼Œå¯¹æ¨¡å‹è¿›è¡Œäº†æœ‰æ•ˆçš„åŸŸçŸ¥è¯†æ•™è‚²ï¼Œç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.13786v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.13786.md)  |
| <span style='display: inline-block; width: 42px;'>03-19</span> | **Towards Robots That Know When They Need Help: Affordance-Based Uncertainty for Large Language Model Planners**<br><sub>æœºæ„: University of Maryland  <br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•LAPï¼Œé€šè¿‡ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å’Œåœºæ™¯å¯ä»¥ä¾›æ€§æ¥å‡å°‘è§„åˆ’ä»»åŠ¡ä¸­çš„å¹»è§‰å¹¶å®ç°ä¸ç¡®å®šæ€§å¯¹é½ã€‚é€šè¿‡åœ¨æ¨¡æ‹Ÿå’Œç°å®ä¸–ç•Œæœºå™¨äººæ“ä½œä»»åŠ¡çš„å®éªŒä¸­è¡¨æ˜ï¼ŒLAPå¯ä»¥æ˜¾è‘—æé«˜æˆåŠŸç‡å¹¶å‡å°‘å¯¹äººç±»å¸®åŠ©çš„ä¾èµ–ï¼Œä»è€Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººé¢†åŸŸçš„è¿›æ­¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.13198v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.13198.md)  |
| <span style='display: inline-block; width: 42px;'>03-18</span> | **Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression**<br><sub>æœºæ„: University of Texas at Austin, Drexel University, MIT<br>æœ¬æ–‡é¦–æ¬¡å¯¹ç»è¿‡å‹ç¼©çš„LLMsåœ¨å¤šä¸ªä¿¡ä»»ç»´åº¦ä¸Šè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå¹¶æä¾›äº†å‹ç¼©æ—¶åŒæ—¶è€ƒè™‘æ•ˆç‡å’Œä¿¡ä»»åº¦çš„å®ç”¨å»ºè®®ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.15447v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.15447.md)  |
| <span style='display: inline-block; width: 42px;'>03-15</span> | **RAFT: Adapting Language Model to Domain Specific RAG**<br><sub>æœºæ„: UC Berkeley<br>æœ¬è®ºæ–‡æå‡ºçš„RAFTæ–¹æ³•é’ˆå¯¹è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸå†…ä»¥â€œå¼€å·â€æ¨¡å¼å›ç­”é—®é¢˜è¿›è¡Œäº†åˆ›æ–°ï¼Œå¼ºåŒ–äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œå¯¹å¹²æ‰°æ–‡æ¡£çš„æŠµæŠ—åŠ›ï¼ŒåŒæ—¶é€šè¿‡é“¾å¼æ¨ç†æ–¹å¼æ”¹è¿›äº†æ¨¡å‹ç”Ÿæˆè§£ç­”çš„å‡†ç¡®æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.10131v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.10131.md)  |
| <span style='display: inline-block; width: 42px;'>03-15</span> | **Uni-SMART: Universal Science Multimodal Analysis and Research Transformer**<br><sub>æœºæ„: DP Technology, AI for Science Institute Beijing<br>Uni-SMART æ˜¯ä¸€æ¬¾åˆ›æ–°çš„æ¨¡å‹ï¼Œæ—¨åœ¨æ·±å…¥ç†è§£å¤šæ¨¡æ€ç§‘å­¦æ–‡çŒ®ï¼Œå®ƒåœ¨å¤šä¸ªé¢†åŸŸç›¸å¯¹äºå…¶ä»–é¡¶å°–æ–‡æœ¬ç„¦ç‚¹çš„ LLMs æ˜¾ç¤ºå‡ºäº†æ›´ä¼˜è¶Šçš„æ€§èƒ½ï¼Œå¹¶æœ‰æ½œåŠ›æ”¹å˜æˆ‘ä»¬ä¸ç§‘å­¦æ–‡çŒ®çš„äº’åŠ¨æ–¹å¼ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.10301v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.10301.md)  |
| <span style='display: inline-block; width: 42px;'>03-15</span> | **VideoAgent: Long-form Video Understanding with Large Language Model as Agent**<br><sub>æœºæ„: Stanford University<br>VideoAgenté€šè¿‡æ¨¡ä»¿äººç±»çš„è®¤çŸ¥è¿‡ç¨‹ï¼Œåœ¨é•¿è§†é¢‘ç†è§£æ–¹é¢è¿ˆå‡ºäº†é‡è¦çš„ä¸€æ­¥ï¼Œå¼ºè°ƒäº†åœ¨é•¿æ—¶é—´è·¨åº¦å†…å¯¹è§†è§‰ä¿¡æ¯è¿›è¡Œæ¨ç†çš„é‡è¦æ€§ã€‚æ­¤å·¥ä½œä¸ä»…ä¸ºé•¿è§†é¢‘ç†è§£è®¾ç«‹äº†æ–°çš„åŸºå‡†ï¼Œä¹Ÿä¸ºæœªæ¥è¯¥æ–¹å‘çš„ç ”ç©¶æä¾›äº†å¯ç¤ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.10517v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.10517.md)  |
| <span style='display: inline-block; width: 42px;'>03-13</span> | **Scaling Instructable Agents Across Many Simulated Worlds**<br><sub>æ­¤è®ºæ–‡æå‡ºçš„SIMAé¡¹ç›®æ—¨åœ¨åˆ›å»ºä¸€ä¸ªèƒ½å¤Ÿåœ¨å„ç§æ¨¡æ‹Ÿ3Dç¯å¢ƒä¸­æ ¹æ®ä»»æ„è¯­è¨€æŒ‡ä»¤è¿›è¡Œæ“ä½œçš„AIç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿçš„è®¾è®¡è‡´åŠ›äºè§£å†³åœ¨æ„ŸçŸ¥å’Œä½“åŒ–è¡ŒåŠ¨ä¸­å…·ä½“åŒ–è¯­è¨€çš„æŒ‘æˆ˜ï¼Œä»¥åŠåœ¨è®¸å¤šä¸åŒç¯å¢ƒä¸­å®ç°é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2404.10179v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2404.10179.md)  |
| <span style='display: inline-block; width: 42px;'>03-13</span> | **Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments**<br><sub>æœºæ„: Nanjing University, Microsoft<br>Readiæ¡†æ¶æå‡ºäº†ä¸€ç§é«˜æ•ˆå¹¶çœŸå®åœ°åœ¨å¤§è§„æ¨¡ç»“æ„åŒ–ç¯å¢ƒä¸­è¿›è¡Œæ¨ç†çš„æ–¹æ³•ï¼Œå®ƒå……åˆ†å‘æŒ¥äº†LLMsçš„è§„åˆ’èƒ½åŠ›ï¼Œå¹¶é€šè¿‡åŠ¨æ€åé¦ˆä¼˜åŒ–æ¨ç†è·¯å¾„ï¼Œå®ç°äº†åœ¨å¤šè·³æ¨ç†ä»»åŠ¡ä¸­çš„æ˜¾è‘—æ”¹è¿›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.08593v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.08593.md)  |
| <span style='display: inline-block; width: 42px;'>03-13</span> | **Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework**<br><sub>æœºæ„: ByteDance Research, University of Maryland College Park, Carnegie Mellon University<br>è¯¥è®ºæ–‡æˆåŠŸæå‡ºäº†ä¸€ä¸ªæ–°çš„å› æœå…³ç³»å¼•å¯¼çš„å»åè§æ¡†æ¶ï¼Œå¹¶é€šè¿‡å®è¯ç ”ç©¶éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œæ—¢å¯ä»¥æ•´åˆç°æœ‰çš„åŸºäºæç¤ºçš„å»åè§æ–¹æ³•ï¼Œä¹Ÿä¸ºè¯±å¯¼æ— åè§æ¨ç†æå‡ºäº†æ–°çš„é€”å¾„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.08743v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.08743.md)  |
| <span style='display: inline-block; width: 42px;'>03-12</span> | **Chronos: Learning the Language of Time Series**<br><sub>æœºæ„: Amazon Web Services, UC San Diego, University of Freiburg<br>Chronosä½œä¸ºä¸€ä¸ªé¢„è®­ç»ƒçš„æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹æ¡†æ¶ï¼Œåœ¨é›¶æ ·æœ¬å’Œæ ‡å‡†é¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚å®ƒåˆ©ç”¨äº†æ•°æ®å¢å¼ºç­–ç•¥å’Œå…¬å…±æ•°æ®é›†çš„ä¼˜åŠ¿ï¼Œè¯å®äº†æ—¶é—´åºåˆ—é¢„æµ‹ä¸­è¯­è¨€æ¨¡å‹æ¶æ„é€šç”¨æ€§çš„æ½œåŠ›ï¼Œä¸ºå°†æ¥çš„æ—¶é—´åºåˆ—æ¨¡å‹æä¾›äº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.07815v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.07815.md)  |
| <span style='display: inline-block; width: 42px;'>03-11</span> | **RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback**<br><sub>æœºæ„: Zhejiang University, Southeast University, Massachusetts Institute of Technology<br>RA-ISFæ˜¯ä¸€ä¸ªåˆ›æ–°çš„æ£€ç´¢å¢å¼ºæ¡†æ¶ï¼Œé€šè¿‡è¿­ä»£é—®é¢˜åˆ†è§£å’Œä¸‰ä¸ªå­æ¨¡å—çš„è¿­ä»£å¤„ç†æ¥æé«˜LLMsçš„é—®é¢˜è§£å†³èƒ½åŠ›ï¼Œå¹¶æœ‰æ•ˆé™ä½ä¸ç›¸å…³æ–‡æœ¬çš„å¹²æ‰°ï¼Œæ˜¾è‘—æå‡çŸ¥è¯†æ£€ç´¢çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.06840v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.0684.md)  |
| <span style='display: inline-block; width: 42px;'>03-11</span> | **ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis**<br><sub>æœºæ„: Zhejiang University, Southeast University<br>è¯¥è®ºæ–‡é€šè¿‡æå‡ºä¸€ç§æ–°çš„æ¡†æ¶ERA-CoTï¼Œæœ‰æ•ˆå¼ºåŒ–äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚å®ä½“åœºæ™¯ä¸­çš„æ¨ç†å’Œé—®é¢˜å›ç­”èƒ½åŠ›ã€‚è¯¥æ–¹æ³•é€šè¿‡å¢å¼ºå¯¹å®ä½“å…³ç³»çš„ç†è§£ï¼Œå®ç°äº†æ˜¾è‘—æå‡æ¨¡å‹æ¨ç†å‡†ç¡®åº¦ï¼Œç‰¹åˆ«æ˜¯åœ¨CoTæ¨ç†è¿‡ç¨‹ä¸­ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.06932v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.06932.md)  |
| <span style='display: inline-block; width: 42px;'>03-11</span> | **Stealing Part of a Production Language Model**<br><sub>æœºæ„: Google DeepMind, ETH Zurich, University of Washington<br>æœ¬æ–‡æå‡ºäº†ä¸€é¡¹å¯¹ç”Ÿäº§è¯­è¨€æ¨¡å‹è¿›è¡Œæ¨¡å‹çªƒå–çš„æ–°æ”»å‡»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æå–Transformeræ¨¡å‹çš„æœ€åä¸€å±‚ï¼Œå¹¶èƒ½ç”¨äºè§£å¯†é»‘ç›’æ¨¡å‹çš„ç»†èŠ‚ä¿¡æ¯ã€å‚æ•°å’Œå°ºå¯¸ã€‚æ–‡ç« è¿˜è®¨è®ºäº†å¯èƒ½çš„é˜²å¾¡æªæ–½ï¼Œå¹¶æŒ‡å‡ºäº†ä¿®æ”¹APIä»¥é˜²æ­¢æœªæ¥æ­¤ç±»æ”»å‡»çš„å¿…è¦æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.06634v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.06634.md)  |
| <span style='display: inline-block; width: 42px;'>03-08</span> | **Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context**<br><sub>æœºæ„: Google<br>Gemini 1.5 Proåœ¨è®°å¿†ä¸æ¨ç†æµ·é‡é•¿ä¸Šä¸‹æ–‡ä¿¡æ¯çš„èƒ½åŠ›ä¸Šå–å¾—äº†æ˜¾è‘—çªç ´ï¼Œå°¤å…¶æ˜¯åœ¨è¶…é•¿æ–‡æœ¬ã€è§†é¢‘å’ŒéŸ³é¢‘å¤„ç†æ–¹é¢ã€‚è¯¥æ¨¡å‹ä¸ä»…åœ¨æ•ˆæœä¸Šä¼˜äºç°æœ‰æ¨¡å‹ï¼Œä¹Ÿåœ¨è®¡ç®—æ•ˆç‡ä¸Šæœ‰æ˜¾è‘—æé«˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.05530v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.0553.md)  |
| <span style='display: inline-block; width: 42px;'>03-08</span> | **Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation**<br><sub>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†Adversarial Policy Optimization (AdvPO)ï¼Œå®ƒæ˜¯è§£å†³åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ä¸­å‡ºç°çš„å¥–åŠ±è¿‡ä¼˜åŒ–é—®é¢˜çš„æ–°æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸äººç±»åå¥½å¯¹é½çš„å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ã€‚AdvPOæœ‰æ•ˆåœ°åœ¨æ²¡æœ‰å¸¦æ¥é«˜é¢è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹ç¼“è§£äº†å¥–åŠ±è¿‡ä¼˜åŒ–ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.05171v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.05171.md)  |
| <span style='display: inline-block; width: 42px;'>03-08</span> | **Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering**<br><sub>æœºæ„: Gaoling School of Artificial Intelligence Renmin University of China, Nankai University, Beijing Academy of Artificial Intelligence<br>LLMQAæ˜¯ä¸€ä¸ªæ–°çš„é€šç”¨æ¡†æ¶æ¨¡å‹ï¼Œé€šè¿‡ç»“åˆæ£€ç´¢å’Œç”ŸæˆèŒƒå¼æœé›†æ›´é«˜è´¨é‡çš„è¯æ®ï¼Œå¹¶è®©LLMsåœ¨æ¡†æ¶ä¸­å‘æŒ¥å¤šé‡è§’è‰²ï¼Œæé«˜äº†å¼€æ”¾åŸŸé—®ç­”ç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½ï¼Œå®éªŒç»“æœä¹Ÿè¯æ˜äº†å…¶è¶…è¶Šç°æœ‰æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.05217v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.05217.md)  |
| <span style='display: inline-block; width: 42px;'>03-07</span> | **Yi: Open Foundation Models by 01.AI**<br><sub>æœºæ„: 01.AI<br>è¯¥è®ºæ–‡æˆåŠŸåœ°æå‡ºäº†ä¸€ä¸ªåœ¨æ€§èƒ½å’Œæ•ˆç‡ä¸Šéƒ½å¯ä¸GPT-3.5ç›¸åª²ç¾çš„Yi-34Bæ¨¡å‹ï¼Œå¹¶è¯¦ç»†æè¿°äº†åœ¨å¤§å‹è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒåŠå…¶æŒ‡ä»¤å¾®è°ƒæ–¹é¢çš„åˆ›æ–°æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.04652v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.04652.md)  |
| <span style='display: inline-block; width: 42px;'>03-07</span> | **Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference**<br><sub>æœºæ„: UC Berkeley, Stanford, UCSD<br>Chatbot Arenaæ˜¯ä¸€ä¸ªåŸºäºç”¨æˆ·åå¥½ï¼Œç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„å¼€æ”¾å¹³å°ã€‚å®ƒé€šè¿‡ä¼—åŒ…æ–¹å¼æ”¶é›†ç”¨æˆ·é—®é¢˜å¹¶è¿›è¡ŒåŒ¿ååŒ–çš„éšæœºåŒ–å¯¹å†³ï¼Œç”¨äºè¯„ä¼°LLMsçš„è¡¨ç°ï¼Œè§£å†³äº†ç°æœ‰é™æ€æ•°æ®é›†åŸºå‡†æµ‹è¯•çš„å±€é™æ€§ï¼Œå¹¶é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„ç»Ÿè®¡æ–¹æ³•ç¡®ä¿äº†è¯„ä¼°ç»“æœçš„å¯ä¿¡åº¦å’Œæ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.04132v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.04132.md)  |
| <span style='display: inline-block; width: 42px;'>03-05</span> | **ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary**<br><sub>æœºæ„: Tsinghua University<br>ChatCiteç³»ç»Ÿæ˜¯ä¸ºäº†å…‹æœLLMåœ¨ç”Ÿæˆæ–‡çŒ®å›é¡¾æ—¶çš„æŒ‘æˆ˜è€Œè®¾è®¡çš„ï¼Œå®ƒé€šè¿‡ç‰¹å®šçš„æ¨¡å—ä½¿LLMä»£ç†å¯ä»¥æ›´æœ‰æ•ˆåœ°ç†è§£ã€æ±‡æ€»å’Œå¯¹æ¯”ä¸åŒçš„ç ”ç©¶å·¥ä½œï¼Œè¿›è€Œç”Ÿæˆæœ‰ç»„ç»‡ã€æœ‰æ¯”è¾ƒæ€§åˆ†æçš„æ–‡çŒ®å›é¡¾ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.02574v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.02574.md)  |
| <span style='display: inline-block; width: 42px;'>03-05</span> | **MathScale: Scaling Instruction Tuning for Mathematical Reasoning**<br><sub>æœºæ„: The Chinese University of Hong Kong Shenzhen, China; Microsoft Research Asia, Beijing, China; Shenzhen Research Institute of Big Data, Shenzhen, China<br>MathScaleæå‡ºäº†ä¸€ä¸ªå¯æ‰©å±•çš„æ–¹æ³•æ¥åˆ›å»ºé«˜è´¨é‡çš„æ•°å­¦æ¨ç†æ•°æ®ï¼Œé€šè¿‡æ„å»ºæ–°çš„è¯„ä¼°åŸºå‡†MWPBENCHå…¨é¢åœ°è¯„ä»·LLMsåœ¨æ•°å­¦æ¨ç†ä¸Šçš„èƒ½åŠ›ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹è§£å†³æ•°å­¦é—®é¢˜çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.02884v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.02884.md)  |
| <span style='display: inline-block; width: 42px;'>03-05</span> | **Design2Code: How Far Are We From Automating Front-End Engineering?**<br><sub>æœºæ„: Stanford University, Georgia Tech, Microsoft<br>æœ¬æ–‡é€šè¿‡å¯¹Design2Codeä»»åŠ¡çš„å½¢å¼åŒ–å’ŒåŸºå‡†æµ‹è¯•ï¼Œè¯„ä¼°äº†å½“å‰å¤šæ¨¡æ€LLMsåœ¨å°†è§†è§‰è®¾è®¡è½¬æ¢ä¸ºä»£ç çš„èƒ½åŠ›ï¼Œå¹¶å‘ç°GPT-4Vè¡¨ç°æœ€ä½³ï¼Œä¸ºè‡ªåŠ¨åŒ–å‰ç«¯å¼€å‘æä¾›äº†ä¸€ç§æ–°çš„èŒƒå¼ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.03163v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-03/2403.03163.md)  |

---

### 02æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **Resonance RoPE: Improving Context Length Generalization of Large Language Models**<br><sub>æœºæ„: 1DIRO UniversitÃ© de MontrÃ©al, Mila - Quebec AI Institute, Huawei Noahâ€™s Ark Lab<br>æœ¬è®ºæ–‡æå‡ºäº† Resonance Ropeï¼Œè¿™æ˜¯ä¸€ä¸ªæ”¹è¿›çš„æ¨¡å‹ï¼Œå®ƒåŸºäºå¯¹ RoPE ä½ç½®åµŒå…¥ç‰¹å¾æ³¢é•¿çš„åˆ†ææ¥æå‡æ¨¡å‹åœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶çš„æ€§èƒ½ã€‚å®ƒè¿˜å¼•å…¥äº† POSGEN åŸºå‡†æµ‹è¯•ï¼Œä»¥å¸®åŠ©ç ”ç©¶å’Œè¯„ä¼°ä½ç½®åµŒå…¥åœ¨é•¿æ–‡æœ¬ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.00071v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2403.00071.md)  |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation**<br><sub>æœºæ„: Peking University<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºSEEDçš„é€‚åº”æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨é”™è¯¯é©±åŠ¨å­¦ä¹ æ¥ä½¿LLMsæ›´å°‘æ ·æœ¬åœ°é«˜æ•ˆå­¦ä¹ ï¼Œé’ˆå¯¹ä»£ç ç”Ÿæˆä»»åŠ¡å®ç°äº†æ›´ä½³çš„æ€§èƒ½å’Œæ³›åŒ–æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2403.00046v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2403.00046.md)  |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **Beyond Language Models: Byte Models are Digital World Simulators**<br><sub>æœºæ„: Microsoft Research Asia<br>è®ºæ–‡å±•ç°äº†bGPTåœ¨å¤„ç†æŒ‘æˆ˜æ€§çš„å­—èŠ‚çº§æ•°æ®æ¨¡æ‹Ÿä»»åŠ¡ä¸­çš„æ½œåŠ›ï¼Œç‰¹åˆ«å¼ºè°ƒäº†å…¶åœ¨è·¨æ¨¡æ€çŸ¥è¯†è½¬ç§»å’Œæ•°å­—ä¸–ç•Œæ¨¡æ‹Ÿæ–¹é¢çš„èƒ½åŠ›ã€‚è¿™æ­ç¤ºäº†å­—èŠ‚æ¨¡å‹åœ¨æ•°å­—åª’ä½“æ•°æ®å¤„ç†å’Œç†è§£ä¸Šçš„å¹¿æ³›é€‚ç”¨æ€§å’Œçµæ´»æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.19155v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.19155.md)  |
| <span style='display: inline-block; width: 42px;'>02-29</span> | **StarCoder 2 and The Stack v2: The Next Generation**<br><sub>æœºæ„: ServiceNow, Hugging Face  <br>æœ¬è®ºæ–‡æå‡ºäº†The Stack v2å’ŒStarCoder2çš„å‘å±•è¿‡ç¨‹ï¼Œè¿™æ˜¯åŸºäºä»£ç å¤§è§„æ¨¡é¢„è®­ç»ƒå’ŒæŒ‡ä»¤å¾®è°ƒçš„ä¸€é¡¹å·¥ä½œã€‚ç ”ç©¶äººå‘˜é€šè¿‡æ•´åˆå¤šæ ·åŒ–æ•°æ®æºå’Œç»è¿‡ç²¾å¿ƒè®¾è®¡çš„è®­ç»ƒè¿‡ç¨‹ï¼Œæ˜¾è‘—æé«˜äº†ä»£ç LLMsçš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†ä½èµ„æºç¼–ç¨‹è¯­è¨€å’Œéœ€è¦ä»£ç æ¨ç†çš„ä»»åŠ¡ä¸Šã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.19173v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.19173.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits**<br><sub>æœºæ„: Microsoft, University of Chinese Academy of Sciences<br>è®ºæ–‡æå‡ºBitNet b1.58æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ä¸ª1.58æ¯”ç‰¹é‡åŒ–çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä¸ä¼ ç»Ÿçš„å®Œæ•´ç²¾åº¦LLMsåœ¨æ€§èƒ½ä¸Šå¯æ¯”ï¼Œè€Œä¸”æ›´é«˜æ•ˆã€æ›´èŠ‚çœèƒ½æºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17764v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17764.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions**<br><sub>æœºæ„: Alibaba Group  <br>EMO æ¡†æ¶é€šè¿‡ç›´æ¥çš„éŸ³é¢‘åˆ°è§†é¢‘åˆæˆæ–¹æ³•æé«˜äº†ç”Ÿæˆè§†é¢‘çš„çœŸå®æ„Ÿå’Œè¡¨ç°åŠ›ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œä¸ºè§†é¢‘åˆæˆé¢†åŸŸæä¾›äº†ä¸€ä¸ªé‡è¦çš„è¿›æ­¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17485v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17485.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method**<br><sub>æœºæ„: Google DeepMind<br>è¯¥è®ºæ–‡æä¾›äº†å¤§å‹è¯­è¨€æ¨¡å‹å¾®è°ƒé˜¶æ®µä¸åŒå› ç´ å¦‚æ•°æ®å¤§å°ã€æ¨¡å‹å¤§å°ä»¥åŠå¾®è°ƒæ–¹æ³•å¯¹æ¨¡å‹æ€§èƒ½å½±å“çš„æ·±å…¥æ´è§ï¼Œå®šä¹‰äº†ä¸€ç§æ–°çš„è¯„ä¼°æ¡†æ¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17193v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17193.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering**<br><sub>æœºæ„: Gaoling School of Artificial Intelligence Renmin University of China, School of Information Renmin University of China<br>è¯¥è®ºæ–‡æå‡ºäº†REARæ¡†æ¶ï¼Œé‡ç‚¹åœ¨äºé€šè¿‡ä¸ºLLMsåŠ å…¥æ–‡æ¡£ç›¸å…³æ€§è‡ªæˆ‘æ„è¯†æ¥å¢å¼ºå…¶åœ¨QAä»»åŠ¡ä¸­åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†çš„èƒ½åŠ›ï¼Œå¹¶è¯å®è¯¥æ¡†æ¶æœ‰æ•ˆåœ°è¶…è¶Šäº†å‰è¿°æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17497v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17497.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RUCAIBox/REAR)</div> |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization**<br><sub>æœºæ„: Zhejiang University, Institute of Software Chinese Academy of Sciences, Nanjing University of Posts and Telecommunications<br>Agent-Proæ˜¯ä¸€ä¸ªæ–°å‹çš„åŸºäºLLMçš„æ™ºèƒ½ä»£ç†ï¼Œèƒ½å¤Ÿé€šè¿‡æ”¿ç­–çº§åæ€å’Œä¼˜åŒ–åœ¨äº¤äº’ç¯å¢ƒä¸­å­¦ä¹ å’Œå‘å±•ç­–ç•¥ï¼Œè§£å†³äº†ç°æœ‰å·¥ä½œæ— æ³•é€šè¿‡äº¤äº’å­¦ä¹ å’Œé€‚åº”çš„é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17574v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17574.md)  |
| <span style='display: inline-block; width: 42px;'>02-27</span> | **Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models**<br><sub>æœºæ„: OpenAI<br>æœ¬æ–‡æ˜¯ä¸€ç¯‡å¯¹Soraâ€”â€”ä¸€ä¸ªå¤§å‹è§†è§‰æ¨¡å‹çš„ç»¼è¿°ã€‚è®ºæ–‡è®¨è®ºäº†Soraçš„æŠ€æœ¯ç‰¹å¾ã€åˆ›æ–°ç‚¹ã€ä»¥åŠå½“å‰åº”ç”¨é¢†åŸŸçš„å±€é™æ€§å’Œæœªæ¥å¯èƒ½çš„å‘å±•æœºä¼šã€‚Soraçš„èƒ½åŠ›åœ¨å¤šä¸ªç»´åº¦ä¸Šå±•ç°äº†å¤§å‹è§†è§‰æ¨¡å‹çš„è¿›æ­¥ï¼ŒåŒ…æ‹¬é•¿è§†é¢‘ç”Ÿæˆå’Œå¤šæ ·åŒ–è§†é¢‘æ ¼å¼çš„å¤„ç†ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.17177v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.17177.md)  |
| <span style='display: inline-block; width: 42px;'>02-26</span> | **Improving LLM-based Machine Translation with Systematic Self-Correction**<br><sub>æœºæ„: Zhejiang University, Tencent, Angelalign Technology Inc.<br>è®ºæ–‡æˆåŠŸæå‡ºäº†ç¬¬ä¸€ä¸ªåŸºäºLLMsçš„è‡ªæˆ‘çº æ­£ç¿»è¯‘æ¡†æ¶TERï¼Œå¹¶éªŒè¯äº†å…¶åœ¨å¤šç§è¯­è¨€å¯¹å’Œä¸åŒæ¨¡å‹é—´çš„ç¿»è¯‘è´¨é‡æ”¹è¿›æ•ˆæœã€‚å®ƒä¸ºæœºå™¨ç¿»è¯‘é¢†åŸŸå¸¦æ¥äº†æ–°çš„è§†è§’ï¼Œç‰¹åˆ«æ˜¯åœ¨è‡ªæˆ‘çº æ­£åœ¨é«˜èµ„æºã€ä½èµ„æºè¯­è¨€å’Œä¸åŒä¸­å¿ƒè¯­è¨€ä¹‹é—´ç¿»è¯‘çš„åº”ç”¨ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16379v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16379.md)  |
| <span style='display: inline-block; width: 42px;'>02-26</span> | **Do Large Language Models Latently Perform Multi-Hop Reasoning?**<br><sub>æœºæ„: Google DeepMind, UCL, Google Research<br>æœ¬æ–‡å¯¹LLMsæ˜¯å¦èƒ½å¤Ÿè¿›è¡Œæ½œåœ¨çš„å¤šè·³æ¨ç†è¿›è¡Œäº†ç ”ç©¶ï¼Œå¹¶é€šè¿‡å®éªŒæå‡ºäº†è¯„ä¼°LLMsæ½œåœ¨å¤šè·³æ¨ç†èƒ½åŠ›çš„æ–°æ–¹æ³•ã€‚ç ”ç©¶æç¤ºLLMså¯¹æŸäº›å…³ç³»ç±»å‹çš„æç¤ºæœ‰å¾ˆå¼ºçš„å¤šè·³æ¨ç†è¯æ®ï¼Œä½†è¿™ç§æ¨ç†è·¯å¾„çš„è¿ç”¨åœ¨ä¸åŒç±»å‹çš„æç¤ºä¸­è¡¨ç°å‡ºé«˜åº¦çš„æƒ…å¢ƒä¾èµ–æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16837v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16837.md)  |
| <span style='display: inline-block; width: 42px;'>02-26</span> | **LLMArena: Assessing Capabilities of Large Language Models in Dynamic Multi-Agent Environments**<br><sub>ç ”ç©¶ä»‹ç»äº†LLMARENAåŸºå‡†ï¼Œç”¨ä»¥è¯„ä¼°LLMsæ™ºèƒ½ä½“åœ¨å¤æ‚å¤šä»£ç†ç¯å¢ƒä¸­çš„èƒ½åŠ›ï¼ŒæŒ‡å‡ºäº†å­˜åœ¨çš„é—®é¢˜å¹¶ä¿ƒè¿›äº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ï¼ŒåŒ…æ‹¬å¤šæ¨¡æ€åŠ¨æ€ç¯å¢ƒä¸­çš„èƒ½åŠ›åŠåˆ©ç”¨å¤–éƒ¨å·¥å…·çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16499v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16499.md)  |
| <span style='display: inline-block; width: 42px;'>02-25</span> | **ChatMusician: Understanding and Generating Music Intrinsically with LLM**<br><sub>æœºæ„: Hong Kong University of Science and Technology<br>æœ¬æ–‡é€šè¿‡åˆ›é€ é¦–ä¸ªé’ˆå¯¹è¯­è¨€æ¨¡å‹çš„éŸ³ä¹é¢„è®­ç»ƒæ•°æ®é›†å’Œè¯„ä¼°åŸºå‡†ï¼Œæå‡äº†LLMsåœ¨éŸ³ä¹ç†è§£å’Œç”Ÿæˆæ–¹é¢çš„è¡¨ç°ï¼Œå¹¶åœ¨è¿™ä¸€æœªè¢«æ·±å…¥ç ”ç©¶çš„é¢†åŸŸå–å¾—äº†å®è´¨æ€§è¿›å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.16153v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.16153.md)  |
| <span style='display: inline-block; width: 42px;'>02-23</span> | **Genie: Generative Interactive Environments**<br><sub>æœºæ„: Google DeepMind, University of British Columbia<br>Genieæ˜¯èƒ½å¤Ÿç”Ÿæˆæ–°è§†é¢‘å¹¶èƒ½é€šè¿‡ç”¨æˆ·è¾“å…¥æ§åˆ¶è§†é¢‘å†…å®¹çš„äº¤äº’ç¯å¢ƒæ¨¡å‹ï¼Œå¼¥è¡¥äº†ä¼ ç»Ÿè§†é¢‘ç”ŸæˆæŠ€æœ¯ä¸äº¤äº’ä½“éªŒä¹‹é—´çš„å·®è·ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.15391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.15391.md)  |
| <span style='display: inline-block; width: 42px;'>02-23</span> | **ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and Two-Phase Partition**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.15220v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.1522.md)  |
| <span style='display: inline-block; width: 42px;'>02-22</span> | **Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments**<br><sub>é€šè¿‡ä¸ºLLMsè®¾è®¡ç‰¹å®šçš„å·¥å…·å’Œæ¨ç†ç®—æ³•ï¼Œç ”ç©¶å¼€å‘äº†åä¸ºFUXIçš„æ–°æ¡†æ¶ï¼Œæœ‰æ•ˆæé«˜äº†LLMsåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œèƒ½</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14672v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14672.md)  |
| <span style='display: inline-block; width: 42px;'>02-22</span> | **CriticBench: Benchmarking LLMs for Critique-Correct Reasoning**<br><sub>æœºæ„: Tsinghua University, University of Hong Kong<br>è¯¥è®ºæ–‡é€šè¿‡CRITICBENCHè¯„ä¼°äº†LLMsçš„æ‰¹åˆ¤å’Œçº æ­£æ¨ç†èƒ½åŠ›ï¼Œå¹¶æ¢ç©¶äº†å½±å“è¿™äº›èƒ½åŠ›çš„å…³é”®å› å­ï¼Œæ—¨åœ¨ä¿ƒè¿›LLMsæ‰¹åˆ¤å’Œè‡ªæˆ‘æ”¹è¿›èƒ½åŠ›çš„åç»­ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14809v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14809.md)  |
| <span style='display: inline-block; width: 42px;'>02-22</span> | **OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14658v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14658.md)  |
| <span style='display: inline-block; width: 42px;'>02-21</span> | **User-LLM: Efficient LLM Contextualization with User Embeddings**<br><sub>USER-LLMæ˜¯ä¸€ä¸ªé€šè¿‡ç”¨æˆ·åµŒå…¥æ¥ä¸Šä¸‹æ–‡åŒ–LLMçš„æ¡†æ¶ã€‚å®ƒèƒ½æœ‰æ•ˆåœ°è§£å†³ç”¨æˆ·æ•°æ®çš„å¤æ‚æ€§å’Œé•¿åºåˆ—å¤„ç†çš„é—®é¢˜ï¼Œæå‡äº†LLMåœ¨ä¸ªæ€§åŒ–åº”ç”¨ä¸Šçš„æ•ˆèƒ½ï¼ŒåŒæ—¶ä¹Ÿä¿è¯äº†è®¡ç®—æ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.13598v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.13598.md)  |
| <span style='display: inline-block; width: 42px;'>02-21</span> | **AgentScope: A Flexible yet Robust Multi-Agent Platform**<br><sub>æœºæ„: Alibaba Group<br>AgentScopeæ˜¯ä¸€ä¸ªç”¨äºæ„å»ºå¤šä»£ç†åº”ç”¨çš„å¤šåŠŸèƒ½å¹³å°ï¼Œå¼ºè°ƒæ˜“ç”¨æ€§ä¸å¯å®šåˆ¶æ€§ï¼Œç‰¹åˆ«é€‚åˆä¸åŒæŠ€èƒ½æ°´å¹³çš„å¼€å‘è€…ä½¿ç”¨ã€‚é€šè¿‡å®ç°å®¹é”™å’Œæ”¯æŒå¤šæ¨¡æ€æ•°æ®å¤„ç†ï¼Œä»¥åŠä¼˜åŒ–åˆ†å¸ƒå¼æ“ä½œï¼ŒAgentScopeæ˜¾è‘—é™ä½äº†å¤šä»£ç†ç³»ç»Ÿå¼€å‘ä¸éƒ¨ç½²çš„éš¾åº¦ï¼Œé¼“åŠ±æ›´å¹¿æ³›çš„å‚ä¸å’Œåˆ›æ–°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.14034v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.14034.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/modelscope/agentscope)</div> |
| <span style='display: inline-block; width: 42px;'>02-20</span> | **Instruction-tuned Language Models are Better Knowledge Learners**<br><sub>æœºæ„: FAIR at Meta, Carnegie Mellon University, University of Washington<br>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºé¢„æŒ‡ä»¤å¾®è°ƒï¼ˆPITï¼‰çš„æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°æé«˜äº†LLMsä»æ–‡æ¡£ä¸­å¸æ”¶çŸ¥è¯†çš„èƒ½åŠ›ï¼Œè§£å†³äº†æ‰€è°“çš„å›°æƒ‘åº¦è¯…å’’é—®é¢˜ï¼Œå¹¶ä¸”åœ¨å¤šåŸŸçš„çŸ¥è¯†è·å–ä¸­ä¹Ÿå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.12847v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.12847.md)  |
| <span style='display: inline-block; width: 42px;'>02-20</span> | **TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue Summarization**<br><sub>æœºæ„: AWS AI Labs, The University of Texas at Austin, KAIST<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºTOFUEVALçš„æ–°å‹è¯„ä¼°åŸºå‡†ï¼Œé’ˆå¯¹LLMåœ¨ç”Ÿæˆè¯é¢˜ç„¦ç‚¹å¯¹è¯æ‘˜è¦æ—¶çš„äº‹å®ä¸€è‡´æ€§è¿›è¡Œäº†è¯„ä¼°ã€‚ç ”ç©¶å‘ç°ï¼Œä¸åŒå¤§å°çš„LLMåœ¨å¯¹è¯é¢†åŸŸç”Ÿæˆçš„æ‘˜è¦ä¸­å­˜åœ¨å¤§é‡äº‹å®é”™è¯¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.13249v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.13249.md)  |
| <span style='display: inline-block; width: 42px;'>02-19</span> | **AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling**<br><sub>æœºæ„: Fudan University, Multimodal Art Projection Research Community, Shanghai AI Laboratory<br>AnyGPT æ˜¯ä¸€ä¸ªå¤šæ¨¡æ€æ¶æ„çš„è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡ç¦»æ•£åºåˆ—å»ºæ¨¡ï¼Œèƒ½å¤Ÿå®ç°ä¸åŒæ¨¡æ€é—´çš„æ— ç¼è½¬æ¢å’Œç»Ÿä¸€å¤„ç†ï¼Œæä¾›ä»»æ„åˆ°ä»»æ„æ¨¡æ€ä¹‹é—´çš„ç”Ÿæˆèƒ½åŠ›ï¼ŒåŒæ—¶ä¸éœ€è¦æ”¹å˜ç°æœ‰çš„ LLM æ¶æ„æˆ–è®­ç»ƒèŒƒå¼ã€‚è¯¥æ¨¡å‹é€šè¿‡åœ¨è¯­ä¹‰å’Œæ„ŸçŸ¥æ°´å¹³è¿›è¡Œå»ºæ¨¡ï¼Œèƒ½æœ‰æ•ˆå¤„ç†å’Œç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å†…å®¹ï¼Œå¹¶ä¸”ä¸ä¸“ä¸šæ¨¡å‹ç›¸æ¯”å…·æœ‰å¯æ¯”è¾ƒçš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.12226v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.12226.md)  |
| <span style='display: inline-block; width: 42px;'>02-16</span> | **Speculative Streaming: Fast LLM Inference without Auxiliary Models**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.11131v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.11131.md)  |
| <span style='display: inline-block; width: 42px;'>02-16</span> | **FinTral: A Family of GPT-4 Level Multimodal Financial Large Language Models**<br><sub>æœºæ„: The University of British Columbia & Invertible AI<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹è´¢åŠ¡åˆ†æä¼˜åŒ–çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¥—ä»¶FinTralã€‚é€šè¿‡ä¸ç°æœ‰æ¨¡å‹çš„å¯¹æ¯”ï¼Œå±•ç¤ºäº†å…¶åœ¨è´¢åŠ¡é¢†åŸŸå¤šä»»åŠ¡ç¯å¢ƒä¸‹çš„å…ˆè¿›æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†é›¶æ ·æœ¬ä»»åŠ¡å’Œå‡å°‘å¹»è§‰ç°è±¡æ–¹é¢çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.10986v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.10986.md)  |
| <span style='display: inline-block; width: 42px;'>02-16</span> | **SPAR: Personalized Content-Based Recommendation via Long Engagement Attention**<br><sub>æœºæ„: The University of British Columbia, Meta<br>SPARæ¡†æ¶å……åˆ†åˆ©ç”¨é•¿æœŸç”¨æˆ·äº’åŠ¨å†å²æ¥æå‡ä¸ªæ€§åŒ–å†…å®¹æ¨èçš„ç²¾åº¦ï¼Œå¹¶åœ¨å¤šé¡¹æ€§èƒ½æŒ‡æ ‡ä¸Šè¶…è¶Šç°æœ‰æŠ€æœ¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.10555v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.10555.md)  |
| <span style='display: inline-block; width: 42px;'>02-15</span> | **How to Train Data-Efficient LLMs**<br><sub>æœºæ„: Google DeepMind, University of California San Diego, Texas A&M University<br>è®ºæ–‡æå‡ºçš„ASK-LLMå’ŒDENSITYæŠ€æœ¯ä¼˜åŒ–äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„æ•°æ®æ•ˆç‡ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹è®­ç»ƒçš„é€Ÿåº¦å’Œè´¨é‡ï¼Œå¹¶åœ¨èµ„æºé™åˆ¶ä¸‹è¡¨ç°å‡ºè‰²ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.09668v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.09668.md)  |
| <span style='display: inline-block; width: 42px;'>02-15</span> | **Chain-of-Thought Reasoning Without Prompting**<br><sub>æœºæ„: Google DeepMind<br>è¿™é¡¹å·¥ä½œæ­ç¤ºäº†é€šè¿‡æ”¹å˜è§£ç ç­–ç•¥ï¼Œå¯ä»¥æœ‰æ•ˆåœ°ä»é¢„è®­ç»ƒçš„LLMsä¸­è‡ªç„¶åœ°å¼•å‘æ¨ç†ï¼Œå¹¶ä¸”åœ¨é¢„è®­ç»ƒæ•°æ®ä¸­é¢‘ç¹å‡ºç°çš„ä»»åŠ¡ä¸ŠCoTè·¯å¾„æ›´å¸¸è§ã€‚æå‡ºçš„CoTè§£ç æ–¹æ³•æ— éœ€æ‰‹åŠ¨å¼•å¯¼ï¼Œå°±èƒ½æ˜¾è‘—æé«˜å„ç§æ¨ç†åŸºå‡†ä¸Šçš„æ¨¡å‹æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.10200v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.102.md)  |
| <span style='display: inline-block; width: 42px;'>02-15</span> | **A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts**<br><sub>æœºæ„: Google DeepMind, Google Research<br>ReadAgent æ˜¯ä¸€ä¸ªå—äººç±»é˜…è¯»æ–¹å¼å¯å‘çš„LLMä»£ç†ç³»ç»Ÿï¼Œé€šè¿‡åˆ›å»ºæ‘˜è¦è®°å¿†å¹¶æ ¹æ®éœ€è¦æ£€ç´¢ä¿¡æ¯æ¥è§£å†³é•¿æ–‡æœ¬ä»»åŠ¡ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„è¡¨ç°å’Œä¼¸ç¼©æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.09727v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.09727.md)  |
| <span style='display: inline-block; width: 42px;'>02-14</span> | **Premise Order Matters in Reasoning with Large Language Models**<br><sub>æœºæ„: Google DeepMind<br>è¿™ç¯‡è®ºæ–‡å…³æ³¨äºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æ¨ç†ä»»åŠ¡æ—¶ï¼Œå‰æé¡ºåºçš„å½±å“ï¼Œå¹¶é€šè¿‡åˆ›å»ºR-GSMåŸºå‡†æµ‹è¯•æ¥è¯„ä¼°è¿™ä¸€ç°è±¡ã€‚ç ”ç©¶æ­ç¤ºäº†LLMså¯¹å‰æé¡ºåºæä¸ºæ•æ„Ÿï¼Œæ€§èƒ½å—é¡ºåºå½±å“æ˜¾è‘—ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.08939v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.08939.md)  |
| <span style='display: inline-block; width: 42px;'>02-09</span> | **InternLM-Math: Open Math Large Language Models Toward Verifiable Reasoning**<br><sub>æœºæ„: Shanghai AI Laboratory, Tsinghua University, Fudan University School of Computer Science<br>InternLM-Mathæ¨¡å‹æ˜¯ä¸€ç§åŸºäºLLMsçš„æ•°å­¦æ¨ç†å·¥å…·ï¼Œå®ƒæ•´åˆäº†å¤šç§èƒ½åŠ›å¹¶æä¾›äº†ç›‘ç£å­¦ä¹ ä»¥å¸®åŠ©æ¨¡å‹åœ¨å„ç§æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶å¼€æºå…¶ä»£ç å’Œæ•°æ®ã€‚è®ºæ–‡è¿˜æ¢è®¨äº†åˆ©ç”¨ç¨‹åºè¯­è¨€LEANåœ¨å¤šä»»åŠ¡å­¦ä¹ è®¾ç½®ä¸­è§£å†³æ•°å­¦é—®é¢˜çš„æ–°æ–¹æ³•ï¼Œå½°æ˜¾äº†LLMsåœ¨å½¢å¼åŒ–å’Œä»£ç è¾…åŠ©æ¨ç†ä¸­çš„æ½œèƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.06332v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.06332.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/InternLM/InternLM-Math)</div> |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **MAGDi: Structured Distillation of Multi-Agent Interaction Graphs Improves Reasoning in Smaller Language Models**<br><sub>æœºæ„: UNC Chapel Hill.<br>æœ¬è®ºæ–‡ä»‹ç»äº†åä¸ºMAGDIçš„æ–°æ–¹æ³•ï¼Œå®ƒé€šè¿‡ç»“æ„åŒ–è’¸é¦æ–¹å¼å°†å¤šLLMä¹‹é—´çš„æ¨ç†äº¤äº’è’¸é¦åˆ°æ›´å°çš„æ¨¡å‹ä¸­ï¼Œæ˜¾è‘—æå‡å°æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶é™ä½äº†æˆæœ¬ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01620v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.0162.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **K-Level Reasoning with Large Language Models**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01521v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01521.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback**<br><sub>æœºæ„: Tsinghua University, Ant Group<br>AMORæ¡†æ¶ç»¼åˆäº†åŸºäºæœ‰é™çŠ¶æ€æœºï¼ˆFSMï¼‰çš„æ¨ç†é€»è¾‘å’Œè¿‡ç¨‹åé¦ˆæœºåˆ¶ï¼Œå±•ç¤ºäº†åŸºäºå¼€æºLLMçš„çŸ¥è¯†ä»£ç†å¦‚ä½•é€šè¿‡äººç±»ç›‘ç£å®ç°æ¨ç†å’Œé€‚åº”æ€§ï¼Œæé«˜äº†æ¨¡å‹åœ¨å®ŒæˆçŸ¥è¯†å¯†é›†ä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01469v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01469.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **LimSim++: A Closed-Loop Platform for Deploying Multimodal LLMs in Autonomous Driving**<br><sub>æœºæ„: Shanghai Artificial Intelligence Laboratory, College of Control Science and Engineering Zhejiang University<br>LimSim++æ˜¯é¦–ä¸ªä¸“ä¸º(M)LLMæ”¯æŒçš„è‡ªåŠ¨é©¾é©¶è€Œå¼€å‘çš„å°é—­å¾ªç¯è¯„ä¼°å¹³å°ã€‚å®ƒè§£å†³äº†ç°æœ‰ä»¿çœŸå¹³å°çš„å±€é™æ€§ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†å…¶åœ¨å¤šç§å¤æ‚äº¤é€šåœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01246v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01246.md)  |
| <span style='display: inline-block; width: 42px;'>02-02</span> | **Reasoning Capacity in Multi-Agent Systems: Limitations, Challenges and Human-Centered Solutions**<br><sub>æœºæ„: Megagon Labs, Carnegie Mellon University<br>æœ¬è®ºæ–‡æå‡ºäº†å¤šä»£ç†ç³»ç»Ÿä¸­çš„â€œæ¨ç†èƒ½åŠ›â€æ¦‚å¿µï¼Œä»¥æ”¹å–„ä¼˜åŒ–å’Œè¯„ä¼°ï¼Œå¹¶æ¢è®¨äº†åˆ©ç”¨äººç±»åé¦ˆå¢å¼ºç³»ç»Ÿæ¨ç†èƒ½åŠ›çš„å¯èƒ½æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01108v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01108.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **Can Large Language Models Understand Context?**<br><sub>æœºæ„: Georgetown University, Apple<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªä¸Šä¸‹æ–‡ç†è§£åŸºå‡†ï¼Œç”¨ä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ã€‚è¯¥åŸºå‡†æ¶µç›–äº†å¯¹æ–‡æ¡£å’Œå¯¹è¯åŸºç¡€ä¸Šä¸‹æ–‡ç†è§£çš„è¦ç´ ï¼Œé€šè¿‡åˆ›æ–°çš„æµ‹è¯•æ–¹æ³•å’Œå®éªŒåˆ†æå±•ç¤ºäº†LLMsåœ¨ä¸Šä¸‹æ–‡ç†è§£æ–¹é¢çš„èƒ½åŠ›å’Œå±€é™æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.00858v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.00858.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **Don't Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration**<br><sub>æœºæ„: University of Washington, University of California Berkeley, The Hong Kong University of Science and Technology<br>æœ¬æ–‡å…³æ³¨çš„æ˜¯å¦‚ä½•åœ¨å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä¸­è¯†åˆ«çŸ¥è¯†å·®è·å¹¶åœ¨å¿…è¦æ—¶æ”¾å¼ƒå›ç­”é—®é¢˜ã€‚ç ”ç©¶æå‡ºäº†ä¸¤ç§åŸºäºå¤šLLMåˆä½œçš„æ–°æ–¹æ³•ï¼Œé€šè¿‡å¯¹æ¯”å®éªŒæ˜¾ç¤ºå®ƒä»¬èƒ½æœ‰æ•ˆæé«˜LLMsæ”¾å¼ƒç”Ÿæˆä½ä¿¡å¿ƒè¾“å‡ºçš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.00367v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.00367.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **HR-MultiWOZ: A Task Oriented Dialogue (TOD) Dataset for HR LLM Agent**<br><sub>æœºæ„: Amazon, University of Milano-Bicocca<br>æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªæ–°çš„é’ˆå¯¹äººåŠ›èµ„æºé¢†åŸŸçš„å¤§è¯­è¨€æ¨¡å‹ä»£ç†ï¼ˆHR LLM Agentï¼‰ä»»åŠ¡çš„å¯¹è¯æ•°æ®é›†ï¼ŒHR-MultiWOZã€‚å®ƒä¸ä»…è§£å†³äº†å½“å‰åœ¨æ„å»ºå’Œè¯„ä¼°HRé¢†åŸŸLLMä»£ç†æ—¶ç¼ºä¹é«˜è´¨é‡è®­ç»ƒæ•°æ®é›†çš„é—®é¢˜ï¼Œè¿˜æä¾›äº†ä¸€ä¸ªç»æµé«˜æ•ˆçš„æ•°æ®é›†ç”Ÿæˆæ–¹æ³•ï¼Œä¸ºåŒé¢†åŸŸä¸­çš„å…¶ä»–ç ”ç©¶æä¾›äº†å®è´µçš„èµ„æºå’Œå‚è€ƒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.01018v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.01018.md)  |
| <span style='display: inline-block; width: 42px;'>02-01</span> | **Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing**<br><sub>æœºæ„: Nanyang Technological University, Institute for Infocomm Research A*STAR, Salesforce Research<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„ç¦»çº¿è®­ç»ƒæ¡†æ¶ï¼Œä¸“æ³¨äºæ”¹è¿›å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æ—¶çš„å¯é æ€§å’Œç²¾ç¡®æ€§ï¼Œé€šè¿‡æ”¶é›†è½¨è¿¹å’ŒåŸºäºç»“æœç›‘ç£çš„ç›´æ¥åå¥½ä¼˜åŒ–ï¼Œæ— éœ€æ•™å¸ˆæ¨¡å‹æˆ–äººç±»æ ‡æ³¨ã€‚åœ¨ä¸¤ä¸ªé€»è¾‘æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„ç»“æœè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2402.00658v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-02/2402.00658.md)  |

---

### 01æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>01-31</span> | **LongAlign: A Recipe for Long Context Alignment of Large Language Models**<br><sub>æœºæ„: Tsinghua University, Zhipu.AI<br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„é•¿ä¸Šä¸‹æ–‡å¯¹é½é…æ–¹LongAlignï¼Œé€šè¿‡æ„å»ºé•¿æŒ‡ä»¤æ•°æ®é›†ã€é‡‡ç”¨æ–°çš„è®­ç»ƒç­–ç•¥å¹¶å¼•å…¥è¯„ä¼°åŸºå‡†æ¥æé«˜LLMså¤„ç†é•¿ä¸Šä¸‹æ–‡çš„èƒ½åŠ›ï¼Œä¸”ä»£ç ã€æ•°æ®å’Œé•¿å¯¹é½çš„æ¨¡å‹å·²å¼€æºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.18058v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.18058.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/THUDM/LongAlign)</div> |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Efficient Tool Use with Chain-of-Abstraction Reasoning**<br><sub>æœºæ„: Meta<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„é“¾å¼æŠ½è±¡æ¨ç†æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°æå‡äº†LLMsä½¿ç”¨å¤–éƒ¨å·¥å…·çš„èƒ½åŠ›ï¼Œå¹¶åŠ é€Ÿäº†æ¨ç†è¿‡ç¨‹ã€‚å®éªŒç»“æœè¯æ˜äº†å…¶åœ¨å¤šæ­¥éª¤æ¨ç†ä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§å’Œé«˜æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.17464v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.17464.md)  |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Can Large Language Models be Trusted for Evaluation? Scalable Meta-Evaluation of LLMs as Evaluators via Agent Debate**<br><sub>æœºæ„: Shanghai Jiao Tong University, Carnegie Mellon University, Shanghai Artificial Intelligence Laboratory<br>SCALEEVAL æ˜¯ä¸€ç§æ–°å‹çš„å…ƒè¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°LLMsä½œä¸ºè¯„ä¼°è€…çš„å¯é æ€§å’Œæ•ˆç‡ã€‚é€šè¿‡åˆ©ç”¨LLMä»£ç†é—´çš„è¾©è®ºå’Œæœ€å°åŒ–çš„äººç±»ç›‘ç£ï¼Œè¯¥æ¡†æ¶åœ¨è¯„ä¼°ä¸­å¼•å…¥çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ï¼Œå¹¶åœ¨å®éªŒä¸­æ˜¾ç¤ºå‡ºä¸çº¯äººå·¥è¯„ä¼°é«˜åº¦ä¸€è‡´çš„ç»“æœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16788v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16788.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/GAIR-NLP/scaleeval)</div> |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Recovering Mental Representations from Large Language Models with Markov Chain Monte Carlo**<br><sub>æœºæ„: Princeton University, University of Warwick<br>æœ¬æ–‡é€šè¿‡å°† LLMs æ•´åˆåˆ°é‡‡æ ·ç®—æ³•ä¸­ï¼Œå¹¶è¿ç”¨ç›´æ¥é‡‡æ ·ä¸ MCMC çš„æ–¹å¼æå–å¿ƒç†è¡¨å¾ï¼Œæœ‰æ•ˆæå‡äº†æ•ˆç‡å’Œæ€§èƒ½ï¼Œå¹¶æ¢ç´¢äº†ç”¨ LLM è¿›è¡Œè´å¶æ–¯æ¨æ–­çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16657v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16657.md)  |
| <span style='display: inline-block; width: 42px;'>01-30</span> | **Incoherent Probability Judgments in Large Language Models**<br><sub>æœºæ„: Princeton University<br>è¿™ç¯‡è®ºæ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å½¢æˆæ¦‚ç‡åˆ¤æ–­æ–¹é¢çš„è¿è´¯æ€§é—®é¢˜ï¼Œå¹¶å‘ç°è¿™äº›æ¨¡å‹åœ¨è¯¥é¢†åŸŸè¡¨ç°å‡ºçš„åå·®ä¸äººç±»è®¤çŸ¥ä¸­çš„ç³»ç»Ÿæ€§åå·®ç›¸ä¼¼ã€‚é€šè¿‡åº”ç”¨æ¦‚ç‡æ’ç­‰å¼å’Œé‡å¤åˆ¤æ–­çš„æ–¹æ³•ï¼Œç ”ç©¶äººå‘˜é‡åŒ–äº†è¿™äº›åˆ¤æ–­çš„ä¸è¿è´¯æ€§ã€‚ç ”ç©¶è¿˜æå‡ºäº†ä¸€ä¸ªå‡è®¾ï¼Œå³LLMsåœ¨åšå‡ºæ¦‚ç‡åˆ¤æ–­æ—¶çš„äººç±»æ ·åå·®å¯èƒ½æºè‡ªå®ƒä»¬é‡‡ç”¨çš„è‡ªå›å½’è®­ç»ƒç›®æ ‡ï¼Œè¿™ä¸€å‡è®¾å¾—åˆ°äº†ä»¥è´å¶æ–¯å–æ ·å™¨æ¨¡å‹å’ŒLLMsä¸­çš„è‡ªå›å½’è¿‡ç¨‹ä¹‹é—´æ½œåœ¨è”ç³»ä¸ºåŸºç¡€çš„æ”¯æŒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16646v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16646.md)  |
| <span style='display: inline-block; width: 42px;'>01-29</span> | **SelectLLM: Can LLMs Select Important Instructions to Annotate?**<br><sub>æœºæ„: University of Minnesota, Carnegie Mellon University<br>è¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ä¸ªåˆ©ç”¨LLMsé€‰æ‹©æœªæ ‡è®°çš„é«˜è´¨é‡æŒ‡ä»¤çš„æ–°æ–¹æ³•SELECTLLMï¼Œé€šè¿‡æŒ‘æˆ˜ä¼ ç»Ÿçš„é€‰æ‹©ç®—æ³•å¹¶åœ¨ä¿æŒæ•°æ®é›†çš„å…¨å±€ç»“æ„çš„åŒæ—¶æå‡é€‰æ‹©æ•ˆæœã€‚å®éªŒç»“æœæ˜¾ç¤ºäº†å…¶åœ¨æŒ‡ä»¤è°ƒæ•´åŸºå‡†æµ‹è¯•ä¸Šçš„ä¼˜è¶Šæ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16553v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16553.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/minnesotanlp/select-llm)</div> |
| <span style='display: inline-block; width: 42px;'>01-29</span> | **Beyond Direct Diagnosis: LLM-based Multi-Specialist Agent Consultation for Automatic Diagnosis**<br><sub>æœºæ„: Harbin Institute of Technology<br>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºLLMçš„è‡ªåŠ¨è¯Šæ–­æ–¹æ³•â€”â€”å¤šä¸“å®¶æ™ºèƒ½ä»£ç†å’¨è¯¢æ¨¡å‹ï¼ˆAMSCï¼‰ï¼Œå®ƒèƒ½æ›´å¥½åœ°æ¨¡æ‹Ÿç°å®ä¸–ç•Œä¸­çš„è¯Šæ–­æµç¨‹ï¼Œå¹¶é€šè¿‡é›†æˆå¤šä¸ªä¸“å®¶ä»£ç†çš„é¢„æµ‹æ¥æå‡è¯Šæ–­çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16107v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16107.md)  |
| <span style='display: inline-block; width: 42px;'>01-29</span> | **LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning**<br><sub>æœºæ„: Nanyang Technological University<br>LLM4Vulnæ˜¯ä¸€ä¸ªåˆ›æ–°çš„æ¡†æ¶ï¼Œå®ƒé€šè¿‡æä¾›æ¼æ´çŸ¥è¯†çš„å‘é‡æ•°æ®åº“ã€è°ƒç”¨å·¥å…·çš„åŠŸèƒ½ã€å®šåˆ¶çš„CoTæç¤ºæ–¹æ¡ˆä»¥åŠä½¿ç”¨ç²¾é€šæŒ‡ä»¤çš„æ¨¡å‹æ¥ç»“æ„åŒ–è¾“å‡ºï¼Œæ˜¾è‘—æé«˜äº†LLMsåœ¨ä»£ç æ¼æ´åˆ†æä¸­çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.16185v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.16185.md)  |
| <span style='display: inline-block; width: 42px;'>01-28</span> | **PRE: A Peer Review Based Large Language Model Evaluator**<br><sub>è¿™ç¯‡è®ºæ–‡æå‡ºçš„PREæ¨¡å‹é€šè¿‡æ¨¡æ‹Ÿå­¦æœ¯ç•Œçš„åŒè¡Œè¯„å®¡æœºåˆ¶ï¼Œæä¾›äº†ä¸€ç§å…¨æ–°çš„è‡ªåŠ¨è¯„ä¼°LLMçš„æ¡†æ¶ï¼Œå®ƒæ˜¾è‘—é™ä½äº†æˆæœ¬ï¼Œå¹¶ä¸”å…·æœ‰æ›´é«˜çš„é€šç”¨æ€§å’Œå¯é æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.15641v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.15641.md)  |
| <span style='display: inline-block; width: 42px;'>01-27</span> | **MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries**<br><sub>æœºæ„: Hong Kong University of Science and Technology<br>è¿™ç¯‡è®ºæ–‡å¼€å‘äº†MultiHop-RAGæ•°æ®é›†ï¼Œä»¥è¯„ä¼°å’Œæ”¹å–„ç°å­˜çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿåœ¨å¤„ç†éœ€è¦å¤šæ­¥æ£€ç´¢å’Œæ¨ç†çš„æŸ¥è¯¢ä¸Šçš„ä¸è¶³ã€‚ç ”ç©¶è¿˜æä¾›äº†ä¸€ç³»åˆ—å®éªŒç»“æœï¼Œæ­ç¤ºäº†ç›®å‰RAGç³»ç»Ÿåœ¨æ­¤ç±»ä»»åŠ¡ä¸Šçš„å±€é™æ€§ï¼Œå¹¶å…¬å¼€äº†æ•°æ®é›†æ¨åŠ¨è¿›ä¸€æ­¥çš„ç ”ç©¶å’Œå¼€å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.15391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.15391.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/yixuantt/MultiHop-RAG)</div> |
| <span style='display: inline-block; width: 42px;'>01-26</span> | **EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty**<br><sub>æœºæ„: Peking University, Microsoft Research, University of Waterloo<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªåä¸ºEAGLEçš„æ–°æ¡†æ¶ï¼Œä»¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡ªå›å½’è§£ç çš„é€Ÿåº¦ï¼ŒåŒæ—¶ä¿è¯ç”Ÿæˆæ–‡æœ¬ä¸åŸå§‹LLMsçš„æ–‡æœ¬åˆ†å¸ƒä¸€è‡´ã€‚EAGLEé€šè¿‡æ”¹è¿›æ¨æµ‹æ€§é‡‡æ ·æ–¹æ³•ï¼Œåœ¨å‡å°‘æ—¶é—´å¼€é”€å’Œæé«˜è‰ç¨¿çš„æ¥å—ç‡æ–¹é¢å–å¾—äº†æ˜¾è‘—æˆæ•ˆï¼Œå¯¹æ¯”Lookaheadå’ŒMedusaå®ç°äº†æ›´å¿«çš„åŠ é€Ÿæ•ˆæœï¼Œå¹¶ä¸”è®­ç»ƒæˆæœ¬ä½ï¼Œæ˜“äºéƒ¨ç½²ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.15077v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.15077.md)  |
| <span style='display: inline-block; width: 42px;'>01-25</span> | **Towards Consistent Natural-Language Explanations via Explanation-Consistency Finetuning**<br><sub>æœºæ„: Columbia University, Microsoft Research, University of California Berkeley<br>EC-Finetuningæ–¹æ³•æˆåŠŸåœ°æé«˜äº†LLMsç”Ÿæˆè§£é‡Šçš„ä¸€è‡´æ€§ï¼Œå¹¶ä¸”å¯ä»¥æ¨å¹¿åˆ°æœªè§è¿‡çš„æ•°æ®é›†ï¼Œè¡¨ç°å‡ºå¾®è°ƒæ•°æ®é›†ä¸Š10.0%å’Œåˆ†å¸ƒå¤–æ•°æ®é›†ä¸Š4.5%çš„è§£é‡Šä¸€è‡´æ€§ç›¸å¯¹æ”¹å–„ï¼ŒåŒæ—¶ä¹Ÿé€‚åº¦æå‡äº†é¢„æµ‹å‡†ç¡®åº¦ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13986v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13986.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/yandachen/explanation-consistency-finetuning)</div> |
| <span style='display: inline-block; width: 42px;'>01-25</span> | **True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning**<br><sub>æœºæ„: Nanyang Technological University, Zhejiang University<br>TWOSOMEæ¡†æ¶é€šè¿‡å¼ºåŒ–å­¦ä¹ æ¥æœ‰æ•ˆåœ°å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸ä½“ç°ç¯å¢ƒå¯¹é½ï¼Œæé«˜äº†æ ·æœ¬æ•ˆç‡å’Œä»»åŠ¡æ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶ä¿ç•™äº†LLMsçš„åŸå§‹åŠŸèƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.14151v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.14151.md)  |
| <span style='display: inline-block; width: 42px;'>01-25</span> | **ConstraintChecker: A Plugin for Large Language Models to Reason on Commonsense Knowledge Bases**<br><sub>æœºæ„: HKUST<br>ConstraintCheckeræ˜¯ä¸€ä¸ªèƒ½æœ‰æ•ˆæå‡LLMsåœ¨CSKBæ¨ç†ä»»åŠ¡ä¸­æ€§èƒ½çš„ç‹¬ç«‹æ’ä»¶å·¥å…·ã€‚é€šè¿‡æä¾›å’Œæ£€æŸ¥æ˜¾å¼çº¦æŸçš„æ–¹å¼ï¼Œå®ƒèƒ½å¤Ÿå¸®åŠ©LLMsåœ¨æ¨ç†ä¸­å–å¾—æ›´å¥½çš„è¡¨ç°ï¼Œä¸”åœ¨ç»è¿‡éªŒè¯åçš„æŒ‡æ ‡ä¸Šè¶…è¿‡äº†å…¶ä»–çš„æç¤ºæŠ€æœ¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.14003v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.14003.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/HKUST-KnowComp/ConstraintChecker)</div> |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **MM-LLMs: Recent Advances in MultiModal Large Language Models**<br><sub>æœºæ„: Tencent AI Lab, Kyoto University, Mohamed Bin Zayed University of Artificial Intelligence<br>æœ¬æ–‡æ˜¯ä¸€é¡¹å…³äºMM-LLMsçš„ç»¼åˆæ€§è°ƒç ”ï¼Œæ—¨åœ¨è¿›ä¸€æ­¥æ¨åŠ¨MM-LLMsé¢†åŸŸçš„ç ”ç©¶å·¥ä½œã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13601v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13601.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **Consistency Guided Knowledge Retrieval and Denoising in LLMs for Zero-shot Document-level Relation Triplet Extraction**<br><sub>æœºæ„: Nanjing University of Science and Technology, Northeastern University, Singapore Institute of Technology<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE)æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡ä»LLMsä¸­æ£€ç´¢å’Œå»å™ªçŸ¥è¯†ç”Ÿæˆå¸¦æ ‡ç­¾çš„æ•°æ®ï¼Œå¹¶é€šè¿‡ä¸€ç³»åˆ—æ–°æ–¹æ³•æ˜¾è‘—æé«˜äº†æ–‡æ¡£çº§å…³ç³»ä¸‰å…ƒç»„æŠ½å–çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13598v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13598.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption**<br><sub>æœºæ„: Tsinghua University, Zhongguancun Laboratory, XinJiang University<br>è®ºæ–‡æå‡ºçš„CGPEæ¡†æ¶èƒ½æœ‰æ•ˆæ”¯æŒLLMsåœ¨é—®ç­”ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œé€šè¿‡çº¿ç´¢å¼•å¯¼çš„è·¯å¾„æ¢ç´¢æœºåˆ¶ï¼Œé™ä½äº†å¯¹LLMsèƒ½åŠ›çš„è¦æ±‚ï¼Œå¹¶æ˜¾è‘—å‡å°‘äº†è®¡ç®—èµ„æºæ¶ˆè€—ï¼Œå¯¹è®¡ç®—èµ„æºæœ‰é™çš„ä¸ªäººå’Œç»„ç»‡å…·æœ‰é‡è¦å®é™…æ„ä¹‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13444v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13444.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents**<br><sub>æœºæ„: The University of Hong Kong, Zhejiang University, Shanghai Jiao Tong University<br>ç ”ç©¶äººå‘˜æå‡ºäº†ä¸€ä¸ªæ–°çš„åŸºå‡†æµ‹è¯• AGENTBOARDï¼Œä¸“é—¨è¯„ä¼°å…·æœ‰å¤šè½®äº¤äº’èƒ½åŠ›çš„å¤§è¯­è¨€æ¨¡å‹ä»£ç†ï¼Œå®ƒæä¾›äº†ç»†ç²’åº¦çš„è¿›å±•ç‡å’Œäº¤äº’å¼åˆ†æå·¥å…·ï¼Œä»¥å¢è¿›å¯¹ LLM ä»£ç†æ€§èƒ½çš„æ·±å…¥ç†è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13178v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13178.md)  |
| <span style='display: inline-block; width: 42px;'>01-24</span> | **Can AI Assistants Know What They Don't Know?**<br><sub>æœºæ„: Fudan University, Shanghai Artificial Intelligence Laboratory<br>è¿™ç¯‡è®ºæ–‡é‡ç‚¹æ¢ç©¶äº†AIåŠ©æ‰‹è¯†åˆ«è‡ªå·±çŸ¥è¯†è¾¹ç•Œçš„èƒ½åŠ›ï¼Œå¹¶é€šè¿‡æ„å»ºIdkæ•°æ®é›†å¹¶å¯¹åŠ©æ‰‹è°ƒæ•´ï¼Œå®ç°äº†è®©AIåŠ©æ‰‹è¯†åˆ«å¹¶æ‰¿è®¤ä¸çŸ¥é“çš„é—®é¢˜ï¼Œä»¥å‡å°‘å›ç­”ä¸­çš„äº‹å®é”™è¯¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13275v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13275.md)  |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **CCA: Collaborative Competitive Agents for Image Editing**<br><sub>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šä¸ªå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æ–°å‹ç”Ÿæˆæ¨¡å‹CCAï¼Œèƒ½å¤Ÿå¤„ç†å¤æ‚çš„å›¾åƒç¼–è¾‘ä»»åŠ¡å¹¶æå‡ç»“æœçš„è´¨é‡å’Œé²æ£’æ€§ã€‚é€šè¿‡é¼“åŠ±ä»£ç†çš„åä½œç«äº‰ï¼Œæ¨¡å‹å±•ç¤ºå‡ºä¼˜äºä¼ ç»Ÿæ–¹æ³•çš„èƒ½åŠ›ï¼Œå°¤å…¶åœ¨ç®¡ç†å¤æ‚ä»»åŠ¡å’Œä»ä¸­é—´æ­¥éª¤ä¸­å­¦ä¹ ä»¥æ”¹è¿›ç»“æœæ–¹é¢ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.13011v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.13011.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/TiankaiHang/CCA)</div> |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents**<br><sub>æœºæ„: Google DeepMind<br>æœ¬è®ºæ–‡æè¿°äº†ä¸€ä¸ªåä¸ºAutoRTçš„ç³»ç»Ÿï¼Œå®ƒåˆ©ç”¨å¤§å‹åŸºç¡€æ¨¡å‹æ§åˆ¶çœŸå®ä¸–ç•Œä¸­çš„æœºå™¨äººï¼Œä½¿å®ƒä»¬èƒ½å¤Ÿè‡ªåŠ¨å¯¼èˆªå¹¶æ‰§è¡Œä»»åŠ¡ã€‚è¿™æ ‡å¿—ç€ç¬¬ä¸€æ¬¡å®ç°LLMæ§åˆ¶çš„æœºå™¨äººåœ¨çœŸå®ç¯å¢ƒä¸­è¿›è¡Œè‡ªåŠ¨æ“ä½œã€æå‡ºç›®æ ‡å¹¶å®ç°è¿™äº›ç›®æ ‡ã€‚é€šè¿‡AutoRTæ”¶é›†åˆ°çš„æ•°æ®ä¸ä»…å¤šæ ·åŒ–ä¸”èƒ½å¤Ÿæé«˜æœºå™¨äººå­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶ä¸”å¯ä»¥ä¸äººç±»åå¥½ä¿æŒä¸€è‡´ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12963v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12963.md)  |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment**<br><sub>æœºæ„: Alibaba Inc.<br>è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºDITTOçš„è‡ªå¯¹é½æ–¹æ³•ï¼Œèƒ½å¤Ÿé€šè¿‡çŸ¥è¯†å¢å¼ºå’Œå¯¹è¯æ¨¡æ‹Ÿå¢å¼ºLLMsçš„è§’è‰²æ‰®æ¼”èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå®ƒæä¾›äº†ä¸€ç§å®¢è§‚ã€å¯å¤åˆ¶ã€å¯è§£é‡Šä¸”é«˜æ•ˆçš„è§’è‰²æ‰®æ¼”è¯„ä¼°æ–¹æ³•ï¼Œå¹¶é€šè¿‡è·¨ç›‘ç£çš„å®éªŒäº†è§£è§’è‰²æ‰®æ¼”çš„åˆ†è§£ï¼Œä¸ºLLMsæ„å»ºè§’è‰²æ‰®æ¼”åŠŸèƒ½æä¾›äº†æ·±å…¥çš„ç†è§£å’Œè§è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12474v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12474.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/OFA-Sys/Ditto)</div> |
| <span style='display: inline-block; width: 42px;'>01-23</span> | **KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning**<br><sub>æœºæ„: Samsung R&D Institute India - Bangalore<br>KAM-CoTæ˜¯ä¸€ä¸ªå¤šæ¨¡æ€CoTæ¨ç†æ¡†æ¶ï¼Œæ•´åˆäº†CoTæ¨ç†ã€çŸ¥è¯†å›¾è°±å’Œå¤šç§æ¨¡æ€ã€‚å®ƒåœ¨å…·æœ‰è¾ƒå°‘å¯è®­ç»ƒå‚æ•°çš„æƒ…å†µä¸‹ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œå±•ç°å‡ºå“è¶Šçš„æ€§èƒ½å’Œæˆæœ¬æ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12863v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12863.md)  |
| <span style='display: inline-block; width: 42px;'>01-22</span> | **PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety**<br><sub>æœºæ„: Shanghai Artificial Intelligence Laboratory, Dalian University of Technology<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå®‰å…¨æ€§çš„ç»¼åˆæ€§æ¡†æ¶PsySafeï¼Œè¯¥æ¡†æ¶ç»“åˆäº†å¿ƒç†å±‚é¢çš„æ”»å‡»ã€é˜²å¾¡ä¸è¯„ä¼°æ–¹æ³•ã€‚ç ”ç©¶çš„å®éªŒç»“æœæœ‰åŠ©äºæ›´æ·±å…¥åœ°ç†è§£å’Œç ”ç©¶å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.11880v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.1188.md)  |
| <span style='display: inline-block; width: 42px;'>01-22</span> | **CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation**<br><sub>æœºæ„: Stanford University, Stability AI  <br>æœ¬è®ºæ–‡è‡´åŠ›äºè§£å†³åœ¨è‡ªåŠ¨åŒ–èƒ¸éƒ¨Xå…‰è§£é‡Šæ–¹é¢å­˜åœ¨çš„æŒ‘æˆ˜ï¼Œé€šè¿‡å¼•å…¥ä¸“ä¸ºCXRè§£é‡Šè®¾è®¡çš„å¤§å‹æ•°æ®é›†ã€å¼€å‘äº†æ–°çš„åŸºç¡€æ¨¡å‹ä»¥åŠåˆ›å»ºäº†ä¸€ä¸ªå…¨é¢çš„è¯„ä¼°åŸºå‡†ï¼Œå®ç°äº†åœ¨åŒ»å­¦æˆåƒé¢†åŸŸçš„åº”ç”¨ï¼Œå¹¶è¯æ˜äº†åœ¨å¤šé¡¹è¯„ä¼°ä»»åŠ¡ä¸­CheXagentçš„æ€§èƒ½ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚åŒæ—¶ä¹Ÿå¯¹æ¨¡å‹ä¸­å¯èƒ½å­˜åœ¨çš„åå·®è¿›è¡Œäº†æ£€æŸ¥ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶å’Œåº”ç”¨æä¾›äº†é‡è¦å‚è€ƒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12208v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12208.md)  |
| <span style='display: inline-block; width: 42px;'>01-22</span> | **Improving Small Language Models' Mathematical Reasoning via Mix Thoughts Distillation**<br><sub>æœºæ„: Institute of Information Engineering, Chinese Academy of Sciences<br>è¿™ç¯‡è®ºæ–‡é€šè¿‡ä»‹ç»EoTDå’ŒMTDï¼Œè¡¨æ˜äº†å¯ä»¥å°†LLMsçš„æ•°å­¦æ¨ç†èƒ½åŠ›è½¬åŒ–ç»™å‚æ•°æ•°é‡å°‘äºä¸€åäº¿ä¸ªçš„SLMsã€‚é€šè¿‡å®éªŒéªŒè¯äº†è¿™äº›æ–¹æ³•ä¸ä»…ä¿ç•™äº†SLMsçš„æ¨ç†èƒ½åŠ›ï¼Œè¿˜åœ¨ä¸€å®šç¨‹åº¦ä¸Šæå‡äº†è¯¥èƒ½åŠ›ï¼Œä½¿SLMsåœ¨æ¨ç†ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å¥½æ°´å¹³ã€‚è¿™ä¸€è¿›å±•å¯¹äºåœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­æ¨å¹¿SLMsçš„åº”ç”¨æ‰“å¼€äº†å¤§é—¨ï¼Œå¹¶ç¼©å°äº†å¯¹å¼ºå¤§æ¨ç†æ¨¡å‹éœ€æ±‚ä¸è®¡ç®—èµ„æºé™åˆ¶ä¹‹é—´çš„å·®è·ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.11864v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.11864.md)  |
| <span style='display: inline-block; width: 42px;'>01-21</span> | **Interactive AI with Retrieval-Augmented Generation for Next Generation Networking**<br><sub>æœºæ„: Nanyang Technological University, Guangdong University of Technology, Institute for Infocomm Research, Agency for Science Technology and Research<br>æœ¬æ–‡ç ”ç©¶äº†å°†äº¤äº’å¼AI (IAI) é›†æˆåˆ°ä¸‹ä¸€ä»£ç½‘ç»œä¸­çš„å¯èƒ½æ€§ï¼Œé‡‡ç”¨äº†æ£€ç´¢å¢å¼ºå‹ç”Ÿæˆï¼ˆRAGï¼‰å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥æå‡å†³ç­–èƒ½åŠ›ï¼Œå¹¶é€šè¿‡çœŸå®ç½‘ç»œä¼˜åŒ–çš„æ¡ˆä¾‹ç ”ç©¶è¯æ˜äº†æå‡ºæ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.11391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.11391.md)  |
| <span style='display: inline-block; width: 42px;'>01-20</span> | **BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models**<br><sub>æœºæ„: University of Illinois Urbana-Champaign, University of Washington, Western Washington University<br>æœ¬æ–‡æå‡ºäº†BadChainï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹é‡‡ç”¨COTæç¤ºçš„LLMsçš„åé—¨æ”»å‡»ï¼Œä¸ä»…ä¸éœ€è¦è®¿é—®è®­ç»ƒæ•°æ®é›†æˆ–æ¨¡å‹å‚æ•°ï¼Œè€Œä¸”è®¡ç®—å¼€é”€ä½ã€‚è¯¥æ–¹æ³•æœ‰æ•ˆåœ°æ­ç¤ºäº†COTæç¤ºä¸‹LLMsçš„å®‰å…¨æ¼æ´ï¼Œå¼ºè°ƒäº†è¿›è¡Œåé—¨æ”»å‡»å’Œè®¾è®¡æœ‰æ•ˆé˜²å¾¡çš„é‡è¦æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.12242v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.12242.md)  |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Pruning for Protection: Increasing Jailbreak Resistance in Aligned LLMs Without Fine-Tuning**<br><sub>æœºæ„: MIT<br>è®ºæ–‡å±•ç¤ºäº†é€šè¿‡Wandaå‰ªææ–¹æ³•ï¼Œæ— éœ€å¾®è°ƒè€Œæå‡LLMsä»å¯¹é½å®‰å…¨æ€§æ–¹é¢æŠµå¾¡â€œè¶Šç‹±â€æ”»å‡»çš„èƒ½åŠ›ï¼Œå¹¶é€šè¿‡æ„å»ºç‰¹å®šçš„æ•°æ®é›†å’Œè¯„ä¼°ä½“ç³»éªŒè¯æ¨¡å‹è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10862v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10862.md)  |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Tool-LMM: A Large Multi-Modal Model for Tool Agent Learning**<br><sub>æœºæ„: ShanghaiTech University, Meituan, UniDT<br>Tool-LMMä¸ºé¦–ä¸ªè‡´åŠ›äºè®­ç»ƒå¤§å‹å¤šæ¨¡æ€æ¨¡å‹ä»¥å­¦ä¹ å·¥å…·ä»£ç†çš„ç³»ç»Ÿï¼Œåˆ›æ–°åœ°æ•´åˆäº†å¤šæ¨¡æ€è¾“å…¥ä¸å¤–éƒ¨å·¥å…·çš„æ­£ç¡®é€‰æ‹©ï¼Œå…‹æœäº†æ–‡æœ¬æ¨¡ç³Šå¸¦æ¥çš„é—®é¢˜ï¼Œå±•ç°äº†åœ¨å¤šæ¨¡æ€æŒ‡ä»¤ä¸‹è‡ªåŠ¨é€‰æ‹©åˆé€‚å·¥å…·çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10727v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10727.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Tool-LMM/Tool-LMM)</div> |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Mitigating Hallucinations of Large Language Models via Knowledge Consistent Alignment**<br><sub>æœºæ„: Sun Yat-sen University, Tencent AI Lab<br>è¿™ç¯‡è®ºæ–‡å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„KCAæ–¹æ³•ï¼Œé€šè¿‡å‡å°‘å¤–éƒ¨çŸ¥è¯†å’Œå†…åœ¨çŸ¥è¯†ä¹‹é—´çš„ä¸ä¸€è‡´æ€§ï¼Œä»è€Œå‡è½»LLMsåœ¨æ ¡å‡†è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å¹»è§‰ã€‚ç ”ç©¶æä¾›äº†æœªæ¥ç ”ç©¶çš„å‡ ä¸ªè§è§£ï¼Œå°¤å…¶æ˜¯KCAæ–¹æ³•åœ¨å¤šç§åœºæ™¯ä¸‹çš„å‡ºè‰²è¡¨ç°ï¼Œä»¥åŠå…¶ç®€å•æ€§ä¸æœ‰æ•ˆæ€§çš„ç»“åˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10768v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10768.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/fanqiwan/KCA)</div> |
| <span style='display: inline-block; width: 42px;'>01-19</span> | **Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads**<br><sub>æœºæ„: Princeton University, Together AI, University of Illinois Urbana-Champaign<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªåä¸ºMedusaçš„LLMæ¨ç†åŠ é€Ÿæ¡†æ¶ï¼Œé€šè¿‡å¢åŠ é¢å¤–çš„è§£ç å¤´å¹¶ç”¨æ ‘å½¢æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¹¶è¡Œç”Ÿæˆå¤šä¸ªtokenï¼Œæœ‰æ•ˆå‡å°‘è§£ç æ­¥éª¤æ•°é‡ï¼Œå®ç°äº†å¯¹å¤§æ¨¡å‹æ¨ç†é€Ÿåº¦çš„æ˜¾è‘—æå‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10774v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10774.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **A Fast, Performant, Secure Distributed Training Framework For Large Language Model**<br><sub>æœºæ„: Ant Group China<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºæ¨¡å‹åˆ‡ç‰‡çš„å®‰å…¨åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ï¼Œèƒ½åœ¨ä¿è¯æ¨¡å‹è®­ç»ƒç²¾åº¦å’Œé«˜æ•ˆç‡çš„åŒæ—¶ï¼Œè§£å†³äº†æœåŠ¡ç«¯å’Œå®¢æˆ·ç«¯çš„æ¨¡å‹å‚æ•°åŠæ•°æ®æ³„éœ²é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.09796v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.09796.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and Visual Question Generation**<br><sub>æœºæ„: The University of Tokyo, RIKEN<br>è¿™é¡¹ç ”ç©¶é€šè¿‡åˆ›æ–°åœ°æ•´åˆä¸€ä¸ªæ˜¾æ€§çš„æ¨ç†è¿‡ç¨‹å’Œç”Ÿæˆé—®é¢˜çš„èƒ½åŠ›åˆ°LMMä¸­ï¼Œä»¥ä¿ƒè¿›æ¨¡å‹è¿›è¡Œæ›´å¯é çš„æ¨ç†ã€‚åˆ›å»ºäº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†å¹¶åˆ©ç”¨å®ƒå¯¹æ¨¡å‹è¿›è¡ŒåŸ¹è®­ï¼Œä¸ºä»ŠåLMMçš„è¿›æ­¥è®¾å®šäº†å…ˆä¾‹ï¼Œå¹¶é€šè¿‡è¿™ç§æ–¹å¼ä½¿æ¨¡å‹åœ¨é¢ä¸´ä¸ç¡®å®šæ€§æ—¶èƒ½ç”Ÿæˆæ˜¾æ€§æ¨ç†æ­¥éª¤å’Œæé—®ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10005v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10005.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **ChatQA: Building GPT-4 Level Conversational QA Models**<br><sub>æœºæ„: NVIDIA<br>ChatQAæ¨¡å‹é€šè¿‡ä¸¤é˜¶æ®µçš„æŒ‡ä»¤å¾®è°ƒç­–ç•¥æ˜¾è‘—æ”¹è¿›äº†å¤šè½®å¯¹è¯å¼é—®ç­”çš„æ•ˆæœï¼Œå°¤å…¶æ˜¯åœ¨ä¸Šä¸‹æ–‡ç†è§£å’Œä¿¡æ¯æ£€ç´¢æ–¹é¢ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10225v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.10225.md)  |
| <span style='display: inline-block; width: 42px;'>01-18</span> | **Self-Rewarding Language Models**<br><sub>æœºæ„: Meta, NYU  <br>æœ¬æ–‡æå‡ºäº†è‡ªå¥–åŠ±è¯­è¨€æ¨¡å‹ï¼ˆSelf-Rewarding Language Modelsï¼‰ï¼Œæ—¨åœ¨é€šè¿‡è‡ªæˆ‘è®­ç»ƒæ¥é¿å…äººç±»åå¥½æ•°æ®çš„ç“¶é¢ˆï¼Œå¹¶æé«˜æ¨¡å‹çš„è‡ªå¥–åŠ±å’Œæ‰§è¡ŒæŒ‡ä»¤çš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹è¡¨ç°å‡ºè‰²ï¼Œæœ‰æœ›æˆä¸ºè¿ç»­è‡ªæˆ‘æ”¹è¿›æ¨¡å‹çš„å¼€å±±ä¹‹ä½œã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10020v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.1002.md)  |
| <span style='display: inline-block; width: 42px;'>01-17</span> | **Vlogger: Make Your Dream A Vlog**<br><sub>æœºæ„: Shanghai Jiao Tong University, Shanghai AI Laboratory, Shenzhen Institute of Advanced Technology Chinese Academy of Sciences<br>æœ¬è®ºæ–‡é€šè¿‡ä»‹ç»Vloggerç³»ç»Ÿï¼Œå±•ç¤ºäº†ä¸€ä¸ªåˆ›æ–°çš„åŠæ³•å°†LLMsåº”ç”¨äºè§†é¢‘åšå®¢çš„ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä»è€Œå…‹æœäº†ç”Ÿæˆåˆ†é’Ÿçº§è¿è´¯è§†é¢‘å†…å®¹çš„æŒ‘æˆ˜ï¼Œå¹¶å–å¾—äº†ä¼˜å¼‚çš„å®éªŒç»“æœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.09414v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.09414.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/zhuangshaobin/Vlogger)</div> |
| <span style='display: inline-block; width: 42px;'>01-17</span> | **LLMs for Relational Reasoning: How Far are We?**<br><sub>æœºæ„: Continental-NTU Corporate Lab, Nanyang Technological University, Singapore<br>æœ¬è®ºæ–‡ä¸»è¦æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å…³ç³»æ¨ç†æ–¹é¢çš„èƒ½åŠ›å’Œå±€é™æ€§ã€‚é€šè¿‡å…¨é¢çš„è¯„ä¼°ï¼ŒåŒ…æ‹¬æ–°æå‡ºçš„æµ‹è¯•æ–¹æ³•å’Œè¯„ä¼°æ¨¡å—ï¼Œå‘ç°LLMsè™½ç„¶åœ¨æŸäº›å…³ç³»æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°ä¸é”™ï¼Œä½†ä¸ä¸“é—¨ä¸ºé€»è¾‘æ¨ç†è®¾è®¡çš„æ¨¡å‹ç›¸æ¯”ï¼Œå…¶æ€§èƒ½ç›¸å¯¹è¾ƒå·®ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.09042v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.09042.md)  |
| <span style='display: inline-block; width: 42px;'>01-17</span> | **ReFT: Reasoning with Reinforced Fine-Tuning**<br><sub>æœºæ„: ByteDance Research<br>ReFTé€šè¿‡åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–éå¯å¾®ç›®æ ‡ï¼Œæ˜¾è‘—æé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•°å­¦é—®é¢˜æ±‚è§£ä»»åŠ¡ä¸­çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚å®ƒè¶…è¶Šäº†ä¼ ç»Ÿçš„ç›‘ç£å¼å­¦ä¹ æ–¹æ³•ï¼Œå±•ç°äº†åœ¨æ›´å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08967v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08967.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **SpecGen: Automated Generation of Formal Program Specifications via Large Language Models**<br><sub>æœºæ„: Nanjing University, Nanyang Technological University, Singapore Management University<br>è®ºæ–‡æå‡ºäº† SpecGenï¼Œä¸€ä¸ªç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹å’Œå¯å‘å¼é€‰æ‹©ç­–ç•¥çš„ç¨‹åºå½¢å¼åŒ–è§„èŒƒè‡ªåŠ¨ç”ŸæˆæŠ€æœ¯ã€‚é€šè¿‡æ¯”è¾ƒä¸ç°æœ‰å·¥å…·å’Œçº¯ LLM æ–¹æ³•ï¼ŒSpecGen è¡¨ç°å‡ºæ›´é«˜æ•ˆå’Œå‡†ç¡®çš„ç”Ÿæˆè§„èŒƒçš„èƒ½åŠ›ï¼Œå¹¶ä¸”æå‡ºäº†æ•°æ®é›†ä¿ƒè¿›åç»­ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08807v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08807.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture**<br><sub>æœºæ„: Microsoft<br>æœ¬æ–‡ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å†œä¸šæ•°æ®ä¸Šç”Ÿæˆé—®ç­”å¯¹çš„æ€§èƒ½ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ–°çš„ç”Ÿæˆç®¡é“ï¼Œæœ‰æ•ˆåœ°ä½¿ç”¨äº†RAGå’Œå¾®è°ƒæŠ€æœ¯å¢å¼ºLLMçš„åº”ç”¨åœºæ™¯ï¼Œæ‹“å±•äº†LLMåœ¨ç‰¹å®šè¡Œä¸šçš„åº”ç”¨æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08406v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08406.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation**<br><sub>æœºæ„: Johns Hopkins University, Microsoft<br>æœ¬è®ºæ–‡æå‡ºäº†CPOï¼Œä¸€ä¸ªæ–°çš„LLMå¾®è°ƒæ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†SFTåœ¨æœºå™¨ç¿»è¯‘ä»»åŠ¡ä¸­å­˜åœ¨çš„ç“¶é¢ˆï¼Œå®ç°äº†åœ¨èµ„æºæ¶ˆè€—æå°‘çš„æƒ…å†µä¸‹æ˜¾è‘—æå‡ä¸­ç­‰è§„æ¨¡LLMç¿»è¯‘æ¨¡å‹çš„æ€§èƒ½ï¼Œæœ€ç»ˆä¸æœ€å…ˆè¿›çš„çŠ¶æ€è‰ºæœ¯ç¿»è¯‘ç³»ç»Ÿé½å¤´å¹¶è¿›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08417v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08417.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language Models**<br><sub>æœºæ„:  Zhejiang University<br>DoraemonGPTæ˜¯ä¸€ä¸ªLLMé©±åŠ¨çš„æ™ºèƒ½ä½“ï¼Œé€šè¿‡ç¬¦å·è®°å¿†å’Œå·¥å…·é›†æ¥ç†è§£å¹¶è§£ç­”æ¶‰åŠåŠ¨æ€è§†é¢‘çš„å¤æ‚é—®é¢˜ã€‚å…¶é‡‡ç”¨äº†MCTSè§„åˆ’å™¨ä¼˜åŒ–å›ç­”çš„ç”Ÿæˆè¿‡ç¨‹ï¼Œèƒ½å¤Ÿåœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­å¤„ç†æ›´ä¸ºå¤æ‚çš„ä»»åŠ¡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08392v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08392.md)  |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **Salute the Classic: Revisiting Challenges of Machine Translation in the Age of Large Language Models**<br><sub>æœºæ„: Tencent AI Lab<br>æœ¬æ–‡æ·±å…¥åˆ†æäº†LLMsåœ¨æœºå™¨ç¿»è¯‘ä»»åŠ¡ä¸­é¢†åŸŸä¸åŒ¹é…é—®é¢˜ï¼Œå¹¶å®éªŒäº†ä¸åŒæ•°é‡çš„å¹³è¡Œæ•°æ®å¯¹LLMsç¿»è¯‘èƒ½åŠ›çš„å½±å“ï¼Œå±•ç°å‡ºLLMsåœ¨å¤„ç†è¿™äº›æŒ‘æˆ˜ä¸­çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08350v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0835.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/pangjh3/LLM4MT)</div> |
| <span style='display: inline-block; width: 42px;'>01-16</span> | **MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible Pipeline**<br><sub>æœºæ„: Alibaba Group  <br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„æ•°å­¦æ¨ç†æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ä¸Pythonä»£ç è§£é‡Šå™¨ç›¸ç»“åˆï¼Œé€šè¿‡æ”¹è¿›æ•°æ®é›†å¹¶å®æ–½ç‰¹å®šå¾®è°ƒæµç¨‹æ˜¾è‘—æé«˜äº†LLMåœ¨æ•°å­¦é—®é¢˜æ±‚è§£ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08190v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0819.md)  |
| <span style='display: inline-block; width: 42px;'>01-15</span> | **A Study on Large Language Models' Limitations in Multiple-Choice Question Answering**<br><sub>æœºæ„: David R. Cheriton School of Computer Science<br>è¯¥è®ºæ–‡é’ˆå¯¹LLMsåœ¨MCQä»»åŠ¡ä¸­çš„é™åˆ¶è¿›è¡Œäº†ç ”ç©¶ï¼ŒæŒ‡å‡ºå¤šæ•°æ¨¡å‹åœ¨æ­¤ç±»ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚è®ºæ–‡è¿˜å‘ç°æ¨¡å‹çš„å›ç­”å¾€å¾€ä¾èµ–äºé€‰é¡¹é¡ºåºï¼Œå¹¶æå‡ºäº†æœ‰æ•ˆçš„è¯„ä¼°æ–¹æ³•æ¥æ’é™¤è¿™äº›åè§ã€‚è®ºæ–‡æ¨èåœ¨ä½¿ç”¨MCQè¯„ä¼°LLMsæ—¶è¦æ ¼å¤–å°å¿ƒï¼Œå¹¶æµ‹è¯•æ¨¡å‹æ˜¯å¦çœŸæ­£ç†è§£äº†ä»»åŠ¡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07955v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07955.md)  |
| <span style='display: inline-block; width: 42px;'>01-15</span> | **MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of Large Language Models**<br><sub>æœºæ„: Microsoft Research India<br>è¿™ç¯‡è®ºæ–‡ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€ä»»åŠ¡ä¸Šé€šè¿‡å‚æ•°é«˜æ•ˆå¾®è°ƒåçš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½èµ„æºè¯­è¨€å’Œè‹±è¯­ä»»åŠ¡ä¸Šã€‚ç ”ç©¶å±•ç¤ºäº†PEFTçš„æ½œåŠ›ï¼ŒåŒæ—¶æŒ‡å‡ºäº†æœªæ¥å·¥ä½œçš„ä¸€äº›å¯èƒ½æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07598v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07598.md)  |
| <span style='display: inline-block; width: 42px;'>01-15</span> | **The What, Why, and How of Context Length Extension Techniques in Large Language Models -- A Detailed Survey**<br><sub>æœºæ„: Technology Innovation Institute UAE, Islamic University of Technology Bangladesh, Stanford University, Amazon GenAI, AI Institute University of South Carolina<br>æœ¬è®ºæ–‡æ˜¯å…³äºLLMsä¸Šä¸‹æ–‡é•¿åº¦æ‰©å±•æŠ€æœ¯çš„è¯¦ç»†è°ƒç ”ã€‚å®ƒä¸ºç ”ç©¶äººå‘˜æä¾›äº†è¯¥é¢†åŸŸçš„ç°æœ‰ç­–ç•¥å’ŒæŒ‘æˆ˜çš„æœ‰ç»„ç»‡æ¦‚è§ˆï¼Œå¹¶é¼“åŠ±äº†å¯¹æœªæ¥å‘å±•çš„è®¨è®ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07872v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07872.md)  |
| <span style='display: inline-block; width: 42px;'>01-14</span> | **Small LLMs Are Weak Tool Learners: A Multi-LLM Agent**<br><sub>æœºæ„: Sun Yat-sen University, Alibaba Group<br>ç ”ç©¶è¡¨æ˜å°å‹LLMåœ¨ä½œä¸ºå·¥å…·å­¦ä¹ è€…æ–¹é¢è¾ƒä¸ºè–„å¼±ï¼Œé€šè¿‡å¼•å…¥Î±-UMiå¤šLLMæ¡†æ¶æ¥æ„å»ºæ€§èƒ½æ›´ä¼˜çš„LLMä»£ç†ï¼Œæå‡ºäº†å¿…è¦çš„åŒé˜¶æ®µå¾®è°ƒç­–ç•¥ï¼Œå¹¶æ·±å…¥åˆ†æäº†æ•°æ®è§„æ¨¡æ³•åˆ™ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.07324v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.07324.md)  |
| <span style='display: inline-block; width: 42px;'>01-13</span> | **Bridging the Preference Gap between Retrievers and LLMs**<br><sub>æœ¬è®ºæ–‡ä»‹ç»äº†BGMæ¡†æ¶ä»¥è§£å†³æ£€ç´¢å™¨å’ŒLLMsä¹‹é—´çš„"åå¥½å·®"é—®é¢˜ï¼Œé€šè¿‡ä¸€ä¸ªåºåˆ—åˆ°åºåˆ—ï¼ˆseq2seqï¼‰çš„æ¡¥æ¨¡å‹ç»“åˆSLå’ŒRLçš„è®­ç»ƒæ–¹æ¡ˆï¼Œä¼˜åŒ–äº†æ£€ç´¢ä¿¡æ¯ä»¥æ»¡è¶³LLMsçš„åå¥½ï¼Œæ”¹è¿›äº†å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡çš„è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06954v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06954.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **Kun: Answer Polishment for Chinese Self-Alignment with Instruction Back-Translation**<br><sub>æœºæ„: Tianyu Zheng, Shuyue Guo, Xingwei Qu, Jiawei Guo, Weixu Zhang, Xinrun Du, Chenghua Lin, Wenhao Huang, Wenhu Chen, Jie Fu, Ge Zhang<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†Kunç­–ç•¥ï¼Œè§£å†³äº†ä¸­æ–‡å¤§å‹è¯­è¨€æ¨¡å‹æŒ‡ä»¤å¾®è°ƒä¸­å­˜åœ¨çš„æ•°æ®ä¸€è‡´æ€§é—®é¢˜ï¼Œé€šè¿‡APè¿‡ç¨‹å’Œæ–°çš„æ•°æ®ç”Ÿæˆæ–¹æ³•ï¼Œå‡å°‘äº†å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒKunç­–ç•¥åœ¨åˆ›å»ºé«˜è´¨é‡æ•°æ®é›†æ–¹é¢å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06477v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06477.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Zheng0428/COIG-Kun)</div> |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **Teaching Code LLMs to Use Autocompletion Tools in Repository-Level Code Generation**<br><sub>æœºæ„: Nanyang Technological University, Fudan University<br>è¯¥è®ºæ–‡æˆåŠŸæå‡ºäº†ä¸€ç§æ–°æ–¹æ³•TOOLGENï¼Œé€šè¿‡é›†æˆè‡ªåŠ¨å®Œæˆå·¥å…·åˆ°ä»“åº“çº§ä»£ç ç”Ÿæˆä¸­çš„LLMsï¼Œè§£å†³äº†ä¾èµ–æ€§é—®é¢˜ï¼Œæé«˜äº†ä»£ç ç”Ÿæˆçš„è´¨é‡å’ŒæˆåŠŸç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06391v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06391.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs**<br><sub>æœºæ„: Virginia Tech, Renmin University of China, UC Davis<br>æœ¬è®ºæ–‡æå‡ºäº†å°†LLMsè§†ä¸ºå…·å¤‡ç±»äººæ²Ÿé€šèƒ½åŠ›çš„å®ä½“ï¼Œåˆ©ç”¨äº†ä¸€ä¸ªæ–°çš„è§†è§’æ¥ç ”ç©¶AIå®‰å…¨é—®é¢˜ã€‚é€šè¿‡å°†åå¤šå¹´çš„ç¤¾ä¼šç§‘å­¦ç ”ç©¶åº”ç”¨äºAIå®‰å…¨ï¼Œåˆ¶å®šäº†ä¸€ä¸ªè¯´æœæŠ€å·§åˆ†ç±»æ³•ï¼Œå¹¶é€šè¿‡åˆ›å»ºçš„å·¥å…·è‡ªåŠ¨ç”Ÿæˆäº†å¯¹æŠ—æ€§æç¤ºã€‚ç»“æœè¡¨æ˜ï¼Œè¯´æœæŠ€å·§å¯ä»¥æœ‰æ•ˆåœ°å¢å¼ºæœ‰é£é™©è¡Œä¸ºè¢«LLMsæ‰§è¡Œçš„å¯èƒ½æ€§ï¼ŒåŒæ—¶æ­ç¤ºäº†å½“å‰é˜²å¾¡æ‰‹æ®µåœ¨åº”å¯¹è¿™ç±»ç­–ç•¥æ—¶çš„ä¸è¶³ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06373v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06373.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **From Automation to Augmentation: Large Language Models Elevating Essay Scoring Landscape**<br><sub>æœºæ„: Tsinghua University, University of Maryland, Beijing Xicheng Educational Research Institute  <br>æœ¬æ–‡çš„ç ”ç©¶å±•ç°äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•™è‚²é¢†åŸŸä¸­ï¼Œç‰¹åˆ«æ˜¯åœ¨AESç³»ç»Ÿä¸­çš„æ½œåŠ›ã€‚LLMsä¸ä»…èƒ½å¤Ÿè‡ªåŠ¨åŒ–è¯„åˆ†è¿‡ç¨‹ï¼Œè¿˜èƒ½å¤Ÿé€šè¿‡ç”Ÿæˆåé¦ˆæ¥å¢å¼ºäººç±»è¯„åˆ†è€…çš„è¡¨ç°ã€‚è¿™ä¸ä»…æ˜¯æŠ€æœ¯ä¸Šçš„è¿›æ­¥ï¼Œæ›´ä¸ºæœªæ¥çš„äººå·¥æ™ºèƒ½è¾…åŠ©æ•™è‚²å’Œäººå·¥æ™ºèƒ½ä¸äººç±»çš„é«˜æ•ˆåä½œæä¾›äº†å®è´µè§è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06431v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06431.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models**<br><sub>æœºæ„: University of Washington Seattle, University of Wisconsin-Madison, Stanford University<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªå®éªŒè®¾è®¡æ¡†æ¶ï¼Œä¸ºäº†æé«˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç›‘ç£å¼å¾®è°ƒï¼ˆSFTï¼‰è¿‡ç¨‹ä¸­çš„æ ‡ç­¾æ•ˆç‡ã€‚å®ƒå±•ç¤ºäº†å®éªŒè®¾è®¡æŠ€æœ¯å¯ä»¥åœ¨ç»´æŒä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œå¤§å¹…æé«˜æ ‡ç­¾æ•ˆç‡ï¼Œåœ¨ä¸€äº›ä»»åŠ¡ä¸­ä¸éšæœºé‡‡æ ·ç›¸æ¯”èŠ‚çœäº†50%çš„æ³¨é‡Šæˆæœ¬ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06692v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06692.md)  |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **TestSpark: IntelliJ IDEA's Ultimate Test Generation Companion**<br><sub>æœºæ„: JetBrains Research, Delft University of Technology<br>è®ºæ–‡æå‡ºäº†TestSparkæ’ä»¶ï¼Œå®ƒç»“åˆäº†åŸºäºæœç´¢çš„è½¯ä»¶æµ‹è¯•ç”Ÿæˆå’ŒåŸºäºè¯­è¨€æ¨¡å‹çš„æµ‹è¯•ç”Ÿæˆæ–¹æ³•ï¼Œåœ¨IntelliJ IDEAä¸­æé«˜äº†å•å…ƒæµ‹è¯•çš„ç”Ÿæˆå’Œé›†æˆæ•ˆç‡ï¼ŒåŒæ—¶è§£å†³äº†LLMç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å¯ç¼–è¯‘æ€§çš„é—®é¢˜ã€‚æ’ä»¶çš„å¼€æºç‰¹æ€§ä½¿å…¶æˆä¸ºè¿æ¥è½¯ä»¶å¼€å‘è€…å’Œç ”ç©¶è€…çš„æ¡¥æ¢ï¼Œæœ‰åŠ©äºæµ‹è¯•ç”ŸæˆæŠ€æœ¯çš„å®ç”¨æ€§è¿›æ­¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06580v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0658.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/JetBrains-Research/TestSpark)</div> |
| <span style='display: inline-block; width: 42px;'>01-12</span> | **APAR: LLMs Can Do Auto-Parallel Auto-Regressive Decoding**<br><sub>æœºæ„: Tsinghua University, Zhipu AI<br>é€šè¿‡å®æ–½APARï¼Œè¯¥ç ”ç©¶æˆåŠŸæé«˜äº†LLMsåœ¨å†…å­˜å—é™åœºæ™¯å’Œé«˜ååç‡åœºæ™¯ä¸‹çš„è§£ç æ•ˆç‡å’Œç”Ÿæˆé€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆè´¨é‡ï¼Œä¸ºå¤§è¯­è¨€æ¨¡å‹çš„éƒ¨ç½²æä¾›äº†ä¸€ç§æ–°çš„é«˜æ•ˆç­–ç•¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06761v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06761.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **LLM-as-a-Coauthor: The Challenges of Detecting LLM-Human Mixcase**<br><sub>æœºæ„: LAIR Lab Lehigh University, Huazhong University of Science and Technology  <br>æœ¬æ–‡å®šä¹‰äº†æ··åˆåœºæ™¯ä¸­çš„æ··åˆæ–‡æœ¬ï¼ˆmixcaseï¼‰ï¼Œæ„å»ºäº†MIXSETæ•°æ®é›†ï¼Œå¹¶æå‡ºäº†é€šå‘è§£å†³æ··åˆæ–‡æœ¬æ£€æµ‹é—®é¢˜çš„è§è§£å’Œæ–¹å‘ã€‚ç ”ç©¶å‘ç°ï¼Œç°æœ‰çš„æ£€æµ‹å™¨åœ¨è¯†åˆ«æ··åˆæ–‡æœ¬æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œè¿™æå‡ºäº†åˆ¶å®šæ›´ç»†ç²’åº¦æ£€æµ‹å™¨çš„ç´§è¿«éœ€æ±‚ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05952v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05952.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Dongping-Chen/MixSet)</div> |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **TOFU: A Task of Fictitious Unlearning for LLMs**<br><sub>æœºæ„: Carnegie Mellon University<br>æ–‡ç« ä¸ºLLMé—å¿˜é—®é¢˜æä¾›äº†æ–°çš„æ•°æ®é›†å’Œè¯„ä¼°æœºåˆ¶ï¼ŒTOFUä»»åŠ¡å±•ç¤ºäº†ç°æœ‰é—å¿˜æŠ€æœ¯çš„ä¸è¶³ï¼Œé¼“åŠ±äº†ç›¸ç»§è€Œæ¥çš„æ”¹è¿›å’Œç ”ç©¶å·¥ä½œã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06121v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06121.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Patchscope: A Unifying Framework for Inspecting Hidden Representations of Language Models**<br><sub>æœºæ„: Google Research, Tel Aviv University<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºPatchscopesçš„æ¡†æ¶ï¼Œæä¾›äº†ä¸€ç§æ–°çš„æ–¹æ³•å»è§£é‡Šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰éšè—è¡¨ç¤ºä¸­ç¼–ç çš„ä¿¡æ¯ï¼Œå¹¶ä¸”èƒ½å¤Ÿçº æ­£å¤šæ­¥æ¨ç†é”™è¯¯ã€‚Patchscopesä½œä¸ºä¸€ç§é€šç”¨çš„å¯é…ç½®æ¡†æ¶ï¼Œä¸ä»…ç»Ÿä¸€äº†ç°æœ‰çš„è§£é‡Šå·¥å…·ï¼Œå¹¶è§£å†³äº†å®ƒä»¬è‡ªèº«çš„ä¸€äº›ä¸è¶³ï¼ŒåŒæ—¶ä¹Ÿå¼€è¾Ÿäº†æ–°çš„ç ”ç©¶å’Œåº”ç”¨å¯èƒ½æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06102v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06102.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Improving Large Language Models via Fine-grained Reinforcement Learning with Minimum Editing Constraint**<br><sub>æœºæ„: Gaoling School of Artificial Intelligence, Renmin University of China; School of Information, Renmin University of China; Kuaishou Technology, Beijing China.<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„RLæ–¹æ³•ï¼Œåä¸ºRLMECï¼Œé€šè¿‡ç”Ÿæˆå¼å¥–åŠ±æ¨¡å‹å’Œæœ€å°ç¼–è¾‘æœºåˆ¶ï¼Œä½¿å¤§å‹è¯­è¨€æ¨¡å‹åœ¨RLè®­ç»ƒè¿‡ç¨‹ä¸­å®ç°æ›´ç²¾ç»†çš„ç›‘ç£å’Œè®­ç»ƒçš„ç¨³å®šæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06081v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06081.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RUCAIBox/RLMEC)</div> |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Chain of History: Learning and Forecasting with LLMs for Temporal Knowledge Graph Completion**<br><sub>æœºæ„: Tsinghua Shenzhen International Graduate School Tsinghua University, School of Computer Science Peking University, Baidu Inc.<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæ—¶é—´çŸ¥è¯†å›¾è°±å®Œæˆçš„æ–¹æ³•ï¼Œé€šè¿‡é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•å’Œç»“åˆç»“æ„ä¿¡æ¯çš„å†å²æ•°æ®å¢å¼ºï¼Œæé«˜äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œæ€§èƒ½ã€‚å®éªŒæ˜¾ç¤ºè¯¥æ–¹æ³•æœ‰æ•ˆåœ°æå‡äº†æ—¶é—´çŸ¥è¯†å›¾è°±é¢„æµ‹çš„ç²¾åº¦ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06072v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06072.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Evidence to Generate (E2G): A Single-agent Two-step Prompting for Context Grounded and Retrieval Augmented Reasoning**<br><sub>æœºæ„: Qatar Computing Research Institute <br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„ã€ç”¨äºæ”¹å–„LLMsåœ¨ä¸Šä¸‹æ–‡æ¨ç†èƒ½åŠ›çš„å•ä»£ç†åŒæ­¥æç¤ºæ¡†æ¶â€”â€”Evidence to Generate (E2G)ã€‚é€šè¿‡è¦æ±‚LLMsåœ¨ç”Ÿæˆç­”æ¡ˆçš„åŒæ—¶æä¾›è¯æ®ä¸è§£é‡Šï¼ŒE2Gèƒ½å¤Ÿå‡å°‘é”™è¯¯æ¨ç†å¹¶æé«˜æ¨¡å‹åœ¨å¤„ç†å„ç§æ¨ç†ä»»åŠ¡æ—¶çš„å‡†ç¡®åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒE2Gæ–¹æ³•åœ¨å¤šä¸ªæƒ…å¢ƒå¯†é›†å‹è¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°å‡ºè¾ƒCoTæ›´å¥½çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05787v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05787.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems**<br><sub>æœºæ„: Zhongguancun Laboratory, Tsinghua University, Institute of Information Engineering Chinese Academy of Sciences<br>æœ¬æ–‡ä¸ºå¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿä¸­çš„é£é™©åˆ†ç±»ã€ç¼“è§£æªæ–½ä»¥åŠè¯„ä¼°æ ‡å‡†æä¾›äº†å…¨é¢çš„æ¦‚è¿°ï¼Œæå‡ºäº†ä¸€ä¸ªæ–°çš„ç³»ç»ŸåŒ–åˆ†ç±»æ¡†æ¶ï¼Œå¸®åŠ©å¼€å‘è€…æ›´å…¨é¢åœ°ç†è§£å’Œå¤„ç†LLMç³»ç»Ÿçš„æ½œåœ¨é£é™©ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05778v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05778.md)  |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction**<br><sub>æœºæ„: Fudan University, Microsoft Research Asia, Zhejiang University<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºEASYTOOLçš„æ–¹æ³•ï¼Œå¯ä»¥é€šè¿‡ç®€åŒ–å’Œç»Ÿä¸€å·¥å…·æ–‡æ¡£çš„æŒ‡ä»¤æ¥æé«˜LLMåŸºç¡€ä»£ç†åœ¨å·¥å…·ä½¿ç”¨æ–¹é¢çš„è¡¨ç°ï¼Œè§£å†³äº†ç°æœ‰å·¥å…·ä½¿ç”¨ä¸­çš„ä¸ä¸€è‡´æ€§ã€å†—ä½™æ€§å’Œä¸å®Œæ•´æ€§é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06201v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.06201.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/microsoft/JARVIS)</div> |
| <span style='display: inline-block; width: 42px;'>01-11</span> | **The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models**<br><sub>æœºæ„: Johns Hopkins University<br>æ­¤ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡ä½¿ç”¨ç®€æ´çš„æ€ç»´é“¾æç¤ºï¼ˆCCoTï¼‰ï¼Œåœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å¯ä»¥å¤§å¹…å‡å°‘æ–‡æœ¬è¾“å‡ºçš„é•¿åº¦ï¼Œè€Œä¸ä¼šå½±å“è§£å†³é—®é¢˜çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05618v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05618.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **AUTOACT: Automatic Agent Learning from Scratch via Self-Planning**<br><sub>æœºæ„: Zhejiang University, Alibaba Group<br>è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåä¸ºAUTOACTçš„æ¡†æ¶ï¼Œå®ƒé€šè¿‡è‡ªæˆ‘æŒ‡å¯¼å’Œè‡ªæˆ‘è§„åˆ’å®ç°è¯­è¨€ä»£ç†çš„è‡ªåŠ¨å­¦ä¹ ï¼Œä»¥åº”å¯¹ä»é›¶å¼€å§‹å­¦ä¹ æ–°ä»»åŠ¡çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºæœ‰æ•ˆçš„æ•°æ®æ‰©å……æ–¹æ³•å’Œé«˜æ•ˆç‡çš„è‡ªåŠ¨ä»£ç†å­¦ä¹ è¿‡ç¨‹ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05268v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05268.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/zjunlp/AutoAct)</div> |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks**<br><sub>InfiAgent-DABenchæä¾›äº†ä¸€ä¸ªæ–°é¢–çš„è¯„ä¼°åŸºå‡†ï¼Œè¿™ä¸ä»…æœ‰åŠ©äºè¡¡é‡æ™ºèƒ½ä»£ç†åœ¨æ•°æ®åˆ†æä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¹Ÿæ˜¯æ¢ç´¢å¦‚ä½•æ”¹è¿›å’Œä¼˜åŒ–LLMåœ¨è¿™ä¸€ç‰¹å®šé¢†åŸŸåº”ç”¨çš„é‡è¦ä¸€æ­¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05507v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05507.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/InfiAgent/InfiAgent)</div> |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security**<br><sub>æœºæ„: Tsinghua University, Xiaomi AI Lab<br>è¯¥è®ºæ–‡ä½œä¸ºä¸€é¡¹è°ƒç ”å·¥ä½œï¼Œä»‹ç»äº†ä¸ªäººLLMä»£ç†çš„ç°çŠ¶ã€æŒ‘æˆ˜å’Œæœªæ¥è¶‹åŠ¿ï¼Œå¹¶æå‡ºäº†ä¸€ç§é€šç”¨çš„ç³»ç»Ÿæ¶æ„å’Œæ™ºèƒ½æ°´å¹³å®šä¹‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05459v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05459.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **CASA: Causality-driven Argument Sufficiency Assessment**<br><sub>æœºæ„: Peking University<br>æœ¬è®ºæ–‡ä»‹ç»äº†ä¸€ä¸ªåŸºäºLLMsçš„é›¶æ ·æœ¬å› æœé©±åŠ¨è®ºè¯å……åˆ†æ€§è¯„ä¼°æ¡†æ¶ï¼ˆCASAï¼‰ï¼ŒæˆåŠŸåº”å¯¹äº†æ— è§‚æµ‹æ•°æ®ä¸‹è®ºè¯å……åˆ†æ€§é‡åŒ–å’Œå¹²é¢„çš„éš¾é¢˜ï¼Œå¹¶åœ¨å®é™…åº”ç”¨ä¸­å±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05249v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05249.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/xxxiaol/CASA)</div> |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Prompting Large Language Models for Recommender Systems: A Comprehensive Framework and Empirical Analysis**<br><sub>æœºæ„: Renmin University of China, Beijing Key Laboratory of Big Data Management and Analysis Methods, Meituan Group<br>è¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ä¸ªåä¸ºProLLM4Recçš„æ¡†æ¶ï¼Œç³»ç»Ÿåœ°åˆ†æäº†åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä½œä¸ºæ¨èç³»ç»Ÿçš„åŸºç¡€æ¨¡å‹ï¼Œå¹¶é€šè¿‡å®éªŒæµ‹è¯•äº†ä¸åŒæƒ…å†µä¸‹å¯¹LLMsçš„å½±å“ã€‚é€šè¿‡å®è¯åˆ†æï¼Œæ€»ç»“äº†å¯¹æœªæ¥ç ”ç©¶çš„å¯å‘æ€§å‘ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04997v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04997.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk**<br><sub>æœºæ„: AWS AI Labs<br>è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡ªæˆ‘å¯¹è¯ç”Ÿæˆè®­ç»ƒæ•°æ®çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æœ‰æ½œåŠ›æ”¹è¿›ä»»åŠ¡å¯¼å‘å¯¹è¯ä»£ç†çš„æ€§èƒ½ã€‚å°½ç®¡å­˜åœ¨ä¸€äº›é™åˆ¶ï¼Œç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå½“é€‰æ‹©é«˜è´¨é‡å¯¹è¯ä½œä¸ºè®­ç»ƒæ•°æ®æ—¶ï¼Œå¯ä»¥æœ‰æ•ˆæé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚è¿™è¯æ˜äº†åœ¨æ­£ç¡®çš„è®¾ç½®ä¸‹ï¼Œé€šè¿‡è‡ªæˆ‘ç”Ÿæˆæ•°æ®è¿›è¡Œå¾®è°ƒçš„è¯­è¨€æ¨¡å‹ç¡®å®æœ‰æ½œåŠ›å®ç°è‡ªæˆ‘æ”¹è¿›ï¼Œå¹¶æˆä¸ºæ›´å¥½çš„ä»»åŠ¡å¯¼å‘å¯¹è¯ä»£ç†ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05033v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05033.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Attendre: Wait To Attend By Retrieval With Evicted Queries in Memory-Based Transformers for Long Context Processing**<br><sub>æœºæ„: Google Research<br>è®ºæ–‡æˆåŠŸåœ°æå‡ºäº†ä¸€ä¸ªæ–°çš„åŸºäºå†…å­˜çš„è½¬æ¢å™¨æ–¹æ³•ï¼Œé€šè¿‡å­˜å‚¨é©±é€ç­–ç•¥å’ŒATTENDREå±‚ï¼Œæœ‰æ•ˆåœ°å‡å°‘å†…å­˜éœ€æ±‚å¹¶æ”¯æŒåŒå‘æ³¨æ„åŠ›ï¼Œåœ¨é•¿åºåˆ—å¤„ç†ä¸Šè¡¨ç°å‡ºä¸ä¼ ç»Ÿæ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04881v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04881.md)  |
| <span style='display: inline-block; width: 42px;'>01-10</span> | **Leveraging Print Debugging to Improve Code Generation in Large Language Models**<br><sub>æœºæ„: Zhejiang University, ByteDance<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨print debuggingæ–¹æ³•æŒ‡å¯¼LLMsè¿›è¡Œä»£ç ç”Ÿæˆå’Œè°ƒè¯•çš„æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨Leetcodeé—®é¢˜é›†ä¸ŠéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨ç®€å•å’Œä¸­ç­‰éš¾åº¦çš„é—®é¢˜ä¸Šã€‚å°½ç®¡åœ¨é«˜éš¾åº¦é—®é¢˜ä¸Šæ•ˆæœæœ‰é™ï¼Œä½†è¿™é¡¹å·¥ä½œä»ç„¶æ˜¯LLMsåœ¨ä»£ç è°ƒè¯•æ–¹é¢çš„ä¸€ä¸ªé‡è¦è¿›æ­¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.05319v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.05319.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs**<br><sub>æœºæ„: Zhejiang University, Ant Group<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºARALLMçš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†ç±»æ¯”æ¨ç†å’Œå¤šä»»åŠ¡æ¨¡å‹æç‚¼ï¼Œæœ‰æ•ˆä¿ƒè¿›äº†å¤§å‹è¯­è¨€æ¨¡å‹ä»è‡ªç„¶è¯­è¨€ä¸­ç†è§£å¹¶è½¬æ¢ä¸ºç»“æ„åŒ–çš„é€»è¾‘è¯­è¨€çš„èƒ½åŠ›ã€‚é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œéä¸“ä¸šè¥é”€äººå‘˜èƒ½å¤Ÿåˆ©ç”¨è‡ªç„¶è¯­è¨€æ¥é€‰æ‹©ç›®æ ‡ç”¨æˆ·ï¼Œæœ‰æœ›æ”¹å˜ç”¨æˆ·å®šä½å®è·µã€‚è¿™ç§èƒ½åŠ›çš„æå‡ï¼Œä¸ä»…åœ¨è¥é”€åœºæ™¯ä¸­æœ‰å®é™…çš„åº”ç”¨ä»·å€¼ï¼ŒåŒæ—¶ä¹Ÿä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„åŠŸèƒ½æ€§å’Œå®ç”¨æ€§åšå‡ºäº†æœ‰ç›Šçš„æ¢ç´¢ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04319v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04319.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Large Language Models for Robotics: Opportunities, Challenges, and Perspectives**<br><sub>æœºæ„: Northwestern Polytechnical University, University of Georgia, Shaanxi Normal University<br>è®ºæ–‡æå‡ºçš„å¤šæ¨¡æ€GPT-4Væ¡†æ¶ï¼Œç»“åˆè‡ªç„¶è¯­è¨€å¤„ç†å’Œè§†è§‰æ„ŸçŸ¥ï¼Œæœ‰æœ›è§£å†³LLMsåœ¨æœºå™¨äººä»»åŠ¡è§„åˆ’ä¸­é¢å¯¹çš„æŒ‘æˆ˜ã€‚è¿™å¯¹äºç†è§£å’Œå®ç°æ›´é«˜çº§åˆ«çš„äººæœºäº¤äº’å’Œäººå·¥æ™ºèƒ½çš„æœªæ¥å…·æœ‰é‡è¦æ„ä¹‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04334v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04334.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding**<br><sub>æœºæ„: University of California San Diego, Google Cloud AI Research, Google Research<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåˆ›æ–°çš„CHAIN-OF-TABLEæ¡†æ¶ï¼Œé€šè¿‡å°†è¡¨æ ¼æ•°æ®æ˜¾å¼åœ°ç”¨äºæ¨ç†é“¾ï¼ŒåŠ¨æ€åœ°è§„åˆ’å¹¶æ›´æ–°æ“ä½œè¿‡ç¨‹ï¼Œä»è€Œæé«˜äº†LLMsåœ¨åŸºäºè¡¨æ ¼çš„æ¨ç†ä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04398v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04398.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search**<br><sub>æœºæ„: Nanyang Technological University Singapore<br>ReCoåˆ©ç”¨LLMsé‡å†™ä»£ç åº“ä¸­çš„ä»£ç ï¼Œé€šè¿‡é£æ ¼è§„èŒƒåŒ–æ˜¾è‘—æé«˜äº†ä»£ç æœç´¢çš„å‡†ç¡®æ€§ï¼Œå¹¶é€šè¿‡æ–°çš„è¯„ä»·æŒ‡æ ‡CSSimé‡åŒ–äº†é£æ ¼çš„å·®å¼‚ï¼Œæ¨åŠ¨äº†ä»£ç æ ·å¼æ ‡å‡†åŒ–çš„ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04514v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04514.md)  |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **The Critique of Critique**<br><sub>æœºæ„: The Hong Kong Polytechnic University, Shanghai Jiao Tong University, Shanghai Artificial Intelligence Laboratory<br>METACRITIQUEæ˜¯é¦–ä¸ªé’ˆå¯¹è‡ªç„¶è¯­è¨€æ‰¹åˆ¤è¿›è¡Œè¯„ä»·çš„æ¡†æ¶ï¼Œå…¶é€šè¿‡ç²¾ç¡®åº¦å’Œå¬å›ç‡çš„åŸåˆ™è¯„ä¼°æ‰¹åˆ¤çš„è´¨é‡ï¼Œå¹¶å®ç°äº†é«˜åº¦çš„å¯è§£é‡Šæ€§å’Œé€æ˜æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04518v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04518.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/GAIR-NLP/MetaCritique)</div> |
| <span style='display: inline-block; width: 42px;'>01-09</span> | **Agent Alignment in Evolving Social Norms**<br><sub>æœºæ„: Fudan University<br>æ­¤è®ºæ–‡æå‡ºäº†ä¸€ä¸ªEvoluationaryAgentæ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å’Œå¢å¼ºå¤§å‹æ™ºèƒ½ä»£ç†åœ¨åŠ¨æ€æŒç»­å˜åŒ–çš„ç¤¾ä¼šè§„èŒƒä¸­çš„è‡ªé€‚åº”æ€§å’Œä¸€è‡´æ€§ã€‚ç ”ç©¶å¼ºè°ƒäº†ä»£ç†åœ¨è¿›åŒ–ä¸­ä¸ç¤¾ä¼šè§„èŒƒå¯¹é½çš„é‡è¦æ€§ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†æ¨¡å‹çš„å¯è¡Œæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04620v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.0462.md)  |
| <span style='display: inline-block; width: 42px;'>01-08</span> | **TTMs: Fast Multi-level Tiny Time Mixers for Improved Zero-shot and Few-shot Forecasting of Multivariate Time Series**<br><sub>æœºæ„: IBM Research<br>TTMå±•ç¤ºäº†ä¸“é—¨é’ˆå¯¹å¤šæ ·åŒ–æ—¶é—´åºåˆ—æ•°æ®è®­ç»ƒçš„å°å‹é¢„è®­ç»ƒæ¨¡å‹åœ¨å¤šå˜é‡æ—¶é—´åºåˆ—é›¶/å°‘æ ·æœ¬é¢„æµ‹ä¸­çš„é«˜æ•ˆæ€§å’Œè½¬ç§»å­¦ä¹ èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03955v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03955.md)  |
| <span style='display: inline-block; width: 42px;'>01-08</span> | **MARG: Multi-Agent Review Generation for Scientific Papers**<br><sub>æœºæ„: Northwestern University, The Hebrew University of Jerusalem, Allen Institute for AI<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåˆ›æ–°çš„å¤šä»£ç†è¯„è®ºç”Ÿæˆæ–¹æ³•ï¼ˆMARGï¼‰ï¼Œå¯ä»¥è·¨è¶ŠåŸºç¡€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å¤§å°é™åˆ¶ï¼Œç”Ÿæˆé«˜è´¨é‡çš„ç§‘å­¦è®ºæ–‡åŒè¡Œè¯„å®¡åé¦ˆã€‚é€šè¿‡ç”¨æˆ·ç ”ç©¶å’Œè‡ªåŠ¨åŒ–åº¦é‡ï¼ŒMARGçš„åé¦ˆè´¨é‡å¯¹æ¯”åŸºçº¿æœ‰æ˜¾è‘—æé«˜ï¼Œç”Ÿæˆçš„æœ‰ç”¨è¯„è®ºæ•°é‡æé«˜äº†2.2å€ï¼ŒåŒæ—¶ç”Ÿæˆäº†æ›´åŠ å…·ä½“çš„è¯„è®ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04259v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04259.md)  |
| <span style='display: inline-block; width: 42px;'>01-08</span> | **SpeechAgents: Human-Communication Simulation with Multi-Modal Multi-Agent Systems**<br><sub>æœºæ„: Fudan University<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šä»£ç†ç³»ç»Ÿâ€”â€”SpeechAgentsï¼Œå…¶èƒ½æ¨¡æ‹ŸåŒ…å«å¤šè¾¾ 25 åä»£ç†äººçš„äººç±»äº¤æµåœºæ™¯ï¼Œå¹¶å±•ç°å‡ºå“è¶Šçš„å¯æ‰©å±•æ€§ã€‚é€šè¿‡ä½¿ç”¨å¤šæ¨¡æ€ä¿¡å·ä½œä¸ºä»£ç†é—´äº¤æµçš„åª’ä»‹ï¼Œç³»ç»Ÿä¸ä»…å¯ä»¥æ¨¡æ‹Ÿå…·æœ‰æ­£ç¡®å†…å®¹ã€çœŸå®èŠ‚å¥å’Œä¸°å¯Œæƒ…æ„Ÿçš„å¯¹è¯ï¼Œè€Œä¸”è¿˜èƒ½åº”ç”¨äºå¦‚æˆå‰§åˆ›ä½œå’Œæœ‰å£°å°è¯´ç”Ÿæˆç­‰ä»»åŠ¡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03945v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03945.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **Soaring from 4K to 400K: Extending LLM's Context with Activation Beacon**<br><sub>æœºæ„: Beijing Academy of Artificial Intelligence, Renmin University of China, Nankai University<br>è¿™ç¯‡æ–‡ç« ä»‹ç»äº†æ¿€æ´»ä¿¡æ ‡è¿™ä¸€èƒ½å¤Ÿæ‰©å±•å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šä¸‹æ–‡é•¿åº¦çš„æ–°æŠ€æœ¯ï¼Œä½¿å¾—æ¨¡å‹èƒ½åœ¨æœ‰é™ä¸Šä¸‹æ–‡çª—å£å†…æ„ŸçŸ¥æ›´å¹¿çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŒæ—¶ä¿ç•™å¯¹çŸ­ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å¤„ç†èƒ½åŠ›ã€‚æ¿€æ´»ä¿¡æ ‡ä»£è¡¨äº†ä¸€ç§æœ‰æ•ˆã€é«˜æ•ˆã€å…¼å®¹ä¸”è®­ç»ƒæˆæœ¬ä½çš„æ–¹æ³•ï¼Œæ¥æ‰©å±•LLMsçš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03462v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03462.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **ChatGPT for Conversational Recommendation: Refining Recommendations by Reprompting with Feedback**<br><sub>æœºæ„: University of Louisville, Microsoft<br>è¯¥è®ºæ–‡æ¢ç´¢äº†ChatGPTä½œä¸ºå¯¹è¯æ¨èç³»ç»Ÿçš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡æ„å»ºå›´ç»•ChatGPTçš„æµç¨‹ï¼Œæ¨¡æ‹Ÿç”¨æˆ·å®é™…ä½¿ç”¨æƒ…æ™¯ï¼Œå¹¶å¯¹æµè¡Œåè§è¿›è¡Œäº†ç ”ç©¶å’Œç¼“è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03605v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03605.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects**<br><sub>æœºæ„: The Chinese University of Hong Kong, DeepWisdom, Peking University<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç”¨äºæŒ‡å¯¼æœªæ¥ç ”ç©¶ä¸å¼€å‘çš„åŸºäºLLMçš„æ™ºèƒ½ä»£ç†ç³»ç»Ÿçš„æ¡†æ¶ï¼Œå¹¶æ¢è®¨äº†æé«˜å®ƒä»¬çš„è®¡åˆ’èƒ½åŠ›å’Œå¤šæ¨¡æ€ä¿¡æ¯å¤„ç†èƒ½åŠ›çš„ä¸åŒæ–¹æ³•ï¼Œä»¥åŠå¦‚ä½•è§£å†³LLMä»£ç†æ‰€é¢ä¸´çš„æŒ‘æˆ˜ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›äº†æ¸…æ™°çš„æŒ‡å—ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03428v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03428.md)  |
| <span style='display: inline-block; width: 42px;'>01-07</span> | **Grimoire is All You Need for Enhancing Large Language Models**<br><sub>æœºæ„: Beihang University, Renmin University of China<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºSLEICLçš„æ–¹æ³•ï¼Œé€šè¿‡å¼ºè¯­è¨€æ¨¡å‹å­¦ä¹ ç¤ºä¾‹æŠ€èƒ½å¹¶å°†å…¶è½¬ç§»ç»™å¼±è¯­è¨€æ¨¡å‹ï¼Œæ˜¾è‘—æé«˜äº†å¼±æ¨¡å‹çš„ICLèƒ½åŠ›ã€‚é€šè¿‡å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå±•ç°äº†è¯¥æŠ€æœ¯åœ¨å¢å¼ºå¼±è¯­è¨€æ¨¡å‹ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›æ–¹é¢çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03385v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03385.md)  |
| <span style='display: inline-block; width: 42px;'>01-06</span> | **The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models**<br><sub>æœºæ„: Renmin University of China, UniversitÃ© de MontrÃ©al<br>æœ¬è®ºæ–‡é€šè¿‡ç³»ç»Ÿæ€§å®è¯ç ”ç©¶ï¼Œæ·±å…¥äº†è§£å¹¶æ¢ç´¢å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰é—®é¢˜ï¼Œè¯†åˆ«äº†å¹»è§‰çš„æ¥æºã€æ£€æµ‹æ–¹æ³•å’Œå‡è½»ç­–ç•¥ï¼Œå¹¶æå‡ºäº†æ–°çš„åŸºå‡†HaluEval 2.0å’Œç®€å•æœ‰æ•ˆçš„å¹»è§‰æ£€æµ‹æ¡†æ¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03205v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03205.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RUCAIBox/HaluEval-2.0)</div> |
| <span style='display: inline-block; width: 42px;'>01-06</span> | **Quartet Logic: A Four-Step Reasoning (QLFR) framework for advancing Short Text Classification**<br><sub>æœºæ„: Aerospace Information Research Institute Chinese Academy of Sciences, Key Laboratory of Target Cognition and Application Technology, University of Chinese Academy of Sciences<br>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹çŸ­æ–‡æœ¬åˆ†ç±»ä»»åŠ¡çš„Quartet Logic: A Four-Step Reasoning (QLFR)æ¡†æ¶ï¼Œä»¥åŠä¸€ä¸ªCoTé©±åŠ¨çš„å¤šä»»åŠ¡å­¦ä¹ ï¼ˆQLFR-CMLï¼‰æ–¹æ³•ï¼Œè¿™ä¸¤è€…éƒ½é€šè¿‡å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†é“¾æ¥è§£å†³STCé¢†åŸŸä¸­çš„æŒ‘æˆ˜ã€‚å®éªŒç»“æœè¯æ˜äº†è¿™äº›æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.03158v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.03158.md)  |
| <span style='display: inline-block; width: 42px;'>01-06</span> | **CogGPT: Unleashing the Power of Cognitive Dynamics on Large Language Models**<br><sub>æœºæ„: Harbin Institute of Technology, Kuaishou Technology<br>CogGPTé€šè¿‡å¼•å…¥è¿­ä»£è®¤çŸ¥æœºåˆ¶å’Œè®°å¿†ä¿æŒç³»ç»Ÿï¼Œæœ‰æ•ˆåœ°è§£å†³äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨¡ä»¿äººç±»è®¤çŸ¥åŠ¨æ€æ–¹é¢çš„æŒ‘æˆ˜ï¼Œå±•ç¤ºäº†åœ¨è¿ç»­ä¿¡æ¯å¤„ç†ä¸­çš„ä¼˜ç§€è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08438v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.08438.md)  |
| <span style='display: inline-block; width: 42px;'>01-05</span> | **Infinite-LLM: Efficient LLM Service for Long Context with DistAttention and Distributed KVCache**<br><sub>æœºæ„: Alibaba Group, Shanghai Jiao Tong University<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªæœ‰æ•ˆæ”¯æŒé•¿ä¸Šä¸‹æ–‡è¯­è¨€æ¨¡å‹äº‘æœåŠ¡çš„ç³»ç»Ÿï¼Œé€šè¿‡åˆ†å¸ƒå¼ç®—æ³•DistAttentionï¼Œä¼˜åŒ–äº†æ³¨æ„åŠ›æ¨¡å—çš„å¤„ç†å’Œå­˜å‚¨ï¼Œå¹¶é€šè¿‡DistKV-LLMæœåŠ¡ç³»ç»Ÿè¿›è¡Œç®¡ç†å’Œåè°ƒï¼Œå®ç°äº†åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­å¯¹èµ„æºçš„é«˜æ•ˆåˆ†é…å’Œç®¡ç†ï¼ŒéªŒè¯äº†å…¶åœ¨æ€§èƒ½ä¸Šçš„æ˜æ˜¾æé«˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02669v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02669.md)  |
| <span style='display: inline-block; width: 42px;'>01-05</span> | **From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models**<br><sub>æœºæ„: Beike Inc.<br>æœ¬è®ºæ–‡ä»‹ç»äº†RAISEæ¡†æ¶ï¼Œé€šè¿‡å¢å¼ºè®°å¿†ç³»ç»Ÿå’Œç»“æ„åŒ–çš„ä»£ç†æ„å»ºè¿‡ç¨‹ï¼Œæé«˜äº†LLMsåœ¨å¤šè½®å¯¹è¯ä¸­çš„è¡¨ç°ï¼Œå°¤å…¶æ˜¯åœ¨æˆ¿åœ°äº§é”€å”®æƒ…å¢ƒä¸­ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02777v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02777.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **SPEER: Sentence-Level Planning of Long Clinical Summaries via Embedded Entity Retrieval**<br><sub>æœºæ„: Columbia University<br>æœ¬è®ºæ–‡é’ˆå¯¹åŒ»é™¢å‡ºé™¢æ€»ç»“çš„é•¿ç¯‡æ–‡æ¡£ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ä¸ªåŸºäºåµŒå…¥å¼å®ä½“æ£€ç´¢çš„å¥å­çº§è§„åˆ’æ–¹æ³•SPEERï¼Œé€šè¿‡å¼•å¯¼å¤§å‹è¯­è¨€æ¨¡å‹LLMsæ›´å¥½åœ°è¦†ç›–å…³é”®å®ä½“ï¼Œç”Ÿæˆæ›´å®Œæ•´å’Œå¯ä¿¡çš„ä¸´åºŠæ€»ç»“ã€‚ç ”ç©¶è¯æ˜äº†SPEERæ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­å¯ä»¥æé«˜æ–‡æ¡£çš„è¦†ç›–åº¦å’Œå‡†ç¡®æ€§ï¼Œå‡è½»ä¸´åºŠåŒ»ç”Ÿçš„æ–‡æ¡£è´Ÿæ‹…ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02369v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02369.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)**<br><sub>æœºæ„: University of South Carolina, New Mexico State University, IBM Research<br>æœ¬æ–‡æ˜¯å¯¹å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨è§„åˆ’å’Œè°ƒåº¦é¢†åŸŸçš„åº”ç”¨è¿›è¡Œäº†ç»¼è¿°ï¼Œæå‡ºäº†å°†é¢†å…ˆçš„ LLMs å¦‚ GPT-4 å’Œ BERT ä¸ç»å…¸è§„åˆ’æ–¹æ³•ç»“åˆçš„å‰æ™¯ï¼Œä»¥åŠåœ¨å…«ä¸ªä¸åŒçš„è§„åˆ’é—®é¢˜ç±»åˆ«ä¸­åº”ç”¨ LLMs çš„æ½œåŠ›ï¼Œä»¥æœŸå‘å±•æ›´å…ˆè¿›ã€æ›´æ™ºèƒ½çš„è§„åˆ’ç³»ç»Ÿã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02500v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.025.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS)**<br><sub>æœºæ„: University of South Carolina, New Mexico State University, IBM Research<br>æœ¬è®ºæ–‡åœ¨ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸è‡ªåŠ¨è§„åˆ’å’Œè°ƒåº¦ï¼ˆAPSï¼‰çš„æ•´åˆå‰æ™¯ï¼Œçªç ´äº†ä¼ ç»Ÿç³»ç»Ÿå¯¹ä¸Šä¸‹æ–‡çš„é€‚åº”æ€§å±€é™æ€§ï¼Œä¸ºå®ç°æ›´åŠ¨æ€ã€ä¸Šä¸‹æ–‡æ•æ„Ÿçš„è§„åˆ’é€”å¾„æä¾›äº†å¯èƒ½æ€§ï¼Œå¹¶ä¸ºè¿›ä¸€æ­¥çš„åº”ç”¨å’Œç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02500v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.025.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **LLM Augmented LLMs: Expanding Capabilities through Composition**<br><sub>æœºæ„: Google Research, Google DeepMind<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„æ¨¡å‹æ‰©å±•æ¡†æ¶ â€”â€” CALMï¼Œæœ‰æ•ˆæ•´åˆäº†ä¸¤ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ä»¥å®ç°æ–°çš„ä»»åŠ¡ï¼Œä¸”åœ¨å¤šä¸ªå®éªŒä¸­è¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02412v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02412.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives**<br><sub>æœºæ„: Zhejiang University, OPPO Research Institute<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºâ€œè‡ªæˆ‘å¯¹æ¯”â€çš„æ–°ç­–ç•¥ï¼Œç”¨äºæ”¹å–„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨åæ€å’Œè‡ªæˆ‘ä¿®æ­£è¿‡ç¨‹ä¸­å­˜åœ¨çš„å›ºæ‰§å’Œä¸ä¸€è‡´é—®é¢˜ï¼Œé€šè¿‡åˆ›å»ºå¤šæ ·åŒ–è§£å†³æ–¹æ¡ˆè§†è§’ï¼Œå¯¹æ¯”ä¸åŒè§£å†³æ–¹æ¡ˆçš„å·®å¼‚ï¼Œå¹¶å°†å·®å¼‚æ€»ç»“ä¸ºæ£€æŸ¥æ¸…å•ï¼Œè¿›è€Œæå‡äº†LLMçš„åæ€è´¨é‡ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†è¯¥ç­–ç•¥çš„æ•ˆæœå’Œå¹¿æ³›é€‚ç”¨æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02009v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02009.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **ICE-GRT: Instruction Context Enhancement by Generative Reinforcement based Transformers**<br><sub>æœºæ„: Bytedance Inc.<br>æœ¬è®ºæ–‡æå‡ºäº†é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸä»»åŠ¡ä¸­æ·±åº¦ä¸å‡†ç¡®æ€§æå‡çš„æ–¹æ³•â€”â€”ICE-GRTã€‚é€šè¿‡ç»“åˆäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ŒICE-GRT åœ¨ä¸ç‰ºç‰²ä¸€èˆ¬æ€§èƒ½çš„å‰æä¸‹ï¼Œæ˜¾è‘—æå‡äº†ç‰¹å®šé¢†åŸŸçš„èƒ½åŠ›ï¼Œå¹¶åœ¨å¤šé¡¹è¯„ä¼°ä»»åŠ¡ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02072v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02072.md)  |
| <span style='display: inline-block; width: 42px;'>01-04</span> | **Using LLM to select the right SQL Query from candidates**<br><sub>æœºæ„: Peking University<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§å€ŸåŠ©å¤§å‹è¯­è¨€æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆtext-to-SQLæµ‹è¯•ç”¨ä¾‹çš„æ–¹æ³•ï¼Œå¹¶è®¾è®¡äº†ä¸‰æ­¥é‡æ–°æ’åºè¿‡ç¨‹ï¼Œå®éªŒæ˜¾ç¤ºè¯¥æ–¹æ³•èƒ½æ˜¾è‘—æé«˜ç°æœ‰text-to-SQLæ¨¡å‹çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.02115v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.02115.md)  |
| <span style='display: inline-block; width: 42px;'>01-03</span> | **Social Media Ready Caption Generation for Brands**<br><sub>æœºæ„: Adobe Research India<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„æ¡†æ¶ï¼Œæ—¨åœ¨å¸®åŠ©å“ç‰Œåœ¨ç¤¾äº¤åª’ä½“ä¸Šåˆ›é€ ä¸å“ç‰Œå½¢è±¡å’Œä¸ªæ€§ç›¸ç¬¦çš„å¸å¼•äººçš„æ ‡é¢˜ã€‚æ¡†æ¶åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼ŒæˆåŠŸåº”å¯¹äº†ç”Ÿæˆä¸å“ç‰Œç›¸å…³æ€§å¼ºä¸”å¸å¼•çœ¼çƒçš„ç¤¾äº¤åª’ä½“æ ‡é¢˜çš„æŒ‘æˆ˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.01637v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.01637.md)  |
| <span style='display: inline-block; width: 42px;'>01-03</span> | **MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries**<br><sub>æœºæ„: Indian Institute of Technology Patna, Stanford University, Amazon GenAI<br>MedSummæ˜¯ä¸€ä¸ªæ–°é¢–çš„å¤šæ¨¡æ€åŒ»ç–—é—®é¢˜æ€»ç»“æ¡†æ¶ï¼Œå®ƒèƒ½å¤Ÿé€šè¿‡æ•´åˆæ–‡æœ¬å’Œè§†è§‰ä¿¡æ¯ç”ŸæˆåŒ»å­¦ç»†èŠ‚ä¸°å¯Œçš„æ€»ç»“ï¼Œæœ‰æ½œåŠ›æé«˜åŒ»ç–—å†³ç­–çš„è´¨é‡å¹¶åŠ æ·±å¯¹æ‚£è€…é—®é¢˜çš„ç†è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.01596v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.01596.md)  |
| <span style='display: inline-block; width: 42px;'>01-02</span> | **LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning**<br><sub>è¿™ç¯‡è®ºæ–‡æˆåŠŸå±•ç¤ºäº†ä¸€ç§æ— éœ€fine-tuningå³å¯æ‰©å±•LLMsä¸Šä¸‹æ–‡çª—å£çš„æ–¹æ³•ï¼Œè¿™å¯¹äºåœ¨è®¡ç®—èµ„æºå—é™æƒ…å†µä¸‹æå‡å¤§å‹è¯­è¨€æ¨¡å‹å¤„ç†é•¿æ–‡æœ¬çš„èƒ½åŠ›å…·æœ‰é‡è¦æ„ä¹‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.01325v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.01325.md)  |
| <span style='display: inline-block; width: 42px;'>01-02</span> | **A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models**<br><sub>æœºæ„: Islamic University of Technology Bangladesh, University of South Carolina, Stanford University<br>æœ¬æ–‡æ˜¯å¯¹LLMå¹»è§‰å‡è½»æŠ€æœ¯çš„å…¨é¢ç»¼è¿°ï¼Œæå‡ºäº†åˆ†ç±»æ¡†æ¶å’Œç³»ç»ŸåŒ–çš„åé¦ˆå’Œç†ç”±æ–¹æ³•ï¼Œå¹¶è¯„ä¼°äº†è¿™äº›æŠ€æœ¯çš„æœ‰æ•ˆæ€§å’Œå½±å“ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.01313v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.01313.md)  |
| <span style='display: inline-block; width: 42px;'>01-01</span> | **A & B == B & A: Triggering Logical Reasoning Failures in Large Language Models**<br><sub>æœºæ„: The Chinese University of Hong Kong, Tencent AI Lab<br>æœ¬è®ºæ–‡é’ˆå¯¹LLMsçš„é€»è¾‘æ¨ç†èƒ½åŠ›çš„è¯„ä¼°å’Œæ”¹è¿›é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåä¸ºLogicAskerçš„æ–¹æ³•ï¼Œèƒ½å¤Ÿå…¨é¢è¯„ä¼°LLMsçš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶é€šè¿‡é—®é¢˜ç”Ÿæˆå’Œä¸Šä¸‹æ–‡å­¦ä¹ æœ‰æ•ˆæå‡è¿™äº›èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.00757v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.00757.md)  |
| <span style='display: inline-block; width: 42px;'>01-01</span> | **From Prompt Engineering to Prompt Science With Human in the Loop**<br><sub>æœºæ„: University of Washington<br>æ–‡ç« å±•ç¤ºäº†å¦‚ä½•å°†LLMsçš„æç¤ºå·¥ç¨‹è½¬åŒ–ä¸ºæ›´ä¸ºç§‘å­¦å’Œç³»ç»Ÿçš„æç¤ºç§‘å­¦ã€‚é€šè¿‡å¼•å…¥äººåœ¨ç¯ä¸­çš„è´¨æ€§ç¼–ç æ–¹æ³•ï¼Œç¡®ä¿äº†LLMç”Ÿæˆçš„å“åº”çš„è´¨é‡å’Œä¸€è‡´æ€§ï¼ŒåŒæ—¶æ¶ˆé™¤äº†ä¸ªä½“ä¸»è§‚æ€§å’Œéšæ„æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.04122v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.04122.md)  |
| <span style='display: inline-block; width: 42px;'>01-01</span> | **The Earth is Flat? Unveiling Factual Errors in Large Language Models**<br><sub>æœºæ„: The Chinese University of Hong Kong, Tencent AI Lab<br>æœ¬æ–‡ä»‹ç»çš„FactCheckeræä¾›äº†é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„äº‹å®é”™è¯¯è‡ªåŠ¨æµ‹è¯•æ–°æ¡†æ¶ï¼Œé€šè¿‡æ„å»ºçŸ¥è¯†å›¾è°±å¹¶ç”Ÿæˆæµ‹è¯•é—®é¢˜ï¼Œæ­ç¤ºå¹¶å‡å°‘äº†æ¨¡å‹çš„äº‹å®é”™è¯¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.00761v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2024-01/2401.00761.md)  |

---

### 12æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>12-31</span> | **BatchEval: Towards Human-like Text Evaluation**<br><sub>æœºæ„: Beijing Institute of Technology, Xiaohongshu Inc  <br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„LLMè¯„ä¼°èŒƒå¼â€”â€”BATCHEVALï¼Œè§£å†³äº†è‡ªåŠ¨æ–‡æœ¬è¯„ä¼°åœ¨é²æ£’æ€§å’Œä¸äººç±»åˆ¤æ–­ä¸€è‡´æ€§æ–¹é¢çš„é—®é¢˜ã€‚é€šè¿‡æ‰¹é‡è¯„ä¼°å’Œè¿­ä»£å¤„ç†ï¼ŒBATCHEVALåœ¨å‡†ç¡®æ€§å’Œæˆæœ¬æ•ˆç‡æ–¹é¢æ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.00437v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2401.00437.md)  |
| <span style='display: inline-block; width: 42px;'>12-31</span> | **Improving Text Embeddings with Large Language Models**<br><sub>æœºæ„: Microsoft Corporation<br>æœ¬æ–‡é‡‡ç”¨æœ€æ–°çš„å¤§å‹è¯­è¨€æ¨¡å‹å’Œåˆæˆæ•°æ®ï¼Œæå‡ºä¸€ç§æ–°é¢–çš„æ–‡æœ¬åµŒå…¥æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨æ— éœ€äººå·¥æ ‡æ³¨æ•°æ®ä¸”è®­ç»ƒæ­¥éª¤å°‘äº1åƒçš„æƒ…å†µä¸‹ï¼Œè¾¾åˆ°ä¸ç«äº‰æ€§åŸºå‡†ç›¸åŒ¹é…çš„æ€§èƒ½ï¼Œä¸ºè¿›ä¸€æ­¥æå‡æ–‡æœ¬åµŒå…¥æŠ€æœ¯æä¾›äº†æœ‰åŠ›è¯æ®ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.00368v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2401.00368.md)  |
| <span style='display: inline-block; width: 42px;'>12-29</span> | **Building Efficient Universal Classifiers with Natural Language Inference**<br><sub>æœºæ„: Vrije Universiteit Amsterdam, University of London Royal Holloway, Hugging Face<br>è¿™ç¯‡è®ºæ–‡æä¾›äº†ä¸€ç§åˆ©ç”¨è‡ªç„¶è¯­è¨€æ¨æ–­è¿›è¡Œé€šç”¨æ–‡æœ¬åˆ†ç±»çš„æ–°æ–¹æ³•ï¼Œå¹¶ä¸”æä¾›äº†å®ç°è¯¥æ–¹æ³•çš„è¯¦ç»†æ­¥éª¤å’Œå·¥å…·ï¼Œèƒ½å¤Ÿåœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹æ˜¾è‘—æé«˜æ¨¡å‹çš„æ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17543v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17543.md)  |
| <span style='display: inline-block; width: 42px;'>12-29</span> | **DB-GPT: Empowering Database Interactions with Private Large Language Models**<br><sub>æœºæ„: Alibaba Group<br>æœ¬æ–‡æå‡ºäº†åä¸ºDB-GPTçš„åˆ›æ–°é¡¹ç›®ï¼Œè¯¥é¡¹ç›®é›†æˆäº†LLMsåŠæ•°æ®åº“ç³»ç»Ÿï¼Œä»¥æå‡ç”¨æˆ·ä½“éªŒå’Œæ— éšœç¢æ€§ã€‚DB-GPTå±•ç°äº†å±‚æ¬¡åŒ–è®¾è®¡ï¼Œæœ‰æ•ˆå¤„ç†äº†éšç§å’Œå®‰å…¨ä¿æŠ¤ç­‰é—®é¢˜ï¼ŒåŒæ—¶é€šè¿‡å¤šæºRAGå’Œè‡ªé€‚åº”ICLæå‡äº†ç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½å’Œæ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17449v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17449.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/eosphoros-ai/DB-GPT)</div> |
| <span style='display: inline-block; width: 42px;'>12-29</span> | **Enhancing Quantitative Reasoning Skills of Large Language Models through Dimension Perception**<br><sub>æœºæ„: **Institution:** Shanghai Key Laboratory of Data Science School of Computer Science Fudan University, School of Data Science Fudan University, DataGrand Co. LTD<br>æœ¬æ–‡çš„ç ”ç©¶é€šè¿‡å»ºç«‹ç»´åº¦å•ä½çŸ¥è¯†åº“å’Œå®šåˆ¶åŒ–åŸºå‡†æµ‹è¯•ï¼Œæ˜¾è‘—æå‡äº†LLMsçš„å®šé‡æ¨ç†èƒ½åŠ›ã€‚è¿™ä¸ºç†è§£æ–‡æœ¬ä¸­é‡è¦çš„é‡å€¼ä¿¡æ¯å¹¶è¿›è¡Œé«˜å‡†ç¡®åº¦çš„æ¨ç†ä»»åŠ¡æä¾›äº†æ–°çš„é€”å¾„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17532v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17532.md)  |
| <span style='display: inline-block; width: 42px;'>12-29</span> | **Truth Forest: Toward Multi-Scale Truthfulness in Large Language Models through Intervention without Tuning**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17484v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17484.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/jongjyh/trfr)</div> |
| <span style='display: inline-block; width: 42px;'>12-29</span> | **The Right Prompts for the Job: Repair Code-Review Defects with Large Language Model**<br><sub>æœºæ„: Ant Group, Nanjing University<br>ç ”ç©¶æ¢è®¨äº†LLMsåœ¨ä»£ç å®¡æŸ¥ç¼ºé™·ä¿®å¤ä¸­çš„åº”ç”¨ï¼Œæå‡ºäº†ä¸€ä¸ªæœ‰æ•ˆçš„åŠè‡ªåŠ¨APRèŒƒä¾‹ï¼Œåˆ†æäº†9ç§æµè¡Œæ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶è®¾è®¡äº†æœ‰æ•ˆçš„æç¤ºä»¥æŒ‡å¯¼ä»£ç ä¿®å¤è¿‡ç¨‹ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17485v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17485.md)  |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **Structured Packing in LLM Training Improves Long Context Utilization**<br><sub>æœºæ„: University of Warsaw, Google DeepMind, Polish Academy of Sciences<br>è¿™ç¯‡è®ºæ–‡é€šè¿‡æå‡ºSPLICEæ–¹æ³•æ¥æ”¹è¿›é•¿è·ç¦»ä¸Šä¸‹æ–‡çš„åˆ©ç”¨ï¼ŒéªŒè¯äº†å…¶åœ¨æé«˜å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ä¸Šä¸‹æ–‡åˆ©ç”¨ç‡å’Œæ”¹è¿›é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡æ€§èƒ½æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚SPLICEç‰¹åˆ«é€‚ç”¨äºåœ¨ç¼ºä¹é¢å¤–ç»“æ„åŒ–ä¿¡æ¯çš„è®­ç»ƒæ•°æ®ä¸Šæ„é€ è®­ç»ƒç¤ºä¾‹ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17296v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17296.md)  |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **GitAgent: Facilitating Autonomous Agent with GitHub by Tool Extension**<br><sub>æœºæ„: Tsinghua University, Renmin University of China<br>æ–‡ç« ä¸»è¦ä»‹ç»äº†ä¸€ä¸ªåä¸ºGITAGENTçš„è‡ªä¸»ä»£ç†ï¼Œå®ƒå¯ä»¥è‡ªä¸»ä»GitHubæ‰©å±•å·¥å…·ï¼Œä»¥æ»¡è¶³ç”¨æˆ·æŸ¥è¯¢çš„å¤šç§éœ€æ±‚ã€‚GITAGENTé€šè¿‡è§£å†³éæ ‡å‡†åŒ–æŒ‘æˆ˜ï¼Œèƒ½å¤Ÿè‡ªä¸»å­¦ä¹ åŸºäºGitHub Issues/PRsçš„äººç±»ç»éªŒï¼Œä»¥è§£å†³å·¥å…·æ‰©å±•è¿‡ç¨‹ä¸­çš„é—®é¢˜ï¼Œå¹¶ä¸”å±•ç¤ºäº†åœ¨è‡ªä¸»é›†æˆå·¥å…·ä»¥å®Œæˆè·¨ä¸“ä¸šé¢†åŸŸä»»åŠ¡æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17294v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17294.md)  |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **Challenge LLMs to Reason About Reasoning: A Benchmark to Unveil Cognitive Depth in LLMs**<br><sub>æœºæ„: Chinese University of Hong Kong, Tencent AI Lab<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåˆ›æ–°çš„è¯„ä¼°æ¨¡å‹ï¼Œè¦æ±‚LLMsä¸ä»…è¦è§£å†³é—®é¢˜ï¼Œè¿˜è¦è¿›è¡Œå…ƒæ¨ç†â€”â€”å³è¯„ä¼°æ¨ç†è¿‡ç¨‹æœ¬èº«ã€‚è¿™ç§æ–¹æ³•æœ‰æœ›æ­ç¤ºç”±äºä»¥å¾€ä»¥ç»“æœä¸ºå¯¼å‘çš„è¯„ä¼°æ–¹æ³•è€Œå¿½ç•¥çš„æ¨¡å‹è®¤çŸ¥ç¼ºé™·ï¼Œä¸ºæœªæ¥LLMsçš„è¯„ä¼°å’Œè®­ç»ƒæä¾›äº†æ–°çš„æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17080v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1708.md)  |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **DrugAssist: A Large Language Model for Molecule Optimization**<br><sub>æœºæ„: Tencent AI Lab, Department of Computer Science Hunan University<br>DrugAssistæ˜¯ä¸€ä¸ªé€šè¿‡äººæœºäº¤äº’è¿›è¡Œåˆ†å­ä¼˜åŒ–çš„æ¨¡å‹ï¼Œå®ƒçªç ´äº†LLMsåœ¨è¯ç‰©å‘ç°è¿‡ç¨‹ä¸­äº’åŠ¨æ€§ä¸è¶³çš„å±€é™ï¼Œå¹¶åœ¨å¤šå±æ€§åˆ†å­ä¼˜åŒ–é¢†åŸŸå±•ç°äº†å‡ºè‰²çš„æ€§èƒ½å’Œè½¬ç§»èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.10334v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2401.10334.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/blazerye/DrugAssist)</div> |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **Experiential Co-Learning of Software-Developing Agents**<br><sub>æœºæ„: Tsinghua University,Dalian University of Technology,Beijing University of Posts and Telecommunications<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œç§°ä¸ºç»éªŒå…±åŒå­¦ä¹ ï¼ˆExperiential Co-Learningï¼‰ï¼Œé€šè¿‡å…±åŒè¿½è¸ªã€å…±åŒè®°å¿†å’Œå…±åŒæ¨ç†æ¨¡å—çš„é¡ºåºå®ç°ï¼Œä½¿å¾—LLMé©±åŠ¨çš„æ™ºèƒ½ä»£ç†èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°ä»å†å²è½¨è¿¹ä¸­å­¦ä¹ ï¼Œå¹¶åˆ©ç”¨å†å²ç»éªŒæ¥ç›¸äº’æ¨ç†è§£å†³æ–°ä»»åŠ¡ã€‚å±•ç¤ºäº†æ˜æ˜¾ä¼˜äºç°æœ‰æŠ€æœ¯çš„ç»©æ•ˆæ”¹è¿›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17025v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17025.md)  |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **Improving In-context Learning via Bidirectional Alignment**<br><sub>æœºæ„: Nanyang Technological University, Princeton University, Salesforce Research USA<br>æœ¬æ–‡é€šè¿‡å¼•å…¥æ–°é¢–çš„æ’åæŸå¤±ä»¥åŠå¯¹è¾“å‡ºåˆ†å¸ƒçš„å¯¹é½ï¼Œæå‡ºäº†åŒå‘å¯¹é½(BiAlign)ï¼Œæœ‰æ•ˆæé«˜äº†å°å‹æ¨¡å‹çš„ ICL èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17055v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17055.md)  |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **Challenge LLMs to Reason About Reasoning: A Benchmark to Unveil Cognitive Depth in LLMs**<br><sub>æœºæ„: Chinese University of Hong Kong, Tencent AI Lab<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæŒ‘æˆ˜LLMsè¿›è¡Œå…ƒæ¨ç†çš„æ–°è¯„ä¼°èŒƒå¼ï¼Œå¹¶å¼€å‘äº†é…å¥—çš„å…¬å¼€åŸºå‡†DiagGSM8Kï¼Œè¿™ä¸ºè¯„ä¼°LLMsçš„è®¤çŸ¥èƒ½åŠ›å¢åŠ äº†ä¸€ä¸ªæ–°ç»´åº¦ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17080v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1708.md)  |
| <span style='display: inline-block; width: 42px;'>12-28</span> | **Grounding-Prompter: Prompting LLM with Multimodal Information for Temporal Sentence Grounding in Long Videos**<br><sub>æœºæ„: Tsinghua University<br>æœ¬è®ºæ–‡æå‡ºäº†Grounding-Prompteræ–¹æ³•ï¼Œé’ˆå¯¹é•¿è§†é¢‘ä¸­çš„TSGé—®é¢˜ï¼Œå°†LLMä¸æ—¶åºæ¨ç†å’Œå¤šæ¨¡æ€ä¿¡æ¯ç»“åˆèµ·æ¥ï¼Œè¯æ˜äº†é€šè¿‡å¤šæ¨¡æ€æç¤ºLLMçš„æœ‰æ•ˆæ€§ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†å…¶åœ¨é•¿è§†é¢‘TSGä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17117v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17117.md)  |
| <span style='display: inline-block; width: 42px;'>12-27</span> | **Conversational Question Answering with Reformulations over Knowledge Graph**<br><sub>æœºæ„: University of Illinois at Urbana-Champaign, Amazon<br>CoRnNet æ˜¯ä¸€ç§æ–°å‹RLæ¨¡å‹ï¼Œç”¨äºåœ¨çŸ¥è¯†å›¾è°±ä¸Šè¿›è¡Œä¼šè¯å¼é—®é¢˜å›ç­”å¹¶ç»“åˆLLMç”Ÿæˆçš„æ”¹å†™ï¼Œå±•ç°äº†æ¯”å…¶ä»–å…ˆè¿›æ¨¡å‹æ›´å‡ºè‰²çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17269v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17269.md)  |
| <span style='display: inline-block; width: 42px;'>12-27</span> | **Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges**<br><sub>æœºæ„: Shanghai Jiao Tong University (SJTU)<br>æœ¬è®ºæ–‡æ˜¯ä¸€ä¸ªå…³äºå¦‚ä½•é€‚é…å¤§å‹è¯­è¨€æ¨¡å‹äºæ•™è‚²ç³»ç»Ÿçš„ç»¼è¿°ï¼Œå®ƒæä¾›äº†å¯¹LLMsåœ¨æ•™è‚²ç›¸å…³èƒ½åŠ›æ–¹é¢çš„å‘å±•æƒ…å†µçš„æ¦‚è¿°ï¼Œå¹¶æ¢è®¨äº†æ„å»ºè¿™æ ·ç³»ç»Ÿçš„æ½œåŠ›ä¸æŒ‘æˆ˜ï¼Œä¸ºæœªæ¥çš„ç›¸å…³ç ”ç©¶æä¾›äº†æ´è§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.08664v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2401.08664.md)  |
| <span style='display: inline-block; width: 42px;'>12-27</span> | **How Robust are LLMs to In-Context Majority Label Bias?**<br><sub>æœºæ„: Amazon<br>æœ¬æ–‡å¯¹LLMsåœ¨é¢å¯¹ICLä¸­å¤šæ•°ç±»æ ‡ç­¾åå·®æ—¶çš„é²æ£’æ€§è¿›è¡Œäº†å…¨é¢ç ”ç©¶ï¼Œé€šè¿‡å®éªŒå‘ç°æŸäº›æ¨¡å‹åœ¨å¤„ç†è¿™ç§åå·®æ—¶æ˜¾ç¤ºå‡ºæ˜¾è‘—çš„ç¨³å®šæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.16549v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.16549.md)  |
| <span style='display: inline-block; width: 42px;'>12-27</span> | **Rethinking Tabular Data Understanding with Large Language Models**<br><sub>æœºæ„: UC San Diego, USC, UC Davis  <br>è¿™ç¯‡è®ºæ–‡æ·±å…¥æ¢è®¨äº†LLMså¯¹è¡¨æ ¼æ•°æ®çš„ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œå¯¹è¡¨æ ¼ç»“æ„çš„é²æ£’æ€§ã€æ–‡æœ¬ä¸ç¬¦å·æ¨ç†çš„æ¯”è¾ƒï¼Œä»¥åŠå¤šæ¨ç†è·¯å¾„èšåˆå¯¹æ¨¡å‹æ€§èƒ½æå‡çš„å½±å“åšå‡ºäº†è´¡çŒ®ã€‚æ‰€æå‡ºçš„è¡¨æ ¼ç»“æ„æ ‡å‡†åŒ–æ–¹æ³•å’Œæ··åˆè‡ªä¸€è‡´æ€§æœºåˆ¶å¯¹æé«˜LLMsåœ¨è¡¨æ ¼æ•°æ®æ¨ç†ä¸Šçš„æ€§èƒ½å…·æœ‰é‡è¦æ„ä¹‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.16702v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.16702.md)  |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **RecRanker: Instruction Tuning Large Language Model as Ranker for Top-k Recommendation**<br><sub>æœºæ„: City University of Hong Kong, The Chinese University of Hong Kong, Hangdian University<br>è¯¥è®ºæ–‡æå‡ºäº†RecRankerè¿™ä¸€æ–°å‹æ¡†æ¶ï¼Œå®ƒé€šè¿‡æŒ‡ä»¤è°ƒæ•´çš„æ–¹å¼ä¼˜åŒ–äº†LLMsåœ¨top-kæ¨èä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œå¹¶æœ‰æ•ˆåœ°èåˆäº†ä¼ ç»Ÿæ¨èç³»ç»Ÿçš„ä¿¡å·ï¼Œæ”¹å–„äº†æ¨¡å‹åœ¨æ¨èåœºæ™¯ä¸­çš„åº”ç”¨è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.16018v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.16018.md)  |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **Scaling Down, LiTting Up: Efficient Zero-Shot Listwise Reranking with Seq2seq Encoder-Decoder Models**<br><sub>æœºæ„: University of Waterloo<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†LiT5-Distillå’ŒLiT5-Scoreä¸¤ç§åºåˆ—åˆ°åºåˆ—çš„ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ï¼Œç”¨äºæœ‰æ•ˆçš„é›¶æ ·æœ¬åˆ—è¡¨çº§é‡æ–°æ’åºã€‚è¿™äº›æ–¹æ³•ä¸ä»…åœ¨æ¨¡å‹æ•ˆæœä¸Šç«äº‰åŠ›å¼ºï¼Œå¹¶ä¸”è§£å†³äº†ä¼ ç»Ÿä¾èµ–äºå¤§å‹LLMå’Œå¤–éƒ¨ç›¸å…³æ€§æ ‡ç­¾çš„é—®é¢˜ï¼Œå±•ç¤ºäº†åœ¨è¿™ä¸€é¢†åŸŸçš„ä¼˜åŒ–å’Œè¿›æ­¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.16098v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.16098.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/castorini/LiT5)</div> |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **Think and Retrieval: A Hypothesis Knowledge Graph Enhanced Medical Large Language Models**<br><sub>æœºæ„: Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education; School of Computer Science Peking University, Beijing China<br>HyKGEæ¡†æ¶æœ‰æ•ˆè§£å†³äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é¢å¯¹åŒ»ç–—é¢†åŸŸå¤æ‚é—®é¢˜æ—¶çš„å‡†ç¡®æ€§å’Œè§£é‡Šæ€§æŒ‘æˆ˜ï¼Œå…·æœ‰åœ¨åŒ»ç–—é¢†åŸŸä¸­çš„æ½œåœ¨åº”ç”¨å¹¶ä¸”åœ¨å®é™…åœºæ™¯ä¸­å±•ç¤ºå‡ºäº†å¾ˆå¤§çš„ä¼˜è¶Šæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.15883v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.15883.md)  |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **A Prompt Learning Framework for Source Code Summarization**<br><sub>æœºæ„: Nanyang Technological University, Tencent Inc., Nanjing University<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„PromptCSæ¡†æ¶ï¼Œç”¨äºæºä»£ç æ‘˜è¦ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„æ‘˜è¦ï¼Œå‡å°‘äº†è®­ç»ƒæˆæœ¬ï¼Œå¹¶æä¾›äº†ä»£ç ä»¥ä¾›ä»–äººç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.16066v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.16066.md)  |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **Supervised Knowledge Makes Large Language Models Better In-context Learners**<br><sub>æœºæ„: School of Engineering Westlake University, Westlake Institute for Advanced Study, Peking University<br>è®ºæ–‡æå‡ºçš„SuperContextæ¡†æ¶é€šè¿‡åˆ©ç”¨ç‰¹å®šä»»åŠ¡å¾®è°ƒçš„SLMsçš„ç›‘ç£çŸ¥è¯†ï¼Œæ˜¾è‘—æé«˜äº†LLMsåœ¨è‡ªç„¶è¯­è¨€ç†è§£å’Œé—®ç­”ä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›å’Œäº‹å®æ€§ã€‚å®ƒä»£è¡¨äº†å°†å°å‹æ¨¡å‹çš„å¼ºå¤§åŠŸèƒ½èå…¥LLMsï¼Œä»¥å¤„ç†åˆ†å¸ƒå¤–æ•°æ®å’Œæœ€å°åŒ–å¹»è§‰ç°è±¡çš„ä¸€ç§åˆ›æ–°åšæ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.15918v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.15918.md)  |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **Aligning Large Language Models with Human Preferences through Representation Engineering**<br><sub>æœºæ„: Fudan University  <br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„æ–¹æ³•RAHFï¼Œé€šè¿‡è¡¨ç¤ºå·¥ç¨‹æŠ€æœ¯æ“çºµå†…éƒ¨æ¨¡å‹è¡¨ç¤ºæ¥å¯¹é½LLMsä¸äººç±»åå¥½ï¼Œè¿™ç§æ–¹æ³•åœ¨è®¡ç®—ä¸Šé«˜æ•ˆä¸”å®¹æ˜“å®ç°ï¼Œå¹¶å±•ç¤ºäº†å¤„ç†å¤šç§äººç±»åå¥½æˆ–ä»·å€¼çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.15997v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.15997.md)  |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **Align on the Fly: Adapting Chatbot Behavior to Established Norms**<br><sub>æœºæ„: Shanghai Jiao Tong University, Shanghai Artificial Intelligence Laboratory, The Hong Kong Polytechnic University<br>è¯¥å·¥ä½œæå‡ºäº†ä¸€ä¸ªåŠ¨æ€çš„OPOæ–¹æ³•ï¼Œé€šè¿‡æ”¶é›†æ³•å¾‹å’Œé“å¾·è§„åˆ™ä½œä¸ºå¤–éƒ¨å­˜å‚¨å™¨æ¥é™åˆ¶LLMsçš„è¡Œä¸ºï¼Œæ— éœ€è¿›ä¸€æ­¥è®­ç»ƒï¼Œå¹¶é€šè¿‡ä¸€ä¸ªå¯æ‰©å±•çš„è¯„ä¼°æ¨¡å—æ¥åº”å¯¹æ½œåœ¨çš„åŸºå‡†æµ‹è¯•æ³„æ¼é—®é¢˜åŠæ‰©å¤§æµ‹è¯•è§„åˆ™çš„èŒƒå›´ã€‚å°½ç®¡è¯¥æ–¹æ³•åœ¨æ¨ç†æ•ˆç‡æ–¹é¢å­˜åœ¨å±€é™æ€§å¹¶ä¸”æ£€ç´¢æ¨¡å‹ä»å¯è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œä½†åœ¨å¤šä¸ªè¯„ä¼°æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.15907v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.15907.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/GAIR-NLP/OPO)</div> |
| <span style='display: inline-block; width: 42px;'>12-26</span> | **KnowledgeNavigator: Leveraging Large Language Models for Enhanced Reasoning over Knowledge Graph**<br><sub>æœºæ„: Northeastern University, Neusoft AI Magic Technology Research, Neusoft Institute of Intelligent Medical Research<br>è¿™ç¯‡è®ºæ–‡ä»‹ç»äº†ä¸€ä¸ªæ–°å‹æ¡†æ¶KnowledgeNavigatorï¼Œå®ƒé€šè¿‡æ”¹å–„çŸ¥è¯†å›¾è°±ä¸Šçš„æ¨ç†è¿‡ç¨‹ï¼Œè§£å†³äº†LLMåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½å±€é™é—®é¢˜ã€‚å®éªŒç»“æœè¯å®äº†å…¶æœ‰æ•ˆæ€§ï¼Œå¹¶æœ‰æœ›åœ¨é«˜é£é™©å’Œé«˜æ•æ„Ÿé¢†åŸŸæ¨å¹¿LLMçš„åº”ç”¨ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.15880v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1588.md)  |
| <span style='display: inline-block; width: 42px;'>12-25</span> | **Alleviating Hallucinations of Large Language Models through Induced Hallucinations**<br><sub>æœºæ„: Soochow University, Tencent AI Lab<br>è®ºæ–‡æå‡ºä¸€ä¸ªæ–°é¢–çš„å‡å°‘LLMså¹»è§‰çš„æ–¹æ³•ï¼Œé€šè¿‡æ„å»ºä¸€ä¸ªäº‹å®ä¸Šè¾ƒå¼±çš„LLMå¹¶åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å‡å»å…¶çŸ¥è¯†ï¼Œæ”¹è¿›äº†æ¨¡å‹åœ¨ç”Ÿæˆäº‹å®æ€§å†…å®¹æ–¹é¢çš„è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.15710v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1571.md)  |
| <span style='display: inline-block; width: 42px;'>12-25</span> | **ESGReveal: An LLM-based approach for extracting structured data from ESG reports**<br><sub>æœºæ„: Alibaba Cloud, Tsinghua University, Sun Yat-Sen University<br>ESGRevealä»£è¡¨äº†åœ¨å¤„ç†ESGæ•°æ®ä¸­çš„ä¸€å¤§æ­¥è¿›ï¼Œæ—¨åœ¨é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹å’Œç›¸å…³æŠ€æœ¯æ¥æé«˜ä»å…¬å¸æŠ¥å‘Šä¸­æå–ç»“æ„åŒ–æ•°æ®çš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§ï¼Œå¹¶æ¨åŠ¨äº†ESGå®è·µå’Œé€æ˜åº¦çš„æ”¹è¿›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.17264v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.17264.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **Reasons to Reject? Aligning Language Models with Judgments**<br><sub>æœºæ„: Tencent AI Lab, The Chinese University of Hong Kong<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„é€šè¿‡ç›´æ¥åˆ©ç”¨è¯­è¨€åé¦ˆæ¥å¯¹é½LLMsçš„æ¡†æ¶Contrastive Unlikelihood Trainingï¼ˆCUTï¼‰ï¼Œå¹¶ä¸”è¯æ˜äº†å…¶åœ¨å¤šç§åœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬ç¦»çº¿å¯¹é½å’Œåœ¨çº¿å¯¹é½ï¼Œä»¥åŠä»æœªå¯¹é½çš„æ¨¡å‹ï¼ˆå†·å¯åŠ¨ï¼‰å’Œå·²å¯¹é½çš„æ¨¡å‹ï¼ˆçƒ­å¯åŠ¨ï¼‰è¿›è¡Œè¿›ä¸€æ­¥ä¼˜åŒ–ã€‚ç ”ç©¶æ˜¾ç¤ºï¼Œä¸å¥–åŠ±ç›¸æ¯”ï¼Œè¯„åˆ¤æ€§åé¦ˆåœ¨å¯¹é½LLMsæ–¹é¢å…·æœ‰æ›´å¤§çš„æ½œåŠ›ï¼Œå€¼å¾—è¿›è¡Œè¿›ä¸€æ­¥ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14591v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14591.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **VIEScore: Towards Explainable Metrics for Conditional Image Synthesis Evaluation**<br><sub>æœºæ„: University of Waterloo, IN.AI Research<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºVIEScoreçš„è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨æä¾›å¯¹æ¡ä»¶å›¾åƒç”Ÿæˆä»»åŠ¡çš„å¯è§£é‡Šæ€§è¯„ä»·ã€‚VIEScoreå…‹æœäº†ç°æœ‰è‡ªåŠ¨åŒ–åº¦é‡æ— æ³•è§£é‡Šè¯„åˆ†ç†ç”±çš„æŒ‘æˆ˜ï¼Œå¹¶èƒ½å¤Ÿé€‚åº”å„ç§ä»»åŠ¡éœ€æ±‚ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14867v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14867.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **A Survey of Reinforcement Learning from Human Feedback**<br><sub>æœºæ„: LMU Munich, Duke Kunshan University<br>è¿™ç¯‡æ–‡ç« æ˜¯å¯¹RLHFçš„ç»¼è¿°ï¼Œåˆ†æäº†å®ƒåœ¨äººå·¥æ™ºèƒ½å’Œäººæœºäº¤äº’äº¤å‰ç‚¹ä¸­çš„åº”ç”¨ï¼Œå¹¶æ¢è®¨äº†ä¸LLMsç›¸å…³çš„æœ€æ–°ç ”ç©¶è¶‹åŠ¿ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14925v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14925.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **Generative AI Beyond LLMs: System Implications of Multi-Modal Generation**<br><sub>è¯¥è®ºæ–‡æ˜¯é’ˆå¯¹è·¨æ–‡æœ¬ã€å›¾åƒå’Œè§†é¢‘ç”Ÿæˆæ¨¡å‹çš„ç³»ç»Ÿæ€§èƒ½ç‰¹å¾åŒ–çš„é¦–æ¬¡å·¥ä½œï¼Œå®ƒæ­ç¤ºäº†ä¸åŒäºä¼ ç»ŸLLMsçš„ç‹¬ç‰¹ç³»ç»Ÿå±æ€§ï¼Œå¹¶æå‡ºäº†å¯¹äºTTI/TTVæ¨¡å‹è€Œè¨€ï¼Œä¼ ç»Ÿçš„ä¼˜åŒ–æŠ€æœ¯éœ€è¦é‡æ–°è€ƒè™‘çš„æŒ‘æˆ˜å’Œæœºä¼šã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14385v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14385.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **Large Language Model (LLM) Bias Index -- LLMBI**<br><sub>æœºæ„: University of Oxford, University Canada West, Amazon Web Services (AWS)<br>å¼•å…¥LLMBIæ˜¯åœ¨åˆ›å»ºå…¬å¹³å¯é çš„LLMsæ–¹é¢è¿ˆå‡ºçš„é‡è¦ä¸€æ­¥ã€‚å®ƒä¸ºç³»ç»Ÿå·¥ç¨‹å¸ˆå’Œç ”ç©¶äººå‘˜æä¾›äº†ä¸€ç§å®šé‡è¡¡é‡åè§çš„å·¥å…·ï¼Œå¼•å¯¼ä»–ä»¬æŒç»­æ”¹è¿›è¿™äº›å¼ºå¤§çš„æ¨¡å‹ï¼Œç¡®ä¿å®ƒä»¬åæ˜ ç¤¾ä¼šçš„å¤šæ ·æ€§å’Œä¸æ–­è¿›åŒ–çš„ç»“æ„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14769v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14769.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **Plan, Posture and Go: Towards Open-World Text-to-Motion Generation**<br><sub>æœºæ„: Tsinghua University, Microsoft Research Asia<br>ç ”ç©¶è€…ä»¬æå‡ºäº†ä¸€ä¸ªåä¸ºPRO-Motionçš„æ–°æ¡†æ¶ï¼Œä»¥å…‹æœä¼ ç»Ÿæ–‡æœ¬åˆ°åŠ¨ä½œç”Ÿæˆæ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶æˆåŠŸåœ¨å¼€æ”¾ä¸–ç•Œåœºæ™¯ä¸­ç”Ÿæˆæ›´å¤šæ ·å’ŒçœŸå®çš„åŠ¨ä½œã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14828v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14828.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **YAYI 2: Multilingual Open-Source Large Language Models**<br><sub>æœºæ„: Beijing Wenge Technology Co. Ltd., Institute of Automation Chinese Academy of Sciences<br>è¯¥è®ºæ–‡æå‡ºäº†YAYI 2ï¼Œä¸€ä¸ªé’ˆå¯¹å¤šè¯­è¨€åœºæ™¯ä¼˜åŒ–çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡åœ¨å¤§è§„æ¨¡è¯­æ–™åº“ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶é€šè¿‡å¤šç§æ–¹æ³•ä¸äººç±»ä»·å€¼è§‚å¯¹é½ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¤šç§ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸­æ–‡ç›¸å…³ä»»åŠ¡ä¸Šã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14862v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14862.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **Pangu-Agent: A Fine-Tunable Generalist Agent with Structured Reasoning**<br><sub>æœºæ„: Huawei Noah's Ark Lab, University College London, University of Oxford<br>æœ¬è®ºæ–‡æå‡ºäº†Pangu-Agentæ¡†æ¶ï¼Œç›®æ ‡æ˜¯è§£å†³æ ‡å‡†RLæ–¹æ³•åœ¨å¤šä»»åŠ¡ç¯å¢ƒä¸­æ‰€é¢ä¸´çš„æŒ‘æˆ˜ã€‚Pangu-Agenté€šè¿‡å†…åœ¨å‡½æ•°å¼•å…¥ç»“æ„æ€§æ¨ç†ï¼Œå¹¶é€šè¿‡ç›‘ç£å­¦ä¹ å’ŒRLå®ç°æ™ºèƒ½ä½“çš„å¾®è°ƒï¼Œæé«˜äº†æ™ºèƒ½ä½“é€‚åº”å¤šç¯å¢ƒäº¤äº’çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14878v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.14878.md)  |
| <span style='display: inline-block; width: 42px;'>12-22</span> | **NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes**<br><sub>æœºæ„: University of Michigan, Rutgers University<br>æœ¬è®ºæ–‡é€šè¿‡NPHardEvalåŸºå‡†æµ‹è¯•æä¾›äº†ä¸€ç§æ–°çš„è¯„ä¼°LLMsæ¨ç†èƒ½åŠ›çš„æ–¹æ³•ã€‚è¯¥åŸºå‡†æµ‹è¯•å¹¿æ³›æ¶µç›–äº†ä»å¤šé¡¹å¼æ—¶é—´åˆ°NP-Hardå¤æ‚æ€§çº§åˆ«çš„é—®é¢˜ï¼Œå¹¶è®¾è®¡äº†åŠ¨æ€æ•°æ®æ›´æ–°æœºåˆ¶ä»¥é˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆï¼Œä»è€Œç¡®ä¿äº†è¯„ä¼°ç»“æœçš„å¯é æ€§å’ŒçœŸå®æ€§ã€‚è¿™äº›å‘ç°æå¤§åœ°ä¿ƒè¿›äº†å¯¹LLMså½“å‰èƒ½åŠ›çš„ç†è§£ï¼Œå¹¶ä¸ºæé«˜è¿™äº›æ¨¡å‹çš„æ¨ç†èƒ½åŠ›é“ºå¹³äº†é“è·¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.14890v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1489.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/casmlab/NPHardEval)</div> |
| <span style='display: inline-block; width: 42px;'>12-21</span> | **AppAgent: Multimodal Agents as Smartphone Users**<br><sub>æœºæ„: Tencent  <br>è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåˆ›æ–°çš„å¤šæ¨¡æ€ä»£ç†æ¡†æ¶ï¼Œå®ƒå…è®¸ä»£ç†åƒäººç±»ç”¨æˆ·ä¸€æ ·æ“ä½œä»»ä½•æ™ºèƒ½æ‰‹æœºåº”ç”¨ï¼Œå¹¶é€šè¿‡è‡ªåŠ¨æ¢ç´¢å’Œè§‚å¯Ÿäººç±»æ¼”ç¤ºæ¥å­¦ä¹ æ–°åº”ç”¨çš„ä½¿ç”¨æ–¹æ³•ã€‚ç ”ç©¶ç»“æœè¯å®äº†è¯¥æ¡†æ¶åœ¨æ‰§è¡Œå¤šæ ·åŒ–é«˜çº§ä»»åŠ¡æ—¶çš„æ•ˆç‡å’Œé€‚åº”æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13771v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.13771.md)  |
| <span style='display: inline-block; width: 42px;'>12-21</span> | **On Task Performance and Model Calibration with Supervised and Self-Ensembled In-Context Learning**<br><sub>æœºæ„: Language Technology Lab University of Cambridge<br>æœ¬æ–‡æä¾›äº†åœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ä¸åŒå­¦ä¹ æ–¹æ³•çš„æ€§èƒ½å’Œæ ¡å‡†çš„å…¨é¢åˆ†æã€‚è¿™è¡¨æ˜è™½ç„¶æé«˜æ€§èƒ½å’Œæ ¡å‡†åŒæ—¶è¾¾æˆæ˜¯å›°éš¾çš„ï¼Œä½†é€šè¿‡è‡ªç»„è£…æŠ€æœ¯èƒ½å¤Ÿåœ¨ä¸å½±å“æ€§èƒ½çš„å‰æä¸‹å¢å¼ºæ¨¡å‹çš„æ ¡å‡†ï¼Œå¯¹äºæœªæ¥LLMsçš„åº”ç”¨æä¾›äº†é‡è¦çš„å®è·µæŒ‡å¯¼ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13772v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.13772.md)  |
| <span style='display: inline-block; width: 42px;'>12-21</span> | **The Truth is in There: Improving Reasoning in Language Models with Layer-Selective Rank Reduction**<br><sub>æœºæ„: MIT, Microsoft Research NYC<br>è¯¥è®ºæ–‡æå‡ºäº†LASERï¼Œä¸€ç§åœ¨æ¨¡å‹è®­ç»ƒå®Œæˆåå¯¹Transformeræ¨¡å‹çš„ç‰¹å®šå±‚è¿›è¡Œè£å‰ªä»¥æå‡æ€§èƒ½çš„æ–¹æ³•ã€‚ä½œè€…è¡¨æ˜ï¼Œè¿™ç§ç­–ç•¥ä¸ä»…æœ‰æ•ˆï¼Œè€Œä¸”æ˜¯é¦–æ¬¡å‘ç°å¯ä»¥é€šè¿‡ç²¾å¿ƒé€‰æ‹©çš„å‰ªææ¥å¢å¼ºTransformeræ¨¡å‹çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13558v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.13558.md)  |
| <span style='display: inline-block; width: 42px;'>12-21</span> | **De novo Drug Design using Reinforcement Learning with Multiple GPT Agents**<br><sub>æœºæ„: Tsinghua University, Microsoft Research AI<br>è¿™ç¯‡è®ºæ–‡æ¨å‡ºäº†ä¸€ä¸ªç»“åˆå¤šä¸ªGPTä»£ç†çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ç”¨äºè¯ç‰©åˆ†å­çš„ç”Ÿæˆï¼Œå¹¶åœ¨GuacaMolåŸºå‡†æµ‹è¯•å’ŒSARS-CoV-2è›‹ç™½é¶æ ‡æŠ‘åˆ¶å‰‚è®¾è®¡ä¸­æ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ€§èƒ½å’Œå®ç”¨æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2401.06155v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2401.06155.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/HXYfighter/MolRL-MGPT)</div> |
| <span style='display: inline-block; width: 42px;'>12-20</span> | **Time is Encoded in the Weights of Finetuned Language Models**<br><sub>è¿™é¡¹ç ”ç©¶é€šè¿‡æ—¶é—´å‘é‡çš„æ¦‚å¿µè¡¨æ˜äº†æ—¶é—´å˜åŒ–å¯ä»¥åœ¨ä¸€å®šç¨‹åº¦ä¸Šé€šè¿‡è¯­è¨€æ¨¡å‹çš„æƒé‡ç©ºé—´æ¥ç¼–ç ï¼Œå¹¶ä¸”æƒé‡æ’å€¼å¯ä»¥å¸®åŠ©å®šåˆ¶æ¨¡å‹ä»¥é€‚åº”æ–°çš„æ—¶é—´æ®µã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13401v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.13401.md)  |
| <span style='display: inline-block; width: 42px;'>12-20</span> | **Generative Multimodal Models are In-Context Learners**<br><sub>æœºæ„: Beijing Academy of Artificial Intelligence, Tsinghua University, Peking University<br>æœ¬è®ºæ–‡é€šè¿‡æ‰©å¤§æ¨¡å‹è§„æ¨¡ï¼ŒæˆåŠŸæå‡äº†å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹ Emu2 åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ä¸Šçš„è¡¨ç°ï¼Œå¹¶åœ¨ä¸€ç³»åˆ—å¤šæ¨¡æ€ç†è§£ä»»åŠ¡ä¸­å–å¾—äº†çªç ´æ€§çš„æ•ˆæœï¼Œå°¤å…¶åœ¨åŸºäºæŒ‡ä»¤å¾®è°ƒåçš„è§†è§‰é—®ç­”å’Œå¯æ§è§†è§‰ç”Ÿæˆæ–¹é¢ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13286v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.13286.md)  |
| <span style='display: inline-block; width: 42px;'>12-20</span> | **AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation**<br><sub>æœºæ„: The University of Hong Kong, Shanghai Jiao Tong University<br>AgentCoderæ˜¯ä¸€ç§æ–°å‹çš„å¤šä»£ç†æ¡†æ¶ï¼Œå®ƒåœ¨è‡ªåŠ¨ä»£ç ç”Ÿæˆä¸­é€šè¿‡è¿›è¡Œè¿­ä»£æµ‹è¯•å’Œä¼˜åŒ–ï¼Œæ˜æ˜¾æé«˜äº†ä»£ç ç”Ÿæˆçš„è´¨é‡å’Œå‡†ç¡®æ€§ï¼Œå°¤å…¶æ˜¯åœ¨é¢å¯¹æŒ‘æˆ˜æ€§æ›´å¤§çš„å¢å¼ºå‹æ•°æ®é›†æ—¶è¡¨ç°å‡ºå…¶ä¼˜åŠ¿ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13010v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1301.md)  |
| <span style='display: inline-block; width: 42px;'>12-20</span> | **Lampr: Boosting the Effectiveness of Language-Generic Program Reduction via Large Language Models**<br><sub>æœºæ„: University of Waterloo, The Hong Kong University of Science and Technology, Concordia University<br>Lampræ˜¯ç¬¬ä¸€ä¸ªæ•´åˆLLMsäºç¨‹åºç¼©å‡è¿‡ç¨‹çš„ç®—æ³•ã€‚å®ƒé€šè¿‡å¤šå±‚æ¬¡æç¤ºæ–¹æ³•å’ŒLLMsçš„è¾…åŠ©ï¼Œå–å¾—äº†è·¨è¯­è¨€é€šç”¨æ€§å’Œç‰¹å®šè¯­è¨€è¯­ä¹‰æ„è¯†ä¹‹é—´çš„å¹³è¡¡ï¼Œå¹¶ä¸”åœ¨å®éªŒä¸­è¯æ˜äº†å…¶ä¼˜è¶Šæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13064v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.13064.md)  |
| <span style='display: inline-block; width: 42px;'>12-20</span> | **Mini-GPTs: Efficient Large Language Models through Contextual Pruning**<br><sub>æœºæ„: Massachusetts Institute of Technology<br>è¿™ç¯‡è®ºæ–‡å±•ç¤ºäº†é€šè¿‡ä¸Šä¸‹æ–‡å‰ªæå¼€å‘å°å‹ä½†é«˜æ•ˆçš„GPTæ¨¡å‹ï¼Œå³Mini-GPTsçš„è¿‡ç¨‹å’Œç»“æœã€‚é€šè¿‡è¿™ç§æ–¹æ³•ï¼Œç ”ç©¶äººå‘˜åœ¨ä¸åŒé¢†åŸŸç‰¹å®šçš„æ•°æ®é›†ä¸ŠæˆåŠŸå‡å°‘äº†LLMsçš„å°ºå¯¸å¹¶ä¸”ä¿æŒäº†æ€§èƒ½ï¼Œå±•ç°äº†å‰ªææŠ€æœ¯ä¸ä»…ç†è®ºä¸Šå¯è¡Œï¼Œè€Œä¸”åœ¨å¼€å‘èµ„æºé«˜æ•ˆçš„é¢†åŸŸç‰¹å®šLLMsä¸­å®è·µä¸Šå…·æœ‰å®ç”¨ä»·å€¼ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.12682v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.12682.md)  |
| <span style='display: inline-block; width: 42px;'>12-20</span> | **Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy**<br><sub>æœºæ„: Ant Group<br>æœ¬è®ºæ–‡æå‡ºäº†åä¸ºLookaheadçš„æ¨ç†åŠ é€Ÿæ¡†æ¶ï¼Œå®ƒé€šè¿‡ä½¿ç”¨åŸºäºTrieæ ‘çš„å¤šåˆ†æ”¯æ¨ç†ç­–ç•¥ï¼Œåœ¨æé«˜LLMsæ¨ç†é€Ÿåº¦çš„åŒæ—¶ï¼Œä¿æŒäº†ç”Ÿæˆå‡†ç¡®æ€§ã€‚æ¡†æ¶é€šè¿‡å¹¿æ³›çš„å®éªŒéªŒè¯äº†å…¶æ€§èƒ½ï¼Œå¹¶åœ¨æ”¯ä»˜å®çš„å®é™…ä½¿ç”¨åœºæ™¯ä¸­å¾—åˆ°äº†éƒ¨ç½²ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.12728v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.12728.md)  |
| <span style='display: inline-block; width: 42px;'>12-20</span> | **AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation**<br><sub>æœºæ„: The University of Hong Kong, Shanghai Jiao Tong University, Kingâ€™s College London<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„åŸºäºå¤šæ™ºèƒ½ä½“çš„ä»£ç ç”Ÿæˆè§£å†³æ–¹æ¡ˆAgentCoderï¼Œé€šè¿‡ç‰¹å®šçš„æ™ºèƒ½ä½“èšç„¦äºä»£ç ç”Ÿæˆã€æµ‹è¯•è®¾è®¡å’Œæµ‹è¯•æ‰§è¡Œï¼Œæœ‰æ•ˆåœ°è§£å†³äº†ä»£ç ç”Ÿæˆä¸æµ‹è¯•ä¹‹é—´çš„å¹³è¡¡é—®é¢˜ï¼Œå¹¶å®ç°äº†ä¼˜äºç°æœ‰SOTAæ–¹æ³•çš„ä»£ç ç”Ÿæˆè´¨é‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.13010v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1301.md)  |
| <span style='display: inline-block; width: 42px;'>12-19</span> | **Active Preference Inference using Language Models and Probabilistic Reasoning**<br><sub>æœºæ„: Cornell University, Cornell Tech<br>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå®æ—¶ç®—æ³•ï¼Œé€šè¿‡ç”Ÿæˆä¿¡æ¯ä¸°å¯Œçš„é—®é¢˜æ¥åŠ å¿«LLMså¯¹ç”¨æˆ·åå¥½çš„æ¨æ–­ï¼Œå¹¶åœ¨ç½‘è´­åœºæ™¯ä¸­éªŒè¯äº†å…¶å‡å°‘ç”¨æˆ·äº¤äº’å¹¶æé«˜ä»»åŠ¡æ€§èƒ½çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.12009v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.12009.md)  |
| <span style='display: inline-block; width: 42px;'>12-19</span> | **Text-Conditioned Resampler For Long Form Video Understanding**<br><sub>æœºæ„: University of Oxford, Google, Google DeepMind<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºTCRçš„æ–°å‹æ¶æ„åŠé¢„è®­ç»ƒæ–¹æ³•ï¼Œèƒ½å¤Ÿå¤„ç†ä¸æ–‡æœ¬æ¡ä»¶ç›¸ç»“åˆçš„é•¿è§†é¢‘ã€‚å®ƒæœ‰æ•ˆåœ°æ¡¥æ¥äº†é¢„è®­ç»ƒçš„è§†è§‰ç¼–ç å™¨å’ŒLLMï¼Œå®ç°äº†é•¿æœŸè§†é¢‘ç†è§£çš„é—®é¢˜ï¼Œå¹¶åœ¨å¤šä¸ªè¯„ä¼°ä»»åŠ¡ä¸Šå–å¾—äº†æœ€ä½³æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11897v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11897.md)  |
| <span style='display: inline-block; width: 42px;'>12-19</span> | **A Revisit of Fake News Dataset with Augmented Fact-checking by ChatGPT**<br><sub>æœ¬æ–‡æå‡ºäº†é¦–ä¸ªç»“åˆäººç±»æ ¸å®ä¸ChatGPTè¾…åŠ©çš„å‡æ–°é—»æ£€æµ‹å…¬å…±åŸºå‡†æ•°æ®é›†ChatGPT-FCï¼Œå¹¶é€šè¿‡å®šé‡åˆ†æå¯¹æ¯”äº†äººç±»è®°è€…ä¸LLMè¿›è¡Œäº‹å®æ ¸æŸ¥çš„å·®å¼‚ã€‚ç ”ç©¶å‘ç°ChatGPTå¯ä»¥å¢å¼ºæ–°é—»äº‹å®æ ¸æŸ¥è¿‡ç¨‹çš„å®¢è§‚æ€§å’Œå¯é æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11870v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1187.md)  |
| <span style='display: inline-block; width: 42px;'>12-19</span> | **Curated LLM: Synergy of LLMs and Data Curation for tabular augmentation in ultra low-data regimes**<br><sub>æœºæ„: University of Cambridge<br>æœ¬æ–‡ä»‹ç»äº†CLLMï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†å’Œå¼ºå¤§çš„æ•°æ®ä¸­å¿ƒæ–¹æ³•æ¥è¿›è¡Œæ•°æ®å¢å¼ºçš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨ä¸ºèµ„æ–™åŒ®ä¹çš„é¢†åŸŸå’Œåœ°åŒºçš„æœºå™¨å­¦ä¹ æä¾›äº†æ–°çš„é€”å¾„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.12112v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.12112.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **MAC-SQL: Multi-Agent Collaboration for Text-to-SQL**<br><sub>æœºæ„: Beihang University, Tencent Cloud AI<br>æ€»ä½“è€Œè¨€ï¼ŒMAC-SQL æ¡†æ¶é€šè¿‡è”åˆæ™ºèƒ½ä»£ç†ï¼Œè§£å†³äº† Text-to-SQL ä»»åŠ¡ä¸­çš„ä¸€äº›å…³é”®æŒ‘æˆ˜ï¼Œå¦‚å¤„ç†å¤§å‹æ•°æ®åº“ã€å¤æ‚æŸ¥è¯¢ä»¥åŠSQLéªŒè¯å’Œä¿®æ­£é—®é¢˜ã€‚è¿˜å‘å¸ƒäº†ä¸€ä¸ªå¼€æºæ¨¡å‹SQL-Llamaï¼Œè¯¥æ¨¡å‹å±•ç¤ºäº†é¼“åŠ±æ€§çš„ç»“æœï¼Œå¹¶å…·å¤‡ä¸æ”¶è´¹æ¨¡å‹å¦‚GPT-4ç›¸åª²ç¾çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11242v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11242.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/wbbeyourself/MAC-SQL)</div> |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **Retrieval-Augmented Generation for Large Language Models: A Survey**<br><sub>æœºæ„: Shanghai Research Institute for Intelligent Autonomous Systems, Tongji University, Fudan University<br>è¿™ç¯‡è®ºæ–‡ä¸ºRAGé¢†åŸŸæä¾›äº†ä¸€ä¸ªå…¨é¢å’Œç³»ç»Ÿçš„æŠ€æœ¯æ¦‚è§ˆï¼Œå¼ºè°ƒäº†æå‡LLMsæ£€ç´¢å’Œç”Ÿæˆèƒ½åŠ›çš„é‡è¦æ€§ï¼ŒæŒ‡å‡ºäº†ç°æœ‰æŒ‘æˆ˜ï¼Œå±•æœ›äº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10997v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10997.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **From Google Gemini to OpenAI Q-Star: A Survey of Reshaping the Generative Artificial Intelligence (AI) Research Landscape**<br><sub>æœºæ„: Cyberstronomy Pty Ltd, Academies Australasia Polytechnic, Massey University<br>è¿™é¡¹ç»¼è¿°è¯¦å°½åœ°åˆ†æäº†ç”Ÿæˆå‹AIé¢†åŸŸçš„å‘å±•åŠå…¶å¯¹ç ”ç©¶æ™¯è§‚çš„é‡å¡‘æ•ˆåº”ï¼Œå°¤å…¶å…³æ³¨äº†MoEå¤šæ¨¡æ€å­¦ä¹ å’ŒAGIçš„å‰æ™¯ã€‚ç ”ç©¶æ¶µç›–äº†ä»AIæ¨¡å‹ç»“æ„å’ŒåŸ¹è®­æŠ€æœ¯åˆ°åº”ç”¨é¢†åŸŸå’Œä¼¦ç†è€ƒè™‘çš„å…¨é¢åˆ†ç±»ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10868v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10868.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **Social Learning: Towards Collaborative Learning with Large Language Models**<br><sub>æœºæ„: Google, EPFL<br>æœ¬æ–‡æå‡ºäº†åœ¨LLMsä¸­å®ç°çŸ¥è¯†ä¼ é€’çš„æ–°æ¡†æ¶â€”ç¤¾äº¤å­¦ä¹ ï¼Œå¹¶æä¾›äº†ä¿æŠ¤éšç§çš„è§£å†³æ–¹æ¡ˆã€‚è¯¥æ¡†æ¶é€šè¿‡è‡ªç„¶è¯­è¨€åœ¨æ¨¡å‹é—´äº¤æ¢çŸ¥è¯†ï¼ŒåŒæ—¶é¿å…æ•æ„Ÿä¿¡æ¯æ³„éœ²ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œéšç§ä¿æŠ¤èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11441v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11441.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **G-LLaVA: Solving Geometric Problem with Multi-Modal Large Language Model**<br><sub>æœºæ„: Huawei Noah's Ark Lab, The University of Hong Kong, The Hong Kong University of Science and Technology<br>è¿™ç¯‡è®ºæ–‡é€šè¿‡æ„å»º Geo170K æ•°æ®é›†å’Œå¼€å‘åŸºäºå®ƒçš„ G-LLaVA æ¨¡å‹ï¼Œå…‹æœäº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è§£å†³å‡ ä½•é—®é¢˜ä¸Šçš„é™åˆ¶ï¼Œå¹¶å®ç°äº†æ¯”ç°æœ‰æœ€å…ˆç«¯æ¨¡å‹æ›´å¥½çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11370v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1137.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **NoMIRACL: Knowing When You Don't Know for Robust Multilingual Retrieval-Augmented Generation**<br><sub>æœºæ„: University of Waterloo, Huawei Noahâ€™s Ark Lab, FEEC-Unicamp Brazil<br>è¿™é¡¹å·¥ä½œé€šè¿‡å¼•å…¥NoMIRACLæ•°æ®é›†ï¼Œä¸ºè¯„ä¼°LLMåœ¨æ£€ç´¢å¼å¢å¼ºç”Ÿæˆä¸­çš„ç¨³å¥æ€§æä¾›äº†ä¸€ä¸ªå¤šè¯­è¨€çš„è¯„ä¼°å·¥å…·ï¼Œå¹¶é€šè¿‡å»ºç«‹GPT-4åŸºçº¿æ¨¡å‹å±•ç¤ºäº†LLMåœ¨è¯†åˆ«ç›¸å…³ä¸éç›¸å…³æ£€ç´¢ç»“æœä¸­å­˜åœ¨çš„æŒ‘æˆ˜ï¼Œçªå‡ºäº†æœªæ¥ç ”ç©¶æé«˜LLMç¨³å¥æ€§çš„å¿…è¦æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11361v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11361.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **Designing LLM Chains by Adapting Techniques from Crowdsourcing Workflows**<br><sub>æœºæ„: University of Washington, Stanford University, Allen Institute for AI<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªè®¾è®¡ç©ºé—´æ¦‚å¿µæ¡†æ¶ä»¥åŠé€šè¿‡è½¬æ¢ä¼—åŒ…å·¥ä½œæµåˆ°LLMé“¾çš„ä¸‰ä¸ªæ¡ˆä¾‹ç ”ç©¶ï¼Œä¸ºæœªæ¥LLMé“¾çš„è®¾è®¡å’Œå¼€å‘æä¾›äº†å®è·µæŒ‡å¯¼å’Œç†è®ºè§è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11681v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11681.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **"Paraphrasing The Original Text" Makes High Accuracy Long-Context QA**<br><sub>æœºæ„: Tsinghua University  <br>è®ºæ–‡ä¸»è¦é€šè¿‡ç†è®ºè¯æ˜å’Œå®éªŒéªŒè¯ï¼Œæå‡ºäº†ä¸€ç§ä½æˆæœ¬ä¸”é«˜æ•ˆçš„æ–¹æ³•ï¼Œé€šè¿‡åŸæ–‡é‡Šä¹‰ä»»åŠ¡å’Œæœ‰æ•ˆçš„æŒ‡ä»¤å¾®è°ƒæ•°æ®æ‰©å±•ç°æœ‰è¯­è¨€æ¨¡å‹å¤„ç†é•¿æ–‡æœ¬çš„èƒ½åŠ›ï¼Œæ˜¾è‘—æé«˜äº†é•¿æ–‡æœ¬é—®ç­”çš„å‡†ç¡®æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11193v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11193.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **Generalized Category Discovery with Large Language Models in the Loop**<br><sub>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„ä¸»åŠ¨å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡å¼•å…¥å¤§å‹è¯­è¨€æ¨¡å‹è¿›å…¥è®­ç»ƒå¾ªç¯ï¼Œæœ‰æ•ˆåœ°æå‡äº†æ¨¡å‹åœ¨æ³›åŒ–ç±»åˆ«å‘ç°ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œå¹¶èƒ½è‡ªåŠ¨ç”Ÿæˆç±»åˆ«åç§°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10897v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10897.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **Towards Better Serialization of Tabular Data for Few-shot Classification with Large Language Models**<br><sub>æœºæ„: Carnegie Mellon University<br>è®ºæ–‡æˆåŠŸåœ°å±•ç¤ºäº†åœ¨è¡¨æ ¼æ•°æ®åˆ†ç±»ä¸­åº”ç”¨LLMsçš„åˆ›æ–°å®è·µï¼Œå¹¶ä»¥LaTeXåºåˆ—åŒ–æ¡†æ¶ä¸ºç‰¹ç‚¹ï¼Œæå‡ºäº†æœ‰æ•ˆå¤„ç†é¢†åŸŸç‰¹å®šæ•°æ®é›†çš„æ–°å‹åºåˆ—åŒ–æ–¹æ³•ã€‚ç ”ç©¶è¿˜å¯¹LLMsåœ¨è§£è¯»å¤æ‚æ•°æ®å…³ç³»æ–¹é¢çš„èƒ½åŠ›è¿›è¡Œäº†æ·±å…¥çš„æ¢ç´¢ã€‚è®ºæ–‡çš„LaTeXåºåˆ—åŒ–æ–¹æ³•ä¸ä»…æå‡äº†LLMsåœ¨åˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œè¿˜æ˜¾è‘—æé«˜äº†å†…å­˜çš„ä½¿ç”¨æ•ˆç‡å’Œè®¡ç®—æ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.12464v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.12464.md)  |
| <span style='display: inline-block; width: 42px;'>12-18</span> | **Agent-based Learning of Materials Datasets from Scientific Literature**<br><sub>æœºæ„: University of Toronto  <br>æœ¬è®ºæ–‡å±•ç¤ºäº†ä¸€ä¸ªä»¥å¤§å‹è¯­è¨€æ¨¡å‹ä¸ºåŸºç¡€çš„æ™ºèƒ½ä»£ç†åœ¨è‡ªåŠ¨å­¦ä¹ å’Œæå–ç§‘å­¦æ–‡çŒ®ä¸­ææ–™ç›¸å…³æ•°æ®é›†æ–¹é¢çš„èƒ½åŠ›ã€‚Eunomiaå±•ç¤ºäº†åœ¨æ²¡æœ‰ä»»ä½•å¾®è°ƒçš„æƒ…å†µä¸‹åœ¨æå–å®ä½“å’Œå…³ç³»æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸”å¯ä»¥å¢å¼ºå…¶åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶é¿å…é”™è¯¯çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11690v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1169.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/AI4ChemS/Eunomia)</div> |
| <span style='display: inline-block; width: 42px;'>12-17</span> | **Distinguishing Translations by Human, NMT, and ChatGPT: A Linguistic and Statistical Approach**<br><sub>æœºæ„: Shanghai Jiao Tong University<br>æœ¬ç ”ç©¶ä¸ºChatGPTä½œä¸ºNMTä¹‹å¤–çš„å¦ä¸€ç§ç¿»è¯‘å·¥å…·çš„å¯èƒ½æ€§æä¾›äº†åˆæ­¥ç­”æ¡ˆï¼Œå¹¶å±•ç¤ºäº†ChatGPTä¸NMTå’ŒHTç›¸æ¯”çš„ç‹¬ç‰¹ç‰¹æ€§ã€‚è¿™äº›æ–°è®¤è¯†æœ‰åŠ©äºæœªæ¥æ›´äººæ€§åŒ–ã€æ›´ç¬¦åˆè¯­å¢ƒçš„ç¿»è¯‘ç³»ç»Ÿçš„å¼€å‘ï¼Œå¹¶ä¸ºå¦‚ä½•æœ‰æ•ˆä½¿ç”¨AIç”Ÿæˆçš„ç¿»è¯‘æä¾›æ´è§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10750v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1075.md)  |
| <span style='display: inline-block; width: 42px;'>12-17</span> | **Mixed Distillation Helps Smaller Language Model Better Reasoning**<br><sub>æœºæ„: Zhejiang University, Dalian Medical University<br>Mixed Distillationæ¡†æ¶é€šè¿‡æ•´åˆLLMsä¸­çš„PoTå’ŒCoTèƒ½åŠ›åˆ°æ›´å°çš„æ¨¡å‹ä¸­ï¼Œæ˜¾è‘—æ”¹å–„äº†å®ƒä»¬çš„é«˜çº§æ¨ç†èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10730v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.1073.md)  |
| <span style='display: inline-block; width: 42px;'>12-16</span> | **RIGHT: Retrieval-augmented Generation for Mainstream Hashtag Recommendation**<br><sub>æœºæ„: CAS Key Lab of Network Data Science and Technology ICT CAS, University of Chinese Academy of Sciences Beijing China<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ£€ç´¢å¢å¼ºå‹ç”Ÿæˆä¸»æµæ ‡ç­¾æ¨èç³»ç»Ÿï¼ˆRIGHTï¼‰ï¼Œé€šè¿‡ç»“åˆæ£€ç´¢å™¨ã€é€‰æ‹©å™¨å’Œç”Ÿæˆå™¨çš„ä¼˜åŠ¿ï¼Œå…‹æœäº†ç°æœ‰æ–¹æ³•åœ¨ç†è§£æ–°ä¿¡æ¯å’Œè¯†åˆ«ä¸»æµæ ‡ç­¾æ–¹é¢çš„é™åˆ¶ï¼Œå¹¶åœ¨å®éªŒä¸­å–å¾—æ˜¾è‘—æˆæ•ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10466v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10466.md)  |
| <span style='display: inline-block; width: 42px;'>12-16</span> | **ProTIP: Progressive Tool Retrieval Improves Planning**<br><sub>æœºæ„: Apple  <br>è¿™ç¯‡è®ºæ–‡æå‡ºäº† ProTIPï¼Œä¸ºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚è§„åˆ’ä»»åŠ¡ä¸­çš„å·¥å…·æ£€ç´¢å’Œä½¿ç”¨æä¾›äº†ä¸€ç§è¿›æ­¥çš„ç­–ç•¥ã€‚ProTIP çš„æ ¸å¿ƒåœ¨äºæ¸è¿›å¼æ£€ç´¢ã€æœ‰æ•ˆåˆ©ç”¨æ‰§è¡Œå†å²å’Œå®ç°å­ä»»åŠ¡ä¸å·¥å…·åŠŸèƒ½çš„å¯¹é½ã€‚å®éªŒç»“æœå±•ç¤ºå‡º ProTIP æ˜æ˜¾è¶…è¿‡ä¼ ç»Ÿæ–¹æ³•ï¼Œé™ä½äº†å·¥å…·è™šæ„ï¼Œå¹¶æé«˜äº†è§„åˆ’æ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10332v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10332.md)  |
| <span style='display: inline-block; width: 42px;'>12-16</span> | **CoAScore: Chain-of-Aspects Prompting for NLG Evaluation**<br><sub>æœºæ„: GSAI Renmin University of China<br>CoAScore æ˜¯ä¸€ä¸ªæ–°é¢–çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå®ƒé€šè¿‡â€œæ–¹é¢é“¾â€çš„æ–¹æ³•æå‡äº†å¯¹äº NLG ä»»åŠ¡çš„è¯„ä¼°ç²¾åº¦ï¼Œå¹¶ä¸”è¯¥æ•ˆæœè·å¾—äº†å®éªŒçš„è¯å®ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10355v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10355.md)  |
| <span style='display: inline-block; width: 42px;'>12-16</span> | **RecPrompt: A Prompt Tuning Framework for News Recommendation Using Large Language Models**<br><sub>æœºæ„: Science Foundation Ireland (SFI), JSPS KAKENHI<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†RecPromptæ¨¡å‹ï¼Œåˆ©ç”¨LLMå¯¹æ–°é—»æ¨èè¿›è¡Œä¼˜åŒ–ã€‚é€šè¿‡æ‰‹åŠ¨å’ŒLLMè‡ªåŠ¨ç”Ÿæˆçš„æç¤ºæ¨¡æ¿çš„è¿­ä»£ä¼˜åŒ–è¿‡ç¨‹ï¼Œæ˜¾è‘—æé«˜äº†æ–°é—»æ¨èæ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨ä½¿ç”¨GPT-4è¿›è¡Œè‡ªåŠ¨ç”Ÿæˆçš„æç¤ºæ¨¡æ¿ä¸‹ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å¹¶éæ€»æ˜¯èƒ½è¶…è¶Šä¼ ç»Ÿçš„æ¨èæ–¹æ³•ï¼Œä¸”æ¨èæ•ˆæœå—åˆ°LLMé€‰æ‹©çš„æ˜¾è‘—å½±å“ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10463v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10463.md)  |
| <span style='display: inline-block; width: 42px;'>12-16</span> | **A Survey on Robotic Manipulation of Deformable Objects: Recent Advances, Open Challenges and New Frontiers**<br><sub>æœºæ„: Tongji University, National Natural Science Foundation of China, Shanghai Municipal Science and Technology Major Project<br>æœ¬ç»¼è¿°å½’çº³äº†æœºå™¨äººæ“ä½œå¯å˜å½¢å¯¹è±¡ï¼ˆDOMï¼‰é¢†åŸŸçš„è¿‘æœŸè¿›å±•ã€å­˜åœ¨çš„æŒ‘æˆ˜å’Œæ–°å‰æ²¿ã€‚ç‰¹åˆ«å¼ºè°ƒäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æœºå™¨äººæ“çºµä¸­çš„åˆå§‹è¿›å±•ï¼Œå¹¶æŒ‡å‡ºè¿™ä¸€é¢†åŸŸå€¼å¾—è¿›ä¸€æ­¥ç ”ç©¶çš„é‡è¦æ–¹å‘ã€‚å°½ç®¡ç»¼è¿°äº†å¤§é‡çš„æ–‡çŒ®å¹¶æŒ‡å‡ºäº†æœªæ¥ç ”ç©¶æ–¹å‘ï¼Œä½†å®é™…çš„éƒ¨ç½²ç¤ºä¾‹å’Œå®šé‡è¯„ä¼°æ˜¯æœ‰é™çš„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10419v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10419.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent**<br><sub>æœºæ„: Google<br>æœ¬è®ºæ–‡é€šè¿‡å®šä¹‰ä¸€ä¸ªèƒ½å¤Ÿè¿›è¡Œæ¨ç†å’Œå¤–éƒ¨çŸ¥è¯†äº’åŠ¨çš„LLMä»£ç†ï¼Œå¹¶é‡‡ç”¨è‡ªæˆ‘æ”¹è¿›ç®—æ³•ï¼Œå®ç°äº†åœ¨åˆæˆé—®ç­”åŸºå‡†æµ‹è¯•ä¸­å°å‹æ¨¡å‹ä¸å¤§å‹æ¨¡å‹ç›¸åª²ç¾çš„è¡¨ç°ã€‚æå‡ºçš„æ–¹æ³•ä¸ä»…æé«˜äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä¹Ÿå¤§å¤§å‡å°äº†æ¨¡å‹æ‰€éœ€çš„å‚æ•°æ•°é‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10003v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10003.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **The Art of Balancing: Revolutionizing Mixture of Experts for Maintaining World Knowledge in Language Model Alignment**<br><sub>æœºæ„: NLP Group Fudan University, Hikvision Inc  <br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºLoRAMoEçš„æ¨¡å‹ï¼Œç”¨äºè§£å†³å¤§è§„æ¨¡å¾®è°ƒæ•°æ®å¯¼è‡´çš„è¯­è¨€æ¨¡å‹ä¸­çš„ä¸–ç•ŒçŸ¥è¯†é—å¿˜é—®é¢˜ï¼Œå¹¶åœ¨å¤šä»»åŠ¡å­¦ä¹ ä¸­è¡¨ç°å‡ºæ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09979v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09979.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **ProCoT: Stimulating Critical Thinking and Writing of Students through Engagement with Large Language Models (LLMs)**<br><sub>æœºæ„: LuleÃ¥ University of Technology Sweden<br>æœ¬æ–‡é€šè¿‡å¼•å…¥ProCoTæ–¹æ³•ï¼Œå±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨LLMä¿ƒè¿›å­¦ç”Ÿæ‰¹åˆ¤æ€§æ€ç»´ä¸å†™ä½œï¼ŒåŒæ—¶é˜²æ­¢ä½œå¼Šã€‚è¿™ç§æ–¹æ³•æœ‰åŠ©äºæ•™è‚²è€…æ›´å¥½åœ°åˆ©ç”¨è¿™äº›æŠ€æœ¯å·¥å…·ï¼Œå¹¶åŸ¹å…»å­¦ç”Ÿæˆä¸ºæ›´å¥½çš„æ‰¹åˆ¤æ€§æ€ç»´è€…ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09801v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09801.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **WEAK-TO-STRONG GENERALIZATION: ELICITING STRONG CAPABILITIES WITH WEAK SUPERVISION**<br><sub>æœºæ„: OpenAI<br></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](https://cdn.openai.com/papers/weak-to-strong-generalization.pdf)</div><div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/openai/weak-to-strong)</div><div style='min-width:85px;'>[![Blog](https://img.shields.io/badge/Blog-Posts-yellow?logo=rss)](https://mp.weixin.qq.com/s/f6YW-CxnLhnfMWTLg4M4Cw)</div> |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **Challenges with unsupervised LLM knowledge discovery**<br><sub>æœºæ„: Google DeepMind, Google Research<br>æœ¬æ–‡é€šè¿‡ç†è®ºè¯æ˜å’Œå®éªŒéªŒè¯ï¼ŒæŒ‘æˆ˜äº†ç°æœ‰æ— ç›‘ç£æ–¹æ³•åœ¨æ¢ç´¢LLMsä¸­éšæ€§çŸ¥è¯†çš„èƒ½åŠ›ï¼Œå¹¶æå‡ºäº†æœªæ¥è¯„ä¼°çŸ¥è¯†å¯å‘æ–¹æ³•æ—¶åº”è€ƒè™‘çš„ç†æ™ºæ£€æŸ¥ã€‚æ€»ä½“ä¸Šï¼Œä½œè€…è®¤ä¸ºæœªæ¥çš„æ— ç›‘ç£æ–¹æ³•å¾ˆå¯èƒ½ä¼šé‡åˆ°ç±»ä¼¼çš„é—®é¢˜ï¼Œå³éš¾ä»¥å‡†ç¡®åŒºåˆ†æ¨¡å‹çŸ¥è¯†å’Œå…¶ä»–ç‰¹å¾ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10029v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10029.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **Generative Context-aware Fine-tuning of Self-supervised Speech Models**<br><sub>æœºæ„: ASAPP, Carnegie Mellon University, Toyota Technological Institute at Chicago<br>è®ºæ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„è‡ªç›‘ç£è¯­éŸ³æ¨¡å‹å¾®è°ƒæ–¹æ³•ï¼Œå®ƒä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ä¿¡æ¯ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œä»¥æé«˜ä»»åŠ¡æ‰§è¡Œçš„è¡¨ç°åŠ›ï¼ŒåŒæ—¶åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„æƒ…å†µä¸‹å‡å°‘å¯¹é¢å¤–å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¾èµ–å’Œå‡å°‘æ¨ç†æ—¶çš„èµ„æºæ¶ˆè€—ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09895v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09895.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **Faithful Persona-based Conversational Dataset Generation with Large Language Models**<br><sub>æœºæ„: University of Southern California, Google, Information Sciences Institute<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºLLMsçš„æ¡†æ¶ï¼Œç”¨äºç”Ÿæˆã€æ‰©å±•å’Œæ›´æ–°å¤§å‹çš„ä¸ªæ€§åŒ–å¯¹è¯æ•°æ®é›†ï¼Œå¹¶ä¸”é€šè¿‡Generator-Criticæ¶æ„å’Œä¿¡å®æ€§æ ‡å‡†æ¥æé«˜å¯¹è¯çš„è´¨é‡ï¼Œæœ‰æ•ˆåœ°å»ºç«‹äº†Synthetic-Persona-Chatæ•°æ®é›†ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10007v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10007.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **No-Skim: Towards Efficiency Robustness Evaluation on Skimming-based Language Models**<br><sub>æœºæ„: Fudan University<br>æœ¬è®ºæ–‡é¦–æ¬¡ç³»ç»Ÿåœ°ç ”ç©¶äº†ä»æ•ˆç‡è§’åº¦å‡ºå‘ï¼ŒåŸºäº"é”™è¿‡"çš„è¯­è¨€æ¨¡å‹çš„è„†å¼±æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæœ‰æ•ˆå’Œé€šç”¨çš„æ•ˆç‡é²æ£’æ€§è¯„ä¼°æ¡†æ¶No-Skimï¼Œä»¥ç”Ÿæˆå¢åŠ è®¡ç®—å¤æ‚åº¦çš„å¯¹æŠ—æ€§è¾“å…¥ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶è¿˜é€šè¿‡ä¸åŒçš„æ’ä»¶æ¨¡å—è¿›è¡Œäº†æ¨¡å—åŒ–è®¾è®¡ï¼Œè¿™äº›æ¨¡å—åœ¨ä¸åŒçš„å®é™…æƒ…æ™¯ä¸‹å·¥ä½œï¼Œè¯„ä¼°å¯ä»¥åœ¨ä¸‰ç§ä¸åŒçš„çŸ¥è¯†æ°´å¹³ä¸‹è¿›è¡Œã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09494v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09494.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **GSVA: Generalized Segmentation via Multimodal Large Language Models**<br><sub>æœºæ„: Tsinghua University<br>è®ºæ–‡æå‡ºçš„GSVAæ–¹æ³•é€šè¿‡å­¦ä¹ é¢„æµ‹å¤šä¸ª[SEG]æ ‡è®°å’Œåˆ›æ–°æ€§åœ°ç”Ÿæˆ[REJ]æ ‡è®°ä»¥è§£å†³GRESä»»åŠ¡ä¸­å­˜åœ¨çš„å¤šç›®æ ‡å’Œç©ºç›®æ ‡æŒ‘æˆ˜ï¼Œç›¸è¾ƒäºç°æœ‰æŠ€æœ¯ï¼Œå±•ç°äº†æ˜¾è‘—ä¼˜åŠ¿ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.10103v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.10103.md)  |
| <span style='display: inline-block; width: 42px;'>12-15</span> | **KGLens: A Parameterized Knowledge Graph Solution to Assess What an LLM Does and Doesn't Know**<br><sub>æœºæ„: Apple<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åä¸ºKGLensçš„æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°LLMä¸­çš„äº‹å®çŸ¥è¯†ã€‚KGLensåˆ©ç”¨KGç»“æ„ç”Ÿæˆè‡ªç„¶è¯­è¨€é—®é¢˜å¹¶è¿›è¡Œè¯„ä¼°ï¼ŒODè¾…ä»¥å‚æ•°åŒ–çš„KGå’Œå›¾æŒ‡å¯¼çš„QGç­–ç•¥ä»¥æé«˜è‡ªç„¶é—®é¢˜çš„ç”Ÿæˆè´¨é‡å’Œè¯„ä¼°è¿‡ç¨‹çš„æ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11539v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11539.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Zebra: Extending Context Window with Layerwise Grouped Local-Global Attention**<br><sub>æœºæ„: Tencent AI Lab Seattle<br>æœ¬æ–‡æå‡ºçš„Zebraæ¨¡å‹é€šè¿‡ä½¿ç”¨åˆ†ç»„çš„å±€éƒ¨-å…¨å±€æ³¨æ„åŠ›å±‚ï¼Œæœ‰æ•ˆåœ°é™ä½äº†è®¡ç®—å’Œå†…å­˜éœ€æ±‚ï¼Œå¹¶åœ¨é•¿çŸ­åºåˆ—å¤„ç†ä¸Šå±•ç¤ºäº†å“è¶Šçš„æ€§èƒ½ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡ä¸€ç³»åˆ—å®éªŒéªŒè¯äº†æ¨¡å‹çš„æ•ˆæœï¼Œè¯æ˜äº†Zebraæ¶æ„çš„ä¼˜åŠ¿ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08618v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08618.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Auto MC-Reward: Automated Dense Reward Design with Large Language Models for Minecraft**<br><sub>æœºæ„: CUHK-SenseTime Joint Laboratory, Shanghai AI Laboratory, Tsinghua University<br>Auto MC-Rewardæ˜¯ä¸€ç§å…ˆè¿›çš„å­¦ä¹ ç³»ç»Ÿï¼Œåˆ©ç”¨LLMsä»¥è‡ªåŠ¨æ–¹å¼è®¾è®¡é’ˆå¯¹Minecraftä»»åŠ¡çš„å¯†é›†å‹å¥–åŠ±ï¼Œé€šè¿‡LLMsçš„ç†è§£å’Œç»éªŒæ€»ç»“èƒ½åŠ›ï¼Œæœ‰æ•ˆåœ°æé«˜äº†ä»£ç†åœ¨å¤æ‚ç¯å¢ƒä¸­å­¦ä¹ æ–°è¡Œä¸ºå’Œå®Œæˆé•¿æœŸä»»åŠ¡çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09238v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09238.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Towards Verifiable Text Generation with Evolving Memory and Self-Reflection**<br><sub>æœºæ„: Peking University, Chinese Academy of Sciences, Baidu Inc<br>VTGé€šè¿‡æ¼”åŒ–çš„é•¿çŸ­æœŸè®°å¿†å’Œè‡ªæˆ‘åæ€çš„æ–¹æ³•æ¥æå‡LLMsç”Ÿæˆæ–‡æœ¬æ—¶çš„å¯é æ€§å’ŒéªŒè¯æ€§ï¼Œå¯¹å¤æ‚çš„æ³¨æ„åŠ›è½¬ç§»é—®é¢˜å’Œæ–‡æ¡£æ£€ç´¢çš„æŒ‘æˆ˜æœ‰ç€æœ‰æ•ˆçš„åº”å¯¹ç­–ç•¥ï¼Œå¹¶ä¸”é€šè¿‡å®éªŒè·å¾—äº†éªŒè¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09075v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09075.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning**<br><sub>æœºæ„: National University of Singapore, University of Illinois Urbana-Champaign, Microsoft  <br>æœ¬æ–‡ä¸­æå‡ºçš„TAP4LLMæ¡†æ¶é€šè¿‡é‡‡æ ·ã€å¢å¼ºå’Œæ‰“åŒ…åŠç»“æ„åŒ–æ•°æ®ï¼Œæ˜¾è‘—æå‡äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¡¨æ ¼æ¨ç†ä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œå¹¶ä¸”å¯ä»¥ä½œä¸ºæ’ä»¶æä¾›ç»™ä¸åŒç»„ä»¶ï¼Œç”¨äºå¢å¼ºLLMså¯¹äºç»“æ„åŒ–æ•°æ®çš„ç†è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09039v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09039.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Entity-Augmented Code Generation**<br><sub>æœºæ„: JetBrains<br>è®ºæ–‡ä¸ºè§£å†³åˆ©ç”¨å¤–éƒ¨å®ä½“è¿›è¡Œä»£ç ç”Ÿæˆçš„ä»»åŠ¡æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„æ¶æ„ã€‚è¯¥æ¶æ„èƒ½åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹æ‰©å±•ï¼Œé€šè¿‡å°†å®ä½“æ£€ç´¢å™¨æ³¨å…¥åˆ°è§£ç å™¨è€Œéç¼–ç å™¨ä¸­ï¼Œæ¨¡å‹å¯ä»¥ä¸€æ¬¡æ€§æŸ¥çœ‹æ‰€æœ‰å®ä½“å¹¶ç›´æ¥ä½¿ç”¨å®ƒä»¬ã€‚æ–°æ¶æ„ä¸ä»…è§£å†³äº†ç°æœ‰æ¨¡å‹çš„é™åˆ¶ï¼Œè¿˜åœ¨å¤šä¸ªå®éªŒåœºæ™¯ä¸­å±•ç¤ºäº†å…¶ä¼˜è¶Šæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08976v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08976.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Math-Shepherd: A Label-Free Step-by-Step Verifier for LLMs in Mathematical Reasoning**<br><sub>æœºæ„: Peking University, DeepSeek-AI, The University of Hong Kong<br>MATH-SHEPHERDé€šè¿‡è‡ªåŠ¨ç”Ÿæˆç›‘ç£æ•°æ®è®­ç»ƒLLMsï¼Œæ¥è§£å†³é«˜æˆæœ¬äººåŠ›æ ‡æ³¨çš„é—®é¢˜ï¼Œå¹¶æé«˜äº†LLMsåœ¨å¤æ‚æ•°å­¦é—®é¢˜ä¸Šçš„å‡†ç¡®æ€§ã€‚è¿™ä¸€æˆæœä¸ºLLMsçš„è¿›æ­¥å’Œå®é™…åº”ç”¨å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08935v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08935.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Modeling Complex Mathematical Reasoning via Large Language Model based MathAgent**<br><sub>æœºæ„: Shanghai Jiao Tong University<br>è®ºæ–‡å»ºè®®é€šè¿‡MathAgentæ¡†æ¶ï¼Œå³Planner-Reasoner-Executor-Reflector (PRER)ï¼Œæå‡LLMsè§£å†³å¤æ‚æ•°å­¦é—®é¢˜çš„èƒ½åŠ›ã€‚é€šè¿‡å°†é—®é¢˜åˆ†è§£ä¸ºå¤šä¸ªé˜¶æ®µå¹¶æ¨¡æ‹Ÿäººç±»è§£é¢˜è¿‡ç¨‹ï¼ŒMathAgentèƒ½æ˜¾è‘—æé«˜å¯¹æŒ‘æˆ˜æ€§æ•°å­¦æ•°æ®é›†çš„è§£å†³èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨ä¼°ç®—å’Œç»¼åˆèƒ½åŠ›è¦æ±‚è¾ƒé«˜çš„é¢†åŸŸã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08926v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08926.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Boosting LLM Reasoning: Push the Limits of Few-shot Learning with Reinforced In-Context Pruning**<br><sub>æœºæ„: Hong Kong University of Science and Technology, Microsoft Research<br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†CoT-Maxï¼Œä¸€ä¸ªé€šè¿‡ç²—åˆ°ç»†çš„å‰ªææŠ€æœ¯æ¥å¢å¼ºLLMsæ•°å­¦æ¨ç†èƒ½åŠ›çš„æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°æé«˜äº†å°‘æ ·æœ¬å­¦ä¹ åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­çš„æ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08901v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08901.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Forbidden Facts: An Investigation of Competing Objectives in Llama-2**<br><sub>æœºæ„: MIT<br>è¿™ç¯‡è®ºæ–‡é€šè¿‡ç ”ç©¶æ¨¡å‹åœ¨ç¦æ­¢äº‹å®ä»»åŠ¡ä¸‹çš„è¡Œä¸ºï¼Œè§£æäº†Llama-2-chatæ¨¡å‹å¦‚ä½•å¤„ç†ç›¸äº’ç«äº‰çš„ç›®æ ‡ï¼Œå¹¶å¯¹å®ƒçš„åˆ†ææå‡ºäº†æ–°çš„æ‰‹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08793v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08793.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **The Earth is Flat because...: Investigating LLMs' Belief towards Misinformation via Persuasive Conversation**<br><sub>æœºæ„: Tsinghua University, Stanford University, Nanyang Technological University<br>æœ¬è®ºæ–‡ä¸ºé¦–æ¬¡å…¨é¢ç ”ç©¶LLMsé¢å¯¹äº‹å®é”™è¯¯ä¿¡æ¯åœ¨åŠè¯´æ€§å¯¹è¯è®¾ç½®ä¸­çš„é²æ£’æ€§ï¼Œå¹¶æ­ç¤ºäº†LLMså¯¹åŠè¯´æ€§é”™è¯¯ä¿¡æ¯çš„æ˜“æ„Ÿæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09085v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09085.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **StemGen: A music generation model that listens**<br><sub>æœºæ„: SAMI, ByteDance Inc.<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„éè‡ªå›å½’çš„è¯­è¨€æ¨¡å‹æ–¹æ³•ç”¨äºéŸ³ä¹ç”Ÿæˆï¼Œä¼˜åŒ–äº†å¤šå£°é“çš„å¤„ç†å’ŒéŸ³ä¹ä¸ä¸Šä¸‹æ–‡ä¿¡æ¯çš„ä¸€è‡´æ€§ï¼Œå¹¶é€šè¿‡å®¢è§‚å’Œä¸»è§‚è¯„ä¼°è¯æ˜äº†æ¨¡å‹ç”Ÿæˆçš„éŸ³ä¹è´¨é‡å’Œä¸ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å¥‘åˆç¨‹åº¦ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08723v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08723.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **CogAgent: A Visual Language Model for GUI Agents**<br><sub>æœºæ„: Tsinghua University, Zhipu AI<br>CogAgent æ‰“ç ´äº†çº¯æ–‡æœ¬è¾“å…¥æ–¹å¼çš„å±€é™æ€§ï¼Œé€šè¿‡ç»“åˆé«˜ä½åˆ†è¾¨ç‡çš„å½±åƒç¼–ç å™¨å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œé«˜æ•ˆåœ°è§£å†³äº†åœ¨å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä¸­ç†è§£å’Œå¯¼èˆªçš„æŒ‘æˆ˜ï¼ŒåŒæ—¶åœ¨ä¹ä¸ªè§†è§‰é—®ç­”åŸºå‡†æµ‹è¯•ä¸­å–å¾—å›½é™…é¢†å…ˆæ°´å¹³ï¼Œæ¨åŠ¨äº†VLMåœ¨AIä»£ç†ç ”ç©¶å’Œåº”ç”¨æ–¹é¢çš„æœªæ¥å‘å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08914v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08914.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/THUDM/CogVLM)</div> |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **TinyGSM: achieving >80% on GSM8k with small language models**<br><sub>æœºæ„: Carnegie Mellon University, Microsoft Research  <br>è¿™ç¯‡è®ºæ–‡é€šè¿‡åˆ›å»ºä¸€ä¸ªåˆæˆçš„æ•°å­¦é—®é¢˜æ•°æ®é›†TinyGSMåŠå…¶å¯¹åº”çš„Pythonè§£å†³æ–¹æ¡ˆï¼ŒæˆåŠŸä½¿å°å‹è¯­è¨€æ¨¡å‹åœ¨GSM8Kæ•°å­¦é—®é¢˜æ¨ç†åŸºå‡†æµ‹è¯•ä¸Šçš„å‡†ç¡®ç‡è¶…è¿‡äº†80%ï¼Œå±•ç¤ºäº†é€šè¿‡é«˜è´¨é‡æ•°æ®é›†å’ŒéªŒè¯å™¨ç­–ç•¥æ˜¾è‘—æé«˜äº†å°å‹æ¨¡å‹æ€§èƒ½çš„å¯è¡Œæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09241v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09241.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Weight subcloning: direct initialization of transformers using larger pretrained ones**<br><sub>æœºæ„: Apple<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„æƒé‡å­å…‹éš†ï¼ˆweight subcloningï¼‰æŠ€æœ¯ï¼Œç”¨ä»¥ä»è¾ƒå¤§çš„é¢„è®­ç»ƒæ¨¡å‹åˆå§‹åŒ–è¾ƒå°çš„å˜æ¢å™¨æ¨¡å‹ï¼Œæ˜¾è‘—æé«˜äº†è®­ç»ƒé€Ÿåº¦ï¼Œå¹¶ä½¿å¾—å…¨æ–°çš„æ¨¡å‹å³ä½¿åœ¨ä½è®¡ç®—èµ„æºæ¡ä»¶ä¸‹ä¹Ÿèƒ½å¾—åˆ°é«˜æ•ˆè®­ç»ƒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09299v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.09299.md)  |
| <span style='display: inline-block; width: 42px;'>12-14</span> | **Self-Evaluation Improves Selective Generation in Large Language Models**<br><sub>æœºæ„: Google DeepMind, Google Research<br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œé€šè¿‡æŒ‡å¯¼LLMè¿›è¡Œè‡ªæˆ‘è¯„ä¼°ï¼Œä»¥æé«˜å…¶åœ¨é€‰æ‹©æ€§ç”Ÿæˆåœºæ™¯ä¸­è¾“å‡ºå†…å®¹è´¨é‡çš„æ ¡å‡†ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥æé«˜LLMç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§å’Œæ•´ä½“è´¨é‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.09300v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.093.md)  |
| <span style='display: inline-block; width: 42px;'>12-13</span> | **LDM$^2$: A Large Decision Model Imitating Human Cognition with Dynamic Memory Enhancement**<br><sub>æœºæ„: University of Chinese Academy of Sciences<br>è¯¥è®ºæ–‡æå‡ºäº†LDM2æ¨¡å‹ï¼Œå®ƒä½¿ç”¨åŠ¨æ€å†…å­˜æœºåˆ¶å’Œæ ‘æ¢ç´¢ç­–ç•¥æ¥å¢å¼ºLLMsçš„å†³ç­–èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿé€‚åº”æ›´å¤æ‚å’ŒæœªçŸ¥çš„ç¯å¢ƒï¼Œå¹¶å®ç°åŠ¨æ€å­¦ä¹ èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08402v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08402.md)  |
| <span style='display: inline-block; width: 42px;'>12-13</span> | **SwitchHead: Accelerating Transformers with Mixture-of-Experts Attention**<br><sub>æœºæ„: The Swiss AI Lab IDSIA USI & SUPSI, AI Initiative KAUST, Center for Brain Science Harvard University<br>SwitchHeadæ˜¯ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œå®ƒé€šè¿‡ä¼˜åŒ–å¤šå¤´è‡ªæ³¨æ„åŠ›ç»“æ„ä¸­çš„èµ„æºä½¿ç”¨ï¼Œå®ç°äº†èµ„æºæ¶ˆè€—çš„é™ä½åŒæ—¶ä¿æŒäº†æ¨¡å‹æ€§èƒ½ã€‚è¯¥æ–¹æ³•å…·æœ‰å®é™…åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶å¯¹äºèµ„æºæœ‰é™çš„ç ”ç©¶äººå‘˜å’Œæœºæ„è€Œè¨€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07987v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07987.md)  |
| <span style='display: inline-block; width: 42px;'>12-13</span> | **E&V: Prompting Large Language Models to Perform Static Analysis by Pseudo-code Execution and Verification**<br><sub>æœºæ„: UC Riverside, Microsoft Research<br>æœ¬è®ºæ–‡é€šè¿‡æå‡ºE&Væ–¹æ³•ï¼Œå±•ç¤ºäº†LLMsåœ¨æ‰§è¡Œä¼ªä»£ç é™æ€åˆ†æå’Œè‡ªæˆ‘éªŒè¯ä¸­çš„æ½œåŠ›ã€‚è¯¥æ–¹æ³•ä¸ä»…æé«˜äº†é™æ€åˆ†æçš„çµæ´»æ€§å’Œç²¾å‡†åº¦ï¼Œè¿˜å‡å°‘äº†ç¼–å†™é™æ€åˆ†æå·¥å…·éœ€è¦çš„äººåŠ›å’Œä¸“ä¸šçŸ¥è¯†ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08477v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08477.md)  |
| <span style='display: inline-block; width: 42px;'>12-13</span> | **Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models**<br><sub>æœºæ„: University of Southern California, Amazon.com Inc.<br>æ–‡ç« é’ˆå¯¹ç°æœ‰çš„ç½‘ç»œæœ‰å®³å†…å®¹è‡ªåŠ¨æ¢æµ‹é¢ä¸´çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªç§°ä¸ºBD-LLMçš„æ–°æ–¹æ³•ï¼Œå®ƒé€šè¿‡ä¸€ä¸ªæ–°çš„æ–¹æ³•DToTæ¥æå‡LLMsåœ¨æœ‰å®³å†…å®¹æ£€æµ‹ä»»åŠ¡ä¸­çš„æ•ˆèƒ½å’Œè½¬ç§»æ€§ï¼Œå¹¶å°†ä¼˜åŒ–æ¨¡å‹å‹ç¼©ä»¥ä¾¿æ›´æœ‰æ•ˆåœ°éƒ¨ç½²ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08303v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08303.md)  |
| <span style='display: inline-block; width: 42px;'>12-13</span> | **Knowledge-Aware Artifact Image Synthesis with LLM-Enhanced Prompting and Multi-Source Supervision**<br><sub>æœºæ„: Peking University<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»“åˆLLMså¢å¼ºæç¤ºå’Œå¤šæºç›‘ç£çš„çŸ¥è¯†æ„ŸçŸ¥å¤ä»£æ–‡ç‰©å›¾åƒåˆæˆæ–¹æ³•ï¼Œè§£å†³äº†ç°æœ‰æ–‡æœ¬åˆ°å›¾åƒåˆæˆæ–¹æ³•åœ¨è€ƒå¤é¢†åŸŸåº”ç”¨æ—¶ç¼ºä¹é¢†åŸŸçŸ¥è¯†çš„é—®é¢˜ï¼Œå¹¶åœ¨è´¨é‡å’Œå†å²çŸ¥è¯†å¯¹é½æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›æ­¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.08056v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.08056.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/danielwusg/artifact_diffusion)</div> |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **Tell, don't show: Declarative facts influence how LLMs generalize**<br><sub>æœºæ„: Apollo Research, University of Oxford<br>æœ¬æ–‡ç ”ç©¶äº†åŸ¹è®­æ•°æ®ä¸­å£°æ˜æ€§é™ˆè¿°ä¸ç»Ÿè®¡æ¨¡å¼æˆ–â€œç¨‹åºâ€ç¤ºä¾‹ç›¸å†²çªæ—¶æ¨¡å‹çš„æ³›åŒ–æƒ…å†µã€‚æ‰€å¾—ç»“æœå¯¹äºAIé£é™©ï¼ˆå…³äºâ€œèƒŒå›è½¬æŠ˜â€ï¼‰å’Œå…¬å¹³æ€§æœ‰é‡è¦å½±å“ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07779v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07779.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **Efficient Few-Shot Clinical Task Adaptation with Large Language Models**<br><sub>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåœ¨å°‘æ ·æœ¬çš„åŒ»å­¦å›¾åƒåˆ†ç±»ä¸­é€šè¿‡å†·å†»ä¸€éƒ¨åˆ†ç½‘ç»œå±‚è¿›è¡Œé«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•ï¼Œå¹¶ä¸”å¼•å…¥äº†å¤§å‹è¯­è¨€æ¨¡å‹æ¥ä¸Šä¸‹æ–‡åŒ–æ ‡ç­¾ï¼Œä»¥æä¾›æœ‰æ•ˆçš„è¯­ä¹‰æŒ‡å¯¼ã€‚æ–¹æ³•åœ¨æŒ‘æˆ˜èµ›ä¸­å–å¾—äº†ä¼˜å¼‚çš„æˆç»©ï¼Œè¡¨æ˜åœ¨å¤„ç†å°‘æ ·æœ¬åœºæ™¯ä¸‹è‡ªç„¶å›¾åƒæ¨¡å‹åˆ°åŒ»å­¦å›¾åƒä»»åŠ¡çš„é€‚é…é—®é¢˜æ—¶å…·æœ‰å¾ˆé«˜çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07125v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07125.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **diff History for Long-Context Language Agents**<br><sub>æœºæ„: New York University<br>è®ºæ–‡æå‡ºå¹¶éªŒè¯äº†ä½¿ç”¨diffå†å²æ¥æé«˜å¯¹é•¿äº¤äº’å†å²çš„æ¨¡å‹å¤„ç†èƒ½åŠ›ã€‚è¿™ä¸€æ–¹æ³•æ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¤æ‚å†³ç­–ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¹¶èƒ½æœ‰æ•ˆæ‰©å¤§æ¨¡å‹å¯å¤„ç†çš„å†å²é•¿åº¦ï¼Œä¸ºé•¿æ—¶é—´åºåˆ—å†³ç­–ä»£ç†çš„è®¾è®¡æä¾›äº†æ–°æ€è·¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07540v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0754.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **Comparable Demonstrations are Important in In-Context Learning: A Novel Perspective on Demonstration Selection**<br><sub>æœºæ„: Shanghai Jiao Tong University<br>æœ¬æ–‡ä»ç¤ºä¾‹é—´å…³ç³»çš„è§’åº¦ç ”ç©¶ICLï¼Œæå‡ºé€šè¿‡æœ€å°åŒ–ç¼–è¾‘æ–‡æœ¬ä»¥æ„é€ Comparable Demonstrationsï¼ˆCDsï¼‰æ¥å‡è½»æ½œåœ¨çš„ç¤ºä¾‹åå€šï¼Œå®éªŒè¯æ˜äº†å…¶åœ¨OODæƒ…å½¢ä¸‹çš„æ€§èƒ½å¢ç›Šï¼Œè¡¨æ˜äº†CDsåœ¨ç®€åŒ–ä»»åŠ¡ä¸­å°¤å…¶å¿…è¦ï¼Œå¹¶å±•ç¤ºäº†å…¶ç›¸å¯¹äºç¤ºä¾‹æ•°çš„ç¨³å¥æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07476v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07476.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **LLMEval: A Preliminary Study on How to Evaluate Large Language Models**<br><sub>æœºæ„: Fudan University, Shanghai Jiaotong University  <br>è®ºæ–‡é’ˆå¯¹å¦‚ä½•è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œå¯¹å¤šç§è¯„ä¼°æ ‡å‡†ã€ä¸åŒç±»å‹çš„è¯„ä¼°è€…ã€è¯„åˆ†æ–¹æ³•å’Œæ’åç³»ç»Ÿè¿›è¡Œäº†æ¯”è¾ƒå’Œåˆ†æï¼Œæå‡ºäº†æ–°çš„è¯„ä¼°æ•°æ®é›†LLMEvalï¼Œå¯¹20ä¸ªLLMsè¿›è¡Œäº†è¯„ä¼°ï¼Œç”Ÿæˆäº†å¤§é‡çš„æ‰‹åŠ¨å’Œè‡ªåŠ¨è¯„ä¼°ç»“æœã€‚è¯¥ç ”ç©¶ä¸ºæœªæ¥çš„LLMè¯„ä¼°æä¾›äº†æœ‰ç›Šçš„æ´è§å’Œç»“è®ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07398v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07398.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **LLM in a flash: Efficient Large Language Model Inference with Limited Memory**<br><sub>æœºæ„: Apple<br>è¿™ä»½ç ”ç©¶æä¾›äº†ä¸€ä¸ªåˆ›æ–°ä¸”å®ç”¨çš„è§£å†³æ–¹æ¡ˆï¼Œä¸ä»…èƒ½æœ‰æ•ˆé™ä½åœ¨å†…å­˜å—é™è®¾å¤‡ä¸Šè¿è¡Œå¤§å‹è¯­è¨€æ¨¡å‹æ—¶çš„æ•°æ®è´Ÿè½½ï¼Œè¿˜èƒ½æ˜¾è‘—æå‡æ¨ç†é€Ÿåº¦ï¼Œåœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰é‡è¦æ„ä¹‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.11514v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.11514.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **VILA: On Pre-training for Visual Language Models**<br><sub>æœºæ„: NVIDIA, MIT  <br>VILAåˆ©ç”¨æ”¹è¿›çš„é¢„è®­ç»ƒç­–ç•¥ï¼Œåœ¨å¤šç§è§†è§‰è¯­è¨€ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºå“è¶Šçš„æ€§èƒ½ï¼Œä¸ºæœªæ¥è§†è§‰è¯­è¨€æ¨¡å‹çš„è®¾è®¡æä¾›äº†å®ç”¨æŒ‡å—ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07533v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07533.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **Alignment for Honesty**<br><sub>æœºæ„: Shanghai Jiao Tong University, Shanghai Artificial Intelligence Laboratory, Fudan University<br>è®ºæ–‡æå‡ºäº†ä¸äººç±»çš„è¯šå®æ€§å¯¹é½çš„æ¦‚å¿µï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šæå‡ºäº†æŒ‘æˆ˜å’Œè§£å†³æ–¹æ³•ã€‚é€šè¿‡æ­£å¼å®šä¹‰é—®é¢˜ã€æå‡ºæ–°æ–¹æ³•å’Œå»ºç«‹è¯„ä¼°æ¡†æ¶ï¼Œè®ºæ–‡ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è¯šå®æ€§å¯¹é½æä¾›äº†å…¨é¢çš„è§£å†³æ–¹æ¡ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07000v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/GAIR-NLP/alignment-for-honesty)</div> |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Oracle-based Protocol Testing with Eywa**<br><sub>æœºæ„: Microsoft Research<br>æœ¬æ–‡ä»‹ç»äº†åŸºäºç¥è°•çš„æµ‹è¯•æ–¹æ³•ï¼Œå……åˆ†åˆ©ç”¨LLMså»ºç«‹äº†ä¸°å¯Œçš„åè®®è¡Œä¸ºæ¨¡å‹ï¼Œå¹¶é€šè¿‡ç¬¦å·æ‰§è¡Œå’Œä¼ ç»Ÿæµ‹è¯•ç”Ÿæˆæ–¹æ³•ç›¸ç»“åˆï¼Œæå‡äº†ç½‘ç»œåè®®æµ‹è¯•ç”¨ä¾‹çš„è‡ªåŠ¨ç”Ÿæˆå’Œè¦†ç›–é¢ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06875v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06875.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **MMICT: Boosting Multi-Modal Fine-Tuning with In-Context Examples**<br><sub>æœºæ„: Xiamen University, Tencent YouTu Lab<br>è¿™é¡¹å·¥ä½œé€šè¿‡æå‡ºMMICTï¼Œå±•ç¤ºäº†åœ¨å¤§å‹å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ä¸Šè¿ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ä»¥å¢å¼ºå¾®è°ƒæ€§èƒ½çš„æ–°èŒƒå¼ã€‚é€šè¿‡è®¾è®¡M-Hubè¿™ä¸€å¤šåŠŸèƒ½æ¨¡å—å¹¶é€šè¿‡å„ç§ä¸Šä¸‹æ–‡ç¤ºèŒƒå®éªŒï¼Œç ”ç©¶æ­ç¤ºäº†ä¸Šä¸‹æ–‡å­¦ä¹ åœ¨æ”¹å–„å¤šæ¨¡æ€ä»»åŠ¡æ€§èƒ½ä¸­çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06363v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06363.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Honeybee: Locality-enhanced Projector for Multimodal LLM**<br><sub>æœºæ„: Kakao Brain<br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„å±€éƒ¨æ€§å¢å¼ºæŠ•å½±å™¨è®¾è®¡ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è§†è§‰ç‰¹å¾å±€éƒ¨æ€§ä¸Šçš„ä¸è¶³ï¼Œå¹¶æœ‰æ•ˆåˆ©ç”¨äº†å¤šé¢å‘æŒ‡ä»¤æ•°æ®é›†ï¼Œæœ€ç»ˆä½¿å¾—Honeybeeæ¨¡å‹åœ¨å¤šä¸ªMLLMåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06742v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06742.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/kakaobrain/honeybee)</div> |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Extracting Self-Consistent Causal Insights from Users Feedback with LLMs and In-context Learning**<br><sub>æœºæ„: Microsoft, Microsoft Research<br>è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°æ¡†æ¶ï¼Œä½¿ç”¨LLMså’ŒICLä»ç”¨æˆ·åé¦ˆä¸­æå–è‡ªæ´½çš„å› æœè§è§£ï¼Œä»¥æ”¯æŒå¾®è½¯Feedback Hubçš„åˆ†æã€‚è¯¥æ¡†æ¶é‡‡ç”¨åˆ›æ–°çš„è‡ªæ´½æ€§å’Œæç¤ºé›†åˆæŠ€æœ¯ä»¥æŠ‘åˆ¶LLMsçš„å¹»è§‰å’Œé”™è¯¯æ¨ç†ï¼Œå¹¶æå‡ºäº†ä¸¤ç§å¯å‘å¼æ–¹æ³•æ¥è¯„ä¼°åé¦ˆçš„ä¿¡æ¯ä¸°å¯Œåº¦ã€‚å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆåœ°æå–å› æœè§è§£å’Œæ–°çš„bugï¼Œå¹¶æœ‰åŠ©äºå¾®è½¯å·¥ç¨‹å¸ˆä¼˜å…ˆå¤„ç†ä¿¡æ¯é‡ä¸°å¯Œçš„åé¦ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06820v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0682.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **On Meta-Prompting**<br><sub>æœºæ„: Microsoft  <br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºèŒƒç•´è®ºçš„ç†è®ºæ¡†æ¶æ¥æ¦‚æ‹¬å’Œæç»˜è‡ªåŠ¨åŒ–æç¤ºæ–¹æ³•ï¼Œé€šè¿‡åœ¨æ„æƒ³åŠ›å’Œåˆ›é€ åŠ›è¿™ä¸¤ä¸ªé¢†åŸŸçš„å®éªŒï¼Œå±•ç¤ºäº†meta-promptingæ¯”ä¼ ç»Ÿå›ºå®šæç¤ºæ–¹æ³•æ›´èƒ½ç”Ÿæˆç”¨æˆ·åå¥½çš„è¾“å‡ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06562v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06562.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Unlocking Anticipatory Text Generation: A Constrained Approach for Faithful Decoding with Large Language Models**<br><sub>æœºæ„: Salesforce AI Research<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡è€ƒè™‘æœªæ¥çº¦æŸæ»¡è¶³æ¥æ”¹å–„å¤§å‹è¯­è¨€æ¨¡å‹è§£ç æ–¹æ³•çš„æ–°é€”å¾„ã€‚æå‡ºçš„æ­£å¼æ–¹æ³•å’Œè¯„åˆ†æœºåˆ¶é€šè¿‡ä¸LLMsçš„åŸºå‡†æµ‹è¯•ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æ–‡æœ¬ç”Ÿæˆçš„è´¨é‡å’Œæ§åˆ¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06149v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06149.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Dense X Retrieval: What Retrieval Granularity Should We Use?**<br><sub>æœºæ„: University of Washington, Tencent AI Lab<br>æœ¬æ–‡æå‡ºå‘½é¢˜ä½œä¸ºä¸€ç§æ–°å‹ç¨ å¯†æ£€ç´¢å•å…ƒï¼Œå…¶åœ¨å‡å°‘æ‰€æ£€ç´¢æ–‡æœ¬ä¸­æ— å…³ä¿¡æ¯çš„åŒæ—¶ï¼Œæé«˜äº†ä¸‹æ¸¸é—®ç­”ä»»åŠ¡çš„æ€§èƒ½å’Œè·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06648v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06648.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **"What's important here?": Opportunities and Challenges of Using LLMs in Retrieving Information from Web Interfaces**<br><sub>æœºæ„: Carnegie Mellon University<br>æœ¬æ–‡ç ”ç©¶äº†LLMsåœ¨ä»Webç•Œé¢æ£€ç´¢ä¿¡æ¯ä¸­çš„åº”ç”¨æ½œåŠ›å’Œé¢ä¸´çš„æŒ‘æˆ˜ã€‚é€šè¿‡ä¸€ç³»åˆ—å®éªŒï¼Œæ­ç¤ºäº†æ¨¡å‹æ€§èƒ½çš„å…³é”®å› ç´ åŠå…¶é™åˆ¶ï¼Œå¹¶ä¸ºæœªæ¥å·¥ä½œæŒ‡æ˜äº†æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06147v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06147.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Federated Full-Parameter Tuning of Billion-Sized Language Models with Communication Cost under 18 Kilobytes**<br><sub>æœºæ„: Zhejiang University, Alibaba Group<br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è”é‚¦å…¨å‚æ•°å¾®è°ƒæ–¹æ³•â€”â€”FedKSeedï¼Œé€šè¿‡ZOOä¸æœ‰é™ç»„ç§å­ç»“åˆï¼Œæ˜¾è‘—é™ä½äº†æ•°åäº¿å¤§å°LLMså…¨å‚æ•°å¾®è°ƒæ‰€éœ€çš„é€šä¿¡å¼€é”€ï¼ŒåŒæ—¶å®ç°äº†è¾ƒé«˜çš„æ¨¡å‹ç²¾ç¡®åº¦å’Œè®¡ç®—æ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06353v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06353.md)  |
| <span style='display: inline-block; width: 42px;'>12-10</span> | **Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs**<br><sub>æœºæ„: Microsoft Israel<br>è¿™é¡¹ç ”ç©¶çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºå®ƒå¯¹æ¯”äº†ç»†åŒ–è®­ç»ƒå’ŒRAGä¸¤ç§æ–¹æ³•å¯¹äºLLMsçŸ¥è¯†æ³¨å…¥èƒ½åŠ›çš„å½±å“ï¼Œå¹¶å‘ç°RAGåœ¨æ³¨å…¥æ–°çš„å’Œå·²æœ‰çš„çŸ¥è¯†æ–¹é¢è¡¨ç°æ›´ä½³ã€‚ç ”ç©¶ä½¿ç”¨äº†åˆ›æ–°çš„æ•°æ®é›†å’Œè¯„ä¼°æ–¹æ³•ï¼Œç¡®ä¿äº†ç†è®ºå‘ç°çš„å®ç”¨æ€§å’Œå¯è¡Œæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05934v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05934.md)  |
| <span style='display: inline-block; width: 42px;'>12-09</span> | **Can Large Language Models Serve as Rational Players in Game Theory? A Systematic Analysis**<br><sub>æœºæ„: Shanghai Jiao Tong University<br>æœ¬ç ”ç©¶ç³»ç»Ÿåœ°æ¢ç´¢äº†LLMsåœ¨æ¸¸æˆç†è®ºèƒŒæ™¯ä¸‹çš„èƒ½åŠ›è¾¹ç•Œï¼Œå¹¶ä»ä¸‰ä¸ªè§’åº¦å‡ºå‘ï¼Œæä¾›äº†å°†LLMsåœ¨ç¤¾ä¼šç§‘å­¦ç ”ç©¶ä¸­ä½¿ç”¨çš„è¿›ä¸€æ­¥æŒ‡å¯¼ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05488v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05488.md)  |
| <span style='display: inline-block; width: 42px;'>12-09</span> | **NLLG Quarterly arXiv Report 09/23: What are the most influential current AI Papers?**<br><sub>æœºæ„: University of Mannheim, University of Bielefeld<br>è¯¥è®ºæ–‡é€šè¿‡åˆ†æåœ¨ç‰¹å®šæ—¶é—´å†…arXivä¸Šå¼•ç”¨æœ€å¤šçš„è®ºæ–‡ï¼Œæä¾›äº†AIç ”ç©¶é¢†åŸŸçš„æœ€æ–°è¶‹åŠ¿å’Œå½±å“åŠ›åˆ†æï¼Œç‰¹åˆ«å¼ºè°ƒäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å…¶ä¸­çš„é‡è¦æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05688v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05688.md)  |
| <span style='display: inline-block; width: 42px;'>12-09</span> | **Sim-GPT: Text Similarity via GPT Annotated Data**<br><sub>æœºæ„: Shannon.AI, Zhejiang University, Bytedance<br>Sim-GPTæ˜¯ä¸€ä¸ªåˆ©ç”¨GPT-4ç”Ÿæˆæ•°æ®æ ‡ç­¾æ¥è®­ç»ƒSTSæ¨¡å‹çš„æ¡†æ¶ã€‚å®ƒåœ¨ç”Ÿæˆæ•°æ®æ—¶ä»…äº§ç”Ÿä¸€æ¬¡æ€§æˆæœ¬ï¼Œé€Ÿåº¦è¾ƒå¿«ï¼Œæ¨¡å‹åœ¨å¤šä¸ªSTSåŸºå‡†ä¸Šæ€§èƒ½ä¼˜è¶Šã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05603v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05603.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/ShuheWang1998/Sim-GPT)</div> |
| <span style='display: inline-block; width: 42px;'>12-09</span> | **Agile-Quant: Activation-Guided Quantization for Faster Inference of LLMs on the Edge**<br><sub>æœºæ„: Northeastern University, Oracle<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºAgile-Quantçš„æ¿€æ´»å¼•å¯¼é‡åŒ–æ¡†æ¶ï¼Œä»¥åŠ é€Ÿå¤§å‹è¯­è¨€æ¨¡å‹çš„è¾¹ç¼˜è®¾å¤‡æ¨ç†ã€‚Agile-Quantå…‹æœäº†æ¿€æ´»å€¼å¼‚å¸¸çš„æŒ‘æˆ˜å’Œè¾¹ç¼˜è®¾å¤‡ä¸Šçš„ç¡¬ä»¶å®æ–½é—®é¢˜ï¼Œå¹¶å®ç°äº†ä¸ä»…æƒé‡é‡åŒ–æ–¹æ³•ç›¸å½“çš„ä»»åŠ¡æ€§èƒ½ï¼ŒåŒæ—¶åœ¨å®é™…è®¾å¤‡ä¸Šè·å¾—äº†æ˜¾è‘—çš„æ¨ç†é€Ÿåº¦æå‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05693v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05693.md)  |
| <span style='display: inline-block; width: 42px;'>12-09</span> | **Context Tuning for Retrieval Augmented Generation**<br><sub>æœºæ„: Apple  <br>æœ¬è®ºæ–‡é€šè¿‡å¼•å…¥ä¸Šä¸‹æ–‡è°ƒä¼˜è¿™ä¸€æ–°é¢–ç»„ä»¶ï¼Œæé«˜äº†åŸºäºæ£€ç´¢çš„å¢å¼ºè®¡åˆ’ï¼ˆRAG-based planningï¼‰çš„æ•ˆæœï¼Œä½¿å…¶èƒ½å¤„ç†ä¸å®Œæ•´æˆ–ä¸æ˜ç¡®çš„æŸ¥è¯¢ï¼ŒåŒæ—¶è¿˜é™ä½äº†å¹»è§‰æ€§é”™è¯¯çš„äº§ç”Ÿã€‚ç ”ç©¶å¯¹æ¯”äº†ä¸åŒçš„æ£€ç´¢æ–¹æ³•åœ¨è½»é‡æ¨¡å‹å’ŒLLMsä¸­çš„åº”ç”¨ï¼Œå¹¶å±•ç¤ºäº†æ–°æ–¹æ³•åœ¨æé«˜ä¸Šä¸‹æ–‡ç†è§£ä¸Šçš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05708v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05708.md)  |
| <span style='display: inline-block; width: 42px;'>12-08</span> | **Using Program Knowledge Graph to Uncover Software Vulnerabilities**<br><sub>è®ºæ–‡é€šè¿‡ç»“åˆç¨‹åºå›¾å’Œå®‰å…¨æ•°æ®ï¼Œæå‡ºäº†ç¨‹åºçŸ¥è¯†å›¾è°±ï¼Œå¹¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„æç¤ºè°ƒæ•´æ¥è‡ªåŠ¨ç”Ÿæˆæ£€æµ‹è½¯ä»¶ä»£ç ä¸­æ¼æ´çš„æŸ¥è¯¢ã€‚è¯¥æ–¹æ³•æ—¨åœ¨å…‹æœä¼ ç»Ÿæ¼æ´æ£€æµ‹æ–¹æ³•çš„å±€é™æ€§ï¼Œæé«˜æ¼æ´æ£€æµ‹çš„è‡ªåŠ¨åŒ–ç¨‹åº¦å’Œæœ‰æ•ˆæ€§ï¼Œå°¤å…¶æ˜¯åœ¨é™æ€åˆ†æä¸­çš„åº”ç”¨ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04818v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04818.md)  |
| <span style='display: inline-block; width: 42px;'>12-08</span> | **PaperQA: Retrieval-Augmented Generative Agent for Scientific Research**<br><sub>æœºæ„: RAND Corporation, Carnegie Mellon University, LangChain<br>è¯¥è®ºæ–‡æå‡ºäº†PaperQAï¼Œä¸€ä¸ªåŸºäºæ£€ç´¢çš„ç”Ÿæˆå‹ä»£ç†ï¼Œç”¨äºç§‘å­¦ç ”ç©¶ã€‚PaperQAå¯ä»¥å‡†ç¡®å›ç­”åŸºäºæœ€æ–°ç§‘å­¦æ–‡çŒ®çš„é—®é¢˜ï¼Œå¹¶ä¸”ä¸äººç±»ä¸“å®¶çš„å›ç­”ç›¸å½“ï¼Œç”šè‡³åœ¨æŸäº›æ–¹é¢è¡¨ç°æ›´å¥½ã€‚è®ºæ–‡å±•ç¤ºäº†PaperQAçš„æœ‰æ•ˆæ€§ï¼Œå¹¶é€šè¿‡ä¸äººç±»ä¸“å®¶å’Œå…¶ä»–å•†ä¸šå·¥å…·çš„å¯¹æ¯”ï¼Œè¯æ˜äº†å…¶ä¼˜è¶Šæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07559v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07559.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Chain of Code: Reasoning with a Language Model-Augmented Code Emulator**<br><sub>æœºæ„: Google DeepMind, Stanford University, University of California Berkeley  <br>Chain of Code (CoC)ä¸ºè¯­è¨€æ¨¡å‹å¢åŠ äº†é€šè¿‡ç¼–å†™ä»£ç å’Œæ¨¡æ‹Ÿä»£ç æ‰§è¡Œæ¥æ”¹å–„æ¨ç†èƒ½åŠ›çš„æ–°ç»´åº¦ã€‚å®ƒåœ¨æ•°å­—å’Œè¯­ä¹‰æ¨ç†ä»»åŠ¡ä¸­å‡å®ç°äº†çªç ´æ€§çš„æ€§èƒ½ï¼Œå¯¹LLMsçš„åº”ç”¨èŒƒå›´è¿›è¡Œäº†æ‰©å±•ï¼Œå¹¶æœ‰æ½œåŠ›åº”ç”¨äºæ›´å¹¿æ³›çš„é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04474v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04474.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **An LLM Compiler for Parallel Function Calling**<br><sub>æœºæ„: UC Berkeley, ICSI, LBNL<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºLLMCompilerçš„ç³»ç»Ÿï¼Œè§£å†³äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ‰§è¡Œå¤šåŠŸèƒ½è°ƒç”¨æ—¶çš„é«˜å»¶è¿Ÿæˆæœ¬å’Œæ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼Œé€šè¿‡å¹¶è¡ŒåŒ–å‡½æ•°è°ƒç”¨å’Œä¼˜åŒ–åè°ƒæ¥æé«˜é€Ÿåº¦ï¼ŒèŠ‚çœæˆæœ¬å¹¶æå‡å‡†ç¡®ç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04511v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04511.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool Use**<br><sub>æœºæ„: Gaoling School of Artificial Intelligence, Renmin University of China, Alibaba Group<br>è¯¥è®ºæ–‡é’ˆå¯¹LLMsåœ¨å·¥å…·ä½¿ç”¨æ—¶å¯¹ä¸Šä¸‹æ–‡è®¤çŸ¥çš„ä¸è¶³æå‡ºäº†Attention Bucketsæ–¹æ³•ï¼Œé€šè¿‡å¤„ç†ä¸åŒçš„RoPEè§’åº¦åŸºç¡€æ¥å¼ºåŒ–å¯¹ä¸Šä¸‹æ–‡çš„å…³æ³¨ï¼Œæ˜¾è‘—æå‡äº†LLMsåœ¨å·¥å…·ä½¿ç”¨ä»»åŠ¡çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04455v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04455.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Generating Illustrated Instructions**<br><sub>æœºæ„: GenAI Meta, Columbia University<br>æœ¬è®ºæ–‡ä»‹ç»äº†ä¸€ç§åä¸ºStackedDiffusionçš„æ–°æ–¹æ³•ï¼Œç”¨äºç”Ÿæˆæ’å›¾è¯´æ˜ï¼Œè¿™æ˜¯ä¸€ç§å°†æ–‡æœ¬å’Œå›¾åƒç»“åˆèµ·æ¥æè¿°å¦‚ä½•å®ç°æŸä¸€ç›®æ ‡çš„ä»»åŠ¡ã€‚è¯¥æ–¹æ³•é€šè¿‡ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹å’Œæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œå¹¶å¼•å…¥ä¸€äº›æ–°é¢–çš„å»ºæ¨¡æŠ€å·§ï¼Œè§£å†³äº†ç°æœ‰T2Iæ¨¡å‹æ— æ³•ç›´æ¥ä»ç”¨æˆ·æŸ¥è¯¢ä¸­ç”Ÿæˆè§†è§‰æ•ˆæœçš„é—®é¢˜ï¼Œå¹¶åœ¨äººç±»è¯„ä¼°ä¸­è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯æ°´å¹³ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04552v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04552.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Beyond Surface: Probing LLaMA Across Scales and Layers**<br><sub>æœºæ„: Hong Kong University of Science and Technology<br>æœ¬ç ”ç©¶çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºæå‡ºäº†ä¸€ç³»åˆ—è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹é«˜é˜¶èƒ½åŠ›çš„æ¢é’ˆä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡å›´ç»•ç€è®¡ç®—èƒ½åŠ›ã€æ•°å­¦æ¨ç†ã€é€»è¾‘æ¨ç†å’ŒçœŸå®æ€§æ£€æµ‹ã€‚ç ”ç©¶æ­ç¤ºäº†LLMçš„è¡¨ç°å¦‚ä½•éšç€æ¨¡å‹è§„æ¨¡å’Œå±‚æ¬¡ç»“æ„çš„å˜åŒ–ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04333v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04333.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models**<br><sub>æœºæ„: MPI for Intelligent Systems, University of Washington<br>æ­¤ç ”ç©¶ä¸ºæµ‹è¯•å’Œåˆ†æå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ­£è§„å› æœæ¨ç†ä¸Šçš„èƒ½åŠ›æå‡ºäº†CLADDERæ•°æ®é›†å’ŒCAUSALCOTæ€ç»´è·¯å¾„æç¤ºç­–ç•¥ï¼Œé€šè¿‡å®éªŒçªæ˜¾äº†LLMsçš„å±€é™å¹¶ä¸ºæœªæ¥ç ”ç©¶æå‡ºäº†æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04350v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0435.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/causalNLP/cladder)</div> |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **A Study on the Calibration of In-context Learning**<br><sub>æœºæ„: Harvard University<br>è¯¥è®ºæ–‡æ·±å…¥ç ”ç©¶äº†ä¸Šä¸‹æ–‡å†…å­¦ä¹ (ICL)åœ¨è¯­è¨€æ¨¡å‹(LMs)ä¸­çš„æ ¡å‡†å‡†ç¡®æ€§é—®é¢˜ï¼Œå¹¶æå‡ºäº†è¯„ä¼°å’Œåˆ†ææ–¹æ³•ã€‚å®ƒæ­ç¤ºäº†æ ¡å‡†è¯¯å·®ä¸æ¨¡å‹å¤§å°å’Œå¾®è°ƒè¿‡ç¨‹ä¸­çš„å˜åŒ–å…³ç³»ï¼Œä»¥åŠæ ¡å‡†åœ¨æ¨ç†ä»»åŠ¡ç”Ÿæˆä¸­çš„é™ä½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04021v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04021.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Cost-Effective In-Context Learning for Entity Resolution: A Design Space Exploration**<br><sub>æœºæ„: Renmin University of China, Beijing Institute of Technology, HKUST (GZ)<br>è¿™ç¯‡è®ºæ–‡æä¾›äº†ä¸€ä¸ªå…¨é¢çš„ç ”ç©¶ï¼Œæ—¨åœ¨æ¢ç´¢å¦‚ä½•å¼€å‘ä¸€ç§æˆæœ¬æ•ˆç›Šçš„æ‰¹é‡æç¤ºæ–¹æ³•æ¥è¿›è¡Œå®ä½“è§£æã€‚ä¸»è¦è´¡çŒ®æ˜¯ä»‹ç» BATCHER æ¡†æ¶å¹¶æå‡ºåŸºäºè¦†ç›–çš„æ¼”ç¤ºé€‰æ‹©ç­–ç•¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03987v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03987.md)  |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **OneLLM: One Framework to Align All Modalities with Language**<br><sub>æœºæ„: MMLab The Chinese University of Hong Kong, Shanghai Artificial Intelligence Laboratory<br>OneLLMé€šè¿‡å…¶ç»Ÿä¸€çš„å¤šæ¨¡æ€ç¼–ç æ¡†æ¶å’Œæ¸è¿›å¼å¯¹é½ç®¡é“ï¼Œåœ¨æ¨ç†å’Œåˆ©ç”¨æ–¹é¢å±•ç¤ºäº†å¼ºå¤§çš„å¤šæ¨¡æ€ç†è§£å’Œå¤„ç†èƒ½åŠ›ï¼Œå¹¶æˆåŠŸåœ°å¤„ç†äº†æ‰©å±•å¤šæ¨¡æ€LLMsçš„æŒ‘æˆ˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03700v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.037.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/csuhan/OneLLM)</div> |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **Generative agent-based modeling with actions grounded in physical, social, or digital space using Concordia**<br><sub>æœºæ„: Google DeepMind, Google Research<br>æœ¬è®ºæ–‡æå‡ºäº†åˆ©ç”¨ç”Ÿæˆå¼å¤§å‹è¯­è¨€æ¨¡å‹å¢å¼ºåŸºäºä»£ç†çš„æ¨¡å‹çš„æ–¹æ³•ï¼Œé€šè¿‡Concordiaåº“å®ç°äº†åœ¨ç¤¾ä¼šã€ç‰©ç†å’Œæ•°å­—ç©ºé—´ä¸­æ¨¡æ‹Ÿä»£ç†çš„äº¤äº’ã€‚è¯¥æ¨¡å‹æ—¨åœ¨æä¾›é€¼çœŸçš„ç¤¾ä¼šæ¨¡æ‹Ÿï¼Œå¹¶æ¢ç´¢æ¨¡å‹çš„æœ‰æ•ˆæ€§éªŒè¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03664v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03664.md)  |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **Holmes: Towards Distributed Training Across Clusters with Heterogeneous NIC Environment**<br><sub>æœºæ„: Zhejiang Lab<br>æ–‡ç« æˆåŠŸä»‹ç»äº†ä¸€ä¸ªèƒ½åœ¨ç½‘ç»œæ¥å£å¡å¼‚æ„ç¯å¢ƒä¸­è¿›è¡Œå¤§å‹è¯­è¨€æ¨¡å‹è®­ç»ƒçš„æ¡†æ¶â€”â€”Holmesã€‚é€šè¿‡å®è¯ç ”ç©¶å…¶æ€§èƒ½ï¼ŒHolmesè¢«è¯æ˜å¯åœ¨å¼‚æ„ç¯å¢ƒä¸­å®ç°ä¸åŒæ„RDMA NICsç›¸å½“çš„æ€§èƒ½æ°´å¹³ï¼Œä»è€Œä½¿LLMè®­ç»ƒæ›´åŠ æ™®åŠå¹¶æ‰©å¤§äº†æœ‰æ•ˆæ‰©å±•çš„å¯èƒ½æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03549v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03549.md)  |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **Efficient Large Language Models: A Survey**<br><sub>æœºæ„: The Ohio State University, Google Research, Amazon AWS AI<br>è®ºæ–‡ç»¼è¿°äº†å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å¯¹äºç¨€ç–æ¿€æ´»æ–¹æ³•çš„æœ€æ–°è¿›å±•ï¼Œç‰¹åˆ«æ˜¯æ··åˆä¸“å®¶ç³»ç»Ÿï¼ˆMoEï¼‰åŠå…¶åœ¨é•¿æ–‡æœ¬å¤„ç†æ–¹é¢çš„åº”ç”¨ã€‚å®ƒæ€»ç»“äº†MoEæ¨¡å‹ä¼˜åŒ–çš„å„ç§æ–¹æ³•ï¼ŒåŒ…æ‹¬ç®—æ³•çº§åˆ«çš„æ”¹è¿›å’Œç³»ç»Ÿçº§åˆ«çš„åŠ é€Ÿæ¡†æ¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03863v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03863.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/AIoT-MLSys-Lab/EfficientLLMs)</div> |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **AnimateZero: Video Diffusion Models are Zero-Shot Image Animators**<br><sub>æœºæ„: Peking University, Tencent AI Lab, HKUST<br>AnimateZeroä¸ºT2Vç”Ÿæˆæä¾›è§£è€¦å’Œç²¾ç¡®çš„å¤–è§‚å’ŒåŠ¨ä½œæ§åˆ¶ï¼Œé€šè¿‡ç©ºé—´å¤–è§‚æ§åˆ¶å’Œæ—¶é—´ä¸€è‡´æ€§æ§åˆ¶ï¼Œå®ç°äº†ä»T2Iåˆ°I2Vçš„æ­¥éª¤å¼è§†é¢‘ç”Ÿæˆï¼ŒåŒæ—¶ç»´æŠ¤è‰¯å¥½çš„åŸŸä¸€è‡´æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03793v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03793.md)  |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **Controllable Human-Object Interaction Synthesis**<br><sub>æœºæ„: Stanford University, FAIR Meta<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„äº¤äº’åˆæˆæ–¹æ³•CHOISï¼Œå®ƒèƒ½åœ¨å—è¯­è¨€æè¿°æŒ‡å¯¼çš„æ¡ä»¶ä¸‹ï¼Œç”Ÿæˆç¬¦åˆä¸‰ç»´åœºæ™¯å‡ ä½•çº¦æŸçš„äººä¸ç‰©ä½“çš„åŒæ­¥è¿åŠ¨ã€‚è¯¥æ–¹æ³•é€šè¿‡é›†æˆåˆ°ä¸€ä¸ªç³»ç»Ÿä¸­ï¼Œå±•ç¤ºäº†å…¶åœ¨åˆæˆè¿ç»­ã€é€¼çœŸå’Œç¯å¢ƒæ„ŸçŸ¥çš„äººç‰©äº’åŠ¨æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03913v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03913.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **A Hardware Evaluation Framework for Large Language Model Inference**<br><sub>æœºæ„: Princeton University<br>LLMCompass ä½œä¸ºä¸€ç§ç¡¬ä»¶è¯„ä¼°æ¡†æ¶ï¼ŒæˆåŠŸåœ°åº”å¯¹äº†è®¾è®¡LLMæ¨ç†ç¡¬ä»¶æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚å®ƒä¸ä»…å¿«é€Ÿç²¾å‡†ï¼Œè€Œä¸”å…·æœ‰æ¶æ„æè¿°æ€§å’Œæˆæœ¬æ„è¯†ï¼Œå·²ç»åœ¨å•†ä¸šç¡¬ä»¶ä¸Šè¿›è¡Œäº†éªŒè¯ä¸”æ˜¾ç¤ºå‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03134v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03134.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **RankZephyr: Effective and Robust Zero-Shot Listwise Reranking is a Breeze!**<br><sub>æœºæ„: University of Waterloo<br>RankZephyræ˜¯ä¸€æ¬¾æ–°å‹å¼€æºLLMï¼Œç‰¹åˆ«ä¼˜åŒ–äº†é›¶æ ·æœ¬åˆ—è¡¨é‡æ–°æ’åºä»»åŠ¡ã€‚å®ƒæä¾›äº†ä¸å¤§å‹ä¸“æœ‰æ¨¡å‹ç›¸å½“æˆ–æ›´ä¼˜çš„é‡æ–°æ’åºæ•ˆæœï¼ŒåŒæ—¶å¼ºè°ƒäº†æ•°æ®å¢å¼ºå¯¹äºæå‡æ¨¡å‹é²æ£’æ€§çš„é‡è¦æ€§ï¼Œå¹¶é€šè¿‡å®éªŒè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œåœ¨ç°å®åœºæ™¯ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02724v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02724.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/castorini/rank_llm)</div> |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Rank-without-GPT: Building GPT-Independent Listwise Rerankers on Open-Source Large Language Models**<br><sub>æœºæ„: University of Waterloo, 2Cohere, Comcast Applied AI<br>æœ¬æ–‡çš„æ ¸å¿ƒæˆæœæ˜¯æ¼”ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ç§ä¸ä¾èµ–GPTæ¨¡å‹çš„æœ‰æ•ˆåˆ—è¡¨é‡æ’åºå™¨ï¼Œèƒ½æ˜¾è‘—è¶…è¶Šç°æœ‰åŸºäºGPTçš„é‡æ’åºå™¨ï¼Œå¹¶å‘¼åç ”ç©¶ç¤¾åŒºå¼€å‘æ›´é«˜è´¨é‡çš„åˆ—è¡¨æ’åºè®­ç»ƒæ•°æ®ï¼Œä»¥æå‡æ¨¡å‹çš„è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02969v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02969.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education**<br><sub>æœºæ„: Carnegie Mellon University  <br>æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯å¼€å‘äº†ä¸€ä¸ªåŸºäºGPT-4çš„è‡ªåŠ¨åŒ–MCQç”Ÿæˆç³»ç»Ÿï¼Œé€šè¿‡ä¸“é—¨çš„å¼¹æ€§æ„æ¶å’Œç²¾ç¡®çš„LOå¯¹é½æœºåˆ¶ï¼ŒæˆåŠŸç”Ÿæˆä¸é«˜ç­‰æ•™è‚²Pythonè¯¾ç¨‹LOä¸€è‡´çš„MCQsã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè‡ªåŠ¨ç”Ÿæˆçš„MCQåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä¸LOä¿æŒè‰¯å¥½çš„ä¸€è‡´æ€§ï¼Œè´¨é‡æ¥è¿‘äººå·¥è®¾è®¡çš„MCQï¼Œä½†åœ¨æ‹¥æœ‰å•ä¸€æ­£ç¡®ç­”æ¡ˆå’Œé«˜è´¨é‡å¹²æ‰°é¡¹æ–¹é¢ç•¥æ˜¾æ¬ ç¼ºï¼Œæœªæ¥å·¥ä½œåº”è¯¥é›†ä¸­åœ¨å‡è½»è¿™äº›é—®é¢˜ä¸Šã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03173v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03173.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Inherent limitations of LLMs regarding spatial information**<br><sub>æœºæ„: ProtagoLabs, International Monetary Fund, NetMind.ai  <br>è®ºæ–‡ä¸ºGPT-4ç­‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†ç©ºé—´ä¿¡æ¯æ–¹é¢çš„èƒ½åŠ›æä¾›äº†æ–°çš„è¯„ä¼°æ¡†æ¶å’Œä¸“é—¨è®¾è®¡çš„æ•°æ®é›†ï¼Œå¹¶åˆ†æäº†GPT-4åœ¨å¤„ç†ç©ºé—´ä¿¡æ¯æ–¹é¢çš„èƒ½åŠ›å’Œå±€é™æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03042v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03042.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph Construction**<br><sub>æœºæ„: Zhejiang Lab, Ant Group<br>é€šè¿‡åœ¨KGCä¸­å¼•å…¥å¤šæ™ºèƒ½ä½“åˆä½œçš„æ–¹æ³•ï¼ŒcooperKGCæ¡†æ¶æå‡äº†æ™ºèƒ½ä½“è§£å†³å®ä½“ã€å…³ç³»å’Œäº‹ä»¶æå–ä»»åŠ¡ä¸­çš„ç²¾ç¡®åº¦ï¼Œå¹¶æœ‰æœ›ä¸ºAIçš„åä½œæ„è¯†åŒ–æœªæ¥å¥ å®šäº†åŸºç¡€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03022v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03022.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Large Knowledge Model: Perspectives and Challenges**<br><sub>æœºæ„: Zhejiang University<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤§å‹çŸ¥è¯†æ¨¡å‹ï¼ˆLKMï¼‰çš„æ¦‚å¿µï¼Œæ—¨åœ¨æ›´æœ‰æ•ˆåœ°ç®¡ç†å’Œè§£è¯»çŸ¥è¯†è¡¨ç¤ºçš„å¤šæ ·æ€§ã€‚ç ”ç©¶æŒ‡å‡ºäº†ä»ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åˆ°LKMè½¬å˜çš„æŒ‘æˆ˜ï¼Œå¼ºè°ƒäº†ç»“æ„åŒ–çŸ¥è¯†åœ¨é¢„è®­ç»ƒä¸­çš„é‡è¦æ€§ï¼Œå¹¶æå‡ºäº†ä¸€å¥—LKMçš„è®¾è®¡åŸåˆ™ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02706v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02706.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **How should the advent of large language models affect the practice of science?**<br><sub>æœºæ„: Max Planck Institute for Biological Cybernetics, University of TÃ¼bingen, University of Washington  <br>æœ¬æ–‡è®¨è®ºäº†LLMså¯¹ç§‘å­¦å®è·µçš„å½±å“ï¼Œå¹¶å»ºè®®å¯¹å…¶ä½¿ç”¨æŒå®¡æ…æ€åº¦ï¼ŒåŒæ—¶å¼ºè°ƒäº†ä¿æŠ¤ç§‘å­¦çš„è§„èŒƒå’Œè®¤è¯†è®ºæ–¹é¢çš„é‡è¦æ€§ã€‚è™½ç„¶LLMså¯èƒ½æå‡æŸäº›ç§‘ç ”ä»»åŠ¡çš„æ•ˆç‡ï¼Œä½†ä½œä¸ºå·¥å…·ï¼Œå…¶ä½¿ç”¨åº”è¯¥è°¨æ…å¹¶ç¡®ä¿ç¬¦åˆç§‘å­¦è§„èŒƒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03759v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03759.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Prompt Optimization via Adversarial In-Context Learning**<br><sub>æœºæ„: National University of Singapore, Hong Kong University of Science and Technology, Institute for Infocomm Research (I2R) A*STAR<br>è®ºæ–‡ä»‹ç»äº†ä¸€ä¸ªæ–°é¢–çš„Adversarial In-Context Learningï¼ˆadv-ICLï¼‰æ–¹æ³•ï¼Œç”¨äºä¼˜åŒ–å¤§å‹æ¨¡å‹ä¸­promptçš„é€‰æ‹©ï¼Œä»¥æ­¤æé«˜æ¨¡å‹æ€§èƒ½ã€‚å®ƒå¯ä»¥å®ç°å¯¹æŠ—è®­ç»ƒç›®æ ‡ï¼Œå…‹æœæ•°æ®å’Œè®¡ç®—èµ„æºé™åˆ¶ï¼Œé€šè¿‡ä¼˜åŒ–promptè€Œä¸æ˜¯æ¨¡å‹å‚æ•°æ¥æå‡æ€§èƒ½ï¼Œä¸”å®éªŒç»“æœåœ¨å¤šä¸ªä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02614v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02614.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Let's Think Outside the Box: Exploring Leap-of-Thought in Large Language Models with Creative Humor Generation**<br><sub>æœºæ„: Sea AI Lab, Sun Yat-sen University, Harvard University  <br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ—¨åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹åˆ›é€ æ€§æ€ç»´èƒ½åŠ›çš„Creative Leap-of-Thought (CLoT)èŒƒå¼ï¼Œå¹¶éªŒè¯äº†å…¶åœ¨å¤šç§ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œæ¦‚æ‹¬èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02439v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02439.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/sail-sg/CLoT)</div> |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large Language Models**<br><sub>æœºæ„: Xiamen University, MBZUAI, Tencent AI Lab<br>æ–‡ç« é€šè¿‡å¼•å…¥åŠ¨æ€è‡ªåŠ¨æ£€ç´¢æœºåˆ¶å’Œåˆ†å±‚æŠ½æ ·æ–¹æ³•ï¼ŒæˆåŠŸæå‡äº†å¤šæ¨¡æ€ä»»åŠ¡ä¸­LLMsçš„CoTæ¨ç†èƒ½åŠ›ã€‚æå‡ºçš„æ–¹æ³•ä¸ä»…æé«˜äº†æ¨¡å‹æ€§èƒ½ï¼Œè€Œä¸”é€šè¿‡å¤šæ ·åŒ–ç¤ºä¾‹é€‰æ‹©è¿›ä¸€æ­¥ç»†åŒ–äº†æ¨ç†è¿‡ç¨‹ï¼Œä¸ºå¤šæ¨¡æ€æ¨ç†é¢†åŸŸæ ‘ç«‹äº†æ–°çš„æ€§èƒ½æ ‡æ†ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01714v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01714.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **LLMs Accelerate Annotation for Medical Information Extraction**<br><sub>æœºæ„: Google Research<br>æœ¬è®ºæ–‡å±•ç¤ºäº†ä¸€ä¸ªåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯Googleçš„PaLM 2ï¼Œæ¥æå‡åŒ»å­¦ä¿¡æ¯æŠ½å–ä»»åŠ¡ä¸­æ³¨é‡Šé€Ÿåº¦çš„æ–¹æ³•ã€‚è¿™ä¸ªåŸºäºLLMçš„æ³¨é‡Šæµç¨‹æé«˜äº†æ•ˆç‡ä¸”ä¸éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œå¤æ‚çš„è°ƒå‚ï¼Œä½¿å…¶æˆä¸ºä¸€ä¸ªæœ‰æ½œåŠ›çš„å·¥å…·æ¥åŠ é€ŸåŒ»ç–—é¢†åŸŸçš„æ•°æ®æ³¨é‡Šå·¥ä½œã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02296v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02296.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication**<br><sub>æœºæ„: Fudan University, National University of Singapore, Shanghai AI Laboratory  <br>æœ¬æ–‡æå‡ºçš„Exchange-of-Thoughtï¼ˆEoTï¼‰æ¡†æ¶é€šè¿‡æ¨¡å‹é—´äº¤æµæå‡LLMsçš„æ¨ç†èƒ½åŠ›ï¼Œå‡­å€Ÿå››ç§é€šä¿¡èŒƒä¾‹å’Œä¿¡å¿ƒè¯„ä¼°æœºåˆ¶ï¼Œåœ¨å¤šä¸ªæ¨ç†ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—æˆæ•ˆï¼Œå¹¶è¯æ˜äº†å¤–éƒ¨æ€ç»´åœ¨å¢å¼ºæ¨¡å‹æ€§èƒ½ä¸­çš„ä½œç”¨ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01823v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01823.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly**<br><sub>æœºæ„: Elsevier<br>è¿™ç¯‡è®ºæ–‡æ€»ç»“äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®‰å…¨æ€§å’Œéšç§ä¿æŠ¤ä¸­çš„åº”ç”¨åŠç›¸å…³æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºLLMsåœ¨è¿™äº›é¢†åŸŸçš„å¥½å¤„ã€åå¤„å’Œä¸‘é™‹ä¹‹å¤„ï¼ŒåŒæ—¶å¼ºè°ƒäº†å…¶åœ¨æ•°æ®ä¿æŠ¤æ–¹é¢çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02003v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02003.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Data Management For Large Language Models: A Survey**<br><sub>æœºæ„: Peking University, Huawei Noahâ€™s Ark Lab<br>è¿™ç¯‡ç»¼è¿°ç ”ç©¶äº†åœ¨LLMsçš„é¢„è®­ç»ƒå’Œç›‘ç£å¼å¾®è°ƒé˜¶æ®µï¼Œæ•°æ®ç®¡ç†çš„ç ”ç©¶ç°çŠ¶ä»¥åŠæ•°æ®ç®¡ç†ç­–ç•¥çš„è®¾è®¡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01700v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.017.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/ZigeW/data_management_LLM)</div> |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **ChatGPT as a Math Questioner? Evaluating ChatGPT on Generating Pre-university Math Questions**<br><sub>æœºæ„: Nanyang Technological University, National University of Singapore<br>è¯¥ç ”ç©¶æå‡ºäº†ç¬¬ä¸€ä¸ªç³»ç»Ÿçš„è¯„ä¼°ChatGPTåœ¨ç”Ÿæˆå‰å¤§å­¦æ•°å­¦é—®é¢˜æ½œåŠ›çš„ç ”ç©¶ã€‚é€šè¿‡ä¸¤ç§ä¸»è¦åœºæ™¯ï¼šç»™å®šä¸Šä¸‹æ–‡å’Œæœªç»™å®šä¸Šä¸‹æ–‡çš„ç”Ÿæˆé—®é¢˜ï¼Œå¹¶ä¸ºæ•™è‚²å·¥ä½œè€…æä¾›å®ç”¨çš„æ´å¯Ÿã€‚ç ”ç©¶çš„ç»“æœæœ‰å¯èƒ½ä¿ƒè¿›ç°ä»£AIæŠ€æœ¯åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨ï¼Œå¹¶æé«˜è‡ªåŠ¨åŒ–æ•°å­¦é—®é¢˜ç”Ÿæˆçš„å®ç”¨æ€§å’Œæ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01661v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01661.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning**<br><sub>æœºæ„: Allen Institute for Artificial Intelligence, University of Washington<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªé€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ å®ç°LLMså¯¹é½çš„ç®€å•æ— é¡»è°ƒæ•´æ–¹æ³•ï¼ˆURIALï¼‰ï¼Œè¡¨ç°å‡ºä¸ä¼ ç»Ÿè°ƒæ•´å¯¹é½æ–¹æ³•ç›¸åŒ¹é…ç”šè‡³æ›´å¥½çš„æ•ˆæœã€‚è¿™ä¸€å‘ç°å¯¹æœªæ¥LLMsç ”ç©¶å…·æœ‰é‡è¦çš„å¯ç¤ºï¼Œè¯´æ˜äº†åœ¨LLMså¯¹é½ä¸Šæ›´æ·±å…¥çš„åˆ†æå’Œç†è®ºç†è§£çš„é‡è¦æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01552v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01552.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Competition-Level Problems are Effective LLM Evaluators**<br><sub>æœºæ„: Microsoft Research Asia, Xiamen University, Microsoft Azure AI<br>æœ¬ç ”ç©¶é€šè¿‡è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†ç«èµ›çº§ç¼–ç¨‹é—®é¢˜ä¸Šçš„è¡¨ç°ï¼Œæ­ç¤ºäº†GPT-4ç­‰æ¨¡å‹åœ¨çœŸå®æ¨ç†èƒ½åŠ›ä¸Šçš„ä¸è¶³ï¼Œå¹¶æå‡ºäº†ä¸€äº›æå‡è¡¨ç°çš„æ–¹æ³•ã€‚è¿™äº›å‘ç°çªæ˜¾äº†è¿™ç±»é—®é¢˜ä½œä¸ºè¯„ä¼°LLMsçš„æœ‰æ•ˆå·¥å…·çš„é‡è¦æ€§ï¼Œå¹¶ä¿ƒè¿›äº†å¯¹äºæé«˜LLMså¤æ‚æ¨ç†èƒ½åŠ›çš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02143v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02143.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **On the Effectiveness of Large Language Models in Domain-Specific Code Generation**<br><sub>æœºæ„: Shanghai Jiao Tong University, Chongqing University, East China Normal University<br>è¿™é¡¹ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡æœ‰æ•ˆåœ°æ•´åˆé¢†åŸŸçŸ¥è¯†åˆ°ä»£ç ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œå¯ä»¥å¢å¼ºLLMsåœ¨ç‰¹å®šé¢†åŸŸå†…çš„ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚DomCoderä½œä¸ºä¸€ä¸ªæ–°çš„ä»£ç ç”Ÿæˆæ–¹æ³•ï¼Œåˆ©ç”¨äº†ä¸åŒç­–ç•¥ä»¥æ•´åˆé¢†åŸŸçŸ¥è¯†ï¼Œå¹¶åœ¨ç‰¹å®šè®¾ç½®ä¸‹æå‡äº†ä»£ç ç”Ÿæˆçš„å®é™…æ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01639v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01639.md)  |
| <span style='display: inline-block; width: 42px;'>12-03</span> | **D-Bot: Database Diagnosis System using Large Language Models**<br><sub>æœºæ„: Tsinghua University, Pigsty, ModelBest<br>D-Botæ˜¯ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ•°æ®åº“è¯Šæ–­ç³»ç»Ÿï¼Œå®ƒé€šè¿‡æ–‡æ¡£ä¸­çš„çŸ¥è¯†æå–å’Œç”Ÿæˆæœ‰æ•ˆçš„è¯Šæ–­æŠ¥å‘Šæ¥æé«˜æ•°æ®åº“è¯Šæ–­çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œè§£å†³äº†åŒºåŸŸä¸“å®¶åœ¨æ•°æ®åº“è¯Šæ–­ä¸­é‡åˆ°çš„æŒ‘æˆ˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01454v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01454.md)  |
| <span style='display: inline-block; width: 42px;'>12-03</span> | **TextGenSHAP: Scalable Post-hoc Explanations in Text Generation with Long Documents**<br><sub>æœºæ„: University of Southern California, Google Cloud AI<br>TextGenSHAPæ˜¯ä¸€ä¸ªä¸ºå¤§å‹è¯­è¨€æ¨¡å‹è®¾è®¡çš„é«˜æ•ˆåéªŒè§£é‡Šæ€§æ–¹æ³•ï¼Œé€šè¿‡æ”¹è¿›è§£é‡Šç”Ÿæˆçš„é€Ÿåº¦ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨è¿™äº›è§£é‡Šæ”¹è¿›é•¿æ–‡æ¡£é—®ç­”å’Œæ–‡æ¡£æ£€ç´¢ç³»ç»Ÿã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01279v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01279.md)  |
| <span style='display: inline-block; width: 42px;'>12-03</span> | **Running cognitive evaluations on large language models: The do's and the don'ts**<br><sub>æœºæ„: Massachusetts Institute of Technology<br>è¿™ç¯‡è®ºæ–‡ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„è®¤çŸ¥è¯„ä¼°ç ”ç©¶æ–¹æ³•æä¾›äº†æŒ‡å¯¼æ€§çš„å»ºè®®ï¼Œæ¢è®¨äº†åœ¨æ–¹æ³•è®ºä¸Šå¦‚ä½•é¿å…åœ¨è¿è¡Œè®¤çŸ¥è¯„ä¼°æ—¶å¯èƒ½å‡ºç°çš„é—®é¢˜ã€‚è®ºæ–‡çš„ç›®æ ‡æ˜¯è´¡çŒ®äºAIå¿ƒç†å­¦é¢†åŸŸæœ€ä½³å®è·µçš„æ›´å¹¿æ³›è®¨è®ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01276v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01276.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Axiomatic Preference Modeling for Longform Question Answering**<br><sub>æœ¬æ–‡æå‡ºçš„åŸºäºå…¬ç†çš„æ¡†æ¶ä¸ºé•¿ç¯‡é—®ç­”åå¥½æ¨¡å‹æä¾›äº†ä¸€ç§æ–°æ–¹æ³•ï¼Œé€šè¿‡ç»†è‡´å®¡è§†äººç±»åå¥½ï¼Œå¹¶ä¼˜åŒ–äº†åå¥½æ‰“åˆ†çš„å‡†ç¡®æ€§ä¸æ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02206v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02206.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Large Language Models Are Zero-Shot Text Classifiers**<br><sub>æœºæ„: Florida Atlantic University<br>è®ºæ–‡å±•ç¤ºäº†LLMså¯ä»¥æœ‰æ•ˆä½œä¸ºé›¶æ ·æœ¬æ–‡æœ¬åˆ†ç±»å™¨çš„èƒ½åŠ›ï¼Œè¿™å¯¹äºéœ€è¦å¿«é€Ÿéƒ¨ç½²æ–‡æœ¬åˆ†ç±»å™¨çš„å°å›¢é˜Ÿæˆ–å°ä¼ä¸šæ¥è¯´ç‰¹åˆ«æœ‰ç›Šã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œåœ¨æ‰€æœ‰å››ä¸ªæ•°æ®é›†ä¸­ï¼ŒGPT-4ä¸€è‡´è¶…è¿‡äº†ä¼ ç»ŸMLç®—æ³•ã€‚æ–‡ç« è¿˜å»ºè®®æœªæ¥çš„ç ”ç©¶æ–¹å‘åŒ…æ‹¬ä¼˜åŒ–æç¤ºä»¥è·å¾—æ›´é«˜çš„ç²¾åº¦æˆ–å¼•å…¥è¯„è®ºä»£ç†ä»¥è¯„ä¼°å’Œæå‡LLMçš„ç»“æœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01044v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01044.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Exploring and Improving the Spatial Reasoning Abilities of Large Language Models**<br><sub>æœºæ„: Stanford University  <br>è®ºæ–‡æé«˜äº†å¯¹LLMsåœ¨ç©ºé—´æ¨ç†å’Œåºåˆ—æ ‡æ³¨æ–¹é¢èƒ½åŠ›çš„ç†è§£ï¼Œæå‡ºäº†ä¸€ç§æ”¹è¿›LLMså¤„ç†3Dè½¨è¿¹è¯†åˆ«ä»»åŠ¡çš„æ–¹æ³•ï¼Œå…·æœ‰æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01054v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01054.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Just-in-Time Security Patch Detection -- LLM At the Rescue for Data Augmentation**<br><sub>æœºæ„: University of Luxembourg, Windows Copilot Microsoft, Singapore Management University<br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å®‰å…¨è¡¥ä¸æ£€æµ‹æ¡†æ¶ LLMDAï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œè¡¥ä¸åˆ†æå’Œæ•°æ®å¢å¼ºï¼Œå¹¶å¯¹å¤šæ¨¡æ€è¾“å…¥è¿›è¡Œå¯¹é½ã€‚è¿™ä½¿ç³»ç»Ÿèƒ½å¤Ÿä»è¡¥ä¸å’Œä»£ç çš„è”åˆä¸Šä¸‹æ–‡ä¸­æå–æ›´ä¸°å¯Œçš„ä¿¡æ¯ï¼Œæå‡æ£€æµ‹å‡†ç¡®æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01241v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01241.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games**<br><sub>æœºæ„: Quebec AI Institute<br>è¿™ç¯‡è®ºæ–‡è´¡çŒ®äº†é€‚åº”JuBenshaæ¸¸æˆå¤æ‚æ€§å’Œæ–°æŒ‘æˆ˜çš„è¯„ä¼°æ–¹æ³•ï¼Œå¹¶åˆ›å»ºäº†ä¸€ä¸ªèƒ½å¤Ÿè¯„ä¼°äº¤äº’å¼ç¯å¢ƒä¸­LLMæ™ºèƒ½ä½“èƒ½åŠ›çš„æ–°æ¡†æ¶ThinkThriceï¼Œæ¨åŠ¨äº†AIåœ¨å¤šç©å®¶è§’è‰²æ‰®æ¼”æ¸¸æˆä¸­çš„åº”ç”¨ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00746v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00746.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Nash Learning from Human Feedback**<br><sub>æœºæ„: Google DeepMind<br>è¿™ç¯‡æ–‡ç« æå‡ºäº†ä¸€ç§å…¨æ–°çš„è°ƒèŠ‚å¤§å‹è¯­è¨€æ¨¡å‹ä»¥é€šè¿‡çº³ä»€å‡è¡¡ä¸äººç±»åå¥½å¯¹é½çš„æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æ½œèƒ½ï¼Œå¹¶é€šè¿‡å®éªŒè¯æ˜äº†å…¶æ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00886v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00886.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Leveraging Large Language Models to Improve REST API Testing**<br><sub>æœºæ„: Georgia Institute of Technology, IBM Research<br>RESTGPTé€šè¿‡åˆ©ç”¨LLMsï¼Œç‰¹åˆ«æ˜¯GPT-3.5 Turboçš„é«˜æ•ˆå‡†ç¡®æ€§å’Œå°‘é‡ç¤ºä¾‹å­¦ä¹ çš„ç²¾å‡†æ€§ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨æå–è‡ªç„¶è¯­è¨€æè¿°ä¸­è§„åˆ™å’Œç”Ÿæˆæœ‰æ•ˆå€¼æ—¶çš„é™åˆ¶ï¼Œæ˜¾è‘—æå‡äº†REST APIæµ‹è¯•çš„è´¨é‡å’Œå‡†ç¡®åº¦ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00894v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00894.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **The Cost of Compression: Investigating the Impact of Compression on Parametric Knowledge in Language Models**<br><sub>æœºæ„: University of Wisconsin - Madison<br>è¿™é¡¹ç ”ç©¶é¦–æ¬¡å¤§è§„æ¨¡è€ƒå¯Ÿäº†LLMsçš„å‹ç¼©æŠ€æœ¯å¯¹æ¨¡å‹å‚æ•°çŸ¥è¯†çš„å½±å“ï¼Œå¹¶ä¸ºå®é™…åº”ç”¨æä¾›äº†é‡è¦è§è§£ï¼Œç‰¹åˆ«æ˜¯åœ¨å…³äºä¿®å‰ªå’Œé‡åŒ–æŠ€æœ¯ç›¸å…³çš„å†³ç­–æ–¹é¢ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00960v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0096.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **The Cost of Compression: Investigating the Impact of Compression on Parametric Knowledge in Language Models**<br><sub>æœºæ„: University of Wisconsin - Madison<br>æœ¬è®ºæ–‡é€šè¿‡å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œå‹ç¼©æŠ€æœ¯ï¼ˆå‰ªæå’Œé‡åŒ–ï¼‰çš„å…¨é¢ç ”ç©¶ï¼Œæ­ç¤ºäº†è¿™äº›æŠ€æœ¯å¯¹æ¨¡å‹å‚æ•°çŸ¥è¯†ä¿ç•™çš„å½±å“ï¼Œä¸ºå®è·µè€…æä¾›äº†å…³äºæ¨¡å‹å‹ç¼©çš„æœ‰ä»·å€¼è§è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00960v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0096.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **On Exploring the Reasoning Capability of Large Language Models with Knowledge Graphs**<br><sub>æœºæ„: Singapore Management University, National Sun Yat-sen University<br>ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼ŒLLMsèƒ½å¤Ÿé€šè¿‡å…¶å†…éƒ¨çŸ¥è¯†å›¾æˆåŠŸå¤„ç†çŸ¥è¯†å›¾æ¨ç†ä»»åŠ¡ï¼Œå¹¶èƒ½ä»ä¸Šä¸‹æ–‡ä¸­æ¨æ–­å‡ºçŸ¥è¯†å›¾å…³ç³»ï¼Œå±•ç¤ºäº†LLMsåœ¨çŸ¥è¯†å›¾æ¨ç†ä¸­çš„æ½œåŠ›åŠåº”ç”¨ä»·å€¼ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00353v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00353.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Instruction-tuning Aligns LLMs to the Human Brain**<br><sub>æœºæ„: EPFL<br>æœ¬ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡æŒ‡ä»¤è°ƒæ•´è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸–ç•ŒçŸ¥è¯†è¡¨ç¤ºæ–¹é¢ä»¥åŠä¸äººè„‘æ´»åŠ¨çš„å¯¹é½ç¨‹åº¦ä¸Šè¡¨ç°æ›´ä½³ã€‚è¿™ä¸ºæœªæ¥LLMsçš„å‘å±•æä¾›äº†å°†ä¸–ç•ŒçŸ¥è¯†é›†æˆåˆ°æ¨¡å‹ä¸­çš„é‡è¦è§†è§’ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00575v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00575.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment from Fine-grained Correctional Human Feedback**<br><sub>RLHF-Væ˜¯ä¸€ä¸ªé€šè¿‡ç»†ç²’åº¦æ ¡æ­£å‹äººç±»åé¦ˆæ ¡æ­£MLLMè¡Œä¸ºçš„æ–°æ¡†æ¶ï¼Œé€šè¿‡æ”¶é›†é«˜è´¨é‡çš„äººç±»åå¥½æ•°æ®ä¸ºMLLMsæä¾›äººç±»å¯¹é½çš„å­¦ä¹ ä¿¡å·ï¼Œå¹¶é€šè¿‡å…¨é¢çš„å®éªŒéªŒè¯äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚è¯¥ç ”ç©¶å¯èƒ½åœ¨æé«˜å¤§å‹å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸­çš„å¯é æ€§å’Œå®ç”¨æ€§æ–¹é¢å–å¾—é‡è¦è¿›å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00849v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00849.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RLHF-V/RLHF-V)</div> |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Learning from One Continuous Video Stream**<br><sub>è¯¥è®ºæ–‡ä»‹ç»äº†ä¸€ä¸ªæ¡†æ¶ï¼Œç”¨äºä»å•ä¸€è¿ç»­è§†é¢‘æµä¸­è¿›è¡Œåœ¨çº¿å­¦ä¹ ï¼Œè¿™ä¸€æ¡†æ¶ä¾§é‡äºé€‚åº”æ€§ä¸æ³›åŒ–çš„è¯„ä¼°ï¼Œå¹¶æå‡ºäº†ä¸€ç³»åˆ—æœªæ¥é¢„æµ‹ä»»åŠ¡è¿›è¡Œé¢„è®­ç»ƒã€‚ç ”ç©¶æ˜¾ç¤ºï¼Œåœ¨è¿™ç§å­¦ä¹ ç¯å¢ƒä¸‹ï¼Œä¼˜åŒ–ç­–ç•¥éœ€è¦è°ƒæ•´ï¼Œé€šè¿‡å‡å°‘åŠ¨é‡å’Œè°ƒæ•´æƒé‡æ›´æ–°é¢‘ç‡å¯ä»¥æ”¹å–„æ¨¡å‹çš„é€‚åº”æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00598v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00598.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Improve Supervised Representation Learning with Masked Image Modeling**<br><sub>æœºæ„: Google Research, OpenAI  <br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§èåˆç›‘ç£è¡¨ç¤ºå­¦ä¹ å’ŒMIMçš„æ–°è®­ç»ƒè®¾ç½®ï¼Œè¯¥è®¾ç½®åœ¨ä¸å¢åŠ æ˜¾è‘—çš„è®­ç»ƒæˆ–æ¨ç†å¼€é”€çš„å‰æä¸‹ï¼Œæ˜¾è‘—æé«˜äº†ä¸‹æ¸¸ä»»åŠ¡å¦‚åˆ†ç±»ã€å›¾åƒæ£€ç´¢å’Œè¯­ä¹‰åˆ†å‰²çš„è¡¨ç¤ºå­¦ä¹ è´¨é‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00950v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0095.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Beyond ChatBots: ExploreLLM for Structured Thoughts and Personalized Model Responses**<br><sub>æœºæ„: Google<br>æœ¬æ–‡ä»‹ç»äº†æ¢ç´¢LLMç³»ç»ŸExploreLLMï¼Œå®ƒé€šè¿‡ç»“åˆåŸºäºæç¤ºçš„ä»»åŠ¡åˆ†è§£æ–¹æ³•å’Œå…¨æ–°çš„ç±»ä¼¼å›¾å¼çš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰ï¼Œåœ¨ç”¨æˆ·å’ŒLLMåŠ©æ‰‹ä¹‹é—´æä¾›äº†ä¸€ç§å…¨æ–°çš„äº¤äº’æ¨¡å¼ã€‚è¯¥ç³»ç»Ÿé€šè¿‡åœ¨ç»“æ„åŒ–å’Œäº¤äº’å¼ç•Œé¢ä¸­è¡¨ç¤ºç”Ÿæˆå­ä»»åŠ¡ï¼Œæ—¨åœ¨å‡è½»ç”¨æˆ·å®Œæˆå¤æ‚ä»»åŠ¡æ—¶çš„è®¤çŸ¥è´Ÿæ‹…ï¼ŒåŒæ—¶æé«˜ä¸ªæ€§åŒ–å“åº”çš„æ°´å¹³ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00763v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00763.md)  |

---

### 11æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text**<br><sub>æœºæ„: The University of Tokyo<br>ç ”ç©¶å±•ç¤ºäº†GPT-4å¤„ç†æ··æ·†æ–‡æœ¬çš„å¼ºå¤§èƒ½åŠ›ï¼Œè®¾ç½®äº†ä¸¤é¡¹æ–°æŒ‡æ ‡RRå’ŒRPGï¼Œå¹¶é€šè¿‡å®ƒä»¬éªŒè¯äº†GPT-4åœ¨ä¸åŒæ··æ·†åœºæ™¯å’Œæ¯”ç‡ä¸‹çš„ç¨³å®šè¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18805v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18805.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **TaskBench: Benchmarking Large Language Models for Task Automation**<br><sub>æœºæ„: Zhejiang University<br>è¯¥æ–‡çŒ®æå‡ºäº†TaskBenchåŸºå‡†æµ‹è¯•å’ŒTASKEVALè¯„ä¼°ç³»ç»Ÿï¼Œé€šè¿‡æ•°æ®ç”Ÿæˆå’Œé‡åŒ–è¯„ä¼°ç³»ç»Ÿï¼Œæœ‰æ•ˆåœ°è§£å†³äº†åœ¨ä»»åŠ¡è‡ªåŠ¨åŒ–é¢†åŸŸå¯¹LLMsçš„è¯„ä¼°é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18760v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1876.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation**<br><sub>æœºæ„: University of Science and Technology of China, Microsoft Research Asia<br>MicroCinemaä»¥å…¶åˆ›æ–°çš„æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆä¸¤é˜¶æ®µæµç¨‹å’Œæœ‰æ•ˆçš„Appearance Injection NetworkåŠAppearance Noise Prioræœºåˆ¶ï¼Œåœ¨è§†é¢‘ç”Ÿæˆè´¨é‡ä¸Šå®ç°äº†æ–°çš„çªç ´ï¼Œä¸ºåç»­å·¥ä½œæä¾›äº†å¯å€Ÿé‰´çš„èŒƒä¾‹ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18829v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18829.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **IAG: Induction-Augmented Generation Framework for Answering Reasoning Questions**<br><sub>æœºæ„: Huawei Poisson Lab<br>IAGæ¡†æ¶é€šè¿‡å½’çº³æç¤ºæ³•åŠ å¼ºçŸ¥è¯†é™ˆè¿°çš„çœŸå®æ€§ï¼Œå¹¶ä¸”ä¼˜åŒ–äº†çŸ¥è¯†èåˆæœºåˆ¶å’Œå­¦ç”Ÿå½’çº³æ¨¡å‹ï¼Œä»¥è§£å†³ç°æœ‰åŸºäºæ£€ç´¢çš„æ–¹æ³•åœ¨éšæ€§æ¨ç†é—®ç­”ä»»åŠ¡ä¸Šçš„ä¸è¶³ã€‚ç ”ç©¶æˆæœè¡¨æ˜ï¼ŒIAGåœ¨å›ç­”æ¶‰åŠéšæ€§æ¨ç†çš„é—®ç­”ä»»åŠ¡ä¸Šè¡¨ç°æ›´ä¼˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18397v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18397.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **Autonomous Agents in Software Development: A Vision Paper**<br><sub>æœºæ„: Tampere University<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªå…³äºåˆ©ç”¨å¤šä¸ª GPT ä»£ç†æ¥è‡ªåŠ¨æ‰§è¡Œè½¯ä»¶å·¥ç¨‹ä»»åŠ¡çš„æ„¿æ™¯ï¼Œå¹¶æ¼”ç¤ºäº†åœ¨ç®€å•è½¯ä»¶ä»»åŠ¡ä¸Šæ‰€å–å¾—çš„åˆæ­¥æˆåŠŸã€‚è¿™é¡¹å·¥ä½œæœ‰å¯èƒ½å½»åº•æ”¹å˜è½¯ä»¶å¼€å‘çš„æ–¹å¼ï¼Œå¹¶ç¼©çŸ­å¼€å‘æ—¶é—´ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18440v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1844.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation**<br><sub>æœºæ„: UC Berkeley, Microsoft Azure AI, ZOOM<br>CoDi-2æ˜¯ä¸€ç§å…·æœ‰å‰æ²¿èƒ½åŠ›çš„å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹ï¼Œå¯ä»¥å¤„ç†å¤æ‚çš„å¤šæ¨¡æ€è¾“å…¥ã€åœ¨ä¸Šä¸‹æ–‡ä¸­æŒ‡å¯¼ç”Ÿæˆã€é€šè¿‡å¤šè½®äº¤äº’ä¸ç”¨æˆ·äº’åŠ¨ï¼Œå¹¶å®ç°äº†ä¼˜ç§€çš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18775v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18775.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **Applying Large Language Models and Chain-of-Thought for Automatic Scoring**<br><sub>æœºæ„: University of Georgia<br>æœ¬æ–‡å±•ç¤ºäº†LLMsåœ¨ä¿ƒè¿›è‡ªåŠ¨è¯„åˆ†æ–¹é¢çš„æ½œåŠ›ï¼Œå¹¶å¼ºè°ƒCoTåœ¨é…åˆé¡¹èŒå’Œè¯„åˆ†æ ‡å‡†ä½¿ç”¨æ—¶èƒ½æ˜¾è‘—å¢å¼ºè¯„åˆ†çš„å‡†ç¡®åº¦ã€‚é€šè¿‡ç»“åˆLLMså’ŒCoTçš„æ–¹æ³•ï¼Œå¯ä»¥é™ä½è‡ªåŠ¨è¯„åˆ†æ¨¡å‹æ„å»ºçš„å¤æ‚æ€§å’ŒäººåŠ›æˆæœ¬ï¼Œå¹¶å¯èƒ½æä¾›æ›´æ¥è¿‘äººç±»è¯„åˆ†ç»“æœçš„è¯„åˆ†ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03748v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2312.03748.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **What Do Llamas Really Think? Revealing Preference Biases in Language Model Representations**<br><sub>æœºæ„: Comcast Applied AI, University of Waterloo<br>ä½œè€…ä»¬æå‡ºäº†ä¸€ä¸ªæ–°å‹æ¢é’ˆæ¥æ£€æµ‹LLMsè¡¨ç¤ºä¸­çš„å†…éšå…³è”åè§ï¼Œå¹¶é€šè¿‡å®éªŒåœ¨åå¥½æ£€æµ‹ä¸­è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ã€‚ç ”ç©¶è¿˜å‘ç°äº†å¤šä¸ªæŒ‡ä»¤éµå¾ªå‹å’Œâ€œä¼ ç»Ÿâ€çš„LLMsä¸­çš„æ˜¾è‘—åè§ï¼Œè¿™äº›åè§å­˜åœ¨äºå›½ç±ã€æ”¿æ²»ã€å®—æ•™å’Œæ€§åˆ«ç­‰æ–¹é¢ï¼Œå°½ç®¡LLMså·²ç»ç»è¿‡æ˜ç¡®çš„å®‰å…¨æŒ‡å¯¼è°ƒæ•´ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18812v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18812.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/castorini/biasprobe)</div> |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **PoseGPT: Chatting about 3D Human Pose**<br><sub>æœºæ„: Max Planck Institute for Intelligent Systems, Meshcapade<br>PoseGPTæ˜¯ä¸€ä¸ªæ–°å‹æ¡†æ¶ï¼Œå®ƒé€šè¿‡åœ¨LLMä¸­åµŒå…¥SMPLå§¿æ€æ ‡è®°ï¼Œä½¿æ¨¡å‹å¯ä»¥ç›´æ¥ä»æ–‡æœ¬å’Œè§†è§‰è¾“å…¥ç”Ÿæˆä¸‰ç»´äººä½“å§¿æ€ï¼Œå¹¶åœ¨è§£é‡Šä¸‰ç»´äººä½“å§¿æ€æ–¹é¢å®ç°äº†ä¸€å®šç¨‹åº¦çš„åˆ›æ–°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18836v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18836.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **TimeBench: A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models**<br><sub>æœºæ„: Harbin Institute of Technology<br>TIMEBENCHåŸºå‡†çš„æå‡ºæ˜¯å¯¹å¤§å‹è¯­è¨€æ¨¡å‹æ—¶é—´æ¨ç†èƒ½åŠ›ç»¼åˆè¯„ä¼°çš„é‡è¦æ­¥éª¤ï¼Œå®ƒå±•ç¤ºäº†å½“å‰æ¨¡å‹ä¸äººç±»åœ¨è¿™æ–¹é¢çš„å·®è·ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æŒ‡å¼•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17667v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17667.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/zchuz/TimeBench)</div> |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **TaskWeaver: A Code-First Agent Framework**<br><sub>æœºæ„: Microsoft<br>TaskWeaveræ˜¯ä¸ºæ„å»ºåŸºäºLLMçš„è‡ªæ²»ä»£ç†è€Œè®¾è®¡çš„ä»£ç ä¼˜å…ˆæ¡†æ¶ï¼Œå®ç°äº†å¯¹å¤æ‚æ•°æ®çš„é«˜æ•ˆå¤„ç†ä»¥åŠæ’ä»¶çš„çµæ´»ä½¿ç”¨ï¼Œå¹¶å°†ç‰¹å®šåŸŸçŸ¥è¯†æˆåŠŸæ•´åˆå…¥ç³»ç»Ÿä¸­ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17541v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17541.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/microsoft/TaskWeaver)</div> |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Large Language Models for Networking: Applications, Enabling Techniques, and Challenges**<br><sub>æœºæ„: BUPT<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ•´åˆå¤§å‹è¯­è¨€æ¨¡å‹ä¸ç½‘ç»œæŠ€æœ¯çš„æ–°æ¡†æ¶ChatNetï¼Œå¹¶æ¢ç©¶äº†å®ƒåœ¨ç½‘ç»œè§„åˆ’ä¸­çš„åº”ç”¨ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒChatNetå¯ä»¥æœ‰æ•ˆæå‡ç½‘ç»œä»»åŠ¡çš„è‡ªåŠ¨åŒ–å’Œæ™ºèƒ½åŒ–æ°´å¹³ï¼Œå°½ç®¡åœ¨éƒ¨ç½²å‰ä»éœ€è§£å†³å¤šæ¨¡æ€æ•°æ®æ•´åˆå’Œæ’ä»¶å¼€å‘ç­‰æŒ‘æˆ˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17474v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17474.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Are Large Language Models Good Fact Checkers: A Preliminary Study**<br><sub>æœºæ„: Chinese Academy of Sciences<br>è¿™ç¯‡æ–‡ç« é€šè¿‡ç³»ç»Ÿè¯„ä¼°LLMsåœ¨æ•´ä¸ªäº‹å®æ ¸æŸ¥æµç¨‹ä¸­çš„æ½œåŠ›ï¼Œå‘ç°å°½ç®¡LLMsåœ¨æŸäº›æ–¹é¢è¡¨ç°å‡ºæ½œåŠ›ï¼Œä½†ä¾ç„¶éœ€è¦æ›´å¤šç ”ç©¶å’Œå°è¯•æ¥æå‡å®ƒä»¬åœ¨äº‹å®æ ¸æŸ¥ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17355v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17355.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Zero-shot Conversational Summarization Evaluations with small Large Language Models**<br><sub>æœºæ„: Intel labs<br>æ–‡ç« ä»¥å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¼šè¯æ‘˜è¦ä»»åŠ¡ä¸­çš„åº”ç”¨ä½œä¸ºç„¦ç‚¹ï¼Œæ·±å…¥æ¢è®¨äº†ä¸åŒæŒ‡ä»¤å¯¹æ¨¡å‹æ‰§è¡Œæ•ˆæœçš„å½±å“ï¼Œå¹¶ç ”ç©¶äº†åœ¨æœ‰é™ç¡¬ä»¶ä¸‹ä½¿ç”¨å‹ç¼©æ¨¡å‹çš„ä¼˜åŒ–æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18041v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18041.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Understanding and Improving In-Context Learning on Vision-language Models**<br><sub>æœºæ„: LMU Munich, University of Oxford<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç”¨äºè§†è§‰-è¯­è¨€æ¨¡å‹åœ¨èƒŒæ™¯å­¦ä¹ ä¸­é€‰æ‹©ç¤ºèŒƒçš„æ–°æ–¹æ³•MMICESï¼Œå¹¶é€šè¿‡ä¸€ç³»åˆ—å®éªŒå±•ç¤ºäº†å…¶åœ¨ä¸åŒæ¨¡å‹å’Œæ•°æ®é›†ä¸Šçš„è‰¯å¥½æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18021v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18021.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **How to Build an AI Tutor that Can Adapt to Any Course and Provide Accurate Answers Using Large Language Model and Retrieval-Augmented Generation**<br><sub>æœºæ„: The Education University of Hong Kong<br>è¿™ç¯‡è®ºæ–‡ä»£è¡¨äº†ä¸€æ¬¡å¼€åˆ›æ€§çš„å°è¯•ï¼Œæ„å»ºäº†ä¸€ä¸ªå¯ä»¥é€‚åº”ä»»ä½•å­¦ç§‘å¹¶æä¾›é«˜è´¨é‡çš„å®šåˆ¶åŒ–æ•™è‚²æ”¯æŒçš„AIå¯¼å¸ˆç³»ç»Ÿã€‚è¿™ä¸ä»…èƒ½ä¿ƒè¿›AIæ•™è‚²æŠ€æœ¯çš„åº”ç”¨ï¼Œè€Œä¸”ä¸ºAIæ•™å­¦ç³»ç»Ÿçš„å‘å±•å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17696v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17696.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Towards Top-Down Reasoning: An Explainable Multi-Agent Approach for Visual Question Answering**<br><sub>æœºæ„: Sun Yat-Sen University<br>è¿™é¡¹å·¥ä½œé€šè¿‡åˆ›æ–°æ€§åœ°ç»“åˆä¸‰ä¸ªä»£ç†æ¥æ¨¡æ‹Ÿäººç±»è®¤çŸ¥ä¸­çš„è‡ªé¡¶å‘ä¸‹æ¨ç†è¿‡ç¨‹ï¼Œå¹¶å¼•å…¥äº†å¤šè§†è§’çŸ¥è¯†åº“çš„æ¦‚å¿µï¼Œæ˜¾è‘—æå‡äº†VQAæ¨¡å‹çš„è¡¨ç°åŠ›å’Œè§£é‡Šèƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17331v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17331.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **LLaFS: When Large-Language Models Meet Few-Shot Segmentation**<br><sub>æœºæ„: Singapore University of Technology and Design, Zhejiang University <br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å°æ ·æœ¬å›¾åƒåˆ†å‰²æ¡†æ¶ï¼Œå¹¶è§£å†³äº†è®©LLMsç†è§£å’Œæ‰§è¡Œè§†è§‰ä»»åŠ¡çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚é€šè¿‡å®šåˆ¶æŒ‡å¯¼å’Œç»†ç²’åº¦ä¸Šä¸‹æ–‡æŒ‡å¯¼ç›¸ç»“åˆçš„æ–¹æ³•ï¼Œå®ç°äº†é«˜è´¨é‡çš„å°æ ·æœ¬åˆ†å‰²ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16926v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16926.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/lanyunzhu99/LLaFS)</div> |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Training Chain-of-Thought via Latent-Variable Inference**<br><sub>æœºæ„: Google<br>æœ¬è®ºæ–‡å¼€å‘äº†ä¸€ç§åŸºäºMCMC-EMçš„å¾®è°ƒç­–ç•¥ï¼Œé€šè¿‡å¹³å‡ç†ç”±å¸®åŠ©LLMsç”Ÿæˆæ­£ç¡®çš„ç­”æ¡ˆï¼Œå…·æœ‰æ½œåœ¨çš„æ¨å¹¿åº”ç”¨çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02179v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2312.02179.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Prompting in Autoregressive Large Language Models**<br><sub>æœºæ„: George Mason University<br>æœ¬è®ºæ–‡ä¸ºè‡ªå›å½’å¤§å‹è¯­è¨€æ¨¡å‹çš„æç¤ºæŠ€æœ¯é¢†åŸŸæä¾›äº†ä¸€ä¸ªç´§å‡‘çš„æ–‡çŒ®ç»¼è¿°ï¼Œå¹¶æŒ‡å‡ºäº†ä¸€äº›å°šæœªè§£å†³çš„æŒ‘æˆ˜å’Œå¼€æ”¾æ€§é—®é¢˜ï¼Œä¸ºæœªæ¥ç ”ç©¶æä¾›äº†æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03740v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2312.0374.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up?**<br><sub>æœºæ„: Nanyang Technological University<br>è¿™ç¯‡ç»¼è¿°æ–‡ç« æä¾›äº†å¯¹å¼€æºLLMsåœ¨å¤šä»»åŠ¡é¢†åŸŸç›¸è¾ƒChatGPTçš„æ€§èƒ½è¯„ä¼°çš„è€ƒå¯Ÿï¼Œçªå‡ºäº†ç›®å‰å¼€æºLLMsçš„å¼ºé¡¹å’Œæ½œåœ¨é—®é¢˜ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶å’Œå¼€å‘æä¾›äº†å¯ç¤ºã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜æ€»ç»“äº†ä¼—å¤šçš„æœ€ä½³å®è·µå’ŒæŒ‘æˆ˜ï¼Œæ˜¾ç¤ºå‡ºå¼€æºé¢†åŸŸåœ¨ä¸€å®šç¨‹åº¦ä¸Šæœ‰æœ›ç¼©å°ä¸å•†ä¸šæ¨¡å‹ä¹‹é—´çš„å·®è·ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16989v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16989.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **RELIC: Investigating Large Language Model Responses using Self-Consistency**<br><sub>æœºæ„: ETH Zurich<br>RELICæ˜¯ä¸€ä¸ªäº¤äº’å¼ç³»ç»Ÿï¼Œå®ƒé€šè¿‡å¤šæ ·æœ¬çš„äº‹å®ä¸€è‡´æ€§æ£€éªŒï¼Œå¸®åŠ©ç”¨æˆ·éªŒè¯å’ŒæŒ‡å¯¼LLMsç”Ÿæˆçš„æ–‡æœ¬ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16842v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16842.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Graph Prompt Learning: A Comprehensive Survey and Beyond**<br><sub>æœºæ„: The Chinese University of Hong Kong, Hong Kong University of Science and Technology, Fudan University  <br>è®ºæ–‡æ˜¯å…³äºå›¾æç¤ºå­¦ä¹ çš„ç»¼åˆæ€§è°ƒç ”ï¼Œæ¶µç›–äº†AGIåœ¨å›¾æ•°æ®å¤„ç†æ–¹é¢é¢ä¸´çš„æŒ‘æˆ˜ä»¥åŠå¦‚ä½•é€šè¿‡å›¾æç¤ºå­¦ä¹ æ¥å®ç°AGIæŠ€æœ¯çš„è·¨æ¨¡æ€ã€è·¨åŸŸå’Œè·¨ä»»åŠ¡é€‚ç”¨æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16534v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16534.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/WxxShirley/Awesome-Graph-Prompt)</div> |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **RankingGPT: Empowering Large Language Models in Text Ranking with Progressive Enhancement**<br><sub>æœºæ„: Alibaba Group<br>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç”¨äºæ–‡æœ¬æ’åºçš„äºŒé˜¶æ®µè®­ç»ƒæ¨¡å‹ï¼Œç»“åˆäº†å¼±ç›‘ç£é¢„è®­ç»ƒå’Œç›‘ç£ç»†åŒ–è®­ç»ƒï¼Œé€šè¿‡åœ¨ä¸æŸå®³é¢„è®­ç»ƒç›Šå¤„çš„åŸºç¡€ä¸Šå¢å¼ºæ¨¡å‹ç»†åŒ–è®­ç»ƒæ€§èƒ½ï¼Œå®Œæˆäº†ä»é¢„è®­ç»ƒåˆ°ç»†åŒ–è®­ç»ƒçš„å¹³æ»‘è¿‡æ¸¡ï¼Œå¹¶åœ¨å®éªŒä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16720v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1672.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine**<br><sub>æœºæ„: Microsoft<br>æœ¬æ–‡é€šè¿‡ç³»ç»Ÿçš„æç¤ºå·¥ç¨‹æ–¹æ³•æ¢è®¨äº†åœ¨æ— éœ€ä¸“å®¶ç›‘ç£çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•æŒ‡å¯¼é€šç”¨çš„åŸºç¡€æ¨¡å‹åœ¨ä¸“ä¸šä»»åŠ¡ä¸Šå‘æŒ¥ä¸“å®¶çº§åˆ«çš„èƒ½åŠ›ï¼Œå…·ä½“ä»¥åŒ»å­¦é¢†åŸŸä¸ºæ¡ˆä¾‹ç ”ç©¶ã€‚æ‰€æå‡ºçš„Medpromptç­–ç•¥è¯æ˜äº†å…¶åœ¨å¢å¼ºåŸºç¡€æ¨¡å‹ä¸“ä¸šèƒ½åŠ›æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ï¼Œå¹¶å±•ç¤ºäº†å¹¿æ³›é€‚ç”¨äºå¤šä¸ªå­¦ç§‘çš„å¯èƒ½æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16452v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16452.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation**<br><sub>æœºæ„: Alibaba Group<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåˆ©ç”¨æ‰©æ•£æ¨¡å‹è¿›è¡Œè§’è‰²åŠ¨ç”»çš„æ–°æ¡†æ¶â€œAnimate Anyoneâ€ã€‚è¯¥æ¡†æ¶é€šè¿‡ReferenceNetä¿æŒå¤–è§‚ä¸€è‡´æ€§ï¼Œå¹¶é€šè¿‡å§¿æ€å¼•å¯¼å™¨ä¸æ—¶é—´å±‚ç¡®ä¿åŠ¨ç”»çš„å¯æ§æ€§ä¸è¿ç»­æ€§ï¼Œå–å¾—äº†å…ˆè¿›çš„è§’è‰²åŠ¨ç”»ç”Ÿæˆç»“æœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17117v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17117.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/HumanAIGC/AnimateAnyone)</div><div style='min-width:85px;'>[![Blog](https://img.shields.io/badge/Blog-Posts-yellow?logo=rss)](https://humanaigc.github.io/animate-anyone/)</div> |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **AvatarGPT: All-in-One Framework for Motion Understanding, Planning, Generation and Beyond**<br><sub>ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåˆ›æ–°çš„ï¼Œä¸€ä½“åŒ–çš„æ¡†æ¶AvatarGPTï¼Œç”¨äºå¤„ç†ç†è§£ã€è§„åˆ’ä»¥åŠç”Ÿæˆäººç±»åŠ¨ä½œç›¸å…³çš„é«˜çº§å’Œä½çº§ä»»åŠ¡ï¼Œå±•ç°å‡ºé•¿æ—¶é—´è¿åŠ¨åˆæˆçš„èƒ½åŠ›å’Œå‡å°‘æ‰‹åŠ¨å¹²é¢„çš„å¯èƒ½æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16468v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16468.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Beyond Hallucinations: Enhancing LVLMs through Hallucination-Aware Direct Preference Optimization**<br><sub>æœºæ„: Shanghai AI Laboratory<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„ç­–ç•¥æ¥ä¼˜åŒ–LVLMså¹¶å‡å°‘å¹»è§‰ç°è±¡ï¼ŒåŒæ—¶ä»‹ç»äº†ä¸€ç§æ–°çš„è¯„ä¼°æ–¹æ³•æ¥æ›´å…¨é¢åœ°è¡¡é‡å¹»è§‰ç°è±¡ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16839v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16839.md)  |
| <span style='display: inline-block; width: 42px;'>11-27</span> | **RoboGPT: an intelligent agent of making embodied long-term decisions for daily instruction tasks**<br><sub>æœºæ„: Chinese Academy of Sciences, Peking University<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªåä¸ºRoboGPTçš„æ™ºèƒ½ä½“ï¼Œè¯¥æ™ºèƒ½ä½“ç”¨äºåˆ¶å®šæ‰§è¡Œæ—¥å¸¸æŒ‡ä»¤ä»»åŠ¡çš„é•¿æœŸå†³ç­–ã€‚è¯¥æ™ºèƒ½ä½“é€šè¿‡ä¸€é¡¹æ–°çš„æœºå™¨äººæ•°æ®é›†ï¼Œç»“åˆäº†LLMsçš„é€šç”¨çŸ¥è¯†å’Œæœºå™¨äººé¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†ï¼Œå¹¶å¼•å…¥äº†Re-Planæ¨¡å—å’ŒRoboSkillæ¨¡å—ä»¥å¢å¼ºä»»åŠ¡è§„åˆ’çš„é€»è¾‘æ€§å’Œé€‚åº”æ€§ã€‚åœ¨ALFREDåŸºå‡†æµ‹è¯•å’Œæ³›åŒ–ä»»åŠ¡ä¸Šï¼ŒRoboGPTä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.15649v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.15649.md)  |
| <span style='display: inline-block; width: 42px;'>11-25</span> | **Faster Minimum Bayes Risk Decoding with Confidence-based Pruning**<br><sub>æœºæ„: University of Cambridge<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç”¨äºMBRè§£ç çš„ç®—æ³•ï¼Œè¯¥ç®—æ³•é€šè¿‡åœ¨æ ·æœ¬ä¼°è®¡ä¸­é€æ¸å¢åŠ æ ·æœ¬æ•°é‡å¹¶ä½¿ç”¨ç½®ä¿¡åº¦å‰ªææ¥å‡å°‘ç”¨æˆ·å‡½æ•°è°ƒç”¨ã€‚åœ¨ä¿æŒå‡†ç¡®åº¦çš„åŒæ—¶ï¼Œè¯¥ç®—æ³•æ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œå¹¶é€šè¿‡ä¸‰ç§è¯­è¨€å¯¹çš„NMTå®éªŒå¾—åˆ°äº†éªŒè¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.14919v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.14919.md)  |
| <span style='display: inline-block; width: 42px;'>11-24</span> | **Data-Efficient Alignment of Large Language Models with Human Feedback Through Natural Language**<br><sub>æœºæ„: Amazon<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªæœ‰æ•ˆçš„CnRæ–¹æ³•ï¼Œå®ƒèƒ½å¤Ÿé€šè¿‡ä½¿ç”¨è‡ªç„¶è¯­è¨€çš„ç²¾ç»†åé¦ˆå’Œå“åº”ä¿®æ­£ï¼Œé«˜æ•ˆåœ°æ ¡å‡†LLMsä»¥ç¬¦åˆäººç±»é¢„æœŸã€‚é€šè¿‡ç›¸å¯¹è¾ƒå°‘çš„äººç±»åé¦ˆæ•°æ®ï¼Œæ­¤æ–¹æ³•å¯ä»¥æ˜¾è‘—æ”¹å–„å³ä½¿æ˜¯é¡¶å°–LLMsçš„å“åº”è´¨é‡ï¼Œå¦‚ChatGPTã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.14543v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.14543.md)  |
| <span style='display: inline-block; width: 42px;'>11-24</span> | **Calibrated Language Models Must Hallucinate**<br><sub>æœºæ„: Microsoft Research<br>è¯¥æ–‡ç« å±•ç¤ºäº†é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹åœ¨å……åˆ†æ ¡å‡†çš„æ¡ä»¶ä¸‹ï¼Œå¿…ç„¶äº§ç”Ÿå¹»è§‰çš„ç»Ÿè®¡æ ¹æºï¼Œå¹¶ä»‹ç»äº†é¢„æµ‹æ€§èƒ½è‰¯å¥½çš„æ¨¡å‹å›ºæœ‰çš„å¹»è§‰äº§ç”Ÿæœºåˆ¶ã€‚åŒæ—¶ï¼Œæ–‡ç« è¿˜æä¾›äº†å¹»è§‰äº§ç”Ÿç‡çš„ä¸‹ç•Œä¼°ç®—ï¼Œå¹¶æ¢è®¨äº†ä¸åŒç±»å‹äº‹å®äº§ç”Ÿå¹»è§‰çš„å¯èƒ½æ€§ï¼ŒæŒ‡å‡ºäº†æœªæ¥å‡è½»ç‰¹å®šç±»å‹å¹»è§‰çš„å¯èƒ½æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.14648v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.14648.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes**<br><sub>æœºæ„: ASRI<br>LucidDreameræ˜¯ä¸€ä¸ªèƒ½å¤Ÿç”¨äºç”Ÿæˆé€¼çœŸè€Œä¸”åˆ†è¾¨ç‡æ›´é«˜çš„3Dåœºæ™¯çš„æ¨¡å‹ã€‚å®ƒä¼˜äºç°æœ‰çš„åœºæ™¯ç”Ÿæˆæ¨¡å‹ï¼Œå› ä¸ºå®ƒä¸ä¾èµ–ç‰¹å®šçš„è®­ç»ƒæ•°æ®é›†ï¼Œå¹¶èƒ½å¤Ÿé€‚åº”å¤šç§è¾“å…¥æ ·å¼ã€‚LucidDreameré€šè¿‡çº¦æŸç‚¹äº‘çš„ç§»åŠ¨å’Œä½¿ç”¨æ’å€¼ç®—æ³•ï¼Œå…‹æœäº†å½¢çŠ¶æ‰­æ›²å’Œç‚¹äº‘ä¸å›¾åƒé”™ä½çš„é—®é¢˜ï¼Œä»è€Œåœ¨æ“çºµ3Dç©ºé—´ä¸­çš„ç‚¹äº‘æ—¶ä¿æŒäº†åœºæ™¯çš„çœŸå®æ„Ÿå’Œä¸€è‡´æ€§ã€‚åœ¨å®éªŒä¸­æ˜æ˜¾å±•ç¤ºäº†å…¶ä¼˜è¶Šæ€§å’Œé«˜æ³›åŒ–èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13384v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13384.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach**<br><sub>æœºæ„: Chinese Academy of Sciences<br>LLaMACæ¡†æ¶å±•ç¤ºäº†åŸºäºLLMçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨é•¿æœŸè§„åˆ’ã€æ•°å­¦æ¨ç†ã€ä¼˜åŒ–é—®é¢˜å’Œç©ºé—´æ¨ç†æ–¹é¢çš„å“è¶Šè¡¨ç°ï¼Œå¹¶ä¸”å‡å°‘äº†å¤§è§„æ¨¡å¤šæ™ºèƒ½ä½“åä½œçš„è®¿é—®æˆæœ¬ã€‚éšç€LLMçš„è¿›ä¸€æ­¥æå‡å’Œæ›´å¤šåä½œæ¡†æ¶çš„å‡ºç°ï¼Œå¤šæ™ºèƒ½ä½“åä½œé¢†åŸŸå°†è¿æ¥æ–°çš„å‘å±•æœºé‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13884v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13884.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **Diffusion Model Alignment Using Direct Preference Optimization**<br><sub>æœºæ„: Nikhil Naik, Stanford University<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºDiffusion-DPOçš„æ–¹æ³•ï¼Œå…¶é€šè¿‡ç›´æ¥ä¼˜åŒ–åŸºäºäººç±»æ¯”è¾ƒæ•°æ®çš„æ¨¡å‹æ¥å®ç°å¯¹æ‰©æ•£æ¨¡å‹ä¸äººç±»åå¥½çš„å¯¹é½ã€‚æ­¤å¤–ï¼Œæ–‡ç« ä¹Ÿæ¢ç´¢äº†åŸºäºAIåé¦ˆçš„è®­ç»ƒï¼Œå–å¾—äº†ä¸åŸºäºäººç±»åå¥½è®­ç»ƒç›¸åª²ç¾çš„æˆç»©ã€‚è¿™æ˜æ˜¾æå‡äº†æ¨¡å‹åœ¨è§†è§‰å¸å¼•åŠ›å’Œæ–‡æœ¬å¯¹é½æ–¹é¢çš„æ€§èƒ½ï¼Œä¸ºåˆ©ç”¨AIåé¦ˆæ‰©å±•æ‰©æ•£æ¨¡å‹å¯¹é½æ–¹æ³•æä¾›äº†æ–°çš„é€”å¾„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12908v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12908.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs**<br><sub>æœºæ„: Google Research<br>æ–‡ç« æå‡ºäº†ä¸€ç§åä¸ºZipLoRAçš„æ–°ç­–ç•¥ï¼Œæ—¨åœ¨é€šè¿‡ä¸€ä¸ªä¼˜åŒ–è¿‡ç¨‹æœ‰æ•ˆåœ°åˆå¹¶ç‹¬ç«‹è®­ç»ƒçš„ä¸»é¢˜å’Œé£æ ¼LoRAsï¼Œä»è€Œèƒ½å¤Ÿç”Ÿæˆä»»ä½•ç”¨æˆ·æä¾›çš„ä¸»é¢˜é£æ ¼çš„ç»„åˆã€‚ZipLoRAå¯¹ç”Ÿæˆä»»ä½•ç‰¹å®šä¸»é¢˜å’Œé£æ ¼çš„å›¾åƒè¿™ä¸€å¼€æ”¾æ€§ç ”ç©¶é—®é¢˜æä¾›äº†åˆ›æ–°çš„è§£å†³æ–¹æ¡ˆï¼Œä¸”ç”±äºå…¶æ— éœ€æ‰‹åŠ¨è¶…å‚æ•°è°ƒæ•´ï¼Œä½¿ç”¨èµ·æ¥æ›´åŠ ç®€ä¾¿é«˜æ•ˆã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨ä¿æŒä¸»é¢˜å’Œé£æ ¼çœŸå®æ€§çš„åŒæ—¶ï¼Œç›¸æ¯”äºç°æœ‰æ–¹æ³•å’Œå…¶ä»–åŸºæœ¬æ–¹æ³•è€Œè¨€ï¼Œå…·æœ‰æ›´å¥½çš„ç”Ÿæˆè´¨é‡å’Œé²æ£’æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13600v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.136.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **GAIA: a benchmark for General AI Assistants**<br><sub>æœºæ„: FAIR, Meta<br>GAIA æ˜¯ä¸€é¡¹é’ˆå¯¹é€šç”¨äººå·¥æ™ºèƒ½åŠ©ç†çš„åŸºå‡†æµ‹è¯•ï¼Œå…¶ç›®çš„åœ¨äºæå‡ºçœŸå®ä¸–ç•Œçš„æŒ‘æˆ˜æ€§é—®é¢˜ï¼Œå¹¶é¿å¼€ä¼ ç»Ÿ LLMs è¯„ä»·ä¸­çš„è®¸å¤šé™·é˜±ã€‚è¯¥åŸºå‡†æµ‹è¯•å¼ºè°ƒä»»åŠ¡å¯¹äººç±»ç®€å•è€Œå¯¹AIéš¾åº¦è¾ƒå¤§ï¼Œä»¥æ­¤æ¥è¯„ä¼°AIçš„æ‰§è¡Œå¤æ‚è¡ŒåŠ¨åºåˆ—çš„å‡†ç¡®èƒ½åŠ›ï¼Œè¿™äº›ä»»åŠ¡åœ¨è®¾è®¡ä¸Šæ— æ³•ç®€å•åœ°é€šè¿‡æš´åŠ›æ–¹æ³•å¾—ä»¥è§£å†³ã€‚GAIA è¿˜è€ƒè™‘äº†å¦‚ä½•æ‰©å±•åŸºå‡†æµ‹è¯•ï¼Œå¹¶æ¢è®¨äº†ä¸€äº›æœ€å…ˆè¿›çš„åŠ©ç†çš„æˆåŠŸä¸çŸ­æ¿ï¼Œå±•ç¤ºäº†å¢å¼º LLMs çš„æ½œåŠ›ã€‚æœ€ç»ˆï¼Œæ–‡ç« æ—¨åœ¨è®¾ç«‹ä¸€ä¸ªå¼€å‘è€…é—®é¢˜é›†ï¼Œä¸ºäººå·¥æ™ºèƒ½ç ”ç©¶æä¾›ä¸€ä¸ªå¯æ‰©å±•çš„åŸºå‡†æµ‹è¯•å¹³å°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12983v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12983.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **Probabilistic Tree-of-thought Reasoning for Answering Knowledge-intensive Complex Questions**<br><sub>æœºæ„: Tsinghua University<br>æ–‡ç« æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¦‚ç‡æ ‘çŠ¶æ¨ç†ï¼ˆProbTreeï¼‰æ–¹æ³•ï¼Œé€šè¿‡æ¢ç´¢LLMåœ¨å›ç­”çŸ¥è¯†å¯†é›†å‹å¤æ‚é—®é¢˜æ—¶çš„èƒ½åŠ›ï¼Œå¹¶å°†ä¸ç¡®å®šæ€§å¼•å…¥æ¨ç†è¿‡ç¨‹ï¼Œåœ¨ç»Ÿä¸€æ¡†æ¶ä¸­æ•´åˆäº†å¤–éƒ¨å’Œå‚æ•°çŸ¥è¯†ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13982v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13982.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **FusionFrames: Efficient Architectural Aspects for Text-to-Video Generation Pipeline**<br><sub>æœºæ„: Sber AI<br>æ€»ä½“è€Œè¨€ï¼Œè¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°å‹ä¸¤é˜¶æ®µæ½œåœ¨æ‰©æ•£çš„æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæ¶æ„ï¼Œè§£å†³äº†å…³é”®å¸§åˆæˆå’Œæ’å€¼å¸§ç”Ÿæˆä¸­å­˜åœ¨çš„é—®é¢˜ï¼Œé€šè¿‡ä½¿ç”¨ç‹¬ç«‹çš„æ—¶åŸŸå—å’Œæœ‰æ•ˆçš„æ’å€¼æ¶æ„ï¼Œå‡å°‘äº†è®¡ç®—æˆæœ¬ï¼Œå¹¶åœ¨å¤šä¸ªè´¨é‡æŒ‡æ ‡ä¸Šå–å¾—äº†ä¼˜äºç°æœ‰æŠ€æœ¯çš„è¡¨ç°ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜é’ˆå¯¹è§†é¢‘è§£ç å™¨è®¾è®¡äº†ä¸åŒçš„æ¶æ„é€‰é¡¹ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–äº†è§†é¢‘çš„ä¸€è‡´æ€§å’Œæ•´ä½“è´¨é‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13073v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13073.md)  |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **Visual In-Context Prompting**<br><sub>æœºæ„: HKUST, Microsoft Research<br>æœ¬è®ºæ–‡æå‡ºäº†DINOvï¼Œä¸€ä¸ªæ–°çš„è§†è§‰ä¸Šä¸‹æ–‡å†…æç¤ºæ¡†æ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤šæ ·åŒ–çš„è§†è§‰æç¤ºï¼Œä½¿ç”¨æ— æ ‡ç­¾æ•°æ®ï¼Œå¹¶åœ¨å¤šä¸ªä»»åŠ¡ä¸­è¾¾åˆ°å¾ˆå¥½çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13601v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13601.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/UX-Decoder/DINOv)</div> |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms**<br><sub>æœºæ„: Princeton University<br>æœ¬è®ºæ–‡çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼šåœ¨å¼€æºæ¨¡å‹ä¸Šå¾®è°ƒä¸åŒå¤§å°å’Œé£æ ¼çš„æŒ‡ä»¤æ•°æ®é›†ï¼Œè¯„ä¼°å¾®è°ƒæ¨¡å‹åœ¨ä¸åŒçš„è¯„ä¼°èŒƒå¼ä¸‹çš„è¡¨ç°ï¼Œå¹¶ä¸”å‘ç°è¾ƒå°‘çš„æ ·æœ¬ï¼ˆç‰¹åˆ«æ˜¯å½“è¿™äº›æ ·æœ¬ç»“åˆäº†ä¸åŒæ¥æºå’Œé£æ ¼æ—¶ï¼‰è¶³ä»¥åœ¨ä¸åŒç±»å‹çš„è¯„ä¼°ä¸­è·å¾—è‰¯å¥½çš„æ€§èƒ½ã€‚è¿™è¡¨æ˜åœ¨åŸ¹å…»LLMsçš„æŒ‡ä»¤éµä»èƒ½åŠ›æ—¶ï¼Œâ€œå°‘å³æ˜¯å¤šâ€ï¼Œä¸”é€šè¿‡ç²¾å¿ƒé€‰æ‹©å¾®è°ƒæ ·æœ¬ï¼Œå¯ä»¥ä½¿æ¨¡å‹åœ¨æ‰§è¡ŒæŒ‡ä»¤èƒ½åŠ›ä¸Šå¾—åˆ°æ˜¾è‘—æå‡ã€‚è¿™ä¸€å‘ç°å¯¹äºå¦‚ä½•æœ‰æ•ˆåœ°å¾®è°ƒLLMsä»¥åŠå¦‚ä½•è¯„ä¼°å®ƒä»¬çš„å®ç”¨æ€§å…·æœ‰é‡è¦æ„ä¹‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13133v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13133.md)  |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **XAGen: 3D Expressive Human Avatars Generation**<br><sub>æœºæ„: National University of Singapore, ByteDance<br>ç ”ç©¶æå‡ºäº†XAGenæ¨¡å‹ï¼Œå®ƒæ˜¯é¦–ä¸ªèƒ½å¤Ÿç”Ÿæˆå…¨é¢å¯æ§3Däººç±»åŒ–èº«çš„GANæ¨¡å‹ã€‚XAGenåœ¨ç»†ç²’åº¦å±æ€§æ§åˆ¶ä¸Šå…·æœ‰ç‹¬ç«‹çš„èƒ½åŠ›ï¼Œå¹¶é€šè¿‡å¤šå°ºåº¦å’Œå¤šéƒ¨åˆ†çš„3Dè¡¨ç¤ºä¸æ¸²æŸ“æŠ€æœ¯æå‡äº†é¢éƒ¨å’Œæ‰‹éƒ¨çš„ç”Ÿæˆè´¨é‡ã€‚å®éªŒç»“æœè¯æ˜XAGenåœ¨å¤–è§‚è´¨é‡ã€æ§åˆ¶èƒ½åŠ›å’Œæ•°æ®åˆ©ç”¨ç‡æ–¹é¢éƒ½è¶…è¿‡äº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæ¨è¿›äº†3Dè™šæ‹ŸåŒ–èº«ç”ŸæˆæŠ€æœ¯çš„å‘å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13574v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13574.md)  |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **Enhancing Summarization Performance through Transformer-Based Prompt Engineering in Automated Medical Reporting**<br><sub>æœºæ„: Utrecht University<br>è¿™é¡¹ç ”ç©¶éªŒè¯äº†åœ¨è‡ªåŠ¨åŒ–åŒ»ç–—æŠ¥å‘Šä¸­åº”ç”¨åŸºäºè½¬æ¢å™¨çš„æç¤ºå·¥ç¨‹å¯ä»¥æé«˜æ‘˜è¦æ€§èƒ½ã€‚å°½ç®¡å­˜åœ¨ä¸€äº›å±€é™æ€§ï¼Œä½†ç ”ç©¶æå‡ºçš„æ–¹æ³•è¯æ˜äº†åœ¨æç¤ºåˆ¶å®šæ—¶åŠ å…¥ç¤ºä¾‹å’Œä¸Šä¸‹æ–‡ä¿¡æ¯çš„æ•ˆç”¨ï¼Œå¹¶ä¸”æŒ‡å‡ºäº†æœªæ¥å·¥ä½œçš„æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13274v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13274.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **How Capable Can a Transformer Become? A Study on Synthetic, Interpretable Tasks**<br><sub>æœºæ„: University of Pennsylvania, MIT<br>æœ¬æ–‡é€šè¿‡è®¾è®¡åˆæˆæ•°æ®ç”Ÿæˆè¿‡ç¨‹å’Œç³»ç»Ÿæ€§å®éªŒï¼Œä»¥è¯„ä¼°å’Œç†è§£è‡ªå›å½’Transformeræ¨¡å‹åœ¨ç»„åˆå…¶åŸå§‹èƒ½åŠ›æ–¹é¢çš„æ½œåŠ›ã€‚ç ”ç©¶ç»“æœçªæ˜¾äº†æ¨¡å‹å­¦ä¹ ç»„åˆç»“æ„çš„èƒ½åŠ›ï¼Œæ­ç¤ºäº†è®­ç»ƒæ•°æ®å¯¹æ­¤èƒ½åŠ›çš„å½±å“ä»¥åŠæ¨¡å‹å†…éƒ¨æ³¨æ„åŠ›å±‚åœ¨ç»„åˆå­¦ä¹ è¿‡ç¨‹ä¸­çš„é‡è¦æ€§ã€‚è¿™æˆ–è®¸ä¸ºè¯„ä¼°å’Œæé«˜ç°ä»£ç¥ç»ç½‘ç»œå¯¹çœŸå®ä¸–ç•Œæ•°æ®çš„ç†è§£å’Œåº”ç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨å…¶å¯èƒ½é¢ä¸´å‰æ‰€æœªè§çš„ä»»åŠ¡æ—¶ï¼Œæä¾›äº†æ–°çš„è§è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12997v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12997.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Oasis: Data Curation and Assessment System for Pretraining of Large Language Models**<br><sub>æœºæ„: Chinese Academy of Sciences<br>æœ¬æ–‡æå‡ºçš„Oasisç³»ç»Ÿæ˜¯é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒçš„æ•°æ®æ•´ç†å’Œè¯„ä¼°é—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚Oasisé€šè¿‡å…¶äº¤äº’å¼çš„è‡ªå®šä¹‰æ•°æ®æ•´ç†æ¨¡å—ã€é’ˆå¯¹åå·®çš„æ¨¡å‹è¿‡æ»¤å™¨å’Œå…¨é¢çš„æ•°æ®è¯„ä¼°ç³»ç»Ÿï¼Œæ—¨åœ¨æé«˜æ•°æ®é›†çš„è´¨é‡å’Œå¤šæ ·æ€§ï¼ŒåŒæ—¶é™ä½å†…å­˜éœ€æ±‚å’Œèµ„æºæ¶ˆè€—ã€‚ç³»ç»Ÿçš„å®ç°ç«‹è¶³äºæå‡æ•°æ®å¤„ç†çš„çµæ´»æ€§å’Œè¯„ä¼°çš„å‡†ç¡®æ€§ï¼Œå¡«è¡¥äº†ç°æœ‰å·¥ä½œåœ¨å…¨é¢æ€§å’Œå¤šç»´åº¦è¯„ä¼°æ–¹é¢çš„ç©ºç™½ã€‚é€šè¿‡ç»¼åˆä½¿ç”¨äººç±»è¯„ä¼°ã€å¯å‘å¼åº¦é‡å’Œæœ€æ–°çš„å¤§å‹è¯­è¨€æ¨¡å‹å¦‚GPT-4è¿›è¡Œè´¨é‡è¯„ä¼°ï¼ŒOasiså±•ç°äº†å¯¹é¢„è®­ç»ƒæ•°æ®é›†è¿›è¡Œå…¨æ–¹ä½ä¼˜åŒ–çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12537v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12537.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Do Smaller Language Models Answer Contextualised Questions Through Memorisation Or Generalisation?**<br><sub>æœºæ„: University of Auckland<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ä»¥è¯„ä»·å°å‹è¯­è¨€æ¨¡å‹åœ¨é—®ç­”ä»»åŠ¡ä¸­ç­”æ¡ˆçš„ç”Ÿæˆæ˜¯å¦ä¸ºè®°å¿†æˆ–æ¦‚æ‹¬èƒ½åŠ›çš„ç»“æœã€‚é€šè¿‡è¯­ä¹‰ç›¸ä¼¼åº¦åˆ†æï¼Œç¡®å®šäº†ä¸å¤ªå¯èƒ½è¢«æ¨¡å‹è®°ä½ç­”æ¡ˆçš„è¯„ä¼°æ ·æœ¬ï¼Œå¹¶ç”¨å¢åŠ é¢å¤–è®­ç»ƒæ•°æ®é›†çš„æ–¹å¼ï¼Œé’ˆå¯¹ç‰¹å®šè¯„ä¼°å­é›†è¿›è¡Œäº†æ¨¡å‹æ€§èƒ½çš„ä¼˜åŒ–ã€‚æœ€ç»ˆï¼Œç ”ç©¶ç»“æœæ˜¾ç¤ºå¢åŠ äº†æ•°æ®é›†çš„æ¨¡å‹åœ¨ç‰¹å®šè¯„ä¼°æ•°æ®é›†ä¸Šæœ‰äº†æ˜¾è‘—æå‡ï¼Œå¹¶æ¨æ–­è¿™ç§æ”¹å–„ä¸æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›æœ‰å…³ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12337v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12337.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Prompting Frameworks for Large Language Models: A Survey**<br><sub>æœºæ„: Zhejiang University<br>è¿™é¡¹ç ”ç©¶æä¾›äº†ä¸€ä¸ªæ¡†æ¶ï¼Œå®ƒé€šè¿‡å®ç°æ–°çš„æŠ€æœ¯æ‰‹æ®µæ¥å¢å¼ºä¸LLMsçš„äº¤äº’ï¼ŒåŒ…æ‹¬æ”¹å–„ä¸ç¼–ç¨‹è¯­è¨€çš„å…¼å®¹æ€§ï¼Œä½¿èƒ½LLMsä½¿ç”¨å¤–éƒ¨å·¥å…·ï¼Œå¹¶ç»´æŠ¤å†å²äº¤äº’ä¿¡æ¯ï¼Œå¹¶ä»¥æ­¤æŒ‡å¯¼æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12785v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12785.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/lxx0628/Prompting-Framework-Survey)</div> |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **AcademicGPT: Empowering Academic Research**<br><sub>æœºæ„: International Digital Economy Academy<br>AcademicGPTé’ˆå¯¹å­¦æœ¯ç ”ç©¶çš„ç‰¹å®šéœ€æ±‚è¿›è¡Œäº†ä¼˜åŒ–ï¼Œé€šè¿‡ç»“åˆé’ˆå¯¹æ€§å¼ºçš„è®­ç»ƒæ•°æ®å’Œå¤šæ–¹é¢çš„åº”ç”¨å¼€å‘ï¼Œä¸ºå­¦æœ¯é¢†åŸŸæä¾›äº†å®è´¨æ€§çš„æ”¯æŒå’Œå·¥å…·ã€‚å®ƒæ ‡å¿—ç€å¤§å‹è¯­è¨€æ¨¡å‹ä¸ªæ€§åŒ–ä¸ä¸“ä¸šåŒ–å‘å±•çš„ä¸€ä¸ªé‡è¦æ­¥éª¤ï¼Œå¹¶æœ‰æœ›å¯¹å­¦æœ¯ç¤¾åŒºäº§ç”Ÿæ·±è¿œçš„å½±å“ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12315v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12315.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey**<br><sub>æœºæ„: Nanjing University<br>æ–‡ç« ä¸ºäº†è§£å†³LLMsåœ¨åº”å¯¹é•¿ä¸Šä¸‹æ–‡æ—¶çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç³»åˆ—æ–¹æ³•å’Œç»¼åˆåˆ†ç±»ä½“ç³»ï¼Œæé«˜äº†LLMsåœ¨æ³¨æ„åŠ›æœºåˆ¶ã€è®°å¿†æ•ˆç‡å’Œæœ€å¤§é•¿åº¦å¤„ç†ä¸Šçš„æ€§èƒ½ã€‚é€šè¿‡ç»¼åˆå›é¡¾å’Œåˆ†ç±»å­¦ç•Œæœ€è¿‘çš„è¿›å±•ï¼Œæœ¬æ–‡ä¸ºæœªæ¥çš„LLMsæ¶æ„è®¾è®¡å’Œä¼˜åŒ–æä¾›äº†æ¸…æ™°çš„æŒ‡å¯¼æ–¹å‘ã€‚ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12351v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12351.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Strivin0311/long-llms-learning)</div> |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Latent Lab: Large Language Models for Knowledge Exploration**<br><sub>æœºæ„: Department of Electrical Engineering and Computer Science, MIT<br>Latent Labä½œä¸ºä¸€ç§æ¢ç´¢å¤§å‹æ•°æ®é›†ä¸­ç›¸äº’è”ç³»å…³ç³»çš„åˆ›æ–°å’Œå¼ºå¤§å·¥å…·ï¼Œé€šè¿‡åˆ©ç”¨LLMså’Œè§†è§‰å¼•äººæ³¨ç›®çš„æ¥å£ï¼Œå®ƒè¶…è¶Šäº†å¸¸è§„æœç´¢çš„å±€é™æ€§ï¼Œæä¾›äº†ä¸€ä¸ªè¯­ä¹‰ä¸Šæœ‰æ„ä¹‰å’Œæƒ…å¢ƒæ„ŸçŸ¥çš„ä½“éªŒã€‚å¼ºè°ƒæ¢ç´¢çš„ä»·å€¼å’Œè¿­ä»£è®¾è®¡ï¼Œåœ¨ç›´è§‚åœ°è®¿é—®å¤§é‡ç›¸äº’è¿æ¥çš„ä¿¡æ¯æ–¹é¢å®ç°äº†ä¿¡æ¯æŠ€æœ¯ä¸“å®¶çš„é•¿æœŸè¿½æ±‚ï¼Œå¹¶é€šè¿‡AIè¾…åŠ©æ¢ç´¢å°†è¿™ä¸€æ„¿æ™¯å˜ä¸ºç°å®ï¼Œä¸ºæœªæ¥äººå·¥æ™ºèƒ½å…±åˆ›ç³»ç»Ÿçš„å‘å±•å¥ å®šäº†åŸºç¡€ï¼Œå¹¶ä¿ƒè¿›äº†æ›´ç›´è§‚å’Œé«˜æ•ˆçš„åˆä½œï¼Œæœ‰èƒ½åŠ›äº§ç”Ÿæ–°é¢–å’Œæœ‰å½±å“åŠ›çš„åˆ›é€ ç‰©ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13051v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13051.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **A Survey on Multimodal Large Language Models for Autonomous Driving**<br><sub>æœºæ„: Purdue University<br>è¯¥è®ºæ–‡å…¨é¢å›é¡¾äº†MLLMsåœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„åº”ç”¨ï¼Œè¡¨æ˜MLLMså…·å¤‡è§£æéæ–‡æœ¬æ•°æ®å’Œèåˆå¤šç§æ¨¡æ€ï¼ˆå¦‚è§†è§‰ã€è¯­è¨€ï¼‰çš„èƒ½åŠ›ï¼Œè¿™äº›èƒ½åŠ›å¯¹äºè¡Œä¸ºé¢„æµ‹å’ŒåŠ¨ä½œè§„åˆ’å°¤ä¸ºé‡è¦ã€‚é€šè¿‡åœ¨ä¸åŒçš„è‡ªåŠ¨é©¾é©¶ç¯èŠ‚ä¸­éƒ¨ç½²MLLMsï¼ˆå¦‚ç†è§£äº¤é€šåœºæ™¯ã€è§„åˆ’æ§åˆ¶ã€æ¨¡å¼ç”Ÿæˆï¼‰ï¼Œå¯ä»¥æ”¹å–„å†³ç­–æµç¨‹ï¼Œå¹¶å®ç°ç±»ä¼¼äººç±»çš„é©¾é©¶ç›´è§‰å’Œå†³ç­–æ¨¡å¼ï¼ŒåŒæ—¶æé«˜è½¦è¾†å¯¼èˆªå’Œè§„åˆ’çš„æ•ˆç‡å’Œå®‰å…¨æ€§ã€‚æ­¤å¤–ï¼Œæ¨¡å‹é€šè¿‡ä¸ºå¤šä¸ªä»»åŠ¡çš„é¢„è®­ç»ƒæä¾›äº†ä¸€ç§æ–°çš„å¯èƒ½æ€§ï¼Œè¿™å¯èƒ½ä¼šæ¨åŠ¨æŠŠæ™ºèƒ½ç³»ç»Ÿæ¨å‘äººå·¥æ™®éæ™ºèƒ½ï¼ˆAGIï¼‰çš„å‘å±•è·¯å¾„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12320v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1232.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks**<br><sub>æœºæ„: University of Cambridge<br>æœ¬æ–‡é’ˆå¯¹å¾®è°ƒå¯¹é¢„å®šä¹‰èƒ½åŠ›çš„å½±å“å¼€å±•äº†ä¸€é¡¹å…¨é¢çš„åˆ†æå’Œè¯„ä¼°ã€‚é€šè¿‡Tracrç¼–è¯‘å¼çš„èƒ½åŠ›è®¾è®¡å’ŒåŸºäºPCFGçš„å­¦ä¹ å¼èƒ½åŠ›è®¾è®¡ï¼Œæ–‡ç« è¯¦ç»†æ¢è®¨äº†å¾®è°ƒè¿‡ç¨‹ä¸­åµŒå…¥ç‰¹å¾çš„ç›¸å…³æ€§ï¼Œæå‡ºäº†reFTæ¥å¼ºåŒ–åˆ†æå¾®è°ƒå½±å“çš„æ·±åº¦ã€‚æœ¬ç ”ç©¶çš„å‘ç°æ”¹è¿›äº†å¯¹å¾®è°ƒå½±å“æœºç†çš„ç†è§£ï¼Œå¹¶ä¸ºåç»­çš„æ¨¡å‹è®¾è®¡å’Œå¾®è°ƒç­–ç•¥æä¾›äº†å®è¯æ”¯æŒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12786v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12786.md)  |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **GPQA: A Graduate-Level Google-Proof Q&A Benchmark**<br><sub>æœºæ„: New York University<br>GPQA æ•°æ®é›†æä¾›äº†ä¸€ä¸ªç”¨äºæµ‹è¯• AI ç³»ç»Ÿåœ¨å¤„ç†éœ€æ·±åº¦ç†è§£å’Œæ¨ç†èƒ½åŠ›çš„å¤æ‚é—®é¢˜ä¸Šçš„èƒ½åŠ›çš„åŸºå‡†ã€‚é€šè¿‡ä¸¥æ ¼çš„é—®é¢˜è´¨é‡æ§åˆ¶å’Œä¸“å®¶çº§åˆ«çš„éš¾åº¦ï¼Œå®ƒå¯èƒ½ä¿ƒè¿›äººç±»ä¸“å®¶ä¸ AI ç³»ç»Ÿåˆä½œçš„æ–¹æ³•å‘å±•ï¼Œå¹¶æ¨åŠ¨ AI ç³»ç»Ÿè®¾è®¡çš„è¿›æ­¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12022v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12022.md)  |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **Continual Learning: Applications and the Road Forward**<br><sub>æœºæ„: KU Leuven<br>è®ºæ–‡ç»¼è¿°äº†å½“å‰çš„æŒç»­å­¦ä¹ ç ”ç©¶ç°çŠ¶ï¼ŒæŒ‡å‡ºäº†å…¶åœ¨è®°å¿†é™åˆ¶æ¡ä»¶ä¸‹ç ”ç©¶è¾ƒå¤šè€Œå¿½è§†è®¡ç®—æˆæœ¬çš„é—®é¢˜ï¼Œå¹¶æå‡ºäº†å››ä¸ªæœ‰å‰é€”çš„ç ”ç©¶æ–¹å‘ã€‚è¿™äº›æ–¹å‘åŒ…æ‹¬ï¼š1) çœŸå®ä¸–ç•Œæ•°æ®å¤„ç†çš„æŒ‘æˆ˜ï¼Œ2) è®¡ç®—æˆæœ¬çš„è€ƒè™‘ï¼Œä»¥åŠå…¶ä»–å¦‚ä½•è·å–æ•°æ®å’Œç†è®ºç†è§£æ–¹é¢çš„å…³æ³¨ç‚¹ã€‚è®ºæ–‡ä¸»å¼ æœªæ¥çš„CLç®—æ³•åº”åœ¨å‡å°‘å¯¹å®Œå…¨æ ‡è®°å’Œå°é—­ä¸–ç•Œå‡è®¾çš„ä¾èµ–ä¸Šåšå‡ºå®è´¨æ€§çš„è¿›å±•ï¼Œä»¥ä½¿CLæˆä¸ºè§£å†³å®é™…æœºå™¨å­¦ä¹ é—®é¢˜çš„ä¸€ä¸ªæœ‰æ•ˆå·¥å…·ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11908v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11908.md)  |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **Assessing Prompt Injection Risks in 200+ Custom GPTs**<br><sub>æœºæ„: Northwestern University<br>è¯¥è®ºæ–‡ç€é‡ç ”ç©¶äº†è‡ªå®šä¹‰GPTæ¨¡å‹ä¸­çš„å®‰å…¨é£é™©ï¼Œå°¤å…¶æ˜¯æç¤ºæ³¨å…¥æ”»å‡»ã€‚ç ”ç©¶è€…ä»¬æå‡ºäº†ä¸€ä¸ªåŒ…å«æ‰«æã€æ³¨å…¥æ•Œæ„æç¤ºå’Œæå–ç›®æ ‡ä¿¡æ¯ä¸‰ä¸ªæ­¥éª¤çš„æ”»å‡»æ–¹æ³•ï¼Œå¹¶é€šè¿‡å®æ–½è¯„ä¼°å‘ç°è‡ªå®šä¹‰GPTæ¨¡å‹å­˜åœ¨ä¸¥é‡çš„ç³»ç»Ÿæç¤ºæå–å’Œæ–‡ä»¶æ³„éœ²æ¼æ´ã€‚è¿™äº›å‘ç°çªå‡ºäº†è‡ªå®šä¹‰GPTæ¨¡å‹ä¸­çš„å…³é”®å®‰å…¨ç¼ºé™·ï¼Œå¹¶æŒ‡å‡ºäº†æå‡è¿™äº›æ¨¡å‹å®‰å…¨æ€§ç»“æ„çš„å¿…è¦æ€§ã€‚æ­¤å¤–ï¼Œçº¢é˜Ÿè¯„ä¼°æ¸…æ¥šåœ°æ˜¾ç¤ºå‡ºï¼Œç°æœ‰é˜²æŠ¤æªæ–½å¹¶ä¸è¶³å¤Ÿå¼ºå¤§ï¼Œç”šè‡³æœ‰æ—¶å€™æ˜ç¡®æŒ‡å‡ºä¸åº”è¯¥åˆ†äº«çš„ä¿¡æ¯ä¹Ÿèƒ½è¢«æå–å‡ºæ¥ï¼Œè¿™è¡¨æ˜äºŸéœ€è¿›ä¸€æ­¥åŠ å¼ºå¯¹æŠ—æç¤ºæ³¨å…¥æ”»å‡»çš„é˜²å¾¡æœºåˆ¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11538v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11538.md)  |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents**<br><sub>æœºæ„: Shanghai Jiao Tong University<br>æœ¬æ–‡ä½œä¸ºé¦–ç¯‡ç³»ç»Ÿæ€§æ¢è®¨CoTåŸºæ­¥æœºåˆ¶ã€èŒƒå¼è½¬å˜ï¼Œä»¥åŠCoTä¸ä»£ç†é—´å¤æ‚äº¤äº’çš„å·¥ä½œï¼Œæä¾›äº†ä¸€äº›å…³é”®è§è§£ã€‚æ–‡ç« æ­ç¤ºäº†CoTåœ¨ç‰¹å®šæ¡ä»¶ä¸‹æ˜¾ç¤ºå‡ºçš„æœ‰æ•ˆæ€§ï¼ŒæŒ‡å‡ºäº†ä½¿CoTå·¥ä½œçš„å¤šä¸ªæ¡ä»¶ï¼Œä»¥åŠç†è®ºå’Œå®è¯ç ”ç©¶ä¸ºå…¶æˆåŠŸæä¾›äº†ä½•ç§è§£é‡Šã€‚æ–‡ç« è¿˜å¯¹CoTç†è®ºè¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œæå‡ºäº†CoTå¯¹äºLLMsåœ¨å¤šä¸ªé¢†åŸŸçš„ä¼˜åŒ–å’Œé©æ–°å¯èƒ½å…·æœ‰é‡è¦çš„è´¡çŒ®ï¼Œå¹¶æŒ‡å‡ºå°½ç®¡LLMsã€CoTæ¨ç†å’Œè¯­è¨€ä»£ç†å¿«é€Ÿå‘å±•ï¼Œä½†ä»å­˜åœ¨æœªè§£å†³çš„æŒ‘æˆ˜ï¼Œå¦‚å¯¹æœªè§é¢†åŸŸçš„æ³›åŒ–ã€æé«˜äº¤äº’æ•ˆç‡ã€ä»£ç†å®šåˆ¶åŒ–ã€ä»£ç†æ‰©å±•åŠä»£ç†å®‰å…¨æ€§ç­‰ã€10â€ æºã€‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11797v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11797.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Zoeyyao27/CoT-Igniting-Agent)</div> |
| <span style='display: inline-block; width: 42px;'>11-19</span> | **TPTU-v2: Boosting Task Planning and Tool Usage of Large Language Model-based Agents in Real-world Systems**<br><sub>æœºæ„: SenseTime Researc<br></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11315v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11315.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **Orca 2: Teaching Small Language Models How to Reason**<br><sub>æœºæ„: Microsoft Research<br>æ–‡ç« é€šè¿‡ä»‹ç»ä¸€ä¸ªæ–°çš„å°å‹è¯­è¨€æ¨¡å‹Orca 2ï¼Œå¹¶å±•ç¤ºå…¶åœ¨å¤šç§æ¨ç†ä»»åŠ¡ä¸Šèƒ½å¤Ÿä¸æ›´å¤§çš„æ¨¡å‹ç›¸åŒ¹æ•Œæˆ–è¶…è¶Šå®ƒä»¬çš„æ€§èƒ½ï¼Œå¯¹å½“å‰å°å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³çš„é—®é¢˜æå‡ºäº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚Orca 2çš„å¼€å‘ä¾èµ–äºå¯¹è®­ç»ƒæ•°æ®å’Œè®­ç»ƒç­–ç•¥çš„ç²¾å¿ƒè®¾è®¡ï¼Œè¯æ˜äº†å³ä½¿æ˜¯å°å‹æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥é€šè¿‡æ”¹è¿›è®­ç»ƒæ–¹æ³•æ¥å¢å¼ºå…¶ç†è§£å’Œæ¨ç†èƒ½åŠ›ã€‚æ–‡ç« è¿˜æä¾›äº†Orca 2åœ¨å„ç§æ ‡å‡†æµ‹è¯•ä¸­çš„å“è¶Šæ€§èƒ½ç»“æœï¼ŒéªŒè¯äº†å…¶æ–¹æ³•è®ºåœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11045v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11045.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **An Embodied Generalist Agent in 3D World**<br><sub>æœºæ„: Beijing Institute for General Artificial Intelligence <br>LEOæ˜¯ä¸€ä¸ªæ–°å‹çš„èº«ä½“åŒ–ã€å¤šæ¨¡æ€ã€å¤šä»»åŠ¡çš„é€šç”¨å‹æ™ºèƒ½ä½“ï¼Œä¸“æ³¨äºåœ¨3Dä¸–ç•Œä¸­çš„æ„ŸçŸ¥ã€åŸºç¡€ã€æ¨ç†ã€è§„åˆ’å’Œè¡ŒåŠ¨ã€‚é€šè¿‡å¯¹3Dè§†è§‰-è¯­è¨€å¯¹é½å’Œè§†è§‰-è¯­è¨€-åŠ¨ä½œæŒ‡ä»¤è°ƒä¼˜çš„è®­ç»ƒï¼ŒLEOèƒ½åœ¨3Dä¸–ç•Œä¸­æ‰§è¡Œä¸€ç³»åˆ—ä»»åŠ¡ã€‚æ–‡ç« é€šè¿‡ä¸€ç³»åˆ—ä¸¥æ ¼å®éªŒå’Œæ¶ˆèå®éªŒçš„ç»“æœï¼Œè¯å®äº†LEOåœ¨ä¸€ç³»åˆ—ä»»åŠ¡ä¸Šçš„é«˜æ•ˆæ€§èƒ½ï¼Œå¹¶ä¸ºæœªæ¥èº«ä½“åŒ–é€šç”¨å‹æ™ºèƒ½ä½“çš„å‘å±•æä¾›äº†å®è´µæ´è§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12871v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12871.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **RecExplainer: Aligning Large Language Models for Recommendation Model Interpretability**<br><sub>æœºæ„: University of Science and Technology of China<br>æ–‡ç« é’ˆå¯¹æ¨èæ¨¡å‹è§£é‡Šæ€§çš„ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„æ–¹æ³•ï¼Œå³é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¯¹é½ï¼Œä»¥æé«˜è§£é‡Šçš„è´¨é‡å’Œå‡†ç¡®æ€§ã€‚æ–‡ç« ä»‹ç»äº†ä¸‰ç§ä¸åŒçš„å¯¹é½æ–¹æ³•ï¼Œå¹¶é€šè¿‡ä¸€ç³»åˆ—ä»»åŠ¡è®­ç»ƒLLMä»¥æ¨¡ä»¿æ¨èæ¨¡å‹çš„é€»è¾‘ã€‚è®ºæ–‡é‡‡ç”¨äº†å¤šç§è¯„ä¼°ç­–ç•¥å’Œè¯„åˆ†ä½“ç³»ï¼ŒåŒ…æ‹¬ä½¿ç”¨æœ€æ–°çš„GPT-4æ¨¡å‹å’Œäººç±»è¯„åˆ†æ¥éªŒè¯æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶åœ¨ä¸‰ä¸ªä¸åŒçš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨æé«˜æ¨èæ¨¡å‹è§£é‡Šæ€§æ–¹é¢çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10947v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10947.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **Adapters: A Unified Library for Parameter-Efficient and Modular Transfer Learning**<br><sub>æœºæ„: Technical University of Darmstadt, University of Cambridge<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„åº“â€”â€”Adaptersï¼Œå®ƒæ•´åˆå¹¶æ‰©å±•äº†å‚æ•°é«˜æ•ˆå’Œæ¨¡å—åŒ–è¿ç§»å­¦ä¹ æ–¹æ³•ï¼Œå®ç°äº†ä¸Transformersåº“çš„ç´§å¯†æ•´åˆï¼Œé€šè¿‡å¤šä¸ªNLPä»»åŠ¡çš„å¯¹æ¯”å®éªŒï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11077v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11077.md)  |
| <span style='display: inline-block; width: 42px;'>11-17</span> | **Exploring the Relationship between In-Context Learning and Instruction Tuning**<br><sub>æœºæ„: HKUST<br>è®ºæ–‡æä¾›äº†ICLä¸ITä¹‹é—´å¯†åˆ‡ç›¸å…³çš„å®è¯è¯æ®ï¼Œå³ä½¿ICLä¸­ä¸æ›´æ”¹æ¨¡å‹å‚æ•°ï¼ŒäºŒè€…æ‰€ä½¿ç”¨çš„æŒ‡ä»¤å’Œç¤ºä¾‹éƒ½é©±åŠ¨æ¨¡å‹æœç€æ”¶æ•›çš„éšè—çŠ¶æ€å‰è¿›ã€‚è¿™ä¸€å‘ç°å¯¹äºå¦‚ä½•è®¾è®¡é«˜æ•ˆçš„æ•°æ®é›†å’Œä»»åŠ¡ä»¥æ¨è¿›åŸºç¡€æ¨¡å‹åœ¨ä¸‹æ¸¸åº”ç”¨çš„å‘å±•å’Œå¯¹é½å…·æœ‰å¯ç¤ºä½œç”¨ã€‚ç ”ç©¶ç»“æœè¿˜å¯ä»¥å¸®åŠ©ç†è§£ç¤ºä¾‹åœ¨ICLå’ŒITä¸­çš„ä½œç”¨ï¼Œä»¥åŠå¦‚ä½•åˆ©ç”¨è¿™äº›è§è§£æ¥è®¾è®¡æœ‰æ•ˆçš„ç¤ºä¾‹ä»»åŠ¡å’Œæ•°æ®é›†ï¼Œä»è€Œæå‡LLMçš„æ€§èƒ½ã€‚è®ºæ–‡ä¸­ç”³æ˜å°†ä¼šæä¾›å®éªŒä»£ç ä»¥ä¾›å¤ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10367v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10367.md)  |
| <span style='display: inline-block; width: 42px;'>11-17</span> | **Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2**<br><sub>æœºæ„: Allen Institute for AI <br>TÃœLU 2é€šè¿‡é‡‡ç”¨æ–°çš„åŸºç¡€æ¨¡å‹å’Œè°ƒæ•´ç­–ç•¥ï¼Œåœ¨å¤šä¸ªæ€§èƒ½æŒ‡æ ‡ä¸Šå®ç°äº†çªç ´ï¼Œå¯¹è¿›ä¸€æ­¥ç†è§£å’Œæ”¹è¿›é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„é€‚é…å…·æœ‰é‡è¦æ„ä¹‰ã€‚é€šè¿‡å¼•å…¥æ–°çš„æ•°æ®æ··åˆç‰©å’Œå…ˆè¿›çš„è®­ç»ƒæ–¹æ³•ï¼ˆå¦‚DPOï¼‰ï¼ŒTÃœLU 2æé«˜äº†æ¨¡å‹åœ¨å„ç§æ¨ç†å’ŒçŸ¥è¯†æ¢æµ‹ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œå¹¶åœ¨å¼€æ”¾å¼ç”ŸæˆæŒ‡æ ‡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…ä»¬é€šè¿‡å…¬å¼€ç›¸å…³æ¨¡å‹ã€æ•°æ®å’Œä»£ç ï¼Œæ¨åŠ¨äº†è¯­è¨€æ¨¡å‹é€‚é…æ–¹æ³•çš„å¼€æ”¾ç ”ç©¶å’Œå‘å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10702v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10702.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **MacGyver: Are Large Language Models Creative Problem Solvers?**<br><sub>æœºæ„: University of California, Princeton University<br>æœ¬ç ”ç©¶é€šè¿‡åˆ›é€ MACGYVERæ•°æ®é›†ï¼Œæ¢ç´¢äº†LLMsåœ¨è§£å†³éä¼ ç»Ÿé—®é¢˜ä¸Šçš„èƒ½åŠ›ï¼Œå¹¶é€šè¿‡äººç±»è¯„ä¼°å‘˜å¯¹GPT-4çš„è¡¨ç°è¿›è¡Œäº†è¯„ä»·ã€‚ç ”ç©¶ç»“æœå±•ç¤ºäº†LLMsåœ¨è¿™ç±»ä»»åŠ¡ä¸Šçš„å±€é™æ€§ï¼ŒåŒæ—¶æå‡ºäº†æé«˜å…¶è¡¨ç°çš„æ–°æ–¹æ³•ã€‚ç ”ç©¶å¼ºè°ƒäº†åˆ›é€ æ€§é—®é¢˜è§£å†³èƒ½åŠ›åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­çš„é‡è¦æ€§ï¼Œå¹¶å°è¯•é€šè¿‡LLMsè¡¥å……äººç±»çš„åˆ›é€ æ€§æ€ç»´ï¼Œä»¥æœŸæé«˜è§£å†³é—®é¢˜çš„èƒ½åŠ›å’Œæ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09682v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.09682.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **Crafting In-context Examples according to LMs' Parametric Knowledge**<br><sub>æœºæ„: The University of Texas at Austin<br>æœ¬æ–‡çš„é‡ç‚¹ç ”ç©¶æ˜¯å¦‚ä½•æ ¹æ®LMçš„å‚æ•°çŸ¥è¯†æœ‰æ•ˆåœ°åˆ›å»ºä¸Šä¸‹æ–‡ç¤ºä¾‹ï¼šé€‰æ‹©æœ€ä¼˜çš„ç¤ºä¾‹ï¼ˆå·²çŸ¥ä¸æœªçŸ¥çš„æ¯”è¾ƒï¼‰ä»¥åŠåœ¨ä¸Šä¸‹æ–‡ç¤ºä¾‹ä¸­å¦‚ä½•æ’åºç­”æ¡ˆã€‚å®éªŒç»“æœæ”¯æŒäº†åŠå·²çŸ¥ç¤ºä¾‹çš„æœ‰æ•ˆæ€§ä»¥åŠåŸºäºå‚æ•°çŸ¥è¯†çš„ç­”æ¡ˆæ’åºæ–¹æ³•ï¼Œè¿™äº›å‘ç°ä¸ºæé«˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šç­”æ¡ˆç”Ÿæˆä»»åŠ¡ä¸­çš„æ€§èƒ½æä¾›äº†å¯è¡Œçš„æŠ€æœ¯é€”å¾„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09579v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.09579.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **Automatic Engineering of Long Prompts**<br><sub>æœºæ„: Google<br>æœ¬æ–‡é’ˆå¯¹è¯­è¨€æ¨¡å‹é•¿æŒ‡ä»¤å·¥ç¨‹ä¸­å­˜åœ¨çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„ç®—æ³•æ¡†æ¶ï¼Œå¹¶è§£å†³äº†è´ªå©ªç®—æ³•æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜å’Œé—ä¼ ç®—æ³•åˆæœŸæ”¶æ•›æ…¢çš„é—®é¢˜ã€‚é€šè¿‡å¯¹æŒ‡ä»¤çš„æ¯ä¸ªå¥å­è¿›è¡Œè¯­ä¹‰ä¿æŒé‡è¿°ï¼Œå¹¶åˆ©ç”¨æ³¢æŸæœç´¢æ¥ç»´æŠ¤å’Œä¼˜åŒ–å€™é€‰æŒ‡ä»¤é›†åˆï¼Œä½¿ç®—æ³•åœ¨æœ‰é™è®­ç»ƒæ•°æ®ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½å’Œè¾ƒå¿«çš„æ”¶æ•›é€Ÿåº¦ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10117v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10117.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **Predictive Minds: LLMs As Atypical Active Inference Agents**<br><sub>æœºæ„: Charles University<br>æœ¬è®ºæ–‡å°†æ´»åŠ¨æ¨æ–­çš„æ¦‚å¿µåº”ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œä»ä¸€ä¸ªæ–°çš„è§†è§’åˆ†æäº†LLMsçš„è¡Œä¸ºå’Œå­¦ä¹ æœºåˆ¶ã€‚è®ºæ–‡æå‡ºï¼Œå°½ç®¡LLMsåœ¨ç‰©ç†ä¸Šæ— æ³•ç›´æ¥ä¸ç¯å¢ƒäº’åŠ¨ï¼Œä½†å®ƒä»¬é€šè¿‡ç”Ÿæˆæ–‡æœ¬åœ¨è™šæ‹Ÿç¯å¢ƒä¸­çš„â€œè¡ŒåŠ¨â€é—´æ¥å½±å“ä¸–ç•Œï¼Œå¹¶æœ‰å¯èƒ½å°†è¿™äº›å½±å“åé¦ˆåˆ°æ¨¡å‹çš„è®­ç»ƒä¸­ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œå¢å¼ºLLMsä¸ç”¨æˆ·äº¤äº’çš„åé¦ˆå¾ªç¯ï¼Œå°†æœ‰åŠ©äºæå‡æ¨¡å‹çš„è‡ªæˆ‘æ„è¯†ï¼Œè®©å…¶æ›´å¥½åœ°é€‚åº”å’Œå“åº”ç¯å¢ƒå˜åŒ–ï¼Œè¿™å°†å¸¦æ¥é‡å¤§çš„ç¤¾ä¼šå½±å“å’Œæ½œåœ¨çš„é£é™©ã€‚è®ºæ–‡ä¸ºç†è§£å’Œæ”¹è¿›LLMsåœ¨å®é™…éƒ¨ç½²æ—¶çš„è¡Œä¸ºæä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€ï¼Œé¢„æµ‹äº†è¿™äº›ç³»ç»Ÿæœªæ¥å¯èƒ½çš„å‘å±•æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10215v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10215.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Memory Augmented Language Models through Mixture of Word Experts**<br><sub>æœºæ„: Google Research<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç§°ä¸ºMoWEçš„æ–°å‹æ¶æ„ï¼Œå®ƒé€šè¿‡èåˆç¨€ç–æ¨¡å‹çš„æ•ˆç‡å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ï¼Œå‡ºè‰²åœ°å¤„ç†äº†æ€§èƒ½ä¸è®¡ç®—æˆæœ¬ä¹‹é—´çš„å¹³è¡¡ã€‚é€šè¿‡é‡‡å–åˆ›æ–°çš„è®¾è®¡åŸåˆ™ï¼Œå¹¶ä¸”åœ¨NLPå¤šç§ä»»åŠ¡ä¸­éªŒè¯äº†å…¶è¶…è¶Šä¼ ç»Ÿæ¨¡å‹å¦‚T5å’ŒMoEçš„æ€§èƒ½ï¼ŒMoWEå±•ç¤ºäº†åœ¨å­¦æœ¯å’Œå®é™…åº”ç”¨é¢†åŸŸçš„æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡æ—¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10768v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10768.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models**<br><sub>æœºæ„: Tecent AI Lab<br>è®ºæ–‡æå‡ºçš„CHAIN-OF-NOTEï¼ˆCONï¼‰æ¡†æ¶æ—¨åœ¨æé«˜RALMsçš„é²æ£’æ€§ï¼Œä¸»è¦é€šè¿‡å¼•å…¥ç»“æ„åŒ–çš„é˜…è¯»ç¬”è®°è¿‡ç¨‹æ¥æ‰¹åˆ¤æ€§åœ°è¯„ä¼°æ£€ç´¢åˆ°çš„æ–‡æ¡£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶æé«˜äº†æ¨¡å‹åœ¨å™ªå£°æ•°æ®å’ŒæœªçŸ¥æƒ…å†µä¸‹çš„å¥å£®æ€§ï¼Œæ”¹å–„äº†æ•´ä½“QAæ€§èƒ½ï¼Œå¹¶åœ¨æ£€ç´¢æ–‡æ¡£å¤±è´¥è¿˜æ˜¯æˆåŠŸæ—¶å‡æé«˜äº†æ¨¡å‹çš„æ€§èƒ½ã€‚CONæ¡†æ¶é€šè¿‡ç”Ÿæˆè¯»å–ç¬”è®°å’Œæœ€ç»ˆå›ç­”ï¼Œæé«˜äº†æ¨¡å‹å¯¹å™ªå£°çš„é²æ£’æ€§ï¼Œå¹¶åœ¨ç¼ºä¹ä¿¡æ¯æ—¶èƒ½å¤Ÿç»™å‡ºâ€œæœªçŸ¥â€çš„å›ç­”ï¼Œå¢å¼ºäº†æ¨¡å‹çš„é€‚åº”æ€§å’Œå¯é æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09210v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.0921.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Exponentially Faster Language Modelling**<br><sub>æœºæ„: ETH Zurich<br>æœ¬æ–‡ä»‹ç»äº†UltraFastBERTï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„å˜ç§ï¼Œå®ƒæ˜¾è‘—å‡å°‘äº†åœ¨æ¨ç†æ—¶éœ€è¦ä½¿ç”¨çš„ç¥ç»å…ƒæ•°é‡ï¼Œå¹¶é€šè¿‡ä½¿ç”¨å¿«é€Ÿå‰é¦ˆç½‘ç»œæ¥æé«˜è®¡ç®—æ•ˆç‡ã€‚å°½ç®¡ä¸å…·å¤‡åŸç”Ÿçš„é«˜æ•ˆå®ç°ï¼Œä½†è¯¥æ¨¡å‹æä¾›äº†ä¸€ä¸ªèƒ½å¤Ÿæ˜¾è‘—åŠ é€Ÿæ¨ç†è¿‡ç¨‹çš„CPUä»£ç å®ç°ï¼Œå¹¶åœ¨æ ‡å‡†ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ã€‚è¿™ä¸€å·¥ä½œå±•ç¤ºäº†æ¡ä»¶ç¥ç»æ‰§è¡Œåœ¨è¯­è¨€å»ºæ¨¡é¢†åŸŸå·¨å¤§çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10770v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1077.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **ToolTalk: Evaluating Tool-Usage in a Conversational Setting**<br><sub>æœºæ„: Microsoft Corporation<br>ToolTalk æ˜¯ä¸€ä¸ªè‡´åŠ›äºè¯„ä¼°å’Œæé«˜ LLM åœ¨å¯¹è¯ç¯å¢ƒä¸­ä½¿ç”¨å¤šæ­¥éª¤å¤–éƒ¨å·¥å…·æ€§èƒ½çš„åŸºå‡†ã€‚å®ƒé€šè¿‡åˆ›æ–°çš„è¯„ä¼°æ–¹æ³•å’ŒçœŸå®åœºæ™¯æ¨¡æ‹Ÿï¼ŒæŒ‘æˆ˜å’Œæ‰©å±•äº†ç°æœ‰ LLMs çš„èƒ½åŠ›è¾¹ç•Œï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æŒ‡å‡ºäº†æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10775v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10775.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/microsoft/ToolTalk)</div> |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Contrastive Chain-of-Thought Prompting**<br><sub>æœºæ„: DAMO Academy, Alibaba Group<br>æœ¬è®ºæ–‡æå‡ºäº†å¯¹æ¯”å¼é“¾å¼æ€ç»´æ–¹æ³•ï¼Œä»¥è§£å†³ä¼ ç»Ÿé“¾å¼æ€ç»´ä¸­å­˜åœ¨çš„é—®é¢˜ï¼Œå³ç¼ºä¹å¯¹é”™è¯¯é¿å…çš„æŒ‡å¯¼ä»¥åŠå®ç°æ¨ç†æ•ˆæœçš„ä¸ç¡®å®šæ€§ã€‚é€šè¿‡æä¾›æœ‰æ•ˆå’Œæ— æ•ˆçš„æ¨ç†ç¤ºä¾‹ï¼Œæ–°æ–¹æ³•æ—¨åœ¨å¼•å¯¼æ¨¡å‹å‡å°‘æ¨ç†é”™è¯¯å¹¶ä¸€æ­¥æ­¥æ¨ç†ï¼ŒåŒæ—¶è¯¥æ–¹æ³•æä¾›äº†è‡ªåŠ¨åŒ–æ„å»ºå¯¹æ¯”ç¤ºä¾‹çš„æŠ€æœ¯ä»¥ä¾¿æ³›åŒ–åˆ°å„ç§ä»»åŠ¡ã€‚å®éªŒç»“æœè¯å®ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä½œä¸ºä¸€ç§é€šç”¨å¢å¼ºæ‰‹æ®µï¼Œæ˜¾è‘—æå‡é“¾å¼æ€ç»´çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09277v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.09277.md)  |
| <span style='display: inline-block; width: 42px;'>11-14</span> | **Instruction-Following Evaluation for Large Language Models**<br><sub>æœºæ„: Google, Yale University<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›çš„æ–°æ–¹æ³•â€”â€”IFEvalï¼Œå®ƒé€šè¿‡åˆæˆé€»è¾‘ä¸€è‡´çš„æŒ‡ä»¤å’Œè®¡ç®—æŒ‡ä»¤éµå¾ªå‡†ç¡®æ€§çš„æ–°å‡†åˆ™æ¥è§£å†³è¯„ä¼°è¿‡ç¨‹ä¸­çš„æŒ‘æˆ˜ã€‚æ­¤æ–¹æ³•ä¸ºè‡ªåŠ¨åŒ–ä¸”æ— åè§ï¼Œå®ƒé€šè¿‡å¤šæ­¥éª¤è¿‡ç¨‹é¿å…æŒ‡ä»¤é—´çš„æ½œåœ¨å†²çªï¼Œå¹¶å¼•å…¥äº†ä¸¥æ ¼å’Œå®½æ¾çš„å‡†ç¡®æ€§è¯„ä»·æ ‡å‡†æ¥å‡å°‘è¯¯åˆ¤ï¼ŒåŒæ—¶è®¤ä¸ºæœªæ¥å¯ä»¥é€šè¿‡å¢åŠ å¤šæ ·åŒ–å’Œä½¿ç”¨å¤šæ¨¡æ€æŒ‡ä»¤æ¥æ”¹è¿›è¯¥æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.07911v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.07911.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/google-research/google-research/tree/master/instruction_following_eval)</div> |
| <span style='display: inline-block; width: 42px;'>11-14</span> | **Learning to Filter Context for Retrieval-Augmented Generation**<br><sub>æœºæ„: Carnegie Mellon University<br>æœ¬æ–‡æå‡ºçš„FILCOæ–¹æ³•é’ˆå¯¹å¼€æ”¾é¢†åŸŸé—®ç­”å’Œäº‹å®éªŒè¯ç­‰çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ï¼Œé€šè¿‡æ”¹å–„æä¾›ç»™ç”Ÿæˆæ¨¡å‹çš„ä¸Šä¸‹æ–‡è´¨é‡æ¥è§£å†³ç”Ÿæˆè¾“å‡ºæ—¶é¢ä¸´çš„é—®é¢˜ã€‚é€šè¿‡ç»“åˆè¯æ±‡å’Œä¿¡æ¯è®ºæ–¹æ³•æ¥è¯†åˆ«æœ‰ç”¨ä¸Šä¸‹æ–‡ï¼Œå¹¶è®­ç»ƒæ¨¡å‹ä»¥åœ¨æµ‹è¯•æ—¶è¿‡æ»¤æ£€ç´¢ä¸Šä¸‹æ–‡ï¼Œå¾ˆå¥½åœ°è§£å†³äº†ä»¥å‰æ–¹æ³•çš„å±€é™æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•ï¼ŒFILCOåœ¨å¤šä¸ªçŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ï¼Œå¹¶ä¸”åœ¨ä¸Šä¸‹æ–‡è¿‡æ»¤è®­ç»ƒä¸Šæ˜¾ç¤ºå‡ºå…¶æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.08377v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.08377.md)  |
| <span style='display: inline-block; width: 42px;'>11-14</span> | **KTRL+F: Knowledge-Augmented In-Document Search**<br><sub>æœºæ„: KAIST AI, Samsung Research<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªæ–°çš„é—®é¢˜â€”â€”KTRL+Fï¼Œä»¥è§£å†³æ–‡çŒ®æœç´¢ä¸­çš„å®æ—¶ã€å‡†ç¡®æ€§ã€å¼•å…¥å¤–éƒ¨çŸ¥è¯†çš„éœ€æ±‚ã€‚é€šè¿‡åˆ†æç°æœ‰åŸºçº¿ï¼Œæ–‡ç« å‘ç°å®ƒä»¬å­˜åœ¨å±€é™æ€§ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šæå‡ºäº†Knowledge-Augmented Phrase Retrievalæ¨¡å‹ã€‚è¯¥æ¨¡å‹æœ‰æ•ˆåœ°åœ¨çŸ­è¯­æ£€ç´¢ä¸­æ•´åˆäº†å¤–éƒ¨çŸ¥è¯†ï¼Œé€šè¿‡ç®€å•çš„æ‰©å±•ä¿æŒäº†å¿«é€Ÿå“åº”ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚é€šè¿‡ç”¨æˆ·ç ”ç©¶ï¼Œè¯æ˜äº†è¯¥æ¨¡å‹èƒ½å¤Ÿæå‡ç”¨æˆ·æœç´¢ä½“éªŒï¼Œå‡å°‘æœç´¢æ—¶é—´å’Œå¤–éƒ¨ä¿¡æ¯æ£€ç´¢é‡ã€‚ä½œè€…é¼“åŠ±ç ”ç©¶ç¤¾åŒºå…³æ³¨KTRL+Fè¿™ä¸€ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œæé«˜æ–‡çŒ®ä¿¡æ¯è®¿é—®çš„æ•ˆç‡å’Œæ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.08329v3)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.08329.md)  |
| <span style='display: inline-block; width: 42px;'>11-13</span> | **Can LLMs Patch Security Issues?**<br><sub>æœºæ„: School of Computer Science Atlanta<br>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹çš„ä»£ç ä¿®æ­£æ–¹æ³•FDSSï¼Œé€šè¿‡ä¸é™æ€ä»£ç åˆ†æå·¥å…·Bandité›†æˆï¼Œèƒ½æ˜¾è‘—æé«˜LLMsè§£å†³ä»£ç ä¸­å®‰å…¨é—®é¢˜çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00024v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2312.00024.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Kamel773/LLM-code-refine)</div> |
| <span style='display: inline-block; width: 42px;'>11-13</span> | **In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax**<br><sub>æœºæ„: NYU, Microsoft<br>æœ¬è®ºæ–‡æ­ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç†è§£å’Œæ³›åŒ–å¥æ³•ç»“æ„æ—¶å¯èƒ½å­˜åœ¨çš„å±€é™æ€§ï¼Œè¿™å¯¹äºæ”¹è¿›è¯­è¨€æ¨¡å‹å¤„ç†å¤æ‚è¯­æ³•ä»»åŠ¡çš„æ–¹å¼å…·æœ‰é‡è¦æ„ä¹‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.07811v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.07811.md)  |
| <span style='display: inline-block; width: 42px;'>11-11</span> | **In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering**<br><sub>æœºæ„: Stanford University<br>æœ¬è®ºæ–‡æå‡ºçš„ICVæ–¹æ³•ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å­¦ä¹ æä¾›äº†ä¸€ç§æ–°é¢–ä¸”æ›´åŠ æœ‰æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚é€šè¿‡å°†æ¼”ç¤ºç¤ºä¾‹çš„å…³é”®ä¿¡æ¯é›†æˆåˆ°ä¸€ä¸ªå¯ä»¥æ§åˆ¶çš„å‘é‡ä¸­ï¼ŒICVæ–¹æ³•æé«˜äº†ä»»åŠ¡æŒ‡å¯¼çš„ç²¾ç¡®åº¦å’Œæ•ˆæœï¼Œå¹¶æ˜¾è‘—ä¼˜äºç°æœ‰çš„æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒICVåœ¨å¤šé¡¹ä»»åŠ¡ä¸­å±•ç°äº†è¾ƒé«˜çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬åœ¨ä¸åŒçš„LLMsä¸Šè¿›è¡Œè¯­è¨€æ¨¡å‹è§£æ¯’ã€é£æ ¼è½¬æ¢å’Œè§’è‰²æ‰®æ¼”ã€‚ICVæ–¹æ³•çš„è®¡ç®—å¼€é”€ä½ï¼Œå¹¶ä¸”æ˜“äºæ§åˆ¶ï¼Œæœ‰åŠ©äºæå‡è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„é€‚ç”¨æ€§å’Œå¼¹æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.06668v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.06668.md)  |
| <span style='display: inline-block; width: 42px;'>11-10</span> | **Making LLMs Worth Every Penny: Resource-Limited Text Classification in Banking**<br><sub>æœºæ„: Helvia.ai<br>è®ºæ–‡é¦–æ¬¡å°†å¤šç§åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹çš„æ–¹æ³•è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼ŒåŒ…æ‹¬æˆæœ¬åˆ†æã€RAGæ–¹æ³•å’Œåˆ©ç”¨GPT-4çš„æ•°æ®å¢å¼ºï¼Œä¸ºé‡‘èè¡Œä¸šæä¾›äº†æ–°çš„æ–¹æ³•ç”¨ä»¥åº”å¯¹æ•°æ®å’Œé¢„ç®—é™åˆ¶çš„æŒ‘æˆ˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.06102v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.06102.md)  |
| <span style='display: inline-block; width: 42px;'>11-05</span> | **ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs**<br><sub>æœºæ„: Cornell University, Microsoft Research<br>æœ¬æ–‡æä¾›äº†ä¸€ä¸ªä½¿ç”¨å¼€æºLLMså¢å¼ºåœ¨çº¿æ•™è‚²QAå¹³å°çš„æ–°æ–¹æ¡ˆï¼Œå¹¶å¯¹å…¶è¿›è¡Œäº†å¹¿æ³›çš„è¯„ä¼°å’Œæµ‹è¯•ã€‚é€šè¿‡å°†RAGã€SFTå’ŒDPOç­‰æŠ€æœ¯ç»“åˆåº”ç”¨ï¼Œç¡®ä¿äº†å›ç­”è´¨é‡çš„æ˜¾è‘—æå‡å’Œæ•°æ®éšç§çš„ä¿æŠ¤ï¼Œå¯¹äºå¼€å‘æ™ºèƒ½QAåŠ©æ‰‹å…·æœ‰é‡è¦çš„æ„ä¹‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.02775v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.02775.md)  |
| <span style='display: inline-block; width: 42px;'>11-01</span> | **LLMRec: Large Language Models with Graph Augmentation for Recommendation**<br><sub>æœºæ„: University of Hong Kong, Baidu<br>LLMRecä½œä¸ºå¼€åˆ›æ€§çš„å·¥ä½œï¼Œå®ƒå¼•å…¥LLMsæ¥å¢å¼ºå›¾æ¨èç³»ç»Ÿï¼ŒæˆåŠŸåœ°è§£å†³äº†äº¤äº’æ•°æ®çš„ç¨€ç–æ€§å’Œä½è´¨é‡ä¾§ä¿¡æ¯çš„é—®é¢˜ï¼Œå¹¶é€šè¿‡å¼ºåŒ–ç”¨æˆ·-é¡¹ç›®äº¤äº’è¾¹ã€é¡¹ç›®èŠ‚ç‚¹å±æ€§ä»¥åŠç”¨æˆ·ç”»åƒç­‰æ‰‹æ®µæå‡äº†æ¨èç³»ç»Ÿçš„æ€§èƒ½ï¼Œç¡®ä¿äº†æ¨èè´¨é‡çš„åŒæ—¶é™ä½äº†æ•°æ®å™ªå£°çš„å½±å“ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.00423v5)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.00423.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/HKUDS/LLMRec.git)</div> |

---

### 10æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>10-20</span> | **The History and Risks of Reinforcement Learning and Human Feedback**<br><sub>æœºæ„: Berkeley<br></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.13595v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.13595.md)  |
| <span style='display: inline-block; width: 42px;'>10-17</span> | **Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection**<br><sub>æœºæ„: University of Washington<br>è®ºæ–‡æ¨å‡ºäº†SELF-RAGï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œé€šè¿‡æŒ‰éœ€æ£€ç´¢å’Œè‡ªæˆ‘åæ€æ¥å¢åŠ LLMsçš„è´¨é‡å’Œäº‹å®æ€§ã€‚å®ƒé€šè¿‡ç”Ÿæˆåæ€æ ‡è®°è®©LMåœ¨æ¨ç†é˜¶æ®µå˜å¾—å¯æ§ï¼Œå¯ä»¥æ»¡è¶³å¤šæ ·åŒ–çš„ä»»åŠ¡è¦æ±‚ã€‚SELF-RAGåœ¨å¤šä¸ªä»»åŠ¡ä¸Šæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰LLMså’ŒRAGæ¨¡å‹ï¼Œå¹¶é€šè¿‡å®šåˆ¶çš„è§£ç ç®—æ³•å’Œåæ€æ ‡è®°ï¼Œä¸ºæ¨¡å‹è‡ªæˆ‘è¯„ä¼°å’Œå®šåˆ¶æä¾›äº†æ–°çš„æ–¹æ¡ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.11511v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.11511.md)  |
| <span style='display: inline-block; width: 42px;'>10-11</span> | **OpsEval: A Comprehensive Task-Oriented AIOps Benchmark for Large Language Models**<br><sub>æœºæ„: Tsinghua University, Chinese Academy of Sciences<br>OpsEval ä½œä¸ºä¸€ä¸ªå…¨é¢çš„ AIOps ä»»åŠ¡å¯¼å‘å‹åŸºå‡†æµ‹è¯•ï¼Œä¸ä»…è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„ç»¼åˆæ€§èƒ½ã€æ¨ç†å’Œå®é™…åº”ç”¨èƒ½åŠ›ï¼Œè¿˜å¯èƒ½æ”¹å˜æœªæ¥å¤§è§„æ¨¡è´¨é‡è¯„ä¼°ä¸­ä½¿ç”¨çš„è¯„ä»·æŒ‡æ ‡ã€‚å®ƒæä¾›äº†ä¸€ä¸ªç”¨äºæŒç»­ç ”ç©¶å’Œä¼˜åŒ–AIOpsé¢†åŸŸå¤§å‹è¯­è¨€æ¨¡å‹çš„åšå®åŸºç¡€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.07637v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.07637.md)  |
| <span style='display: inline-block; width: 42px;'>10-10</span> | **GPT-4 as an Agronomist Assistant? Answering Agriculture Exams Using Large Language Models**<br><sub>æœºæ„: Microsoft Research<br>æœ¬ç ”ç©¶å±•ç¤ºäº†åœ¨å†œä¸šé¢†åŸŸä½¿ç”¨LLMsè¿›è¡Œé—®é¢˜å›ç­”çš„æ–°æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡Ensemble Refinementç­–ç•¥ï¼Œå¤§å¹…æå‡äº†LLMsåœ¨å¤šé€‰é¢˜ç›®ä¸Šçš„è¡¨ç°ï¼Œå¹¶æ˜¾ç¤ºå‡ºåœ¨å¤„ç†ä¸“ä¸šé¢†åŸŸé—®é¢˜æ—¶çš„å¹¿æ³›æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.06225v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.06225.md)  |

---

### 09æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>09-04</span> | **Benchmarking Large Language Models in Retrieval-Augmented Generation**<br><sub>æœºæ„: Chinese Information Processing Laboratory <br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºå®é™…æ–°é—»æ–‡ç« çš„æ£€ç´¢å¢å¼ºç”ŸæˆåŸºå‡†æµ‹è¯•ï¼Œç”¨ä»¥å½»åº•è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ä¿¡æ¯ç¯å¢ƒä¸­çš„å¤šé¡¹èƒ½åŠ›ï¼Œå¹¶é€šè¿‡å®éªŒç»“æœå±•ç°äº†ç°æœ‰LLMsåœ¨è¿™äº›æ–¹é¢çš„å±€é™æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2309.01431v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-09/2309.01431.md)  |

---

### 08æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>08-18</span> | **Learning Representations on Logs for AIOps**<br><sub>æœºæ„: IBM Research<br>æœ¬æ–‡æå‡ºçš„BERTOpsæ¨¡å‹é€šè¿‡ä½¿ç”¨LLMsä¸­çš„é€šç”¨è¡¨ç¤ºï¼Œå¹¶ç»“åˆä¸“é—¨é’ˆå¯¹AIOpsæ—¥å¿—æ•°æ®çš„é¢„è®­ç»ƒï¼Œæœ‰æ•ˆåœ°æé«˜äº†è‡ªåŠ¨åŒ–æ—¥å¿—åˆ†æä»»åŠ¡çš„æ€§èƒ½ï¼Œå¹¶å±•ç¤ºäº†æ˜¾è‘—çš„æ”¹è¿›ã€‚BERTOpsä¸ä»…ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œåœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­ä¹Ÿè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œæœ‰åŠ©äºåŠ é€ŸAIOpsçš„å®è·µåº”ç”¨ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2308.11526v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-08/2308.11526.md)  |

---

### 07æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>07-11</span> | **Towards Understanding In-Context Learning with Contrastive Demonstrations and Saliency Maps**<br><sub>æœºæ„: UNIVERSITY OF MARYLAND<br>æœ¬ç ”ç©¶ä½¿ç”¨å¯¹æ¯”ç¤ºä¾‹å’Œæ˜¾è‘—å›¾åˆ†ææ³•æ¥æ¢ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ä¸Šä¸‹æ–‡å­¦ä¹ çš„å†…åœ¨æœºåˆ¶ï¼Œæ­ç¤ºäº†æ ‡ç­¾ç¿»è½¬ã€è¾“å…¥å˜åŒ–ã€å’Œè¡¥å……æ€§è§£é‡Šå¯¹é¢„æµ‹çš„ä¸åŒå½±å“ï¼Œå¹¶ä¸ºå®è·µè€…æä¾›äº†å¦‚ä½•ç­–åˆ’ç¤ºä¾‹çš„æ´è§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2307.05052v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-07/2307.05052.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/paihengxu/XICL)</div> |

---

### 05æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>05-24</span> | **In-Context Demonstration Selection with Cross Entropy Difference**<br><sub>æœºæ„: Microsoft Cognitive Service Research<br>æ–‡ç« æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºäº¤å‰ç†µå·®å¼‚ï¼ˆCEDï¼‰çš„ä¸Šä¸‹æ–‡ç¤ºä¾‹é€‰æ‹©æ–¹æ³•ï¼Œå¹¶æä¾›äº†ç†è®ºä¸Šçš„è§£é‡Šï¼Œå®ç°äº†å¯¹ä¸åŒå¤§å°å’Œç±»å‹çš„å¤§å‹è¯­è¨€æ¨¡å‹æ€§èƒ½çš„æå‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2305.14726v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-05/2305.14726.md)  |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning**<br><sub>æœºæ„: Lean Wang, Lei Li, Damai Dai, Deli Chen, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun<br>æœ¬è®ºæ–‡é€šè¿‡ä¿¡æ¯æµè§†è§’ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰çš„å†…éƒ¨æœºåˆ¶ï¼Œå‘ç°äº†æ ‡ç­¾è¯åœ¨ä¿¡æ¯æµä¸­ä½œä¸ºé”šç‚¹çš„ç°è±¡ï¼Œæå‡ºäº†æ–°å‡è®¾ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œä½¿ç”¨æ‰€å¾—æ´è§æå‡ºäº†æé«˜ICLæ€§èƒ½çš„æ–¹æ³•ï¼Œä¸ºæœªæ¥ç›¸å…³ç ”ç©¶æä¾›äº†ç†è®ºåŸºç¡€å’Œå®è·µæŒ‡å¯¼ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2305.14160v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-05/2305.1416.md)  |
| <span style='display: inline-block; width: 42px;'>05-19</span> | **How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings**<br><sub>æœºæ„: The Ohio State University<br>æœ¬ç ”ç©¶æ­ç¤ºå‡ºæœ‰æ•ˆæç¤ºæ„é€ çš„å…³é”®æ•°æ®åº“çŸ¥è¯†å’Œæœ€ä¼˜è¡¨è¿°ï¼Œä¸ºLLMsåœ¨text-to-SQLä»»åŠ¡ä¸­çš„åº”ç”¨æä¾›æŒ‡å¯¼ï¼Œå¹¶æŒ‡å‡ºåœ¨è·¨åŸŸè®¾ç½®ä¸­å¯¹äºæç¤ºé•¿åº¦å­˜åœ¨ä¸€ä¸ªâ€œç”œèœœç‚¹â€ã€‚æœ¬ç ”ç©¶çš„å‘ç°å¯èƒ½å¯¹äºç‰¹å®šæ•°æ®åº“ä¸æ€»æ˜¯é€‚ç”¨ï¼Œç‰¹åˆ«æ˜¯å¦‚æœè¯¥æ•°æ®åº“ä¸Spideræ•°æ®åº“æ˜¾è‘—ä¸åŒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2305.11853v3)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-05/2305.11853.md)  |

---

### 03æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>03-31</span> | **A Survey of Large Language Models**<br><sub>æœºæ„: Renmin University of China<br>æ€»çš„æ¥è¯´ï¼Œè¿™ç¯‡ç»¼è¿°æ–‡ç« ä»‹ç»äº†LLMsé¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œç‰¹åˆ«æ˜¯OpenAIæ¨å‡ºçš„ChatGPTå’ŒGPT-4æ¨¡å‹ï¼Œå¹¶å¼ºè°ƒäº†è¿™äº›äº§å“å¯¹äººå·¥æ™ºèƒ½ç ”ç©¶çš„é‡å¤§å½±å“ï¼Œç‰¹åˆ«æŒ‡å‡ºäº†å®ƒä»¬åœ¨äººæœºäº¤æµã€å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆã€ä»¥åŠäººå·¥æ™ºèƒ½å¯¹é½å’Œå®‰å…¨æ€§æ–¹é¢çš„çªç ´ã€‚åŒæ—¶ï¼Œæ–‡ç« è®¤è¯†åˆ°å°½ç®¡å–å¾—äº†å·¨å¤§çš„æŠ€æœ¯è¿›å±•ï¼Œä½†åœ¨å®‰å…¨æ€§ã€ç”Ÿæˆè´¨é‡å’Œå¤šæ¨¡æ€æ€§åŠŸèƒ½æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†ä¸€ç³»åˆ—çš„æŠ€æœ¯å’Œç­–ç•¥æ¥ç¼“è§£è¿™äº›é—®é¢˜ã€‚é€šè¿‡è¿™ç¯‡æ–‡ç« ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°ç†è§£LLMsçš„å‘å±•æ–¹å‘ä»¥åŠå¯¹æœªæ¥äººå·¥æ™ºèƒ½åº”ç”¨å’Œç ”ç©¶çš„æ½œåœ¨å½±å“ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2303.18223v13)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-03/2303.18223.md)  |

---

### 02æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>02-08</span> | **A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity**<br><sub>æœºæ„: Centre for Artificial Intelligence Research<br>æ–‡ç« é€šè¿‡æ›´ç»†ç²’åº¦çš„æ–¹å¼è¯„ä¼°äº†ChatGPTçš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶ä¸”æ‰¾åˆ°äº†LLMsä¸­çš„ä¸€ä¸ªå…³é”®é—®é¢˜ï¼Œå³åœ¨éæ–‡æœ¬è¯­ä¹‰ç†è§£æ–¹é¢çš„ä¸è¶³ã€‚è¿™ä¸€å‘ç°å¯¹äºæœªæ¥LLMsçš„æ”¹è¿›å’Œæ¨ç†èƒ½åŠ›çš„ç ”ç©¶æä¾›äº†é‡è¦çš„æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2302.04023v4)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-02/2302.04023.md)  |

---


## Star History
<picture>
<source
    media="(prefers-color-scheme: dark)"
    srcset="
    https://api.star-history.com/svg?repos=xianshang33/llm-paper-daily&type=Date&theme=dark
    "
/>
<source
    media="(prefers-color-scheme: light)"
    srcset="
    https://api.star-history.com/svg?repos=xianshang33/llm-paper-daily&type=Date
    "
/>
<img
    alt="Star History Chart"
    src="https://api.star-history.com/svg?repos=xianshang33/llm-paper-daily&type=Date"
/>
</picture>
            