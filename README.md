<h2 align='center'>llm-paper-daily æ—¥å¸¸è®ºæ–‡ç²¾é€‰</h2>
<div align='center'>

[![Status](https://img.shields.io/badge/status-Update_12.13_16:59-success.svg)]() [![ç®€ä½“ä¸­æ–‡ badge](https://img.shields.io/badge/%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87-Simplified%20Chinese-blue)](./README.md) [![English badge](https://img.shields.io/badge/%E8%8B%B1%E6%96%87-English-blue)](./README_en.md) 

</div>

**å…³äºä»“åº“**
æ¯æ—¥æ›´æ–°çš„è®ºæ–‡ä¼šå¸¦æœ‰arxivåœ°å€ã€ç›¸å…³ git ä»“åº“å’ŒåŸºäº GPT-4 çš„ç®€å•æ€»ç»“&nbsp;&nbsp;![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)

**è®ºæ–‡åˆ†ç±»**
è¿™ä¸ªå§Šå¦¹ä»“åº“ [Awesome-LLM-Papers](https://github.com/xianshang33/Awesome-LLM-Papers) å¯¹æ–‡ç« è¿›è¡Œäº†åˆ†ç±»ï¼Œâœ¨æ–°ä»“åº“å¼ºçƒˆæ¬¢è¿å¤§å®¶åšå‡ºè´¡çŒ®
- ğŸ’ æå‡ºå®è´µçš„å»ºè®® **Adding Issues**
- ğŸŒˆ å°†æ”¶é›†çš„å¥½æ–‡å’Œå…·æœ‰é‡Œç¨‹ç¢‘æ„ä¹‰çš„æ–‡ç« æäº¤ **Pull Requests**
ğŸ‘‰ [Visit Awesome-LLM-Papers](https://github.com/xianshang33/Awesome-LLM-Papers)

<details>
  <summary>æŸ¥çœ‹æ›´æ–°æ–‡ç«  &nbsp;&nbsp;<sub>æ›´æ–°æ—¶é—´: 12æœˆ13æ—¥ 16:59</sub></summary>
<br>

- VILA: On Pre-training for Visual Language Models 
- Comparable Demonstrations are Important in In-Context Learning: A Novel Perspective on Demonstration Selection 
- LLMEval: A Preliminary Study on How to Evaluate Large Language Models 
- Efficient Few-Shot Clinical Task Adaptation with Large Language Models 
- Alignment for Honesty 
- Oracle-based Protocol Testing with Eywa 
- Extracting Self-Consistent Causal Insights from Users Feedback with LLMs and In-context Learning 
- On Meta-Prompting 
- diff History for Long-Context Language Agents 
- LLM360: Towards Fully Transparent Open-Source LLMs 
- Honeybee: Locality-enhanced Projector for Multimodal LLM 
</details>

## 12æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **diff History for Long-Context Language Agents**<br><sub>æœºæ„: New York University<br>è®ºæ–‡æå‡ºå¹¶éªŒè¯äº†ä½¿ç”¨diffå†å²æ¥æé«˜å¯¹é•¿äº¤äº’å†å²çš„æ¨¡å‹å¤„ç†èƒ½åŠ›ã€‚è¿™ä¸€æ–¹æ³•æ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¤æ‚å†³ç­–ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¹¶èƒ½æœ‰æ•ˆæ‰©å¤§æ¨¡å‹å¯å¤„ç†çš„å†å²é•¿åº¦ï¼Œä¸ºé•¿æ—¶é—´åºåˆ—å†³ç­–ä»£ç†çš„è®¾è®¡æä¾›äº†æ–°æ€è·¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07540v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0754.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **Alignment for Honesty**<br><sub>æœºæ„: Shanghai Jiao Tong University, Shanghai Artificial Intelligence Laboratory, Fudan University<br>è®ºæ–‡æå‡ºäº†ä¸äººç±»çš„è¯šå®æ€§å¯¹é½çš„æ¦‚å¿µï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šæå‡ºäº†æŒ‘æˆ˜å’Œè§£å†³æ–¹æ³•ã€‚é€šè¿‡æ­£å¼å®šä¹‰é—®é¢˜ã€æå‡ºæ–°æ–¹æ³•å’Œå»ºç«‹è¯„ä¼°æ¡†æ¶ï¼Œè®ºæ–‡ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è¯šå®æ€§å¯¹é½æä¾›äº†å…¨é¢çš„è§£å†³æ–¹æ¡ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07000v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/GAIR-NLP/alignment-for-honesty)</div> |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **Efficient Few-Shot Clinical Task Adaptation with Large Language Models**<br><sub>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåœ¨å°‘æ ·æœ¬çš„åŒ»å­¦å›¾åƒåˆ†ç±»ä¸­é€šè¿‡å†·å†»ä¸€éƒ¨åˆ†ç½‘ç»œå±‚è¿›è¡Œé«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•ï¼Œå¹¶ä¸”å¼•å…¥äº†å¤§å‹è¯­è¨€æ¨¡å‹æ¥ä¸Šä¸‹æ–‡åŒ–æ ‡ç­¾ï¼Œä»¥æä¾›æœ‰æ•ˆçš„è¯­ä¹‰æŒ‡å¯¼ã€‚æ–¹æ³•åœ¨æŒ‘æˆ˜èµ›ä¸­å–å¾—äº†ä¼˜å¼‚çš„æˆç»©ï¼Œè¡¨æ˜åœ¨å¤„ç†å°‘æ ·æœ¬åœºæ™¯ä¸‹è‡ªç„¶å›¾åƒæ¨¡å‹åˆ°åŒ»å­¦å›¾åƒä»»åŠ¡çš„é€‚é…é—®é¢˜æ—¶å…·æœ‰å¾ˆé«˜çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07125v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07125.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **LLMEval: A Preliminary Study on How to Evaluate Large Language Models**<br><sub>æœºæ„: Fudan University, Shanghai Jiaotong University  <br>è®ºæ–‡é’ˆå¯¹å¦‚ä½•è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œå¯¹å¤šç§è¯„ä¼°æ ‡å‡†ã€ä¸åŒç±»å‹çš„è¯„ä¼°è€…ã€è¯„åˆ†æ–¹æ³•å’Œæ’åç³»ç»Ÿè¿›è¡Œäº†æ¯”è¾ƒå’Œåˆ†æï¼Œæå‡ºäº†æ–°çš„è¯„ä¼°æ•°æ®é›†LLMEvalï¼Œå¯¹20ä¸ªLLMsè¿›è¡Œäº†è¯„ä¼°ï¼Œç”Ÿæˆäº†å¤§é‡çš„æ‰‹åŠ¨å’Œè‡ªåŠ¨è¯„ä¼°ç»“æœã€‚è¯¥ç ”ç©¶ä¸ºæœªæ¥çš„LLMè¯„ä¼°æä¾›äº†æœ‰ç›Šçš„æ´è§å’Œç»“è®ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07398v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07398.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **Comparable Demonstrations are Important in In-Context Learning: A Novel Perspective on Demonstration Selection**<br><sub>æœºæ„: Shanghai Jiao Tong University<br>æœ¬æ–‡ä»ç¤ºä¾‹é—´å…³ç³»çš„è§’åº¦ç ”ç©¶ICLï¼Œæå‡ºé€šè¿‡æœ€å°åŒ–ç¼–è¾‘æ–‡æœ¬ä»¥æ„é€ Comparable Demonstrationsï¼ˆCDsï¼‰æ¥å‡è½»æ½œåœ¨çš„ç¤ºä¾‹åå€šï¼Œå®éªŒè¯æ˜äº†å…¶åœ¨OODæƒ…å½¢ä¸‹çš„æ€§èƒ½å¢ç›Šï¼Œè¡¨æ˜äº†CDsåœ¨ç®€åŒ–ä»»åŠ¡ä¸­å°¤å…¶å¿…è¦ï¼Œå¹¶å±•ç¤ºäº†å…¶ç›¸å¯¹äºç¤ºä¾‹æ•°çš„ç¨³å¥æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07476v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07476.md)  |
| <span style='display: inline-block; width: 42px;'>12-12</span> | **VILA: On Pre-training for Visual Language Models**<br><sub>æœºæ„: NVIDIA, MIT  <br>VILAåˆ©ç”¨æ”¹è¿›çš„é¢„è®­ç»ƒç­–ç•¥ï¼Œåœ¨å¤šç§è§†è§‰è¯­è¨€ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºå“è¶Šçš„æ€§èƒ½ï¼Œä¸ºæœªæ¥è§†è§‰è¯­è¨€æ¨¡å‹çš„è®¾è®¡æä¾›äº†å®ç”¨æŒ‡å—ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.07533v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.07533.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Honeybee: Locality-enhanced Projector for Multimodal LLM**<br><sub>æœºæ„: Kakao Brain<br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„å±€éƒ¨æ€§å¢å¼ºæŠ•å½±å™¨è®¾è®¡ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è§†è§‰ç‰¹å¾å±€éƒ¨æ€§ä¸Šçš„ä¸è¶³ï¼Œå¹¶æœ‰æ•ˆåˆ©ç”¨äº†å¤šé¢å‘æŒ‡ä»¤æ•°æ®é›†ï¼Œæœ€ç»ˆä½¿å¾—Honeybeeæ¨¡å‹åœ¨å¤šä¸ªMLLMåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06742v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06742.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/kakaobrain/honeybee)</div> |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **On Meta-Prompting**<br><sub>æœºæ„: Microsoft  <br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºèŒƒç•´è®ºçš„ç†è®ºæ¡†æ¶æ¥æ¦‚æ‹¬å’Œæç»˜è‡ªåŠ¨åŒ–æç¤ºæ–¹æ³•ï¼Œé€šè¿‡åœ¨æ„æƒ³åŠ›å’Œåˆ›é€ åŠ›è¿™ä¸¤ä¸ªé¢†åŸŸçš„å®éªŒï¼Œå±•ç¤ºäº†meta-promptingæ¯”ä¼ ç»Ÿå›ºå®šæç¤ºæ–¹æ³•æ›´èƒ½ç”Ÿæˆç”¨æˆ·åå¥½çš„è¾“å‡ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06562v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06562.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Extracting Self-Consistent Causal Insights from Users Feedback with LLMs and In-context Learning**<br><sub>æœºæ„: Microsoft, Microsoft Research<br>è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°æ¡†æ¶ï¼Œä½¿ç”¨LLMså’ŒICLä»ç”¨æˆ·åé¦ˆä¸­æå–è‡ªæ´½çš„å› æœè§è§£ï¼Œä»¥æ”¯æŒå¾®è½¯Feedback Hubçš„åˆ†æã€‚è¯¥æ¡†æ¶é‡‡ç”¨åˆ›æ–°çš„è‡ªæ´½æ€§å’Œæç¤ºé›†åˆæŠ€æœ¯ä»¥æŠ‘åˆ¶LLMsçš„å¹»è§‰å’Œé”™è¯¯æ¨ç†ï¼Œå¹¶æå‡ºäº†ä¸¤ç§å¯å‘å¼æ–¹æ³•æ¥è¯„ä¼°åé¦ˆçš„ä¿¡æ¯ä¸°å¯Œåº¦ã€‚å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆåœ°æå–å› æœè§è§£å’Œæ–°çš„bugï¼Œå¹¶æœ‰åŠ©äºå¾®è½¯å·¥ç¨‹å¸ˆä¼˜å…ˆå¤„ç†ä¿¡æ¯é‡ä¸°å¯Œçš„åé¦ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06820v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0682.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Oracle-based Protocol Testing with Eywa**<br><sub>æœºæ„: Microsoft Research<br>æœ¬æ–‡ä»‹ç»äº†åŸºäºç¥è°•çš„æµ‹è¯•æ–¹æ³•ï¼Œå……åˆ†åˆ©ç”¨LLMså»ºç«‹äº†ä¸°å¯Œçš„åè®®è¡Œä¸ºæ¨¡å‹ï¼Œå¹¶é€šè¿‡ç¬¦å·æ‰§è¡Œå’Œä¼ ç»Ÿæµ‹è¯•ç”Ÿæˆæ–¹æ³•ç›¸ç»“åˆï¼Œæå‡äº†ç½‘ç»œåè®®æµ‹è¯•ç”¨ä¾‹çš„è‡ªåŠ¨ç”Ÿæˆå’Œè¦†ç›–é¢ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06875v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06875.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **MMICT: Boosting Multi-Modal Fine-Tuning with In-Context Examples**<br><sub>æœºæ„: Xiamen University, Tencent YouTu Lab<br>è¿™é¡¹å·¥ä½œé€šè¿‡æå‡ºMMICTï¼Œå±•ç¤ºäº†åœ¨å¤§å‹å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ä¸Šè¿ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ä»¥å¢å¼ºå¾®è°ƒæ€§èƒ½çš„æ–°èŒƒå¼ã€‚é€šè¿‡è®¾è®¡M-Hubè¿™ä¸€å¤šåŠŸèƒ½æ¨¡å—å¹¶é€šè¿‡å„ç§ä¸Šä¸‹æ–‡ç¤ºèŒƒå®éªŒï¼Œç ”ç©¶æ­ç¤ºäº†ä¸Šä¸‹æ–‡å­¦ä¹ åœ¨æ”¹å–„å¤šæ¨¡æ€ä»»åŠ¡æ€§èƒ½ä¸­çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06363v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06363.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Federated Full-Parameter Tuning of Billion-Sized Language Models with Communication Cost under 18 Kilobytes**<br><sub>æœºæ„: Zhejiang University, Alibaba Group<br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è”é‚¦å…¨å‚æ•°å¾®è°ƒæ–¹æ³•â€”â€”FedKSeedï¼Œé€šè¿‡ZOOä¸æœ‰é™ç»„ç§å­ç»“åˆï¼Œæ˜¾è‘—é™ä½äº†æ•°åäº¿å¤§å°LLMså…¨å‚æ•°å¾®è°ƒæ‰€éœ€çš„é€šä¿¡å¼€é”€ï¼ŒåŒæ—¶å®ç°äº†è¾ƒé«˜çš„æ¨¡å‹ç²¾ç¡®åº¦å’Œè®¡ç®—æ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06353v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06353.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **Unlocking Anticipatory Text Generation: A Constrained Approach for Faithful Decoding with Large Language Models**<br><sub>æœºæ„: Salesforce AI Research<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡è€ƒè™‘æœªæ¥çº¦æŸæ»¡è¶³æ¥æ”¹å–„å¤§å‹è¯­è¨€æ¨¡å‹è§£ç æ–¹æ³•çš„æ–°é€”å¾„ã€‚æå‡ºçš„æ­£å¼æ–¹æ³•å’Œè¯„åˆ†æœºåˆ¶é€šè¿‡ä¸LLMsçš„åŸºå‡†æµ‹è¯•ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æ–‡æœ¬ç”Ÿæˆçš„è´¨é‡å’Œæ§åˆ¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06149v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06149.md)  |
| <span style='display: inline-block; width: 42px;'>12-11</span> | **"What's important here?": Opportunities and Challenges of Using LLMs in Retrieving Information from Web Interfaces**<br><sub>æœºæ„: Carnegie Mellon University<br>æœ¬æ–‡ç ”ç©¶äº†LLMsåœ¨ä»Webç•Œé¢æ£€ç´¢ä¿¡æ¯ä¸­çš„åº”ç”¨æ½œåŠ›å’Œé¢ä¸´çš„æŒ‘æˆ˜ã€‚é€šè¿‡ä¸€ç³»åˆ—å®éªŒï¼Œæ­ç¤ºäº†æ¨¡å‹æ€§èƒ½çš„å…³é”®å› ç´ åŠå…¶é™åˆ¶ï¼Œå¹¶ä¸ºæœªæ¥å·¥ä½œæŒ‡æ˜äº†æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.06147v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.06147.md)  |
| <span style='display: inline-block; width: 42px;'>12-10</span> | **Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs**<br><sub>æœºæ„: Microsoft Israel<br>è¿™é¡¹ç ”ç©¶çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºå®ƒå¯¹æ¯”äº†ç»†åŒ–è®­ç»ƒå’ŒRAGä¸¤ç§æ–¹æ³•å¯¹äºLLMsçŸ¥è¯†æ³¨å…¥èƒ½åŠ›çš„å½±å“ï¼Œå¹¶å‘ç°RAGåœ¨æ³¨å…¥æ–°çš„å’Œå·²æœ‰çš„çŸ¥è¯†æ–¹é¢è¡¨ç°æ›´ä½³ã€‚ç ”ç©¶ä½¿ç”¨äº†åˆ›æ–°çš„æ•°æ®é›†å’Œè¯„ä¼°æ–¹æ³•ï¼Œç¡®ä¿äº†ç†è®ºå‘ç°çš„å®ç”¨æ€§å’Œå¯è¡Œæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05934v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05934.md)  |
| <span style='display: inline-block; width: 42px;'>12-09</span> | **Context Tuning for Retrieval Augmented Generation**<br><sub>æœºæ„: Apple  <br>æœ¬è®ºæ–‡é€šè¿‡å¼•å…¥ä¸Šä¸‹æ–‡è°ƒä¼˜è¿™ä¸€æ–°é¢–ç»„ä»¶ï¼Œæé«˜äº†åŸºäºæ£€ç´¢çš„å¢å¼ºè®¡åˆ’ï¼ˆRAG-based planningï¼‰çš„æ•ˆæœï¼Œä½¿å…¶èƒ½å¤„ç†ä¸å®Œæ•´æˆ–ä¸æ˜ç¡®çš„æŸ¥è¯¢ï¼ŒåŒæ—¶è¿˜é™ä½äº†å¹»è§‰æ€§é”™è¯¯çš„äº§ç”Ÿã€‚ç ”ç©¶å¯¹æ¯”äº†ä¸åŒçš„æ£€ç´¢æ–¹æ³•åœ¨è½»é‡æ¨¡å‹å’ŒLLMsä¸­çš„åº”ç”¨ï¼Œå¹¶å±•ç¤ºäº†æ–°æ–¹æ³•åœ¨æé«˜ä¸Šä¸‹æ–‡ç†è§£ä¸Šçš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05708v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05708.md)  |
| <span style='display: inline-block; width: 42px;'>12-09</span> | **Can Large Language Models Serve as Rational Players in Game Theory? A Systematic Analysis**<br><sub>æœºæ„: Shanghai Jiao Tong University<br>æœ¬ç ”ç©¶ç³»ç»Ÿåœ°æ¢ç´¢äº†LLMsåœ¨æ¸¸æˆç†è®ºèƒŒæ™¯ä¸‹çš„èƒ½åŠ›è¾¹ç•Œï¼Œå¹¶ä»ä¸‰ä¸ªè§’åº¦å‡ºå‘ï¼Œæä¾›äº†å°†LLMsåœ¨ç¤¾ä¼šç§‘å­¦ç ”ç©¶ä¸­ä½¿ç”¨çš„è¿›ä¸€æ­¥æŒ‡å¯¼ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05488v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05488.md)  |
| <span style='display: inline-block; width: 42px;'>12-09</span> | **Agile-Quant: Activation-Guided Quantization for Faster Inference of LLMs on the Edge**<br><sub>æœºæ„: Northeastern University, Oracle<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºAgile-Quantçš„æ¿€æ´»å¼•å¯¼é‡åŒ–æ¡†æ¶ï¼Œä»¥åŠ é€Ÿå¤§å‹è¯­è¨€æ¨¡å‹çš„è¾¹ç¼˜è®¾å¤‡æ¨ç†ã€‚Agile-Quantå…‹æœäº†æ¿€æ´»å€¼å¼‚å¸¸çš„æŒ‘æˆ˜å’Œè¾¹ç¼˜è®¾å¤‡ä¸Šçš„ç¡¬ä»¶å®æ–½é—®é¢˜ï¼Œå¹¶å®ç°äº†ä¸ä»…æƒé‡é‡åŒ–æ–¹æ³•ç›¸å½“çš„ä»»åŠ¡æ€§èƒ½ï¼ŒåŒæ—¶åœ¨å®é™…è®¾å¤‡ä¸Šè·å¾—äº†æ˜¾è‘—çš„æ¨ç†é€Ÿåº¦æå‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05693v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05693.md)  |
| <span style='display: inline-block; width: 42px;'>12-09</span> | **Sim-GPT: Text Similarity via GPT Annotated Data**<br><sub>æœºæ„: Shannon.AI, Zhejiang University, Bytedance<br>Sim-GPTæ˜¯ä¸€ä¸ªåˆ©ç”¨GPT-4ç”Ÿæˆæ•°æ®æ ‡ç­¾æ¥è®­ç»ƒSTSæ¨¡å‹çš„æ¡†æ¶ã€‚å®ƒåœ¨ç”Ÿæˆæ•°æ®æ—¶ä»…äº§ç”Ÿä¸€æ¬¡æ€§æˆæœ¬ï¼Œé€Ÿåº¦è¾ƒå¿«ï¼Œæ¨¡å‹åœ¨å¤šä¸ªSTSåŸºå‡†ä¸Šæ€§èƒ½ä¼˜è¶Šã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05603v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05603.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/ShuheWang1998/Sim-GPT)</div> |
| <span style='display: inline-block; width: 42px;'>12-09</span> | **NLLG Quarterly arXiv Report 09/23: What are the most influential current AI Papers?**<br><sub>æœºæ„: University of Mannheim, University of Bielefeld<br>è¯¥è®ºæ–‡é€šè¿‡åˆ†æåœ¨ç‰¹å®šæ—¶é—´å†…arXivä¸Šå¼•ç”¨æœ€å¤šçš„è®ºæ–‡ï¼Œæä¾›äº†AIç ”ç©¶é¢†åŸŸçš„æœ€æ–°è¶‹åŠ¿å’Œå½±å“åŠ›åˆ†æï¼Œç‰¹åˆ«å¼ºè°ƒäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å…¶ä¸­çš„é‡è¦æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.05688v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.05688.md)  |
| <span style='display: inline-block; width: 42px;'>12-08</span> | **Using Program Knowledge Graph to Uncover Software Vulnerabilities**<br><sub>è®ºæ–‡é€šè¿‡ç»“åˆç¨‹åºå›¾å’Œå®‰å…¨æ•°æ®ï¼Œæå‡ºäº†ç¨‹åºçŸ¥è¯†å›¾è°±ï¼Œå¹¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„æç¤ºè°ƒæ•´æ¥è‡ªåŠ¨ç”Ÿæˆæ£€æµ‹è½¯ä»¶ä»£ç ä¸­æ¼æ´çš„æŸ¥è¯¢ã€‚è¯¥æ–¹æ³•æ—¨åœ¨å…‹æœä¼ ç»Ÿæ¼æ´æ£€æµ‹æ–¹æ³•çš„å±€é™æ€§ï¼Œæé«˜æ¼æ´æ£€æµ‹çš„è‡ªåŠ¨åŒ–ç¨‹åº¦å’Œæœ‰æ•ˆæ€§ï¼Œå°¤å…¶æ˜¯åœ¨é™æ€åˆ†æä¸­çš„åº”ç”¨ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04818v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04818.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Chain of Code: Reasoning with a Language Model-Augmented Code Emulator**<br><sub>æœºæ„: Google DeepMind, Stanford University, University of California Berkeley  <br>Chain of Code (CoC)ä¸ºè¯­è¨€æ¨¡å‹å¢åŠ äº†é€šè¿‡ç¼–å†™ä»£ç å’Œæ¨¡æ‹Ÿä»£ç æ‰§è¡Œæ¥æ”¹å–„æ¨ç†èƒ½åŠ›çš„æ–°ç»´åº¦ã€‚å®ƒåœ¨æ•°å­—å’Œè¯­ä¹‰æ¨ç†ä»»åŠ¡ä¸­å‡å®ç°äº†çªç ´æ€§çš„æ€§èƒ½ï¼Œå¯¹LLMsçš„åº”ç”¨èŒƒå›´è¿›è¡Œäº†æ‰©å±•ï¼Œå¹¶æœ‰æ½œåŠ›åº”ç”¨äºæ›´å¹¿æ³›çš„é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04474v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04474.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool Use**<br><sub>æœºæ„: Gaoling School of Artificial Intelligence, Renmin University of China, Alibaba Group<br>è¯¥è®ºæ–‡é’ˆå¯¹LLMsåœ¨å·¥å…·ä½¿ç”¨æ—¶å¯¹ä¸Šä¸‹æ–‡è®¤çŸ¥çš„ä¸è¶³æå‡ºäº†Attention Bucketsæ–¹æ³•ï¼Œé€šè¿‡å¤„ç†ä¸åŒçš„RoPEè§’åº¦åŸºç¡€æ¥å¼ºåŒ–å¯¹ä¸Šä¸‹æ–‡çš„å…³æ³¨ï¼Œæ˜¾è‘—æå‡äº†LLMsåœ¨å·¥å…·ä½¿ç”¨ä»»åŠ¡çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04455v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04455.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Generating Illustrated Instructions**<br><sub>æœºæ„: GenAI Meta, Columbia University<br>æœ¬è®ºæ–‡ä»‹ç»äº†ä¸€ç§åä¸ºStackedDiffusionçš„æ–°æ–¹æ³•ï¼Œç”¨äºç”Ÿæˆæ’å›¾è¯´æ˜ï¼Œè¿™æ˜¯ä¸€ç§å°†æ–‡æœ¬å’Œå›¾åƒç»“åˆèµ·æ¥æè¿°å¦‚ä½•å®ç°æŸä¸€ç›®æ ‡çš„ä»»åŠ¡ã€‚è¯¥æ–¹æ³•é€šè¿‡ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹å’Œæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œå¹¶å¼•å…¥ä¸€äº›æ–°é¢–çš„å»ºæ¨¡æŠ€å·§ï¼Œè§£å†³äº†ç°æœ‰T2Iæ¨¡å‹æ— æ³•ç›´æ¥ä»ç”¨æˆ·æŸ¥è¯¢ä¸­ç”Ÿæˆè§†è§‰æ•ˆæœçš„é—®é¢˜ï¼Œå¹¶åœ¨äººç±»è¯„ä¼°ä¸­è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯æ°´å¹³ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04552v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04552.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models**<br><sub>æœºæ„: MPI for Intelligent Systems, University of Washington<br>æ­¤ç ”ç©¶ä¸ºæµ‹è¯•å’Œåˆ†æå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ­£è§„å› æœæ¨ç†ä¸Šçš„èƒ½åŠ›æå‡ºäº†CLADDERæ•°æ®é›†å’ŒCAUSALCOTæ€ç»´è·¯å¾„æç¤ºç­–ç•¥ï¼Œé€šè¿‡å®éªŒçªæ˜¾äº†LLMsçš„å±€é™å¹¶ä¸ºæœªæ¥ç ”ç©¶æå‡ºäº†æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04350v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0435.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/causalNLP/cladder)</div> |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **A Study on the Calibration of In-context Learning**<br><sub>æœºæ„: Harvard University<br>è¯¥è®ºæ–‡æ·±å…¥ç ”ç©¶äº†ä¸Šä¸‹æ–‡å†…å­¦ä¹ (ICL)åœ¨è¯­è¨€æ¨¡å‹(LMs)ä¸­çš„æ ¡å‡†å‡†ç¡®æ€§é—®é¢˜ï¼Œå¹¶æå‡ºäº†è¯„ä¼°å’Œåˆ†ææ–¹æ³•ã€‚å®ƒæ­ç¤ºäº†æ ¡å‡†è¯¯å·®ä¸æ¨¡å‹å¤§å°å’Œå¾®è°ƒè¿‡ç¨‹ä¸­çš„å˜åŒ–å…³ç³»ï¼Œä»¥åŠæ ¡å‡†åœ¨æ¨ç†ä»»åŠ¡ç”Ÿæˆä¸­çš„é™ä½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04021v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04021.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Cost-Effective In-Context Learning for Entity Resolution: A Design Space Exploration**<br><sub>æœºæ„: Renmin University of China, Beijing Institute of Technology, HKUST (GZ)<br>è¿™ç¯‡è®ºæ–‡æä¾›äº†ä¸€ä¸ªå…¨é¢çš„ç ”ç©¶ï¼Œæ—¨åœ¨æ¢ç´¢å¦‚ä½•å¼€å‘ä¸€ç§æˆæœ¬æ•ˆç›Šçš„æ‰¹é‡æç¤ºæ–¹æ³•æ¥è¿›è¡Œå®ä½“è§£æã€‚ä¸»è¦è´¡çŒ®æ˜¯ä»‹ç» BATCHER æ¡†æ¶å¹¶æå‡ºåŸºäºè¦†ç›–çš„æ¼”ç¤ºé€‰æ‹©ç­–ç•¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03987v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03987.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **An LLM Compiler for Parallel Function Calling**<br><sub>æœºæ„: UC Berkeley, ICSI, LBNL<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºLLMCompilerçš„ç³»ç»Ÿï¼Œè§£å†³äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ‰§è¡Œå¤šåŠŸèƒ½è°ƒç”¨æ—¶çš„é«˜å»¶è¿Ÿæˆæœ¬å’Œæ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼Œé€šè¿‡å¹¶è¡ŒåŒ–å‡½æ•°è°ƒç”¨å’Œä¼˜åŒ–åè°ƒæ¥æé«˜é€Ÿåº¦ï¼ŒèŠ‚çœæˆæœ¬å¹¶æå‡å‡†ç¡®ç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04511v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04511.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Beyond Surface: Probing LLaMA Across Scales and Layers**<br><sub>æœºæ„: Hong Kong University of Science and Technology<br>æœ¬ç ”ç©¶çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºæå‡ºäº†ä¸€ç³»åˆ—è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹é«˜é˜¶èƒ½åŠ›çš„æ¢é’ˆä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡å›´ç»•ç€è®¡ç®—èƒ½åŠ›ã€æ•°å­¦æ¨ç†ã€é€»è¾‘æ¨ç†å’ŒçœŸå®æ€§æ£€æµ‹ã€‚ç ”ç©¶æ­ç¤ºäº†LLMçš„è¡¨ç°å¦‚ä½•éšç€æ¨¡å‹è§„æ¨¡å’Œå±‚æ¬¡ç»“æ„çš„å˜åŒ–ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04333v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04333.md)  |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **Generative agent-based modeling with actions grounded in physical, social, or digital space using Concordia**<br><sub>æœºæ„: Google DeepMind, Google Research<br>æœ¬è®ºæ–‡æå‡ºäº†åˆ©ç”¨ç”Ÿæˆå¼å¤§å‹è¯­è¨€æ¨¡å‹å¢å¼ºåŸºäºä»£ç†çš„æ¨¡å‹çš„æ–¹æ³•ï¼Œé€šè¿‡Concordiaåº“å®ç°äº†åœ¨ç¤¾ä¼šã€ç‰©ç†å’Œæ•°å­—ç©ºé—´ä¸­æ¨¡æ‹Ÿä»£ç†çš„äº¤äº’ã€‚è¯¥æ¨¡å‹æ—¨åœ¨æä¾›é€¼çœŸçš„ç¤¾ä¼šæ¨¡æ‹Ÿï¼Œå¹¶æ¢ç´¢æ¨¡å‹çš„æœ‰æ•ˆæ€§éªŒè¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03664v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03664.md)  |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **Efficient Large Language Models: A Survey**<br><sub>æœºæ„: The Ohio State University, Google Research, Amazon AWS AI<br>è®ºæ–‡ç»¼è¿°äº†å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å¯¹äºç¨€ç–æ¿€æ´»æ–¹æ³•çš„æœ€æ–°è¿›å±•ï¼Œç‰¹åˆ«æ˜¯æ··åˆä¸“å®¶ç³»ç»Ÿï¼ˆMoEï¼‰åŠå…¶åœ¨é•¿æ–‡æœ¬å¤„ç†æ–¹é¢çš„åº”ç”¨ã€‚å®ƒæ€»ç»“äº†MoEæ¨¡å‹ä¼˜åŒ–çš„å„ç§æ–¹æ³•ï¼ŒåŒ…æ‹¬ç®—æ³•çº§åˆ«çš„æ”¹è¿›å’Œç³»ç»Ÿçº§åˆ«çš„åŠ é€Ÿæ¡†æ¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03863v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03863.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/AIoT-MLSys-Lab/EfficientLLMs)</div> |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **AnimateZero: Video Diffusion Models are Zero-Shot Image Animators**<br><sub>æœºæ„: Peking University, Tencent AI Lab, HKUST<br>AnimateZeroä¸ºT2Vç”Ÿæˆæä¾›è§£è€¦å’Œç²¾ç¡®çš„å¤–è§‚å’ŒåŠ¨ä½œæ§åˆ¶ï¼Œé€šè¿‡ç©ºé—´å¤–è§‚æ§åˆ¶å’Œæ—¶é—´ä¸€è‡´æ€§æ§åˆ¶ï¼Œå®ç°äº†ä»T2Iåˆ°I2Vçš„æ­¥éª¤å¼è§†é¢‘ç”Ÿæˆï¼ŒåŒæ—¶ç»´æŠ¤è‰¯å¥½çš„åŸŸä¸€è‡´æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03793v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03793.md)  |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **Controllable Human-Object Interaction Synthesis**<br><sub>æœºæ„: Stanford University, FAIR Meta<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„äº¤äº’åˆæˆæ–¹æ³•CHOISï¼Œå®ƒèƒ½åœ¨å—è¯­è¨€æè¿°æŒ‡å¯¼çš„æ¡ä»¶ä¸‹ï¼Œç”Ÿæˆç¬¦åˆä¸‰ç»´åœºæ™¯å‡ ä½•çº¦æŸçš„äººä¸ç‰©ä½“çš„åŒæ­¥è¿åŠ¨ã€‚è¯¥æ–¹æ³•é€šè¿‡é›†æˆåˆ°ä¸€ä¸ªç³»ç»Ÿä¸­ï¼Œå±•ç¤ºäº†å…¶åœ¨åˆæˆè¿ç»­ã€é€¼çœŸå’Œç¯å¢ƒæ„ŸçŸ¥çš„äººç‰©äº’åŠ¨æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03913v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03913.md)  |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **OneLLM: One Framework to Align All Modalities with Language**<br><sub>æœºæ„: MMLab The Chinese University of Hong Kong, Shanghai Artificial Intelligence Laboratory<br>OneLLMé€šè¿‡å…¶ç»Ÿä¸€çš„å¤šæ¨¡æ€ç¼–ç æ¡†æ¶å’Œæ¸è¿›å¼å¯¹é½ç®¡é“ï¼Œåœ¨æ¨ç†å’Œåˆ©ç”¨æ–¹é¢å±•ç¤ºäº†å¼ºå¤§çš„å¤šæ¨¡æ€ç†è§£å’Œå¤„ç†èƒ½åŠ›ï¼Œå¹¶æˆåŠŸåœ°å¤„ç†äº†æ‰©å±•å¤šæ¨¡æ€LLMsçš„æŒ‘æˆ˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03700v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.037.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/csuhan/OneLLM)</div> |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **Holmes: Towards Distributed Training Across Clusters with Heterogeneous NIC Environment**<br><sub>æœºæ„: Zhejiang Lab<br>æ–‡ç« æˆåŠŸä»‹ç»äº†ä¸€ä¸ªèƒ½åœ¨ç½‘ç»œæ¥å£å¡å¼‚æ„ç¯å¢ƒä¸­è¿›è¡Œå¤§å‹è¯­è¨€æ¨¡å‹è®­ç»ƒçš„æ¡†æ¶â€”â€”Holmesã€‚é€šè¿‡å®è¯ç ”ç©¶å…¶æ€§èƒ½ï¼ŒHolmesè¢«è¯æ˜å¯åœ¨å¼‚æ„ç¯å¢ƒä¸­å®ç°ä¸åŒæ„RDMA NICsç›¸å½“çš„æ€§èƒ½æ°´å¹³ï¼Œä»è€Œä½¿LLMè®­ç»ƒæ›´åŠ æ™®åŠå¹¶æ‰©å¤§äº†æœ‰æ•ˆæ‰©å±•çš„å¯èƒ½æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03549v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03549.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education**<br><sub>æœºæ„: Carnegie Mellon University  <br>æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯å¼€å‘äº†ä¸€ä¸ªåŸºäºGPT-4çš„è‡ªåŠ¨åŒ–MCQç”Ÿæˆç³»ç»Ÿï¼Œé€šè¿‡ä¸“é—¨çš„å¼¹æ€§æ„æ¶å’Œç²¾ç¡®çš„LOå¯¹é½æœºåˆ¶ï¼ŒæˆåŠŸç”Ÿæˆä¸é«˜ç­‰æ•™è‚²Pythonè¯¾ç¨‹LOä¸€è‡´çš„MCQsã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè‡ªåŠ¨ç”Ÿæˆçš„MCQåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä¸LOä¿æŒè‰¯å¥½çš„ä¸€è‡´æ€§ï¼Œè´¨é‡æ¥è¿‘äººå·¥è®¾è®¡çš„MCQï¼Œä½†åœ¨æ‹¥æœ‰å•ä¸€æ­£ç¡®ç­”æ¡ˆå’Œé«˜è´¨é‡å¹²æ‰°é¡¹æ–¹é¢ç•¥æ˜¾æ¬ ç¼ºï¼Œæœªæ¥å·¥ä½œåº”è¯¥é›†ä¸­åœ¨å‡è½»è¿™äº›é—®é¢˜ä¸Šã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03173v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03173.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Let's Think Outside the Box: Exploring Leap-of-Thought in Large Language Models with Creative Humor Generation**<br><sub>æœºæ„: Sea AI Lab, Sun Yat-sen University, Harvard University  <br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ—¨åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹åˆ›é€ æ€§æ€ç»´èƒ½åŠ›çš„Creative Leap-of-Thought (CLoT)èŒƒå¼ï¼Œå¹¶éªŒè¯äº†å…¶åœ¨å¤šç§ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œæ¦‚æ‹¬èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02439v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02439.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/sail-sg/CLoT)</div> |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Prompt Optimization via Adversarial In-Context Learning**<br><sub>æœºæ„: National University of Singapore, Hong Kong University of Science and Technology, Institute for Infocomm Research (I2R) A*STAR<br>è®ºæ–‡ä»‹ç»äº†ä¸€ä¸ªæ–°é¢–çš„Adversarial In-Context Learningï¼ˆadv-ICLï¼‰æ–¹æ³•ï¼Œç”¨äºä¼˜åŒ–å¤§å‹æ¨¡å‹ä¸­promptçš„é€‰æ‹©ï¼Œä»¥æ­¤æé«˜æ¨¡å‹æ€§èƒ½ã€‚å®ƒå¯ä»¥å®ç°å¯¹æŠ—è®­ç»ƒç›®æ ‡ï¼Œå…‹æœæ•°æ®å’Œè®¡ç®—èµ„æºé™åˆ¶ï¼Œé€šè¿‡ä¼˜åŒ–promptè€Œä¸æ˜¯æ¨¡å‹å‚æ•°æ¥æå‡æ€§èƒ½ï¼Œä¸”å®éªŒç»“æœåœ¨å¤šä¸ªä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02614v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02614.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **RankZephyr: Effective and Robust Zero-Shot Listwise Reranking is a Breeze!**<br><sub>æœºæ„: University of Waterloo<br>RankZephyræ˜¯ä¸€æ¬¾æ–°å‹å¼€æºLLMï¼Œç‰¹åˆ«ä¼˜åŒ–äº†é›¶æ ·æœ¬åˆ—è¡¨é‡æ–°æ’åºä»»åŠ¡ã€‚å®ƒæä¾›äº†ä¸å¤§å‹ä¸“æœ‰æ¨¡å‹ç›¸å½“æˆ–æ›´ä¼˜çš„é‡æ–°æ’åºæ•ˆæœï¼ŒåŒæ—¶å¼ºè°ƒäº†æ•°æ®å¢å¼ºå¯¹äºæå‡æ¨¡å‹é²æ£’æ€§çš„é‡è¦æ€§ï¼Œå¹¶é€šè¿‡å®éªŒè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œåœ¨ç°å®åœºæ™¯ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02724v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02724.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/castorini/rank_llm)</div> |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Rank-without-GPT: Building GPT-Independent Listwise Rerankers on Open-Source Large Language Models**<br><sub>æœºæ„: University of Waterloo, 2Cohere, Comcast Applied AI<br>æœ¬æ–‡çš„æ ¸å¿ƒæˆæœæ˜¯æ¼”ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ç§ä¸ä¾èµ–GPTæ¨¡å‹çš„æœ‰æ•ˆåˆ—è¡¨é‡æ’åºå™¨ï¼Œèƒ½æ˜¾è‘—è¶…è¶Šç°æœ‰åŸºäºGPTçš„é‡æ’åºå™¨ï¼Œå¹¶å‘¼åç ”ç©¶ç¤¾åŒºå¼€å‘æ›´é«˜è´¨é‡çš„åˆ—è¡¨æ’åºè®­ç»ƒæ•°æ®ï¼Œä»¥æå‡æ¨¡å‹çš„è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02969v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02969.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Large Knowledge Model: Perspectives and Challenges**<br><sub>æœºæ„: Zhejiang University<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤§å‹çŸ¥è¯†æ¨¡å‹ï¼ˆLKMï¼‰çš„æ¦‚å¿µï¼Œæ—¨åœ¨æ›´æœ‰æ•ˆåœ°ç®¡ç†å’Œè§£è¯»çŸ¥è¯†è¡¨ç¤ºçš„å¤šæ ·æ€§ã€‚ç ”ç©¶æŒ‡å‡ºäº†ä»ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åˆ°LKMè½¬å˜çš„æŒ‘æˆ˜ï¼Œå¼ºè°ƒäº†ç»“æ„åŒ–çŸ¥è¯†åœ¨é¢„è®­ç»ƒä¸­çš„é‡è¦æ€§ï¼Œå¹¶æå‡ºäº†ä¸€å¥—LKMçš„è®¾è®¡åŸåˆ™ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02706v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02706.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Inherent limitations of LLMs regarding spatial information**<br><sub>æœºæ„: ProtagoLabs, International Monetary Fund, NetMind.ai  <br>è®ºæ–‡ä¸ºGPT-4ç­‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†ç©ºé—´ä¿¡æ¯æ–¹é¢çš„èƒ½åŠ›æä¾›äº†æ–°çš„è¯„ä¼°æ¡†æ¶å’Œä¸“é—¨è®¾è®¡çš„æ•°æ®é›†ï¼Œå¹¶åˆ†æäº†GPT-4åœ¨å¤„ç†ç©ºé—´ä¿¡æ¯æ–¹é¢çš„èƒ½åŠ›å’Œå±€é™æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03042v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03042.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **A Hardware Evaluation Framework for Large Language Model Inference**<br><sub>æœºæ„: Princeton University<br>LLMCompass ä½œä¸ºä¸€ç§ç¡¬ä»¶è¯„ä¼°æ¡†æ¶ï¼ŒæˆåŠŸåœ°åº”å¯¹äº†è®¾è®¡LLMæ¨ç†ç¡¬ä»¶æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚å®ƒä¸ä»…å¿«é€Ÿç²¾å‡†ï¼Œè€Œä¸”å…·æœ‰æ¶æ„æè¿°æ€§å’Œæˆæœ¬æ„è¯†ï¼Œå·²ç»åœ¨å•†ä¸šç¡¬ä»¶ä¸Šè¿›è¡Œäº†éªŒè¯ä¸”æ˜¾ç¤ºå‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03134v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03134.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **How should the advent of large language models affect the practice of science?**<br><sub>æœºæ„: Max Planck Institute for Biological Cybernetics, University of TÃ¼bingen, University of Washington  <br>æœ¬æ–‡è®¨è®ºäº†LLMså¯¹ç§‘å­¦å®è·µçš„å½±å“ï¼Œå¹¶å»ºè®®å¯¹å…¶ä½¿ç”¨æŒå®¡æ…æ€åº¦ï¼ŒåŒæ—¶å¼ºè°ƒäº†ä¿æŠ¤ç§‘å­¦çš„è§„èŒƒå’Œè®¤è¯†è®ºæ–¹é¢çš„é‡è¦æ€§ã€‚è™½ç„¶LLMså¯èƒ½æå‡æŸäº›ç§‘ç ”ä»»åŠ¡çš„æ•ˆç‡ï¼Œä½†ä½œä¸ºå·¥å…·ï¼Œå…¶ä½¿ç”¨åº”è¯¥è°¨æ…å¹¶ç¡®ä¿ç¬¦åˆç§‘å­¦è§„èŒƒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03759v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03759.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph Construction**<br><sub>æœºæ„: Zhejiang Lab, Ant Group<br>é€šè¿‡åœ¨KGCä¸­å¼•å…¥å¤šæ™ºèƒ½ä½“åˆä½œçš„æ–¹æ³•ï¼ŒcooperKGCæ¡†æ¶æå‡äº†æ™ºèƒ½ä½“è§£å†³å®ä½“ã€å…³ç³»å’Œäº‹ä»¶æå–ä»»åŠ¡ä¸­çš„ç²¾ç¡®åº¦ï¼Œå¹¶æœ‰æœ›ä¸ºAIçš„åä½œæ„è¯†åŒ–æœªæ¥å¥ å®šäº†åŸºç¡€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03022v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03022.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Competition-Level Problems are Effective LLM Evaluators**<br><sub>æœºæ„: Microsoft Research Asia, Xiamen University, Microsoft Azure AI<br>æœ¬ç ”ç©¶é€šè¿‡è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†ç«èµ›çº§ç¼–ç¨‹é—®é¢˜ä¸Šçš„è¡¨ç°ï¼Œæ­ç¤ºäº†GPT-4ç­‰æ¨¡å‹åœ¨çœŸå®æ¨ç†èƒ½åŠ›ä¸Šçš„ä¸è¶³ï¼Œå¹¶æå‡ºäº†ä¸€äº›æå‡è¡¨ç°çš„æ–¹æ³•ã€‚è¿™äº›å‘ç°çªæ˜¾äº†è¿™ç±»é—®é¢˜ä½œä¸ºè¯„ä¼°LLMsçš„æœ‰æ•ˆå·¥å…·çš„é‡è¦æ€§ï¼Œå¹¶ä¿ƒè¿›äº†å¯¹äºæé«˜LLMså¤æ‚æ¨ç†èƒ½åŠ›çš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02143v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02143.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **ChatGPT as a Math Questioner? Evaluating ChatGPT on Generating Pre-university Math Questions**<br><sub>æœºæ„: Nanyang Technological University, National University of Singapore<br>è¯¥ç ”ç©¶æå‡ºäº†ç¬¬ä¸€ä¸ªç³»ç»Ÿçš„è¯„ä¼°ChatGPTåœ¨ç”Ÿæˆå‰å¤§å­¦æ•°å­¦é—®é¢˜æ½œåŠ›çš„ç ”ç©¶ã€‚é€šè¿‡ä¸¤ç§ä¸»è¦åœºæ™¯ï¼šç»™å®šä¸Šä¸‹æ–‡å’Œæœªç»™å®šä¸Šä¸‹æ–‡çš„ç”Ÿæˆé—®é¢˜ï¼Œå¹¶ä¸ºæ•™è‚²å·¥ä½œè€…æä¾›å®ç”¨çš„æ´å¯Ÿã€‚ç ”ç©¶çš„ç»“æœæœ‰å¯èƒ½ä¿ƒè¿›ç°ä»£AIæŠ€æœ¯åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨ï¼Œå¹¶æé«˜è‡ªåŠ¨åŒ–æ•°å­¦é—®é¢˜ç”Ÿæˆçš„å®ç”¨æ€§å’Œæ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01661v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01661.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Data Management For Large Language Models: A Survey**<br><sub>æœºæ„: Peking University, Huawei Noahâ€™s Ark Lab<br>è¿™ç¯‡ç»¼è¿°ç ”ç©¶äº†åœ¨LLMsçš„é¢„è®­ç»ƒå’Œç›‘ç£å¼å¾®è°ƒé˜¶æ®µï¼Œæ•°æ®ç®¡ç†çš„ç ”ç©¶ç°çŠ¶ä»¥åŠæ•°æ®ç®¡ç†ç­–ç•¥çš„è®¾è®¡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01700v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.017.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/ZigeW/data_management_LLM)</div> |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large Language Models**<br><sub>æœºæ„: Xiamen University, MBZUAI, Tencent AI Lab<br>æ–‡ç« é€šè¿‡å¼•å…¥åŠ¨æ€è‡ªåŠ¨æ£€ç´¢æœºåˆ¶å’Œåˆ†å±‚æŠ½æ ·æ–¹æ³•ï¼ŒæˆåŠŸæå‡äº†å¤šæ¨¡æ€ä»»åŠ¡ä¸­LLMsçš„CoTæ¨ç†èƒ½åŠ›ã€‚æå‡ºçš„æ–¹æ³•ä¸ä»…æé«˜äº†æ¨¡å‹æ€§èƒ½ï¼Œè€Œä¸”é€šè¿‡å¤šæ ·åŒ–ç¤ºä¾‹é€‰æ‹©è¿›ä¸€æ­¥ç»†åŒ–äº†æ¨ç†è¿‡ç¨‹ï¼Œä¸ºå¤šæ¨¡æ€æ¨ç†é¢†åŸŸæ ‘ç«‹äº†æ–°çš„æ€§èƒ½æ ‡æ†ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01714v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01714.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication**<br><sub>æœºæ„: Fudan University, National University of Singapore, Shanghai AI Laboratory  <br>æœ¬æ–‡æå‡ºçš„Exchange-of-Thoughtï¼ˆEoTï¼‰æ¡†æ¶é€šè¿‡æ¨¡å‹é—´äº¤æµæå‡LLMsçš„æ¨ç†èƒ½åŠ›ï¼Œå‡­å€Ÿå››ç§é€šä¿¡èŒƒä¾‹å’Œä¿¡å¿ƒè¯„ä¼°æœºåˆ¶ï¼Œåœ¨å¤šä¸ªæ¨ç†ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—æˆæ•ˆï¼Œå¹¶è¯æ˜äº†å¤–éƒ¨æ€ç»´åœ¨å¢å¼ºæ¨¡å‹æ€§èƒ½ä¸­çš„ä½œç”¨ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01823v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01823.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly**<br><sub>æœºæ„: Elsevier<br>è¿™ç¯‡è®ºæ–‡æ€»ç»“äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®‰å…¨æ€§å’Œéšç§ä¿æŠ¤ä¸­çš„åº”ç”¨åŠç›¸å…³æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºLLMsåœ¨è¿™äº›é¢†åŸŸçš„å¥½å¤„ã€åå¤„å’Œä¸‘é™‹ä¹‹å¤„ï¼ŒåŒæ—¶å¼ºè°ƒäº†å…¶åœ¨æ•°æ®ä¿æŠ¤æ–¹é¢çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02003v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02003.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **LLMs Accelerate Annotation for Medical Information Extraction**<br><sub>æœºæ„: Google Research<br>æœ¬è®ºæ–‡å±•ç¤ºäº†ä¸€ä¸ªåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯Googleçš„PaLM 2ï¼Œæ¥æå‡åŒ»å­¦ä¿¡æ¯æŠ½å–ä»»åŠ¡ä¸­æ³¨é‡Šé€Ÿåº¦çš„æ–¹æ³•ã€‚è¿™ä¸ªåŸºäºLLMçš„æ³¨é‡Šæµç¨‹æé«˜äº†æ•ˆç‡ä¸”ä¸éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œå¤æ‚çš„è°ƒå‚ï¼Œä½¿å…¶æˆä¸ºä¸€ä¸ªæœ‰æ½œåŠ›çš„å·¥å…·æ¥åŠ é€ŸåŒ»ç–—é¢†åŸŸçš„æ•°æ®æ³¨é‡Šå·¥ä½œã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02296v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02296.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning**<br><sub>æœºæ„: Allen Institute for Artificial Intelligence, University of Washington<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªé€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ å®ç°LLMså¯¹é½çš„ç®€å•æ— é¡»è°ƒæ•´æ–¹æ³•ï¼ˆURIALï¼‰ï¼Œè¡¨ç°å‡ºä¸ä¼ ç»Ÿè°ƒæ•´å¯¹é½æ–¹æ³•ç›¸åŒ¹é…ç”šè‡³æ›´å¥½çš„æ•ˆæœã€‚è¿™ä¸€å‘ç°å¯¹æœªæ¥LLMsç ”ç©¶å…·æœ‰é‡è¦çš„å¯ç¤ºï¼Œè¯´æ˜äº†åœ¨LLMså¯¹é½ä¸Šæ›´æ·±å…¥çš„åˆ†æå’Œç†è®ºç†è§£çš„é‡è¦æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01552v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01552.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **On the Effectiveness of Large Language Models in Domain-Specific Code Generation**<br><sub>æœºæ„: Shanghai Jiao Tong University, Chongqing University, East China Normal University<br>è¿™é¡¹ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡æœ‰æ•ˆåœ°æ•´åˆé¢†åŸŸçŸ¥è¯†åˆ°ä»£ç ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œå¯ä»¥å¢å¼ºLLMsåœ¨ç‰¹å®šé¢†åŸŸå†…çš„ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚DomCoderä½œä¸ºä¸€ä¸ªæ–°çš„ä»£ç ç”Ÿæˆæ–¹æ³•ï¼Œåˆ©ç”¨äº†ä¸åŒç­–ç•¥ä»¥æ•´åˆé¢†åŸŸçŸ¥è¯†ï¼Œå¹¶åœ¨ç‰¹å®šè®¾ç½®ä¸‹æå‡äº†ä»£ç ç”Ÿæˆçš„å®é™…æ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01639v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01639.md)  |
| <span style='display: inline-block; width: 42px;'>12-03</span> | **D-Bot: Database Diagnosis System using Large Language Models**<br><sub>æœºæ„: Tsinghua University, Pigsty, ModelBest<br>D-Botæ˜¯ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ•°æ®åº“è¯Šæ–­ç³»ç»Ÿï¼Œå®ƒé€šè¿‡æ–‡æ¡£ä¸­çš„çŸ¥è¯†æå–å’Œç”Ÿæˆæœ‰æ•ˆçš„è¯Šæ–­æŠ¥å‘Šæ¥æé«˜æ•°æ®åº“è¯Šæ–­çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œè§£å†³äº†åŒºåŸŸä¸“å®¶åœ¨æ•°æ®åº“è¯Šæ–­ä¸­é‡åˆ°çš„æŒ‘æˆ˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01454v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01454.md)  |
| <span style='display: inline-block; width: 42px;'>12-03</span> | **TextGenSHAP: Scalable Post-hoc Explanations in Text Generation with Long Documents**<br><sub>æœºæ„: University of Southern California, Google Cloud AI<br>TextGenSHAPæ˜¯ä¸€ä¸ªä¸ºå¤§å‹è¯­è¨€æ¨¡å‹è®¾è®¡çš„é«˜æ•ˆåéªŒè§£é‡Šæ€§æ–¹æ³•ï¼Œé€šè¿‡æ”¹è¿›è§£é‡Šç”Ÿæˆçš„é€Ÿåº¦ï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨è¿™äº›è§£é‡Šæ”¹è¿›é•¿æ–‡æ¡£é—®ç­”å’Œæ–‡æ¡£æ£€ç´¢ç³»ç»Ÿã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01279v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01279.md)  |
| <span style='display: inline-block; width: 42px;'>12-03</span> | **Running cognitive evaluations on large language models: The do's and the don'ts**<br><sub>æœºæ„: Massachusetts Institute of Technology<br>è¿™ç¯‡è®ºæ–‡ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„è®¤çŸ¥è¯„ä¼°ç ”ç©¶æ–¹æ³•æä¾›äº†æŒ‡å¯¼æ€§çš„å»ºè®®ï¼Œæ¢è®¨äº†åœ¨æ–¹æ³•è®ºä¸Šå¦‚ä½•é¿å…åœ¨è¿è¡Œè®¤çŸ¥è¯„ä¼°æ—¶å¯èƒ½å‡ºç°çš„é—®é¢˜ã€‚è®ºæ–‡çš„ç›®æ ‡æ˜¯è´¡çŒ®äºAIå¿ƒç†å­¦é¢†åŸŸæœ€ä½³å®è·µçš„æ›´å¹¿æ³›è®¨è®ºã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01276v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01276.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Exploring and Improving the Spatial Reasoning Abilities of Large Language Models**<br><sub>æœºæ„: Stanford University  <br>è®ºæ–‡æé«˜äº†å¯¹LLMsåœ¨ç©ºé—´æ¨ç†å’Œåºåˆ—æ ‡æ³¨æ–¹é¢èƒ½åŠ›çš„ç†è§£ï¼Œæå‡ºäº†ä¸€ç§æ”¹è¿›LLMså¤„ç†3Dè½¨è¿¹è¯†åˆ«ä»»åŠ¡çš„æ–¹æ³•ï¼Œå…·æœ‰æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01054v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01054.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Just-in-Time Security Patch Detection -- LLM At the Rescue for Data Augmentation**<br><sub>æœºæ„: University of Luxembourg, Windows Copilot Microsoft, Singapore Management University<br>è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å®‰å…¨è¡¥ä¸æ£€æµ‹æ¡†æ¶ LLMDAï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œè¡¥ä¸åˆ†æå’Œæ•°æ®å¢å¼ºï¼Œå¹¶å¯¹å¤šæ¨¡æ€è¾“å…¥è¿›è¡Œå¯¹é½ã€‚è¿™ä½¿ç³»ç»Ÿèƒ½å¤Ÿä»è¡¥ä¸å’Œä»£ç çš„è”åˆä¸Šä¸‹æ–‡ä¸­æå–æ›´ä¸°å¯Œçš„ä¿¡æ¯ï¼Œæå‡æ£€æµ‹å‡†ç¡®æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01241v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01241.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Axiomatic Preference Modeling for Longform Question Answering**<br><sub>æœ¬æ–‡æå‡ºçš„åŸºäºå…¬ç†çš„æ¡†æ¶ä¸ºé•¿ç¯‡é—®ç­”åå¥½æ¨¡å‹æä¾›äº†ä¸€ç§æ–°æ–¹æ³•ï¼Œé€šè¿‡ç»†è‡´å®¡è§†äººç±»åå¥½ï¼Œå¹¶ä¼˜åŒ–äº†åå¥½æ‰“åˆ†çš„å‡†ç¡®æ€§ä¸æ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02206v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02206.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Large Language Models Are Zero-Shot Text Classifiers**<br><sub>æœºæ„: Florida Atlantic University<br>è®ºæ–‡å±•ç¤ºäº†LLMså¯ä»¥æœ‰æ•ˆä½œä¸ºé›¶æ ·æœ¬æ–‡æœ¬åˆ†ç±»å™¨çš„èƒ½åŠ›ï¼Œè¿™å¯¹äºéœ€è¦å¿«é€Ÿéƒ¨ç½²æ–‡æœ¬åˆ†ç±»å™¨çš„å°å›¢é˜Ÿæˆ–å°ä¼ä¸šæ¥è¯´ç‰¹åˆ«æœ‰ç›Šã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œåœ¨æ‰€æœ‰å››ä¸ªæ•°æ®é›†ä¸­ï¼ŒGPT-4ä¸€è‡´è¶…è¿‡äº†ä¼ ç»ŸMLç®—æ³•ã€‚æ–‡ç« è¿˜å»ºè®®æœªæ¥çš„ç ”ç©¶æ–¹å‘åŒ…æ‹¬ä¼˜åŒ–æç¤ºä»¥è·å¾—æ›´é«˜çš„ç²¾åº¦æˆ–å¼•å…¥è¯„è®ºä»£ç†ä»¥è¯„ä¼°å’Œæå‡LLMçš„ç»“æœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01044v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01044.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games**<br><sub>æœºæ„: Quebec AI Institute<br>è¿™ç¯‡è®ºæ–‡è´¡çŒ®äº†é€‚åº”JuBenshaæ¸¸æˆå¤æ‚æ€§å’Œæ–°æŒ‘æˆ˜çš„è¯„ä¼°æ–¹æ³•ï¼Œå¹¶åˆ›å»ºäº†ä¸€ä¸ªèƒ½å¤Ÿè¯„ä¼°äº¤äº’å¼ç¯å¢ƒä¸­LLMæ™ºèƒ½ä½“èƒ½åŠ›çš„æ–°æ¡†æ¶ThinkThriceï¼Œæ¨åŠ¨äº†AIåœ¨å¤šç©å®¶è§’è‰²æ‰®æ¼”æ¸¸æˆä¸­çš„åº”ç”¨ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00746v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00746.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Leveraging Large Language Models to Improve REST API Testing**<br><sub>æœºæ„: Georgia Institute of Technology, IBM Research<br>RESTGPTé€šè¿‡åˆ©ç”¨LLMsï¼Œç‰¹åˆ«æ˜¯GPT-3.5 Turboçš„é«˜æ•ˆå‡†ç¡®æ€§å’Œå°‘é‡ç¤ºä¾‹å­¦ä¹ çš„ç²¾å‡†æ€§ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨æå–è‡ªç„¶è¯­è¨€æè¿°ä¸­è§„åˆ™å’Œç”Ÿæˆæœ‰æ•ˆå€¼æ—¶çš„é™åˆ¶ï¼Œæ˜¾è‘—æå‡äº†REST APIæµ‹è¯•çš„è´¨é‡å’Œå‡†ç¡®åº¦ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00894v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00894.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **On Exploring the Reasoning Capability of Large Language Models with Knowledge Graphs**<br><sub>æœºæ„: Singapore Management University, National Sun Yat-sen University<br>ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼ŒLLMsèƒ½å¤Ÿé€šè¿‡å…¶å†…éƒ¨çŸ¥è¯†å›¾æˆåŠŸå¤„ç†çŸ¥è¯†å›¾æ¨ç†ä»»åŠ¡ï¼Œå¹¶èƒ½ä»ä¸Šä¸‹æ–‡ä¸­æ¨æ–­å‡ºçŸ¥è¯†å›¾å…³ç³»ï¼Œå±•ç¤ºäº†LLMsåœ¨çŸ¥è¯†å›¾æ¨ç†ä¸­çš„æ½œåŠ›åŠåº”ç”¨ä»·å€¼ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00353v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00353.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Instruction-tuning Aligns LLMs to the Human Brain**<br><sub>æœºæ„: EPFL<br>æœ¬ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡æŒ‡ä»¤è°ƒæ•´è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸–ç•ŒçŸ¥è¯†è¡¨ç¤ºæ–¹é¢ä»¥åŠä¸äººè„‘æ´»åŠ¨çš„å¯¹é½ç¨‹åº¦ä¸Šè¡¨ç°æ›´ä½³ã€‚è¿™ä¸ºæœªæ¥LLMsçš„å‘å±•æä¾›äº†å°†ä¸–ç•ŒçŸ¥è¯†é›†æˆåˆ°æ¨¡å‹ä¸­çš„é‡è¦è§†è§’ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00575v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00575.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Beyond ChatBots: ExploreLLM for Structured Thoughts and Personalized Model Responses**<br><sub>æœºæ„: Google<br>æœ¬æ–‡ä»‹ç»äº†æ¢ç´¢LLMç³»ç»ŸExploreLLMï¼Œå®ƒé€šè¿‡ç»“åˆåŸºäºæç¤ºçš„ä»»åŠ¡åˆ†è§£æ–¹æ³•å’Œå…¨æ–°çš„ç±»ä¼¼å›¾å¼çš„å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆUIï¼‰ï¼Œåœ¨ç”¨æˆ·å’ŒLLMåŠ©æ‰‹ä¹‹é—´æä¾›äº†ä¸€ç§å…¨æ–°çš„äº¤äº’æ¨¡å¼ã€‚è¯¥ç³»ç»Ÿé€šè¿‡åœ¨ç»“æ„åŒ–å’Œäº¤äº’å¼ç•Œé¢ä¸­è¡¨ç¤ºç”Ÿæˆå­ä»»åŠ¡ï¼Œæ—¨åœ¨å‡è½»ç”¨æˆ·å®Œæˆå¤æ‚ä»»åŠ¡æ—¶çš„è®¤çŸ¥è´Ÿæ‹…ï¼ŒåŒæ—¶æé«˜ä¸ªæ€§åŒ–å“åº”çš„æ°´å¹³ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00763v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00763.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Nash Learning from Human Feedback**<br><sub>æœºæ„: Google DeepMind<br>è¿™ç¯‡æ–‡ç« æå‡ºäº†ä¸€ç§å…¨æ–°çš„è°ƒèŠ‚å¤§å‹è¯­è¨€æ¨¡å‹ä»¥é€šè¿‡çº³ä»€å‡è¡¡ä¸äººç±»åå¥½å¯¹é½çš„æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æ½œèƒ½ï¼Œå¹¶é€šè¿‡å®éªŒè¯æ˜äº†å…¶æ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00886v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00886.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Improve Supervised Representation Learning with Masked Image Modeling**<br><sub>æœºæ„: Google Research, OpenAI  <br>è¿™ç¯‡è®ºæ–‡æå‡ºäº†ä¸€ç§èåˆç›‘ç£è¡¨ç¤ºå­¦ä¹ å’ŒMIMçš„æ–°è®­ç»ƒè®¾ç½®ï¼Œè¯¥è®¾ç½®åœ¨ä¸å¢åŠ æ˜¾è‘—çš„è®­ç»ƒæˆ–æ¨ç†å¼€é”€çš„å‰æä¸‹ï¼Œæ˜¾è‘—æé«˜äº†ä¸‹æ¸¸ä»»åŠ¡å¦‚åˆ†ç±»ã€å›¾åƒæ£€ç´¢å’Œè¯­ä¹‰åˆ†å‰²çš„è¡¨ç¤ºå­¦ä¹ è´¨é‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00950v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0095.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **The Cost of Compression: Investigating the Impact of Compression on Parametric Knowledge in Language Models**<br><sub>æœºæ„: University of Wisconsin - Madison<br>è¿™é¡¹ç ”ç©¶é¦–æ¬¡å¤§è§„æ¨¡è€ƒå¯Ÿäº†LLMsçš„å‹ç¼©æŠ€æœ¯å¯¹æ¨¡å‹å‚æ•°çŸ¥è¯†çš„å½±å“ï¼Œå¹¶ä¸ºå®é™…åº”ç”¨æä¾›äº†é‡è¦è§è§£ï¼Œç‰¹åˆ«æ˜¯åœ¨å…³äºä¿®å‰ªå’Œé‡åŒ–æŠ€æœ¯ç›¸å…³çš„å†³ç­–æ–¹é¢ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00960v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0096.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **The Cost of Compression: Investigating the Impact of Compression on Parametric Knowledge in Language Models**<br><sub>æœºæ„: University of Wisconsin - Madison<br>æœ¬è®ºæ–‡é€šè¿‡å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œå‹ç¼©æŠ€æœ¯ï¼ˆå‰ªæå’Œé‡åŒ–ï¼‰çš„å…¨é¢ç ”ç©¶ï¼Œæ­ç¤ºäº†è¿™äº›æŠ€æœ¯å¯¹æ¨¡å‹å‚æ•°çŸ¥è¯†ä¿ç•™çš„å½±å“ï¼Œä¸ºå®è·µè€…æä¾›äº†å…³äºæ¨¡å‹å‹ç¼©çš„æœ‰ä»·å€¼è§è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00960v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0096.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Learning from One Continuous Video Stream**<br><sub>è¯¥è®ºæ–‡ä»‹ç»äº†ä¸€ä¸ªæ¡†æ¶ï¼Œç”¨äºä»å•ä¸€è¿ç»­è§†é¢‘æµä¸­è¿›è¡Œåœ¨çº¿å­¦ä¹ ï¼Œè¿™ä¸€æ¡†æ¶ä¾§é‡äºé€‚åº”æ€§ä¸æ³›åŒ–çš„è¯„ä¼°ï¼Œå¹¶æå‡ºäº†ä¸€ç³»åˆ—æœªæ¥é¢„æµ‹ä»»åŠ¡è¿›è¡Œé¢„è®­ç»ƒã€‚ç ”ç©¶æ˜¾ç¤ºï¼Œåœ¨è¿™ç§å­¦ä¹ ç¯å¢ƒä¸‹ï¼Œä¼˜åŒ–ç­–ç•¥éœ€è¦è°ƒæ•´ï¼Œé€šè¿‡å‡å°‘åŠ¨é‡å’Œè°ƒæ•´æƒé‡æ›´æ–°é¢‘ç‡å¯ä»¥æ”¹å–„æ¨¡å‹çš„é€‚åº”æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00598v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00598.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment from Fine-grained Correctional Human Feedback**<br><sub>RLHF-Væ˜¯ä¸€ä¸ªé€šè¿‡ç»†ç²’åº¦æ ¡æ­£å‹äººç±»åé¦ˆæ ¡æ­£MLLMè¡Œä¸ºçš„æ–°æ¡†æ¶ï¼Œé€šè¿‡æ”¶é›†é«˜è´¨é‡çš„äººç±»åå¥½æ•°æ®ä¸ºMLLMsæä¾›äººç±»å¯¹é½çš„å­¦ä¹ ä¿¡å·ï¼Œå¹¶é€šè¿‡å…¨é¢çš„å®éªŒéªŒè¯äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚è¯¥ç ”ç©¶å¯èƒ½åœ¨æé«˜å¤§å‹å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸­çš„å¯é æ€§å’Œå®ç”¨æ€§æ–¹é¢å–å¾—é‡è¦è¿›å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00849v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00849.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/RLHF-V/RLHF-V)</div> |

---

## 11æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation**<br><sub>æœºæ„: University of Science and Technology of China, Microsoft Research Asia<br>MicroCinemaä»¥å…¶åˆ›æ–°çš„æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆä¸¤é˜¶æ®µæµç¨‹å’Œæœ‰æ•ˆçš„Appearance Injection NetworkåŠAppearance Noise Prioræœºåˆ¶ï¼Œåœ¨è§†é¢‘ç”Ÿæˆè´¨é‡ä¸Šå®ç°äº†æ–°çš„çªç ´ï¼Œä¸ºåç»­å·¥ä½œæä¾›äº†å¯å€Ÿé‰´çš„èŒƒä¾‹ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18829v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18829.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **Applying Large Language Models and Chain-of-Thought for Automatic Scoring**<br><sub>æœºæ„: University of Georgia<br>æœ¬æ–‡å±•ç¤ºäº†LLMsåœ¨ä¿ƒè¿›è‡ªåŠ¨è¯„åˆ†æ–¹é¢çš„æ½œåŠ›ï¼Œå¹¶å¼ºè°ƒCoTåœ¨é…åˆé¡¹èŒå’Œè¯„åˆ†æ ‡å‡†ä½¿ç”¨æ—¶èƒ½æ˜¾è‘—å¢å¼ºè¯„åˆ†çš„å‡†ç¡®åº¦ã€‚é€šè¿‡ç»“åˆLLMså’ŒCoTçš„æ–¹æ³•ï¼Œå¯ä»¥é™ä½è‡ªåŠ¨è¯„åˆ†æ¨¡å‹æ„å»ºçš„å¤æ‚æ€§å’ŒäººåŠ›æˆæœ¬ï¼Œå¹¶å¯èƒ½æä¾›æ›´æ¥è¿‘äººç±»è¯„åˆ†ç»“æœçš„è¯„åˆ†ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03748v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2312.03748.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **TaskBench: Benchmarking Large Language Models for Task Automation**<br><sub>æœºæ„: Zhejiang University<br>è¯¥æ–‡çŒ®æå‡ºäº†TaskBenchåŸºå‡†æµ‹è¯•å’ŒTASKEVALè¯„ä¼°ç³»ç»Ÿï¼Œé€šè¿‡æ•°æ®ç”Ÿæˆå’Œé‡åŒ–è¯„ä¼°ç³»ç»Ÿï¼Œæœ‰æ•ˆåœ°è§£å†³äº†åœ¨ä»»åŠ¡è‡ªåŠ¨åŒ–é¢†åŸŸå¯¹LLMsçš„è¯„ä¼°é—®é¢˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18760v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1876.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text**<br><sub>æœºæ„: The University of Tokyo<br>ç ”ç©¶å±•ç¤ºäº†GPT-4å¤„ç†æ··æ·†æ–‡æœ¬çš„å¼ºå¤§èƒ½åŠ›ï¼Œè®¾ç½®äº†ä¸¤é¡¹æ–°æŒ‡æ ‡RRå’ŒRPGï¼Œå¹¶é€šè¿‡å®ƒä»¬éªŒè¯äº†GPT-4åœ¨ä¸åŒæ··æ·†åœºæ™¯å’Œæ¯”ç‡ä¸‹çš„ç¨³å®šè¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18805v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18805.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **PoseGPT: Chatting about 3D Human Pose**<br><sub>æœºæ„: Max Planck Institute for Intelligent Systems, Meshcapade<br>PoseGPTæ˜¯ä¸€ä¸ªæ–°å‹æ¡†æ¶ï¼Œå®ƒé€šè¿‡åœ¨LLMä¸­åµŒå…¥SMPLå§¿æ€æ ‡è®°ï¼Œä½¿æ¨¡å‹å¯ä»¥ç›´æ¥ä»æ–‡æœ¬å’Œè§†è§‰è¾“å…¥ç”Ÿæˆä¸‰ç»´äººä½“å§¿æ€ï¼Œå¹¶åœ¨è§£é‡Šä¸‰ç»´äººä½“å§¿æ€æ–¹é¢å®ç°äº†ä¸€å®šç¨‹åº¦çš„åˆ›æ–°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18836v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18836.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **What Do Llamas Really Think? Revealing Preference Biases in Language Model Representations**<br><sub>æœºæ„: Comcast Applied AI, University of Waterloo<br>ä½œè€…ä»¬æå‡ºäº†ä¸€ä¸ªæ–°å‹æ¢é’ˆæ¥æ£€æµ‹LLMsè¡¨ç¤ºä¸­çš„å†…éšå…³è”åè§ï¼Œå¹¶é€šè¿‡å®éªŒåœ¨åå¥½æ£€æµ‹ä¸­è¾¾åˆ°äº†æœ€æ–°æ°´å¹³ã€‚ç ”ç©¶è¿˜å‘ç°äº†å¤šä¸ªæŒ‡ä»¤éµå¾ªå‹å’Œâ€œä¼ ç»Ÿâ€çš„LLMsä¸­çš„æ˜¾è‘—åè§ï¼Œè¿™äº›åè§å­˜åœ¨äºå›½ç±ã€æ”¿æ²»ã€å®—æ•™å’Œæ€§åˆ«ç­‰æ–¹é¢ï¼Œå°½ç®¡LLMså·²ç»ç»è¿‡æ˜ç¡®çš„å®‰å…¨æŒ‡å¯¼è°ƒæ•´ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18812v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18812.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/castorini/biasprobe)</div> |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation**<br><sub>æœºæ„: UC Berkeley, Microsoft Azure AI, ZOOM<br>CoDi-2æ˜¯ä¸€ç§å…·æœ‰å‰æ²¿èƒ½åŠ›çš„å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹ï¼Œå¯ä»¥å¤„ç†å¤æ‚çš„å¤šæ¨¡æ€è¾“å…¥ã€åœ¨ä¸Šä¸‹æ–‡ä¸­æŒ‡å¯¼ç”Ÿæˆã€é€šè¿‡å¤šè½®äº¤äº’ä¸ç”¨æˆ·äº’åŠ¨ï¼Œå¹¶å®ç°äº†ä¼˜ç§€çš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18775v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18775.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **Autonomous Agents in Software Development: A Vision Paper**<br><sub>æœºæ„: Tampere University<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªå…³äºåˆ©ç”¨å¤šä¸ª GPT ä»£ç†æ¥è‡ªåŠ¨æ‰§è¡Œè½¯ä»¶å·¥ç¨‹ä»»åŠ¡çš„æ„¿æ™¯ï¼Œå¹¶æ¼”ç¤ºäº†åœ¨ç®€å•è½¯ä»¶ä»»åŠ¡ä¸Šæ‰€å–å¾—çš„åˆæ­¥æˆåŠŸã€‚è¿™é¡¹å·¥ä½œæœ‰å¯èƒ½å½»åº•æ”¹å˜è½¯ä»¶å¼€å‘çš„æ–¹å¼ï¼Œå¹¶ç¼©çŸ­å¼€å‘æ—¶é—´ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18440v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1844.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **IAG: Induction-Augmented Generation Framework for Answering Reasoning Questions**<br><sub>æœºæ„: Huawei Poisson Lab<br>IAGæ¡†æ¶é€šè¿‡å½’çº³æç¤ºæ³•åŠ å¼ºçŸ¥è¯†é™ˆè¿°çš„çœŸå®æ€§ï¼Œå¹¶ä¸”ä¼˜åŒ–äº†çŸ¥è¯†èåˆæœºåˆ¶å’Œå­¦ç”Ÿå½’çº³æ¨¡å‹ï¼Œä»¥è§£å†³ç°æœ‰åŸºäºæ£€ç´¢çš„æ–¹æ³•åœ¨éšæ€§æ¨ç†é—®ç­”ä»»åŠ¡ä¸Šçš„ä¸è¶³ã€‚ç ”ç©¶æˆæœè¡¨æ˜ï¼ŒIAGåœ¨å›ç­”æ¶‰åŠéšæ€§æ¨ç†çš„é—®ç­”ä»»åŠ¡ä¸Šè¡¨ç°æ›´ä¼˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18397v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18397.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Zero-shot Conversational Summarization Evaluations with small Large Language Models**<br><sub>æœºæ„: Intel labs<br>æ–‡ç« ä»¥å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¼šè¯æ‘˜è¦ä»»åŠ¡ä¸­çš„åº”ç”¨ä½œä¸ºç„¦ç‚¹ï¼Œæ·±å…¥æ¢è®¨äº†ä¸åŒæŒ‡ä»¤å¯¹æ¨¡å‹æ‰§è¡Œæ•ˆæœçš„å½±å“ï¼Œå¹¶ç ”ç©¶äº†åœ¨æœ‰é™ç¡¬ä»¶ä¸‹ä½¿ç”¨å‹ç¼©æ¨¡å‹çš„ä¼˜åŒ–æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18041v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18041.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Towards Top-Down Reasoning: An Explainable Multi-Agent Approach for Visual Question Answering**<br><sub>æœºæ„: Sun Yat-Sen University<br>è¿™é¡¹å·¥ä½œé€šè¿‡åˆ›æ–°æ€§åœ°ç»“åˆä¸‰ä¸ªä»£ç†æ¥æ¨¡æ‹Ÿäººç±»è®¤çŸ¥ä¸­çš„è‡ªé¡¶å‘ä¸‹æ¨ç†è¿‡ç¨‹ï¼Œå¹¶å¼•å…¥äº†å¤šè§†è§’çŸ¥è¯†åº“çš„æ¦‚å¿µï¼Œæ˜¾è‘—æå‡äº†VQAæ¨¡å‹çš„è¡¨ç°åŠ›å’Œè§£é‡Šèƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17331v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17331.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **TimeBench: A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models**<br><sub>æœºæ„: Harbin Institute of Technology<br>TIMEBENCHåŸºå‡†çš„æå‡ºæ˜¯å¯¹å¤§å‹è¯­è¨€æ¨¡å‹æ—¶é—´æ¨ç†èƒ½åŠ›ç»¼åˆè¯„ä¼°çš„é‡è¦æ­¥éª¤ï¼Œå®ƒå±•ç¤ºäº†å½“å‰æ¨¡å‹ä¸äººç±»åœ¨è¿™æ–¹é¢çš„å·®è·ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æŒ‡å¼•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17667v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17667.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/zchuz/TimeBench)</div> |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Large Language Models for Networking: Applications, Enabling Techniques, and Challenges**<br><sub>æœºæ„: BUPT<br>è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ•´åˆå¤§å‹è¯­è¨€æ¨¡å‹ä¸ç½‘ç»œæŠ€æœ¯çš„æ–°æ¡†æ¶ChatNetï¼Œå¹¶æ¢ç©¶äº†å®ƒåœ¨ç½‘ç»œè§„åˆ’ä¸­çš„åº”ç”¨ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒChatNetå¯ä»¥æœ‰æ•ˆæå‡ç½‘ç»œä»»åŠ¡çš„è‡ªåŠ¨åŒ–å’Œæ™ºèƒ½åŒ–æ°´å¹³ï¼Œå°½ç®¡åœ¨éƒ¨ç½²å‰ä»éœ€è§£å†³å¤šæ¨¡æ€æ•°æ®æ•´åˆå’Œæ’ä»¶å¼€å‘ç­‰æŒ‘æˆ˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17474v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17474.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Understanding and Improving In-Context Learning on Vision-language Models**<br><sub>æœºæ„: LMU Munich, University of Oxford<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç”¨äºè§†è§‰-è¯­è¨€æ¨¡å‹åœ¨èƒŒæ™¯å­¦ä¹ ä¸­é€‰æ‹©ç¤ºèŒƒçš„æ–°æ–¹æ³•MMICESï¼Œå¹¶é€šè¿‡ä¸€ç³»åˆ—å®éªŒå±•ç¤ºäº†å…¶åœ¨ä¸åŒæ¨¡å‹å’Œæ•°æ®é›†ä¸Šçš„è‰¯å¥½æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18021v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18021.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **How to Build an AI Tutor that Can Adapt to Any Course and Provide Accurate Answers Using Large Language Model and Retrieval-Augmented Generation**<br><sub>æœºæ„: The Education University of Hong Kong<br>è¿™ç¯‡è®ºæ–‡ä»£è¡¨äº†ä¸€æ¬¡å¼€åˆ›æ€§çš„å°è¯•ï¼Œæ„å»ºäº†ä¸€ä¸ªå¯ä»¥é€‚åº”ä»»ä½•å­¦ç§‘å¹¶æä¾›é«˜è´¨é‡çš„å®šåˆ¶åŒ–æ•™è‚²æ”¯æŒçš„AIå¯¼å¸ˆç³»ç»Ÿã€‚è¿™ä¸ä»…èƒ½ä¿ƒè¿›AIæ•™è‚²æŠ€æœ¯çš„åº”ç”¨ï¼Œè€Œä¸”ä¸ºAIæ•™å­¦ç³»ç»Ÿçš„å‘å±•å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17696v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17696.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Are Large Language Models Good Fact Checkers: A Preliminary Study**<br><sub>æœºæ„: Chinese Academy of Sciences<br>è¿™ç¯‡æ–‡ç« é€šè¿‡ç³»ç»Ÿè¯„ä¼°LLMsåœ¨æ•´ä¸ªäº‹å®æ ¸æŸ¥æµç¨‹ä¸­çš„æ½œåŠ›ï¼Œå‘ç°å°½ç®¡LLMsåœ¨æŸäº›æ–¹é¢è¡¨ç°å‡ºæ½œåŠ›ï¼Œä½†ä¾ç„¶éœ€è¦æ›´å¤šç ”ç©¶å’Œå°è¯•æ¥æå‡å®ƒä»¬åœ¨äº‹å®æ ¸æŸ¥ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17355v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17355.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **TaskWeaver: A Code-First Agent Framework**<br><sub>æœºæ„: Microsoft<br>TaskWeaveræ˜¯ä¸ºæ„å»ºåŸºäºLLMçš„è‡ªæ²»ä»£ç†è€Œè®¾è®¡çš„ä»£ç ä¼˜å…ˆæ¡†æ¶ï¼Œå®ç°äº†å¯¹å¤æ‚æ•°æ®çš„é«˜æ•ˆå¤„ç†ä»¥åŠæ’ä»¶çš„çµæ´»ä½¿ç”¨ï¼Œå¹¶å°†ç‰¹å®šåŸŸçŸ¥è¯†æˆåŠŸæ•´åˆå…¥ç³»ç»Ÿä¸­ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17541v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17541.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/microsoft/TaskWeaver)</div> |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **AvatarGPT: All-in-One Framework for Motion Understanding, Planning, Generation and Beyond**<br><sub>ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåˆ›æ–°çš„ï¼Œä¸€ä½“åŒ–çš„æ¡†æ¶AvatarGPTï¼Œç”¨äºå¤„ç†ç†è§£ã€è§„åˆ’ä»¥åŠç”Ÿæˆäººç±»åŠ¨ä½œç›¸å…³çš„é«˜çº§å’Œä½çº§ä»»åŠ¡ï¼Œå±•ç°å‡ºé•¿æ—¶é—´è¿åŠ¨åˆæˆçš„èƒ½åŠ›å’Œå‡å°‘æ‰‹åŠ¨å¹²é¢„çš„å¯èƒ½æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16468v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16468.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Prompting in Autoregressive Large Language Models**<br><sub>æœºæ„: George Mason University<br>æœ¬è®ºæ–‡ä¸ºè‡ªå›å½’å¤§å‹è¯­è¨€æ¨¡å‹çš„æç¤ºæŠ€æœ¯é¢†åŸŸæä¾›äº†ä¸€ä¸ªç´§å‡‘çš„æ–‡çŒ®ç»¼è¿°ï¼Œå¹¶æŒ‡å‡ºäº†ä¸€äº›å°šæœªè§£å†³çš„æŒ‘æˆ˜å’Œå¼€æ”¾æ€§é—®é¢˜ï¼Œä¸ºæœªæ¥ç ”ç©¶æä¾›äº†æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03740v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2312.0374.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Training Chain-of-Thought via Latent-Variable Inference**<br><sub>æœºæ„: Google<br>æœ¬è®ºæ–‡å¼€å‘äº†ä¸€ç§åŸºäºMCMC-EMçš„å¾®è°ƒç­–ç•¥ï¼Œé€šè¿‡å¹³å‡ç†ç”±å¸®åŠ©LLMsç”Ÿæˆæ­£ç¡®çš„ç­”æ¡ˆï¼Œå…·æœ‰æ½œåœ¨çš„æ¨å¹¿åº”ç”¨çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02179v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2312.02179.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up?**<br><sub>æœºæ„: Nanyang Technological University<br>è¿™ç¯‡ç»¼è¿°æ–‡ç« æä¾›äº†å¯¹å¼€æºLLMsåœ¨å¤šä»»åŠ¡é¢†åŸŸç›¸è¾ƒChatGPTçš„æ€§èƒ½è¯„ä¼°çš„è€ƒå¯Ÿï¼Œçªå‡ºäº†ç›®å‰å¼€æºLLMsçš„å¼ºé¡¹å’Œæ½œåœ¨é—®é¢˜ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶å’Œå¼€å‘æä¾›äº†å¯ç¤ºã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜æ€»ç»“äº†ä¼—å¤šçš„æœ€ä½³å®è·µå’ŒæŒ‘æˆ˜ï¼Œæ˜¾ç¤ºå‡ºå¼€æºé¢†åŸŸåœ¨ä¸€å®šç¨‹åº¦ä¸Šæœ‰æœ›ç¼©å°ä¸å•†ä¸šæ¨¡å‹ä¹‹é—´çš„å·®è·ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16989v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16989.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **LLaFS: When Large-Language Models Meet Few-Shot Segmentation**<br><sub>æœºæ„: Singapore University of Technology and Design, Zhejiang University <br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å°æ ·æœ¬å›¾åƒåˆ†å‰²æ¡†æ¶ï¼Œå¹¶è§£å†³äº†è®©LLMsç†è§£å’Œæ‰§è¡Œè§†è§‰ä»»åŠ¡çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚é€šè¿‡å®šåˆ¶æŒ‡å¯¼å’Œç»†ç²’åº¦ä¸Šä¸‹æ–‡æŒ‡å¯¼ç›¸ç»“åˆçš„æ–¹æ³•ï¼Œå®ç°äº†é«˜è´¨é‡çš„å°æ ·æœ¬åˆ†å‰²ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16926v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16926.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/lanyunzhu99/LLaFS)</div> |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **RELIC: Investigating Large Language Model Responses using Self-Consistency**<br><sub>æœºæ„: ETH Zurich<br>RELICæ˜¯ä¸€ä¸ªäº¤äº’å¼ç³»ç»Ÿï¼Œå®ƒé€šè¿‡å¤šæ ·æœ¬çš„äº‹å®ä¸€è‡´æ€§æ£€éªŒï¼Œå¸®åŠ©ç”¨æˆ·éªŒè¯å’ŒæŒ‡å¯¼LLMsç”Ÿæˆçš„æ–‡æœ¬ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16842v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16842.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **RankingGPT: Empowering Large Language Models in Text Ranking with Progressive Enhancement**<br><sub>æœºæ„: Alibaba Group<br>æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç”¨äºæ–‡æœ¬æ’åºçš„äºŒé˜¶æ®µè®­ç»ƒæ¨¡å‹ï¼Œç»“åˆäº†å¼±ç›‘ç£é¢„è®­ç»ƒå’Œç›‘ç£ç»†åŒ–è®­ç»ƒï¼Œé€šè¿‡åœ¨ä¸æŸå®³é¢„è®­ç»ƒç›Šå¤„çš„åŸºç¡€ä¸Šå¢å¼ºæ¨¡å‹ç»†åŒ–è®­ç»ƒæ€§èƒ½ï¼Œå®Œæˆäº†ä»é¢„è®­ç»ƒåˆ°ç»†åŒ–è®­ç»ƒçš„å¹³æ»‘è¿‡æ¸¡ï¼Œå¹¶åœ¨å®éªŒä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16720v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1672.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation**<br><sub>æœºæ„: Alibaba Group<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåˆ©ç”¨æ‰©æ•£æ¨¡å‹è¿›è¡Œè§’è‰²åŠ¨ç”»çš„æ–°æ¡†æ¶â€œAnimate Anyoneâ€ã€‚è¯¥æ¡†æ¶é€šè¿‡ReferenceNetä¿æŒå¤–è§‚ä¸€è‡´æ€§ï¼Œå¹¶é€šè¿‡å§¿æ€å¼•å¯¼å™¨ä¸æ—¶é—´å±‚ç¡®ä¿åŠ¨ç”»çš„å¯æ§æ€§ä¸è¿ç»­æ€§ï¼Œå–å¾—äº†å…ˆè¿›çš„è§’è‰²åŠ¨ç”»ç”Ÿæˆç»“æœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17117v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17117.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/HumanAIGC/AnimateAnyone)</div><div style='min-width:85px;'>[![Blog](https://img.shields.io/badge/Blog-Posts-yellow?logo=rss)](https://humanaigc.github.io/animate-anyone/)</div> |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Beyond Hallucinations: Enhancing LVLMs through Hallucination-Aware Direct Preference Optimization**<br><sub>æœºæ„: Shanghai AI Laboratory<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„ç­–ç•¥æ¥ä¼˜åŒ–LVLMså¹¶å‡å°‘å¹»è§‰ç°è±¡ï¼ŒåŒæ—¶ä»‹ç»äº†ä¸€ç§æ–°çš„è¯„ä¼°æ–¹æ³•æ¥æ›´å…¨é¢åœ°è¡¡é‡å¹»è§‰ç°è±¡ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16839v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16839.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine**<br><sub>æœºæ„: Microsoft<br>æœ¬æ–‡é€šè¿‡ç³»ç»Ÿçš„æç¤ºå·¥ç¨‹æ–¹æ³•æ¢è®¨äº†åœ¨æ— éœ€ä¸“å®¶ç›‘ç£çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•æŒ‡å¯¼é€šç”¨çš„åŸºç¡€æ¨¡å‹åœ¨ä¸“ä¸šä»»åŠ¡ä¸Šå‘æŒ¥ä¸“å®¶çº§åˆ«çš„èƒ½åŠ›ï¼Œå…·ä½“ä»¥åŒ»å­¦é¢†åŸŸä¸ºæ¡ˆä¾‹ç ”ç©¶ã€‚æ‰€æå‡ºçš„Medpromptç­–ç•¥è¯æ˜äº†å…¶åœ¨å¢å¼ºåŸºç¡€æ¨¡å‹ä¸“ä¸šèƒ½åŠ›æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ï¼Œå¹¶å±•ç¤ºäº†å¹¿æ³›é€‚ç”¨äºå¤šä¸ªå­¦ç§‘çš„å¯èƒ½æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16452v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16452.md)  |
| <span style='display: inline-block; width: 42px;'>11-27</span> | **RoboGPT: an intelligent agent of making embodied long-term decisions for daily instruction tasks**<br><sub>æœºæ„: Chinese Academy of Sciences, Peking University<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªåä¸ºRoboGPTçš„æ™ºèƒ½ä½“ï¼Œè¯¥æ™ºèƒ½ä½“ç”¨äºåˆ¶å®šæ‰§è¡Œæ—¥å¸¸æŒ‡ä»¤ä»»åŠ¡çš„é•¿æœŸå†³ç­–ã€‚è¯¥æ™ºèƒ½ä½“é€šè¿‡ä¸€é¡¹æ–°çš„æœºå™¨äººæ•°æ®é›†ï¼Œç»“åˆäº†LLMsçš„é€šç”¨çŸ¥è¯†å’Œæœºå™¨äººé¢†åŸŸçš„ä¸“ä¸šçŸ¥è¯†ï¼Œå¹¶å¼•å…¥äº†Re-Planæ¨¡å—å’ŒRoboSkillæ¨¡å—ä»¥å¢å¼ºä»»åŠ¡è§„åˆ’çš„é€»è¾‘æ€§å’Œé€‚åº”æ€§ã€‚åœ¨ALFREDåŸºå‡†æµ‹è¯•å’Œæ³›åŒ–ä»»åŠ¡ä¸Šï¼ŒRoboGPTä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.15649v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.15649.md)  |
| <span style='display: inline-block; width: 42px;'>11-25</span> | **Faster Minimum Bayes Risk Decoding with Confidence-based Pruning**<br><sub>æœºæ„: University of Cambridge<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç”¨äºMBRè§£ç çš„ç®—æ³•ï¼Œè¯¥ç®—æ³•é€šè¿‡åœ¨æ ·æœ¬ä¼°è®¡ä¸­é€æ¸å¢åŠ æ ·æœ¬æ•°é‡å¹¶ä½¿ç”¨ç½®ä¿¡åº¦å‰ªææ¥å‡å°‘ç”¨æˆ·å‡½æ•°è°ƒç”¨ã€‚åœ¨ä¿æŒå‡†ç¡®åº¦çš„åŒæ—¶ï¼Œè¯¥ç®—æ³•æ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œå¹¶é€šè¿‡ä¸‰ç§è¯­è¨€å¯¹çš„NMTå®éªŒå¾—åˆ°äº†éªŒè¯ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.14919v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.14919.md)  |
| <span style='display: inline-block; width: 42px;'>11-24</span> | **Calibrated Language Models Must Hallucinate**<br><sub>æœºæ„: Microsoft Research<br>è¯¥æ–‡ç« å±•ç¤ºäº†é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹åœ¨å……åˆ†æ ¡å‡†çš„æ¡ä»¶ä¸‹ï¼Œå¿…ç„¶äº§ç”Ÿå¹»è§‰çš„ç»Ÿè®¡æ ¹æºï¼Œå¹¶ä»‹ç»äº†é¢„æµ‹æ€§èƒ½è‰¯å¥½çš„æ¨¡å‹å›ºæœ‰çš„å¹»è§‰äº§ç”Ÿæœºåˆ¶ã€‚åŒæ—¶ï¼Œæ–‡ç« è¿˜æä¾›äº†å¹»è§‰äº§ç”Ÿç‡çš„ä¸‹ç•Œä¼°ç®—ï¼Œå¹¶æ¢è®¨äº†ä¸åŒç±»å‹äº‹å®äº§ç”Ÿå¹»è§‰çš„å¯èƒ½æ€§ï¼ŒæŒ‡å‡ºäº†æœªæ¥å‡è½»ç‰¹å®šç±»å‹å¹»è§‰çš„å¯èƒ½æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.14648v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.14648.md)  |
| <span style='display: inline-block; width: 42px;'>11-24</span> | **Data-Efficient Alignment of Large Language Models with Human Feedback Through Natural Language**<br><sub>æœºæ„: Amazon<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªæœ‰æ•ˆçš„CnRæ–¹æ³•ï¼Œå®ƒèƒ½å¤Ÿé€šè¿‡ä½¿ç”¨è‡ªç„¶è¯­è¨€çš„ç²¾ç»†åé¦ˆå’Œå“åº”ä¿®æ­£ï¼Œé«˜æ•ˆåœ°æ ¡å‡†LLMsä»¥ç¬¦åˆäººç±»é¢„æœŸã€‚é€šè¿‡ç›¸å¯¹è¾ƒå°‘çš„äººç±»åé¦ˆæ•°æ®ï¼Œæ­¤æ–¹æ³•å¯ä»¥æ˜¾è‘—æ”¹å–„å³ä½¿æ˜¯é¡¶å°–LLMsçš„å“åº”è´¨é‡ï¼Œå¦‚ChatGPTã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.14543v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.14543.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes**<br><sub>æœºæ„: ASRI<br>LucidDreameræ˜¯ä¸€ä¸ªèƒ½å¤Ÿç”¨äºç”Ÿæˆé€¼çœŸè€Œä¸”åˆ†è¾¨ç‡æ›´é«˜çš„3Dåœºæ™¯çš„æ¨¡å‹ã€‚å®ƒä¼˜äºç°æœ‰çš„åœºæ™¯ç”Ÿæˆæ¨¡å‹ï¼Œå› ä¸ºå®ƒä¸ä¾èµ–ç‰¹å®šçš„è®­ç»ƒæ•°æ®é›†ï¼Œå¹¶èƒ½å¤Ÿé€‚åº”å¤šç§è¾“å…¥æ ·å¼ã€‚LucidDreameré€šè¿‡çº¦æŸç‚¹äº‘çš„ç§»åŠ¨å’Œä½¿ç”¨æ’å€¼ç®—æ³•ï¼Œå…‹æœäº†å½¢çŠ¶æ‰­æ›²å’Œç‚¹äº‘ä¸å›¾åƒé”™ä½çš„é—®é¢˜ï¼Œä»è€Œåœ¨æ“çºµ3Dç©ºé—´ä¸­çš„ç‚¹äº‘æ—¶ä¿æŒäº†åœºæ™¯çš„çœŸå®æ„Ÿå’Œä¸€è‡´æ€§ã€‚åœ¨å®éªŒä¸­æ˜æ˜¾å±•ç¤ºäº†å…¶ä¼˜è¶Šæ€§å’Œé«˜æ³›åŒ–èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13384v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13384.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **Diffusion Model Alignment Using Direct Preference Optimization**<br><sub>æœºæ„: Nikhil Naik, Stanford University<br>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºDiffusion-DPOçš„æ–¹æ³•ï¼Œå…¶é€šè¿‡ç›´æ¥ä¼˜åŒ–åŸºäºäººç±»æ¯”è¾ƒæ•°æ®çš„æ¨¡å‹æ¥å®ç°å¯¹æ‰©æ•£æ¨¡å‹ä¸äººç±»åå¥½çš„å¯¹é½ã€‚æ­¤å¤–ï¼Œæ–‡ç« ä¹Ÿæ¢ç´¢äº†åŸºäºAIåé¦ˆçš„è®­ç»ƒï¼Œå–å¾—äº†ä¸åŸºäºäººç±»åå¥½è®­ç»ƒç›¸åª²ç¾çš„æˆç»©ã€‚è¿™æ˜æ˜¾æå‡äº†æ¨¡å‹åœ¨è§†è§‰å¸å¼•åŠ›å’Œæ–‡æœ¬å¯¹é½æ–¹é¢çš„æ€§èƒ½ï¼Œä¸ºåˆ©ç”¨AIåé¦ˆæ‰©å±•æ‰©æ•£æ¨¡å‹å¯¹é½æ–¹æ³•æä¾›äº†æ–°çš„é€”å¾„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12908v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12908.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs**<br><sub>æœºæ„: Google Research<br>æ–‡ç« æå‡ºäº†ä¸€ç§åä¸ºZipLoRAçš„æ–°ç­–ç•¥ï¼Œæ—¨åœ¨é€šè¿‡ä¸€ä¸ªä¼˜åŒ–è¿‡ç¨‹æœ‰æ•ˆåœ°åˆå¹¶ç‹¬ç«‹è®­ç»ƒçš„ä¸»é¢˜å’Œé£æ ¼LoRAsï¼Œä»è€Œèƒ½å¤Ÿç”Ÿæˆä»»ä½•ç”¨æˆ·æä¾›çš„ä¸»é¢˜é£æ ¼çš„ç»„åˆã€‚ZipLoRAå¯¹ç”Ÿæˆä»»ä½•ç‰¹å®šä¸»é¢˜å’Œé£æ ¼çš„å›¾åƒè¿™ä¸€å¼€æ”¾æ€§ç ”ç©¶é—®é¢˜æä¾›äº†åˆ›æ–°çš„è§£å†³æ–¹æ¡ˆï¼Œä¸”ç”±äºå…¶æ— éœ€æ‰‹åŠ¨è¶…å‚æ•°è°ƒæ•´ï¼Œä½¿ç”¨èµ·æ¥æ›´åŠ ç®€ä¾¿é«˜æ•ˆã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•åœ¨ä¿æŒä¸»é¢˜å’Œé£æ ¼çœŸå®æ€§çš„åŒæ—¶ï¼Œç›¸æ¯”äºç°æœ‰æ–¹æ³•å’Œå…¶ä»–åŸºæœ¬æ–¹æ³•è€Œè¨€ï¼Œå…·æœ‰æ›´å¥½çš„ç”Ÿæˆè´¨é‡å’Œé²æ£’æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13600v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.136.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **GAIA: a benchmark for General AI Assistants**<br><sub>æœºæ„: FAIR, Meta<br>GAIA æ˜¯ä¸€é¡¹é’ˆå¯¹é€šç”¨äººå·¥æ™ºèƒ½åŠ©ç†çš„åŸºå‡†æµ‹è¯•ï¼Œå…¶ç›®çš„åœ¨äºæå‡ºçœŸå®ä¸–ç•Œçš„æŒ‘æˆ˜æ€§é—®é¢˜ï¼Œå¹¶é¿å¼€ä¼ ç»Ÿ LLMs è¯„ä»·ä¸­çš„è®¸å¤šé™·é˜±ã€‚è¯¥åŸºå‡†æµ‹è¯•å¼ºè°ƒä»»åŠ¡å¯¹äººç±»ç®€å•è€Œå¯¹AIéš¾åº¦è¾ƒå¤§ï¼Œä»¥æ­¤æ¥è¯„ä¼°AIçš„æ‰§è¡Œå¤æ‚è¡ŒåŠ¨åºåˆ—çš„å‡†ç¡®èƒ½åŠ›ï¼Œè¿™äº›ä»»åŠ¡åœ¨è®¾è®¡ä¸Šæ— æ³•ç®€å•åœ°é€šè¿‡æš´åŠ›æ–¹æ³•å¾—ä»¥è§£å†³ã€‚GAIA è¿˜è€ƒè™‘äº†å¦‚ä½•æ‰©å±•åŸºå‡†æµ‹è¯•ï¼Œå¹¶æ¢è®¨äº†ä¸€äº›æœ€å…ˆè¿›çš„åŠ©ç†çš„æˆåŠŸä¸çŸ­æ¿ï¼Œå±•ç¤ºäº†å¢å¼º LLMs çš„æ½œåŠ›ã€‚æœ€ç»ˆï¼Œæ–‡ç« æ—¨åœ¨è®¾ç«‹ä¸€ä¸ªå¼€å‘è€…é—®é¢˜é›†ï¼Œä¸ºäººå·¥æ™ºèƒ½ç ”ç©¶æä¾›ä¸€ä¸ªå¯æ‰©å±•çš„åŸºå‡†æµ‹è¯•å¹³å°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12983v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12983.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **FusionFrames: Efficient Architectural Aspects for Text-to-Video Generation Pipeline**<br><sub>æœºæ„: Sber AI<br>æ€»ä½“è€Œè¨€ï¼Œè¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªæ–°å‹ä¸¤é˜¶æ®µæ½œåœ¨æ‰©æ•£çš„æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæ¶æ„ï¼Œè§£å†³äº†å…³é”®å¸§åˆæˆå’Œæ’å€¼å¸§ç”Ÿæˆä¸­å­˜åœ¨çš„é—®é¢˜ï¼Œé€šè¿‡ä½¿ç”¨ç‹¬ç«‹çš„æ—¶åŸŸå—å’Œæœ‰æ•ˆçš„æ’å€¼æ¶æ„ï¼Œå‡å°‘äº†è®¡ç®—æˆæœ¬ï¼Œå¹¶åœ¨å¤šä¸ªè´¨é‡æŒ‡æ ‡ä¸Šå–å¾—äº†ä¼˜äºç°æœ‰æŠ€æœ¯çš„è¡¨ç°ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜é’ˆå¯¹è§†é¢‘è§£ç å™¨è®¾è®¡äº†ä¸åŒçš„æ¶æ„é€‰é¡¹ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–äº†è§†é¢‘çš„ä¸€è‡´æ€§å’Œæ•´ä½“è´¨é‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13073v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13073.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **Probabilistic Tree-of-thought Reasoning for Answering Knowledge-intensive Complex Questions**<br><sub>æœºæ„: Tsinghua University<br>æ–‡ç« æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¦‚ç‡æ ‘çŠ¶æ¨ç†ï¼ˆProbTreeï¼‰æ–¹æ³•ï¼Œé€šè¿‡æ¢ç´¢LLMåœ¨å›ç­”çŸ¥è¯†å¯†é›†å‹å¤æ‚é—®é¢˜æ—¶çš„èƒ½åŠ›ï¼Œå¹¶å°†ä¸ç¡®å®šæ€§å¼•å…¥æ¨ç†è¿‡ç¨‹ï¼Œåœ¨ç»Ÿä¸€æ¡†æ¶ä¸­æ•´åˆäº†å¤–éƒ¨å’Œå‚æ•°çŸ¥è¯†ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13982v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13982.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach**<br><sub>æœºæ„: Chinese Academy of Sciences<br>LLaMACæ¡†æ¶å±•ç¤ºäº†åŸºäºLLMçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨é•¿æœŸè§„åˆ’ã€æ•°å­¦æ¨ç†ã€ä¼˜åŒ–é—®é¢˜å’Œç©ºé—´æ¨ç†æ–¹é¢çš„å“è¶Šè¡¨ç°ï¼Œå¹¶ä¸”å‡å°‘äº†å¤§è§„æ¨¡å¤šæ™ºèƒ½ä½“åä½œçš„è®¿é—®æˆæœ¬ã€‚éšç€LLMçš„è¿›ä¸€æ­¥æå‡å’Œæ›´å¤šåä½œæ¡†æ¶çš„å‡ºç°ï¼Œå¤šæ™ºèƒ½ä½“åä½œé¢†åŸŸå°†è¿æ¥æ–°çš„å‘å±•æœºé‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13884v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13884.md)  |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **Visual In-Context Prompting**<br><sub>æœºæ„: HKUST, Microsoft Research<br>æœ¬è®ºæ–‡æå‡ºäº†DINOvï¼Œä¸€ä¸ªæ–°çš„è§†è§‰ä¸Šä¸‹æ–‡å†…æç¤ºæ¡†æ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤šæ ·åŒ–çš„è§†è§‰æç¤ºï¼Œä½¿ç”¨æ— æ ‡ç­¾æ•°æ®ï¼Œå¹¶åœ¨å¤šä¸ªä»»åŠ¡ä¸­è¾¾åˆ°å¾ˆå¥½çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13601v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13601.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/UX-Decoder/DINOv)</div> |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **Enhancing Summarization Performance through Transformer-Based Prompt Engineering in Automated Medical Reporting**<br><sub>æœºæ„: Utrecht University<br>è¿™é¡¹ç ”ç©¶éªŒè¯äº†åœ¨è‡ªåŠ¨åŒ–åŒ»ç–—æŠ¥å‘Šä¸­åº”ç”¨åŸºäºè½¬æ¢å™¨çš„æç¤ºå·¥ç¨‹å¯ä»¥æé«˜æ‘˜è¦æ€§èƒ½ã€‚å°½ç®¡å­˜åœ¨ä¸€äº›å±€é™æ€§ï¼Œä½†ç ”ç©¶æå‡ºçš„æ–¹æ³•è¯æ˜äº†åœ¨æç¤ºåˆ¶å®šæ—¶åŠ å…¥ç¤ºä¾‹å’Œä¸Šä¸‹æ–‡ä¿¡æ¯çš„æ•ˆç”¨ï¼Œå¹¶ä¸”æŒ‡å‡ºäº†æœªæ¥å·¥ä½œçš„æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13274v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13274.md)  |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms**<br><sub>æœºæ„: Princeton University<br>æœ¬è®ºæ–‡çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼šåœ¨å¼€æºæ¨¡å‹ä¸Šå¾®è°ƒä¸åŒå¤§å°å’Œé£æ ¼çš„æŒ‡ä»¤æ•°æ®é›†ï¼Œè¯„ä¼°å¾®è°ƒæ¨¡å‹åœ¨ä¸åŒçš„è¯„ä¼°èŒƒå¼ä¸‹çš„è¡¨ç°ï¼Œå¹¶ä¸”å‘ç°è¾ƒå°‘çš„æ ·æœ¬ï¼ˆç‰¹åˆ«æ˜¯å½“è¿™äº›æ ·æœ¬ç»“åˆäº†ä¸åŒæ¥æºå’Œé£æ ¼æ—¶ï¼‰è¶³ä»¥åœ¨ä¸åŒç±»å‹çš„è¯„ä¼°ä¸­è·å¾—è‰¯å¥½çš„æ€§èƒ½ã€‚è¿™è¡¨æ˜åœ¨åŸ¹å…»LLMsçš„æŒ‡ä»¤éµä»èƒ½åŠ›æ—¶ï¼Œâ€œå°‘å³æ˜¯å¤šâ€ï¼Œä¸”é€šè¿‡ç²¾å¿ƒé€‰æ‹©å¾®è°ƒæ ·æœ¬ï¼Œå¯ä»¥ä½¿æ¨¡å‹åœ¨æ‰§è¡ŒæŒ‡ä»¤èƒ½åŠ›ä¸Šå¾—åˆ°æ˜¾è‘—æå‡ã€‚è¿™ä¸€å‘ç°å¯¹äºå¦‚ä½•æœ‰æ•ˆåœ°å¾®è°ƒLLMsä»¥åŠå¦‚ä½•è¯„ä¼°å®ƒä»¬çš„å®ç”¨æ€§å…·æœ‰é‡è¦æ„ä¹‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13133v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13133.md)  |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **XAGen: 3D Expressive Human Avatars Generation**<br><sub>æœºæ„: National University of Singapore, ByteDance<br>ç ”ç©¶æå‡ºäº†XAGenæ¨¡å‹ï¼Œå®ƒæ˜¯é¦–ä¸ªèƒ½å¤Ÿç”Ÿæˆå…¨é¢å¯æ§3Däººç±»åŒ–èº«çš„GANæ¨¡å‹ã€‚XAGenåœ¨ç»†ç²’åº¦å±æ€§æ§åˆ¶ä¸Šå…·æœ‰ç‹¬ç«‹çš„èƒ½åŠ›ï¼Œå¹¶é€šè¿‡å¤šå°ºåº¦å’Œå¤šéƒ¨åˆ†çš„3Dè¡¨ç¤ºä¸æ¸²æŸ“æŠ€æœ¯æå‡äº†é¢éƒ¨å’Œæ‰‹éƒ¨çš„ç”Ÿæˆè´¨é‡ã€‚å®éªŒç»“æœè¯æ˜XAGenåœ¨å¤–è§‚è´¨é‡ã€æ§åˆ¶èƒ½åŠ›å’Œæ•°æ®åˆ©ç”¨ç‡æ–¹é¢éƒ½è¶…è¿‡äº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæ¨è¿›äº†3Dè™šæ‹ŸåŒ–èº«ç”ŸæˆæŠ€æœ¯çš„å‘å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13574v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13574.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey**<br><sub>æœºæ„: Nanjing University<br>æ–‡ç« ä¸ºäº†è§£å†³LLMsåœ¨åº”å¯¹é•¿ä¸Šä¸‹æ–‡æ—¶çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç³»åˆ—æ–¹æ³•å’Œç»¼åˆåˆ†ç±»ä½“ç³»ï¼Œæé«˜äº†LLMsåœ¨æ³¨æ„åŠ›æœºåˆ¶ã€è®°å¿†æ•ˆç‡å’Œæœ€å¤§é•¿åº¦å¤„ç†ä¸Šçš„æ€§èƒ½ã€‚é€šè¿‡ç»¼åˆå›é¡¾å’Œåˆ†ç±»å­¦ç•Œæœ€è¿‘çš„è¿›å±•ï¼Œæœ¬æ–‡ä¸ºæœªæ¥çš„LLMsæ¶æ„è®¾è®¡å’Œä¼˜åŒ–æä¾›äº†æ¸…æ™°çš„æŒ‡å¯¼æ–¹å‘ã€‚ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12351v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12351.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Strivin0311/long-llms-learning)</div> |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **AcademicGPT: Empowering Academic Research**<br><sub>æœºæ„: International Digital Economy Academy<br>AcademicGPTé’ˆå¯¹å­¦æœ¯ç ”ç©¶çš„ç‰¹å®šéœ€æ±‚è¿›è¡Œäº†ä¼˜åŒ–ï¼Œé€šè¿‡ç»“åˆé’ˆå¯¹æ€§å¼ºçš„è®­ç»ƒæ•°æ®å’Œå¤šæ–¹é¢çš„åº”ç”¨å¼€å‘ï¼Œä¸ºå­¦æœ¯é¢†åŸŸæä¾›äº†å®è´¨æ€§çš„æ”¯æŒå’Œå·¥å…·ã€‚å®ƒæ ‡å¿—ç€å¤§å‹è¯­è¨€æ¨¡å‹ä¸ªæ€§åŒ–ä¸ä¸“ä¸šåŒ–å‘å±•çš„ä¸€ä¸ªé‡è¦æ­¥éª¤ï¼Œå¹¶æœ‰æœ›å¯¹å­¦æœ¯ç¤¾åŒºäº§ç”Ÿæ·±è¿œçš„å½±å“ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12315v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12315.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **A Survey on Multimodal Large Language Models for Autonomous Driving**<br><sub>æœºæ„: Purdue University<br>è¯¥è®ºæ–‡å…¨é¢å›é¡¾äº†MLLMsåœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„åº”ç”¨ï¼Œè¡¨æ˜MLLMså…·å¤‡è§£æéæ–‡æœ¬æ•°æ®å’Œèåˆå¤šç§æ¨¡æ€ï¼ˆå¦‚è§†è§‰ã€è¯­è¨€ï¼‰çš„èƒ½åŠ›ï¼Œè¿™äº›èƒ½åŠ›å¯¹äºè¡Œä¸ºé¢„æµ‹å’ŒåŠ¨ä½œè§„åˆ’å°¤ä¸ºé‡è¦ã€‚é€šè¿‡åœ¨ä¸åŒçš„è‡ªåŠ¨é©¾é©¶ç¯èŠ‚ä¸­éƒ¨ç½²MLLMsï¼ˆå¦‚ç†è§£äº¤é€šåœºæ™¯ã€è§„åˆ’æ§åˆ¶ã€æ¨¡å¼ç”Ÿæˆï¼‰ï¼Œå¯ä»¥æ”¹å–„å†³ç­–æµç¨‹ï¼Œå¹¶å®ç°ç±»ä¼¼äººç±»çš„é©¾é©¶ç›´è§‰å’Œå†³ç­–æ¨¡å¼ï¼ŒåŒæ—¶æé«˜è½¦è¾†å¯¼èˆªå’Œè§„åˆ’çš„æ•ˆç‡å’Œå®‰å…¨æ€§ã€‚æ­¤å¤–ï¼Œæ¨¡å‹é€šè¿‡ä¸ºå¤šä¸ªä»»åŠ¡çš„é¢„è®­ç»ƒæä¾›äº†ä¸€ç§æ–°çš„å¯èƒ½æ€§ï¼Œè¿™å¯èƒ½ä¼šæ¨åŠ¨æŠŠæ™ºèƒ½ç³»ç»Ÿæ¨å‘äººå·¥æ™®éæ™ºèƒ½ï¼ˆAGIï¼‰çš„å‘å±•è·¯å¾„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12320v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1232.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Oasis: Data Curation and Assessment System for Pretraining of Large Language Models**<br><sub>æœºæ„: Chinese Academy of Sciences<br>æœ¬æ–‡æå‡ºçš„Oasisç³»ç»Ÿæ˜¯é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒçš„æ•°æ®æ•´ç†å’Œè¯„ä¼°é—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚Oasisé€šè¿‡å…¶äº¤äº’å¼çš„è‡ªå®šä¹‰æ•°æ®æ•´ç†æ¨¡å—ã€é’ˆå¯¹åå·®çš„æ¨¡å‹è¿‡æ»¤å™¨å’Œå…¨é¢çš„æ•°æ®è¯„ä¼°ç³»ç»Ÿï¼Œæ—¨åœ¨æé«˜æ•°æ®é›†çš„è´¨é‡å’Œå¤šæ ·æ€§ï¼ŒåŒæ—¶é™ä½å†…å­˜éœ€æ±‚å’Œèµ„æºæ¶ˆè€—ã€‚ç³»ç»Ÿçš„å®ç°ç«‹è¶³äºæå‡æ•°æ®å¤„ç†çš„çµæ´»æ€§å’Œè¯„ä¼°çš„å‡†ç¡®æ€§ï¼Œå¡«è¡¥äº†ç°æœ‰å·¥ä½œåœ¨å…¨é¢æ€§å’Œå¤šç»´åº¦è¯„ä¼°æ–¹é¢çš„ç©ºç™½ã€‚é€šè¿‡ç»¼åˆä½¿ç”¨äººç±»è¯„ä¼°ã€å¯å‘å¼åº¦é‡å’Œæœ€æ–°çš„å¤§å‹è¯­è¨€æ¨¡å‹å¦‚GPT-4è¿›è¡Œè´¨é‡è¯„ä¼°ï¼ŒOasiså±•ç°äº†å¯¹é¢„è®­ç»ƒæ•°æ®é›†è¿›è¡Œå…¨æ–¹ä½ä¼˜åŒ–çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12537v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12537.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Do Smaller Language Models Answer Contextualised Questions Through Memorisation Or Generalisation?**<br><sub>æœºæ„: University of Auckland<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ä»¥è¯„ä»·å°å‹è¯­è¨€æ¨¡å‹åœ¨é—®ç­”ä»»åŠ¡ä¸­ç­”æ¡ˆçš„ç”Ÿæˆæ˜¯å¦ä¸ºè®°å¿†æˆ–æ¦‚æ‹¬èƒ½åŠ›çš„ç»“æœã€‚é€šè¿‡è¯­ä¹‰ç›¸ä¼¼åº¦åˆ†æï¼Œç¡®å®šäº†ä¸å¤ªå¯èƒ½è¢«æ¨¡å‹è®°ä½ç­”æ¡ˆçš„è¯„ä¼°æ ·æœ¬ï¼Œå¹¶ç”¨å¢åŠ é¢å¤–è®­ç»ƒæ•°æ®é›†çš„æ–¹å¼ï¼Œé’ˆå¯¹ç‰¹å®šè¯„ä¼°å­é›†è¿›è¡Œäº†æ¨¡å‹æ€§èƒ½çš„ä¼˜åŒ–ã€‚æœ€ç»ˆï¼Œç ”ç©¶ç»“æœæ˜¾ç¤ºå¢åŠ äº†æ•°æ®é›†çš„æ¨¡å‹åœ¨ç‰¹å®šè¯„ä¼°æ•°æ®é›†ä¸Šæœ‰äº†æ˜¾è‘—æå‡ï¼Œå¹¶æ¨æ–­è¿™ç§æ”¹å–„ä¸æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›æœ‰å…³ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12337v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12337.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks**<br><sub>æœºæ„: University of Cambridge<br>æœ¬æ–‡é’ˆå¯¹å¾®è°ƒå¯¹é¢„å®šä¹‰èƒ½åŠ›çš„å½±å“å¼€å±•äº†ä¸€é¡¹å…¨é¢çš„åˆ†æå’Œè¯„ä¼°ã€‚é€šè¿‡Tracrç¼–è¯‘å¼çš„èƒ½åŠ›è®¾è®¡å’ŒåŸºäºPCFGçš„å­¦ä¹ å¼èƒ½åŠ›è®¾è®¡ï¼Œæ–‡ç« è¯¦ç»†æ¢è®¨äº†å¾®è°ƒè¿‡ç¨‹ä¸­åµŒå…¥ç‰¹å¾çš„ç›¸å…³æ€§ï¼Œæå‡ºäº†reFTæ¥å¼ºåŒ–åˆ†æå¾®è°ƒå½±å“çš„æ·±åº¦ã€‚æœ¬ç ”ç©¶çš„å‘ç°æ”¹è¿›äº†å¯¹å¾®è°ƒå½±å“æœºç†çš„ç†è§£ï¼Œå¹¶ä¸ºåç»­çš„æ¨¡å‹è®¾è®¡å’Œå¾®è°ƒç­–ç•¥æä¾›äº†å®è¯æ”¯æŒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12786v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12786.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **How Capable Can a Transformer Become? A Study on Synthetic, Interpretable Tasks**<br><sub>æœºæ„: University of Pennsylvania, MIT<br>æœ¬æ–‡é€šè¿‡è®¾è®¡åˆæˆæ•°æ®ç”Ÿæˆè¿‡ç¨‹å’Œç³»ç»Ÿæ€§å®éªŒï¼Œä»¥è¯„ä¼°å’Œç†è§£è‡ªå›å½’Transformeræ¨¡å‹åœ¨ç»„åˆå…¶åŸå§‹èƒ½åŠ›æ–¹é¢çš„æ½œåŠ›ã€‚ç ”ç©¶ç»“æœçªæ˜¾äº†æ¨¡å‹å­¦ä¹ ç»„åˆç»“æ„çš„èƒ½åŠ›ï¼Œæ­ç¤ºäº†è®­ç»ƒæ•°æ®å¯¹æ­¤èƒ½åŠ›çš„å½±å“ä»¥åŠæ¨¡å‹å†…éƒ¨æ³¨æ„åŠ›å±‚åœ¨ç»„åˆå­¦ä¹ è¿‡ç¨‹ä¸­çš„é‡è¦æ€§ã€‚è¿™æˆ–è®¸ä¸ºè¯„ä¼°å’Œæé«˜ç°ä»£ç¥ç»ç½‘ç»œå¯¹çœŸå®ä¸–ç•Œæ•°æ®çš„ç†è§£å’Œåº”ç”¨ï¼Œç‰¹åˆ«æ˜¯åœ¨å…¶å¯èƒ½é¢ä¸´å‰æ‰€æœªè§çš„ä»»åŠ¡æ—¶ï¼Œæä¾›äº†æ–°çš„è§è§£ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12997v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12997.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Latent Lab: Large Language Models for Knowledge Exploration**<br><sub>æœºæ„: Department of Electrical Engineering and Computer Science, MIT<br>Latent Labä½œä¸ºä¸€ç§æ¢ç´¢å¤§å‹æ•°æ®é›†ä¸­ç›¸äº’è”ç³»å…³ç³»çš„åˆ›æ–°å’Œå¼ºå¤§å·¥å…·ï¼Œé€šè¿‡åˆ©ç”¨LLMså’Œè§†è§‰å¼•äººæ³¨ç›®çš„æ¥å£ï¼Œå®ƒè¶…è¶Šäº†å¸¸è§„æœç´¢çš„å±€é™æ€§ï¼Œæä¾›äº†ä¸€ä¸ªè¯­ä¹‰ä¸Šæœ‰æ„ä¹‰å’Œæƒ…å¢ƒæ„ŸçŸ¥çš„ä½“éªŒã€‚å¼ºè°ƒæ¢ç´¢çš„ä»·å€¼å’Œè¿­ä»£è®¾è®¡ï¼Œåœ¨ç›´è§‚åœ°è®¿é—®å¤§é‡ç›¸äº’è¿æ¥çš„ä¿¡æ¯æ–¹é¢å®ç°äº†ä¿¡æ¯æŠ€æœ¯ä¸“å®¶çš„é•¿æœŸè¿½æ±‚ï¼Œå¹¶é€šè¿‡AIè¾…åŠ©æ¢ç´¢å°†è¿™ä¸€æ„¿æ™¯å˜ä¸ºç°å®ï¼Œä¸ºæœªæ¥äººå·¥æ™ºèƒ½å…±åˆ›ç³»ç»Ÿçš„å‘å±•å¥ å®šäº†åŸºç¡€ï¼Œå¹¶ä¿ƒè¿›äº†æ›´ç›´è§‚å’Œé«˜æ•ˆçš„åˆä½œï¼Œæœ‰èƒ½åŠ›äº§ç”Ÿæ–°é¢–å’Œæœ‰å½±å“åŠ›çš„åˆ›é€ ç‰©ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13051v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13051.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Prompting Frameworks for Large Language Models: A Survey**<br><sub>æœºæ„: Zhejiang University<br>è¿™é¡¹ç ”ç©¶æä¾›äº†ä¸€ä¸ªæ¡†æ¶ï¼Œå®ƒé€šè¿‡å®ç°æ–°çš„æŠ€æœ¯æ‰‹æ®µæ¥å¢å¼ºä¸LLMsçš„äº¤äº’ï¼ŒåŒ…æ‹¬æ”¹å–„ä¸ç¼–ç¨‹è¯­è¨€çš„å…¼å®¹æ€§ï¼Œä½¿èƒ½LLMsä½¿ç”¨å¤–éƒ¨å·¥å…·ï¼Œå¹¶ç»´æŠ¤å†å²äº¤äº’ä¿¡æ¯ï¼Œå¹¶ä»¥æ­¤æŒ‡å¯¼æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12785v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12785.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/lxx0628/Prompting-Framework-Survey)</div> |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **Continual Learning: Applications and the Road Forward**<br><sub>æœºæ„: KU Leuven<br>è®ºæ–‡ç»¼è¿°äº†å½“å‰çš„æŒç»­å­¦ä¹ ç ”ç©¶ç°çŠ¶ï¼ŒæŒ‡å‡ºäº†å…¶åœ¨è®°å¿†é™åˆ¶æ¡ä»¶ä¸‹ç ”ç©¶è¾ƒå¤šè€Œå¿½è§†è®¡ç®—æˆæœ¬çš„é—®é¢˜ï¼Œå¹¶æå‡ºäº†å››ä¸ªæœ‰å‰é€”çš„ç ”ç©¶æ–¹å‘ã€‚è¿™äº›æ–¹å‘åŒ…æ‹¬ï¼š1) çœŸå®ä¸–ç•Œæ•°æ®å¤„ç†çš„æŒ‘æˆ˜ï¼Œ2) è®¡ç®—æˆæœ¬çš„è€ƒè™‘ï¼Œä»¥åŠå…¶ä»–å¦‚ä½•è·å–æ•°æ®å’Œç†è®ºç†è§£æ–¹é¢çš„å…³æ³¨ç‚¹ã€‚è®ºæ–‡ä¸»å¼ æœªæ¥çš„CLç®—æ³•åº”åœ¨å‡å°‘å¯¹å®Œå…¨æ ‡è®°å’Œå°é—­ä¸–ç•Œå‡è®¾çš„ä¾èµ–ä¸Šåšå‡ºå®è´¨æ€§çš„è¿›å±•ï¼Œä»¥ä½¿CLæˆä¸ºè§£å†³å®é™…æœºå™¨å­¦ä¹ é—®é¢˜çš„ä¸€ä¸ªæœ‰æ•ˆå·¥å…·ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11908v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11908.md)  |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **GPQA: A Graduate-Level Google-Proof Q&A Benchmark**<br><sub>æœºæ„: New York University<br>GPQA æ•°æ®é›†æä¾›äº†ä¸€ä¸ªç”¨äºæµ‹è¯• AI ç³»ç»Ÿåœ¨å¤„ç†éœ€æ·±åº¦ç†è§£å’Œæ¨ç†èƒ½åŠ›çš„å¤æ‚é—®é¢˜ä¸Šçš„èƒ½åŠ›çš„åŸºå‡†ã€‚é€šè¿‡ä¸¥æ ¼çš„é—®é¢˜è´¨é‡æ§åˆ¶å’Œä¸“å®¶çº§åˆ«çš„éš¾åº¦ï¼Œå®ƒå¯èƒ½ä¿ƒè¿›äººç±»ä¸“å®¶ä¸ AI ç³»ç»Ÿåˆä½œçš„æ–¹æ³•å‘å±•ï¼Œå¹¶æ¨åŠ¨ AI ç³»ç»Ÿè®¾è®¡çš„è¿›æ­¥ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12022v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12022.md)  |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents**<br><sub>æœºæ„: Shanghai Jiao Tong University<br>æœ¬æ–‡ä½œä¸ºé¦–ç¯‡ç³»ç»Ÿæ€§æ¢è®¨CoTåŸºæ­¥æœºåˆ¶ã€èŒƒå¼è½¬å˜ï¼Œä»¥åŠCoTä¸ä»£ç†é—´å¤æ‚äº¤äº’çš„å·¥ä½œï¼Œæä¾›äº†ä¸€äº›å…³é”®è§è§£ã€‚æ–‡ç« æ­ç¤ºäº†CoTåœ¨ç‰¹å®šæ¡ä»¶ä¸‹æ˜¾ç¤ºå‡ºçš„æœ‰æ•ˆæ€§ï¼ŒæŒ‡å‡ºäº†ä½¿CoTå·¥ä½œçš„å¤šä¸ªæ¡ä»¶ï¼Œä»¥åŠç†è®ºå’Œå®è¯ç ”ç©¶ä¸ºå…¶æˆåŠŸæä¾›äº†ä½•ç§è§£é‡Šã€‚æ–‡ç« è¿˜å¯¹CoTç†è®ºè¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œæå‡ºäº†CoTå¯¹äºLLMsåœ¨å¤šä¸ªé¢†åŸŸçš„ä¼˜åŒ–å’Œé©æ–°å¯èƒ½å…·æœ‰é‡è¦çš„è´¡çŒ®ï¼Œå¹¶æŒ‡å‡ºå°½ç®¡LLMsã€CoTæ¨ç†å’Œè¯­è¨€ä»£ç†å¿«é€Ÿå‘å±•ï¼Œä½†ä»å­˜åœ¨æœªè§£å†³çš„æŒ‘æˆ˜ï¼Œå¦‚å¯¹æœªè§é¢†åŸŸçš„æ³›åŒ–ã€æé«˜äº¤äº’æ•ˆç‡ã€ä»£ç†å®šåˆ¶åŒ–ã€ä»£ç†æ‰©å±•åŠä»£ç†å®‰å…¨æ€§ç­‰ã€10â€ æºã€‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11797v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11797.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Zoeyyao27/CoT-Igniting-Agent)</div> |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **Assessing Prompt Injection Risks in 200+ Custom GPTs**<br><sub>æœºæ„: Northwestern University<br>è¯¥è®ºæ–‡ç€é‡ç ”ç©¶äº†è‡ªå®šä¹‰GPTæ¨¡å‹ä¸­çš„å®‰å…¨é£é™©ï¼Œå°¤å…¶æ˜¯æç¤ºæ³¨å…¥æ”»å‡»ã€‚ç ”ç©¶è€…ä»¬æå‡ºäº†ä¸€ä¸ªåŒ…å«æ‰«æã€æ³¨å…¥æ•Œæ„æç¤ºå’Œæå–ç›®æ ‡ä¿¡æ¯ä¸‰ä¸ªæ­¥éª¤çš„æ”»å‡»æ–¹æ³•ï¼Œå¹¶é€šè¿‡å®æ–½è¯„ä¼°å‘ç°è‡ªå®šä¹‰GPTæ¨¡å‹å­˜åœ¨ä¸¥é‡çš„ç³»ç»Ÿæç¤ºæå–å’Œæ–‡ä»¶æ³„éœ²æ¼æ´ã€‚è¿™äº›å‘ç°çªå‡ºäº†è‡ªå®šä¹‰GPTæ¨¡å‹ä¸­çš„å…³é”®å®‰å…¨ç¼ºé™·ï¼Œå¹¶æŒ‡å‡ºäº†æå‡è¿™äº›æ¨¡å‹å®‰å…¨æ€§ç»“æ„çš„å¿…è¦æ€§ã€‚æ­¤å¤–ï¼Œçº¢é˜Ÿè¯„ä¼°æ¸…æ¥šåœ°æ˜¾ç¤ºå‡ºï¼Œç°æœ‰é˜²æŠ¤æªæ–½å¹¶ä¸è¶³å¤Ÿå¼ºå¤§ï¼Œç”šè‡³æœ‰æ—¶å€™æ˜ç¡®æŒ‡å‡ºä¸åº”è¯¥åˆ†äº«çš„ä¿¡æ¯ä¹Ÿèƒ½è¢«æå–å‡ºæ¥ï¼Œè¿™è¡¨æ˜äºŸéœ€è¿›ä¸€æ­¥åŠ å¼ºå¯¹æŠ—æç¤ºæ³¨å…¥æ”»å‡»çš„é˜²å¾¡æœºåˆ¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11538v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11538.md)  |
| <span style='display: inline-block; width: 42px;'>11-19</span> | **TPTU-v2: Boosting Task Planning and Tool Usage of Large Language Model-based Agents in Real-world Systems**<br><sub>æœºæ„: SenseTime Researc<br></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11315v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11315.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **An Embodied Generalist Agent in 3D World**<br><sub>æœºæ„: Beijing Institute for General Artificial Intelligence <br>LEOæ˜¯ä¸€ä¸ªæ–°å‹çš„èº«ä½“åŒ–ã€å¤šæ¨¡æ€ã€å¤šä»»åŠ¡çš„é€šç”¨å‹æ™ºèƒ½ä½“ï¼Œä¸“æ³¨äºåœ¨3Dä¸–ç•Œä¸­çš„æ„ŸçŸ¥ã€åŸºç¡€ã€æ¨ç†ã€è§„åˆ’å’Œè¡ŒåŠ¨ã€‚é€šè¿‡å¯¹3Dè§†è§‰-è¯­è¨€å¯¹é½å’Œè§†è§‰-è¯­è¨€-åŠ¨ä½œæŒ‡ä»¤è°ƒä¼˜çš„è®­ç»ƒï¼ŒLEOèƒ½åœ¨3Dä¸–ç•Œä¸­æ‰§è¡Œä¸€ç³»åˆ—ä»»åŠ¡ã€‚æ–‡ç« é€šè¿‡ä¸€ç³»åˆ—ä¸¥æ ¼å®éªŒå’Œæ¶ˆèå®éªŒçš„ç»“æœï¼Œè¯å®äº†LEOåœ¨ä¸€ç³»åˆ—ä»»åŠ¡ä¸Šçš„é«˜æ•ˆæ€§èƒ½ï¼Œå¹¶ä¸ºæœªæ¥èº«ä½“åŒ–é€šç”¨å‹æ™ºèƒ½ä½“çš„å‘å±•æä¾›äº†å®è´µæ´è§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12871v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12871.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **RecExplainer: Aligning Large Language Models for Recommendation Model Interpretability**<br><sub>æœºæ„: University of Science and Technology of China<br>æ–‡ç« é’ˆå¯¹æ¨èæ¨¡å‹è§£é‡Šæ€§çš„ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„æ–¹æ³•ï¼Œå³é€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¯¹é½ï¼Œä»¥æé«˜è§£é‡Šçš„è´¨é‡å’Œå‡†ç¡®æ€§ã€‚æ–‡ç« ä»‹ç»äº†ä¸‰ç§ä¸åŒçš„å¯¹é½æ–¹æ³•ï¼Œå¹¶é€šè¿‡ä¸€ç³»åˆ—ä»»åŠ¡è®­ç»ƒLLMä»¥æ¨¡ä»¿æ¨èæ¨¡å‹çš„é€»è¾‘ã€‚è®ºæ–‡é‡‡ç”¨äº†å¤šç§è¯„ä¼°ç­–ç•¥å’Œè¯„åˆ†ä½“ç³»ï¼ŒåŒ…æ‹¬ä½¿ç”¨æœ€æ–°çš„GPT-4æ¨¡å‹å’Œäººç±»è¯„åˆ†æ¥éªŒè¯æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶åœ¨ä¸‰ä¸ªä¸åŒçš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨æé«˜æ¨èæ¨¡å‹è§£é‡Šæ€§æ–¹é¢çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10947v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10947.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **Orca 2: Teaching Small Language Models How to Reason**<br><sub>æœºæ„: Microsoft Research<br>æ–‡ç« é€šè¿‡ä»‹ç»ä¸€ä¸ªæ–°çš„å°å‹è¯­è¨€æ¨¡å‹Orca 2ï¼Œå¹¶å±•ç¤ºå…¶åœ¨å¤šç§æ¨ç†ä»»åŠ¡ä¸Šèƒ½å¤Ÿä¸æ›´å¤§çš„æ¨¡å‹ç›¸åŒ¹æ•Œæˆ–è¶…è¶Šå®ƒä»¬çš„æ€§èƒ½ï¼Œå¯¹å½“å‰å°å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³çš„é—®é¢˜æå‡ºäº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚Orca 2çš„å¼€å‘ä¾èµ–äºå¯¹è®­ç»ƒæ•°æ®å’Œè®­ç»ƒç­–ç•¥çš„ç²¾å¿ƒè®¾è®¡ï¼Œè¯æ˜äº†å³ä½¿æ˜¯å°å‹æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥é€šè¿‡æ”¹è¿›è®­ç»ƒæ–¹æ³•æ¥å¢å¼ºå…¶ç†è§£å’Œæ¨ç†èƒ½åŠ›ã€‚æ–‡ç« è¿˜æä¾›äº†Orca 2åœ¨å„ç§æ ‡å‡†æµ‹è¯•ä¸­çš„å“è¶Šæ€§èƒ½ç»“æœï¼ŒéªŒè¯äº†å…¶æ–¹æ³•è®ºåœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11045v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11045.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **Adapters: A Unified Library for Parameter-Efficient and Modular Transfer Learning**<br><sub>æœºæ„: Technical University of Darmstadt, University of Cambridge<br>è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„åº“â€”â€”Adaptersï¼Œå®ƒæ•´åˆå¹¶æ‰©å±•äº†å‚æ•°é«˜æ•ˆå’Œæ¨¡å—åŒ–è¿ç§»å­¦ä¹ æ–¹æ³•ï¼Œå®ç°äº†ä¸Transformersåº“çš„ç´§å¯†æ•´åˆï¼Œé€šè¿‡å¤šä¸ªNLPä»»åŠ¡çš„å¯¹æ¯”å®éªŒï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11077v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11077.md)  |
| <span style='display: inline-block; width: 42px;'>11-17</span> | **Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2**<br><sub>æœºæ„: Allen Institute for AI <br>TÃœLU 2é€šè¿‡é‡‡ç”¨æ–°çš„åŸºç¡€æ¨¡å‹å’Œè°ƒæ•´ç­–ç•¥ï¼Œåœ¨å¤šä¸ªæ€§èƒ½æŒ‡æ ‡ä¸Šå®ç°äº†çªç ´ï¼Œå¯¹è¿›ä¸€æ­¥ç†è§£å’Œæ”¹è¿›é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„é€‚é…å…·æœ‰é‡è¦æ„ä¹‰ã€‚é€šè¿‡å¼•å…¥æ–°çš„æ•°æ®æ··åˆç‰©å’Œå…ˆè¿›çš„è®­ç»ƒæ–¹æ³•ï¼ˆå¦‚DPOï¼‰ï¼ŒTÃœLU 2æé«˜äº†æ¨¡å‹åœ¨å„ç§æ¨ç†å’ŒçŸ¥è¯†æ¢æµ‹ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œå¹¶åœ¨å¼€æ”¾å¼ç”ŸæˆæŒ‡æ ‡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æå‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…ä»¬é€šè¿‡å…¬å¼€ç›¸å…³æ¨¡å‹ã€æ•°æ®å’Œä»£ç ï¼Œæ¨åŠ¨äº†è¯­è¨€æ¨¡å‹é€‚é…æ–¹æ³•çš„å¼€æ”¾ç ”ç©¶å’Œå‘å±•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10702v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10702.md)  |
| <span style='display: inline-block; width: 42px;'>11-17</span> | **Exploring the Relationship between In-Context Learning and Instruction Tuning**<br><sub>æœºæ„: HKUST<br>è®ºæ–‡æä¾›äº†ICLä¸ITä¹‹é—´å¯†åˆ‡ç›¸å…³çš„å®è¯è¯æ®ï¼Œå³ä½¿ICLä¸­ä¸æ›´æ”¹æ¨¡å‹å‚æ•°ï¼ŒäºŒè€…æ‰€ä½¿ç”¨çš„æŒ‡ä»¤å’Œç¤ºä¾‹éƒ½é©±åŠ¨æ¨¡å‹æœç€æ”¶æ•›çš„éšè—çŠ¶æ€å‰è¿›ã€‚è¿™ä¸€å‘ç°å¯¹äºå¦‚ä½•è®¾è®¡é«˜æ•ˆçš„æ•°æ®é›†å’Œä»»åŠ¡ä»¥æ¨è¿›åŸºç¡€æ¨¡å‹åœ¨ä¸‹æ¸¸åº”ç”¨çš„å‘å±•å’Œå¯¹é½å…·æœ‰å¯ç¤ºä½œç”¨ã€‚ç ”ç©¶ç»“æœè¿˜å¯ä»¥å¸®åŠ©ç†è§£ç¤ºä¾‹åœ¨ICLå’ŒITä¸­çš„ä½œç”¨ï¼Œä»¥åŠå¦‚ä½•åˆ©ç”¨è¿™äº›è§è§£æ¥è®¾è®¡æœ‰æ•ˆçš„ç¤ºä¾‹ä»»åŠ¡å’Œæ•°æ®é›†ï¼Œä»è€Œæå‡LLMçš„æ€§èƒ½ã€‚è®ºæ–‡ä¸­ç”³æ˜å°†ä¼šæä¾›å®éªŒä»£ç ä»¥ä¾›å¤ç°ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10367v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10367.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **Predictive Minds: LLMs As Atypical Active Inference Agents**<br><sub>æœºæ„: Charles University<br>æœ¬è®ºæ–‡å°†æ´»åŠ¨æ¨æ–­çš„æ¦‚å¿µåº”ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œä»ä¸€ä¸ªæ–°çš„è§†è§’åˆ†æäº†LLMsçš„è¡Œä¸ºå’Œå­¦ä¹ æœºåˆ¶ã€‚è®ºæ–‡æå‡ºï¼Œå°½ç®¡LLMsåœ¨ç‰©ç†ä¸Šæ— æ³•ç›´æ¥ä¸ç¯å¢ƒäº’åŠ¨ï¼Œä½†å®ƒä»¬é€šè¿‡ç”Ÿæˆæ–‡æœ¬åœ¨è™šæ‹Ÿç¯å¢ƒä¸­çš„â€œè¡ŒåŠ¨â€é—´æ¥å½±å“ä¸–ç•Œï¼Œå¹¶æœ‰å¯èƒ½å°†è¿™äº›å½±å“åé¦ˆåˆ°æ¨¡å‹çš„è®­ç»ƒä¸­ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œå¢å¼ºLLMsä¸ç”¨æˆ·äº¤äº’çš„åé¦ˆå¾ªç¯ï¼Œå°†æœ‰åŠ©äºæå‡æ¨¡å‹çš„è‡ªæˆ‘æ„è¯†ï¼Œè®©å…¶æ›´å¥½åœ°é€‚åº”å’Œå“åº”ç¯å¢ƒå˜åŒ–ï¼Œè¿™å°†å¸¦æ¥é‡å¤§çš„ç¤¾ä¼šå½±å“å’Œæ½œåœ¨çš„é£é™©ã€‚è®ºæ–‡ä¸ºç†è§£å’Œæ”¹è¿›LLMsåœ¨å®é™…éƒ¨ç½²æ—¶çš„è¡Œä¸ºæä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€ï¼Œé¢„æµ‹äº†è¿™äº›ç³»ç»Ÿæœªæ¥å¯èƒ½çš„å‘å±•æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10215v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10215.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **Automatic Engineering of Long Prompts**<br><sub>æœºæ„: Google<br>æœ¬æ–‡é’ˆå¯¹è¯­è¨€æ¨¡å‹é•¿æŒ‡ä»¤å·¥ç¨‹ä¸­å­˜åœ¨çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„ç®—æ³•æ¡†æ¶ï¼Œå¹¶è§£å†³äº†è´ªå©ªç®—æ³•æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜å’Œé—ä¼ ç®—æ³•åˆæœŸæ”¶æ•›æ…¢çš„é—®é¢˜ã€‚é€šè¿‡å¯¹æŒ‡ä»¤çš„æ¯ä¸ªå¥å­è¿›è¡Œè¯­ä¹‰ä¿æŒé‡è¿°ï¼Œå¹¶åˆ©ç”¨æ³¢æŸæœç´¢æ¥ç»´æŠ¤å’Œä¼˜åŒ–å€™é€‰æŒ‡ä»¤é›†åˆï¼Œä½¿ç®—æ³•åœ¨æœ‰é™è®­ç»ƒæ•°æ®ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½å’Œè¾ƒå¿«çš„æ”¶æ•›é€Ÿåº¦ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10117v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10117.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **MacGyver: Are Large Language Models Creative Problem Solvers?**<br><sub>æœºæ„: University of California, Princeton University<br>æœ¬ç ”ç©¶é€šè¿‡åˆ›é€ MACGYVERæ•°æ®é›†ï¼Œæ¢ç´¢äº†LLMsåœ¨è§£å†³éä¼ ç»Ÿé—®é¢˜ä¸Šçš„èƒ½åŠ›ï¼Œå¹¶é€šè¿‡äººç±»è¯„ä¼°å‘˜å¯¹GPT-4çš„è¡¨ç°è¿›è¡Œäº†è¯„ä»·ã€‚ç ”ç©¶ç»“æœå±•ç¤ºäº†LLMsåœ¨è¿™ç±»ä»»åŠ¡ä¸Šçš„å±€é™æ€§ï¼ŒåŒæ—¶æå‡ºäº†æé«˜å…¶è¡¨ç°çš„æ–°æ–¹æ³•ã€‚ç ”ç©¶å¼ºè°ƒäº†åˆ›é€ æ€§é—®é¢˜è§£å†³èƒ½åŠ›åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­çš„é‡è¦æ€§ï¼Œå¹¶å°è¯•é€šè¿‡LLMsè¡¥å……äººç±»çš„åˆ›é€ æ€§æ€ç»´ï¼Œä»¥æœŸæé«˜è§£å†³é—®é¢˜çš„èƒ½åŠ›å’Œæ•ˆç‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09682v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.09682.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **Crafting In-context Examples according to LMs' Parametric Knowledge**<br><sub>æœºæ„: The University of Texas at Austin<br>æœ¬æ–‡çš„é‡ç‚¹ç ”ç©¶æ˜¯å¦‚ä½•æ ¹æ®LMçš„å‚æ•°çŸ¥è¯†æœ‰æ•ˆåœ°åˆ›å»ºä¸Šä¸‹æ–‡ç¤ºä¾‹ï¼šé€‰æ‹©æœ€ä¼˜çš„ç¤ºä¾‹ï¼ˆå·²çŸ¥ä¸æœªçŸ¥çš„æ¯”è¾ƒï¼‰ä»¥åŠåœ¨ä¸Šä¸‹æ–‡ç¤ºä¾‹ä¸­å¦‚ä½•æ’åºç­”æ¡ˆã€‚å®éªŒç»“æœæ”¯æŒäº†åŠå·²çŸ¥ç¤ºä¾‹çš„æœ‰æ•ˆæ€§ä»¥åŠåŸºäºå‚æ•°çŸ¥è¯†çš„ç­”æ¡ˆæ’åºæ–¹æ³•ï¼Œè¿™äº›å‘ç°ä¸ºæé«˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šç­”æ¡ˆç”Ÿæˆä»»åŠ¡ä¸­çš„æ€§èƒ½æä¾›äº†å¯è¡Œçš„æŠ€æœ¯é€”å¾„ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09579v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.09579.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Memory Augmented Language Models through Mixture of Word Experts**<br><sub>æœºæ„: Google Research<br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç§°ä¸ºMoWEçš„æ–°å‹æ¶æ„ï¼Œå®ƒé€šè¿‡èåˆç¨€ç–æ¨¡å‹çš„æ•ˆç‡å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ï¼Œå‡ºè‰²åœ°å¤„ç†äº†æ€§èƒ½ä¸è®¡ç®—æˆæœ¬ä¹‹é—´çš„å¹³è¡¡ã€‚é€šè¿‡é‡‡å–åˆ›æ–°çš„è®¾è®¡åŸåˆ™ï¼Œå¹¶ä¸”åœ¨NLPå¤šç§ä»»åŠ¡ä¸­éªŒè¯äº†å…¶è¶…è¶Šä¼ ç»Ÿæ¨¡å‹å¦‚T5å’ŒMoEçš„æ€§èƒ½ï¼ŒMoWEå±•ç¤ºäº†åœ¨å­¦æœ¯å’Œå®é™…åº”ç”¨é¢†åŸŸçš„æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡æ—¶ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10768v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10768.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Contrastive Chain-of-Thought Prompting**<br><sub>æœºæ„: DAMO Academy, Alibaba Group<br>æœ¬è®ºæ–‡æå‡ºäº†å¯¹æ¯”å¼é“¾å¼æ€ç»´æ–¹æ³•ï¼Œä»¥è§£å†³ä¼ ç»Ÿé“¾å¼æ€ç»´ä¸­å­˜åœ¨çš„é—®é¢˜ï¼Œå³ç¼ºä¹å¯¹é”™è¯¯é¿å…çš„æŒ‡å¯¼ä»¥åŠå®ç°æ¨ç†æ•ˆæœçš„ä¸ç¡®å®šæ€§ã€‚é€šè¿‡æä¾›æœ‰æ•ˆå’Œæ— æ•ˆçš„æ¨ç†ç¤ºä¾‹ï¼Œæ–°æ–¹æ³•æ—¨åœ¨å¼•å¯¼æ¨¡å‹å‡å°‘æ¨ç†é”™è¯¯å¹¶ä¸€æ­¥æ­¥æ¨ç†ï¼ŒåŒæ—¶è¯¥æ–¹æ³•æä¾›äº†è‡ªåŠ¨åŒ–æ„å»ºå¯¹æ¯”ç¤ºä¾‹çš„æŠ€æœ¯ä»¥ä¾¿æ³›åŒ–åˆ°å„ç§ä»»åŠ¡ã€‚å®éªŒç»“æœè¯å®ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä½œä¸ºä¸€ç§é€šç”¨å¢å¼ºæ‰‹æ®µï¼Œæ˜¾è‘—æå‡é“¾å¼æ€ç»´çš„æ€§èƒ½ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09277v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.09277.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models**<br><sub>æœºæ„: Tecent AI Lab<br>è®ºæ–‡æå‡ºçš„CHAIN-OF-NOTEï¼ˆCONï¼‰æ¡†æ¶æ—¨åœ¨æé«˜RALMsçš„é²æ£’æ€§ï¼Œä¸»è¦é€šè¿‡å¼•å…¥ç»“æ„åŒ–çš„é˜…è¯»ç¬”è®°è¿‡ç¨‹æ¥æ‰¹åˆ¤æ€§åœ°è¯„ä¼°æ£€ç´¢åˆ°çš„æ–‡æ¡£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶æé«˜äº†æ¨¡å‹åœ¨å™ªå£°æ•°æ®å’ŒæœªçŸ¥æƒ…å†µä¸‹çš„å¥å£®æ€§ï¼Œæ”¹å–„äº†æ•´ä½“QAæ€§èƒ½ï¼Œå¹¶åœ¨æ£€ç´¢æ–‡æ¡£å¤±è´¥è¿˜æ˜¯æˆåŠŸæ—¶å‡æé«˜äº†æ¨¡å‹çš„æ€§èƒ½ã€‚CONæ¡†æ¶é€šè¿‡ç”Ÿæˆè¯»å–ç¬”è®°å’Œæœ€ç»ˆå›ç­”ï¼Œæé«˜äº†æ¨¡å‹å¯¹å™ªå£°çš„é²æ£’æ€§ï¼Œå¹¶åœ¨ç¼ºä¹ä¿¡æ¯æ—¶èƒ½å¤Ÿç»™å‡ºâ€œæœªçŸ¥â€çš„å›ç­”ï¼Œå¢å¼ºäº†æ¨¡å‹çš„é€‚åº”æ€§å’Œå¯é æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09210v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.0921.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **ToolTalk: Evaluating Tool-Usage in a Conversational Setting**<br><sub>æœºæ„: Microsoft Corporation<br>ToolTalk æ˜¯ä¸€ä¸ªè‡´åŠ›äºè¯„ä¼°å’Œæé«˜ LLM åœ¨å¯¹è¯ç¯å¢ƒä¸­ä½¿ç”¨å¤šæ­¥éª¤å¤–éƒ¨å·¥å…·æ€§èƒ½çš„åŸºå‡†ã€‚å®ƒé€šè¿‡åˆ›æ–°çš„è¯„ä¼°æ–¹æ³•å’ŒçœŸå®åœºæ™¯æ¨¡æ‹Ÿï¼ŒæŒ‘æˆ˜å’Œæ‰©å±•äº†ç°æœ‰ LLMs çš„èƒ½åŠ›è¾¹ç•Œï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æŒ‡å‡ºäº†æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10775v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10775.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/microsoft/ToolTalk)</div> |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Exponentially Faster Language Modelling**<br><sub>æœºæ„: ETH Zurich<br>æœ¬æ–‡ä»‹ç»äº†UltraFastBERTï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„å˜ç§ï¼Œå®ƒæ˜¾è‘—å‡å°‘äº†åœ¨æ¨ç†æ—¶éœ€è¦ä½¿ç”¨çš„ç¥ç»å…ƒæ•°é‡ï¼Œå¹¶é€šè¿‡ä½¿ç”¨å¿«é€Ÿå‰é¦ˆç½‘ç»œæ¥æé«˜è®¡ç®—æ•ˆç‡ã€‚å°½ç®¡ä¸å…·å¤‡åŸç”Ÿçš„é«˜æ•ˆå®ç°ï¼Œä½†è¯¥æ¨¡å‹æä¾›äº†ä¸€ä¸ªèƒ½å¤Ÿæ˜¾è‘—åŠ é€Ÿæ¨ç†è¿‡ç¨‹çš„CPUä»£ç å®ç°ï¼Œå¹¶åœ¨æ ‡å‡†ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ã€‚è¿™ä¸€å·¥ä½œå±•ç¤ºäº†æ¡ä»¶ç¥ç»æ‰§è¡Œåœ¨è¯­è¨€å»ºæ¨¡é¢†åŸŸå·¨å¤§çš„æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10770v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1077.md)  |
| <span style='display: inline-block; width: 42px;'>11-14</span> | **Learning to Filter Context for Retrieval-Augmented Generation**<br><sub>æœºæ„: Carnegie Mellon University<br>æœ¬æ–‡æå‡ºçš„FILCOæ–¹æ³•é’ˆå¯¹å¼€æ”¾é¢†åŸŸé—®ç­”å’Œäº‹å®éªŒè¯ç­‰çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ï¼Œé€šè¿‡æ”¹å–„æä¾›ç»™ç”Ÿæˆæ¨¡å‹çš„ä¸Šä¸‹æ–‡è´¨é‡æ¥è§£å†³ç”Ÿæˆè¾“å‡ºæ—¶é¢ä¸´çš„é—®é¢˜ã€‚é€šè¿‡ç»“åˆè¯æ±‡å’Œä¿¡æ¯è®ºæ–¹æ³•æ¥è¯†åˆ«æœ‰ç”¨ä¸Šä¸‹æ–‡ï¼Œå¹¶è®­ç»ƒæ¨¡å‹ä»¥åœ¨æµ‹è¯•æ—¶è¿‡æ»¤æ£€ç´¢ä¸Šä¸‹æ–‡ï¼Œå¾ˆå¥½åœ°è§£å†³äº†ä»¥å‰æ–¹æ³•çš„å±€é™æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•ï¼ŒFILCOåœ¨å¤šä¸ªçŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ï¼Œå¹¶ä¸”åœ¨ä¸Šä¸‹æ–‡è¿‡æ»¤è®­ç»ƒä¸Šæ˜¾ç¤ºå‡ºå…¶æœ‰æ•ˆæ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.08377v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.08377.md)  |
| <span style='display: inline-block; width: 42px;'>11-14</span> | **Instruction-Following Evaluation for Large Language Models**<br><sub>æœºæ„: Google, Yale University<br>æœ¬æ–‡æå‡ºäº†ä¸€ç§è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›çš„æ–°æ–¹æ³•â€”â€”IFEvalï¼Œå®ƒé€šè¿‡åˆæˆé€»è¾‘ä¸€è‡´çš„æŒ‡ä»¤å’Œè®¡ç®—æŒ‡ä»¤éµå¾ªå‡†ç¡®æ€§çš„æ–°å‡†åˆ™æ¥è§£å†³è¯„ä¼°è¿‡ç¨‹ä¸­çš„æŒ‘æˆ˜ã€‚æ­¤æ–¹æ³•ä¸ºè‡ªåŠ¨åŒ–ä¸”æ— åè§ï¼Œå®ƒé€šè¿‡å¤šæ­¥éª¤è¿‡ç¨‹é¿å…æŒ‡ä»¤é—´çš„æ½œåœ¨å†²çªï¼Œå¹¶å¼•å…¥äº†ä¸¥æ ¼å’Œå®½æ¾çš„å‡†ç¡®æ€§è¯„ä»·æ ‡å‡†æ¥å‡å°‘è¯¯åˆ¤ï¼ŒåŒæ—¶è®¤ä¸ºæœªæ¥å¯ä»¥é€šè¿‡å¢åŠ å¤šæ ·åŒ–å’Œä½¿ç”¨å¤šæ¨¡æ€æŒ‡ä»¤æ¥æ”¹è¿›è¯¥æ–¹æ³•ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.07911v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.07911.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/google-research/google-research/tree/master/instruction_following_eval)</div> |
| <span style='display: inline-block; width: 42px;'>11-14</span> | **KTRL+F: Knowledge-Augmented In-Document Search**<br><sub>æœºæ„: KAIST AI, Samsung Research<br>æ–‡ç« æå‡ºäº†ä¸€ä¸ªæ–°çš„é—®é¢˜â€”â€”KTRL+Fï¼Œä»¥è§£å†³æ–‡çŒ®æœç´¢ä¸­çš„å®æ—¶ã€å‡†ç¡®æ€§ã€å¼•å…¥å¤–éƒ¨çŸ¥è¯†çš„éœ€æ±‚ã€‚é€šè¿‡åˆ†æç°æœ‰åŸºçº¿ï¼Œæ–‡ç« å‘ç°å®ƒä»¬å­˜åœ¨å±€é™æ€§ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šæå‡ºäº†Knowledge-Augmented Phrase Retrievalæ¨¡å‹ã€‚è¯¥æ¨¡å‹æœ‰æ•ˆåœ°åœ¨çŸ­è¯­æ£€ç´¢ä¸­æ•´åˆäº†å¤–éƒ¨çŸ¥è¯†ï¼Œé€šè¿‡ç®€å•çš„æ‰©å±•ä¿æŒäº†å¿«é€Ÿå“åº”ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚é€šè¿‡ç”¨æˆ·ç ”ç©¶ï¼Œè¯æ˜äº†è¯¥æ¨¡å‹èƒ½å¤Ÿæå‡ç”¨æˆ·æœç´¢ä½“éªŒï¼Œå‡å°‘æœç´¢æ—¶é—´å’Œå¤–éƒ¨ä¿¡æ¯æ£€ç´¢é‡ã€‚ä½œè€…é¼“åŠ±ç ”ç©¶ç¤¾åŒºå…³æ³¨KTRL+Fè¿™ä¸€ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œæé«˜æ–‡çŒ®ä¿¡æ¯è®¿é—®çš„æ•ˆç‡å’Œæ•ˆæœã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.08329v3)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.08329.md)  |
| <span style='display: inline-block; width: 42px;'>11-13</span> | **Can LLMs Patch Security Issues?**<br><sub>æœºæ„: School of Computer Science Atlanta<br>æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹çš„ä»£ç ä¿®æ­£æ–¹æ³•FDSSï¼Œé€šè¿‡ä¸é™æ€ä»£ç åˆ†æå·¥å…·Bandité›†æˆï¼Œèƒ½æ˜¾è‘—æé«˜LLMsè§£å†³ä»£ç ä¸­å®‰å…¨é—®é¢˜çš„èƒ½åŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00024v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2312.00024.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Kamel773/LLM-code-refine)</div> |
| <span style='display: inline-block; width: 42px;'>11-11</span> | **In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering**<br><sub>æœºæ„: Stanford University<br>æœ¬è®ºæ–‡æå‡ºçš„ICVæ–¹æ³•ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å­¦ä¹ æä¾›äº†ä¸€ç§æ–°é¢–ä¸”æ›´åŠ æœ‰æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆã€‚é€šè¿‡å°†æ¼”ç¤ºç¤ºä¾‹çš„å…³é”®ä¿¡æ¯é›†æˆåˆ°ä¸€ä¸ªå¯ä»¥æ§åˆ¶çš„å‘é‡ä¸­ï¼ŒICVæ–¹æ³•æé«˜äº†ä»»åŠ¡æŒ‡å¯¼çš„ç²¾ç¡®åº¦å’Œæ•ˆæœï¼Œå¹¶æ˜¾è‘—ä¼˜äºç°æœ‰çš„æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒICVåœ¨å¤šé¡¹ä»»åŠ¡ä¸­å±•ç°äº†è¾ƒé«˜çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬åœ¨ä¸åŒçš„LLMsä¸Šè¿›è¡Œè¯­è¨€æ¨¡å‹è§£æ¯’ã€é£æ ¼è½¬æ¢å’Œè§’è‰²æ‰®æ¼”ã€‚ICVæ–¹æ³•çš„è®¡ç®—å¼€é”€ä½ï¼Œå¹¶ä¸”æ˜“äºæ§åˆ¶ï¼Œæœ‰åŠ©äºæå‡è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„é€‚ç”¨æ€§å’Œå¼¹æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.06668v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.06668.md)  |
| <span style='display: inline-block; width: 42px;'>11-10</span> | **Making LLMs Worth Every Penny: Resource-Limited Text Classification in Banking**<br><sub>æœºæ„: Helvia.ai<br>è®ºæ–‡é¦–æ¬¡å°†å¤šç§åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹çš„æ–¹æ³•è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼ŒåŒ…æ‹¬æˆæœ¬åˆ†æã€RAGæ–¹æ³•å’Œåˆ©ç”¨GPT-4çš„æ•°æ®å¢å¼ºï¼Œä¸ºé‡‘èè¡Œä¸šæä¾›äº†æ–°çš„æ–¹æ³•ç”¨ä»¥åº”å¯¹æ•°æ®å’Œé¢„ç®—é™åˆ¶çš„æŒ‘æˆ˜ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.06102v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.06102.md)  |
| <span style='display: inline-block; width: 42px;'>11-05</span> | **ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs**<br><sub>æœºæ„: Cornell University, Microsoft Research<br>æœ¬æ–‡æä¾›äº†ä¸€ä¸ªä½¿ç”¨å¼€æºLLMså¢å¼ºåœ¨çº¿æ•™è‚²QAå¹³å°çš„æ–°æ–¹æ¡ˆï¼Œå¹¶å¯¹å…¶è¿›è¡Œäº†å¹¿æ³›çš„è¯„ä¼°å’Œæµ‹è¯•ã€‚é€šè¿‡å°†RAGã€SFTå’ŒDPOç­‰æŠ€æœ¯ç»“åˆåº”ç”¨ï¼Œç¡®ä¿äº†å›ç­”è´¨é‡çš„æ˜¾è‘—æå‡å’Œæ•°æ®éšç§çš„ä¿æŠ¤ï¼Œå¯¹äºå¼€å‘æ™ºèƒ½QAåŠ©æ‰‹å…·æœ‰é‡è¦çš„æ„ä¹‰ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.02775v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.02775.md)  |
| <span style='display: inline-block; width: 42px;'>11-01</span> | **LLMRec: Large Language Models with Graph Augmentation for Recommendation**<br><sub>æœºæ„: University of Hong Kong, Baidu<br>LLMRecä½œä¸ºå¼€åˆ›æ€§çš„å·¥ä½œï¼Œå®ƒå¼•å…¥LLMsæ¥å¢å¼ºå›¾æ¨èç³»ç»Ÿï¼ŒæˆåŠŸåœ°è§£å†³äº†äº¤äº’æ•°æ®çš„ç¨€ç–æ€§å’Œä½è´¨é‡ä¾§ä¿¡æ¯çš„é—®é¢˜ï¼Œå¹¶é€šè¿‡å¼ºåŒ–ç”¨æˆ·-é¡¹ç›®äº¤äº’è¾¹ã€é¡¹ç›®èŠ‚ç‚¹å±æ€§ä»¥åŠç”¨æˆ·ç”»åƒç­‰æ‰‹æ®µæå‡äº†æ¨èç³»ç»Ÿçš„æ€§èƒ½ï¼Œç¡®ä¿äº†æ¨èè´¨é‡çš„åŒæ—¶é™ä½äº†æ•°æ®å™ªå£°çš„å½±å“ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.00423v5)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.00423.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/HKUDS/LLMRec.git)</div> |

---

## 10æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>10-20</span> | **The History and Risks of Reinforcement Learning and Human Feedback**<br><sub>æœºæ„: Berkeley<br></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.13595v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.13595.md)  |
| <span style='display: inline-block; width: 42px;'>10-17</span> | **Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection**<br><sub>æœºæ„: University of Washington<br>è®ºæ–‡æ¨å‡ºäº†SELF-RAGï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œé€šè¿‡æŒ‰éœ€æ£€ç´¢å’Œè‡ªæˆ‘åæ€æ¥å¢åŠ LLMsçš„è´¨é‡å’Œäº‹å®æ€§ã€‚å®ƒé€šè¿‡ç”Ÿæˆåæ€æ ‡è®°è®©LMåœ¨æ¨ç†é˜¶æ®µå˜å¾—å¯æ§ï¼Œå¯ä»¥æ»¡è¶³å¤šæ ·åŒ–çš„ä»»åŠ¡è¦æ±‚ã€‚SELF-RAGåœ¨å¤šä¸ªä»»åŠ¡ä¸Šæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰LLMså’ŒRAGæ¨¡å‹ï¼Œå¹¶é€šè¿‡å®šåˆ¶çš„è§£ç ç®—æ³•å’Œåæ€æ ‡è®°ï¼Œä¸ºæ¨¡å‹è‡ªæˆ‘è¯„ä¼°å’Œå®šåˆ¶æä¾›äº†æ–°çš„æ–¹æ¡ˆã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.11511v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.11511.md)  |
| <span style='display: inline-block; width: 42px;'>10-11</span> | **OpsEval: A Comprehensive Task-Oriented AIOps Benchmark for Large Language Models**<br><sub>æœºæ„: Tsinghua University, Chinese Academy of Sciences<br>OpsEval ä½œä¸ºä¸€ä¸ªå…¨é¢çš„ AIOps ä»»åŠ¡å¯¼å‘å‹åŸºå‡†æµ‹è¯•ï¼Œä¸ä»…è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„ç»¼åˆæ€§èƒ½ã€æ¨ç†å’Œå®é™…åº”ç”¨èƒ½åŠ›ï¼Œè¿˜å¯èƒ½æ”¹å˜æœªæ¥å¤§è§„æ¨¡è´¨é‡è¯„ä¼°ä¸­ä½¿ç”¨çš„è¯„ä»·æŒ‡æ ‡ã€‚å®ƒæä¾›äº†ä¸€ä¸ªç”¨äºæŒç»­ç ”ç©¶å’Œä¼˜åŒ–AIOpsé¢†åŸŸå¤§å‹è¯­è¨€æ¨¡å‹çš„åšå®åŸºç¡€ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.07637v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.07637.md)  |
| <span style='display: inline-block; width: 42px;'>10-10</span> | **GPT-4 as an Agronomist Assistant? Answering Agriculture Exams Using Large Language Models**<br><sub>æœºæ„: Microsoft Research<br>æœ¬ç ”ç©¶å±•ç¤ºäº†åœ¨å†œä¸šé¢†åŸŸä½¿ç”¨LLMsè¿›è¡Œé—®é¢˜å›ç­”çš„æ–°æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡Ensemble Refinementç­–ç•¥ï¼Œå¤§å¹…æå‡äº†LLMsåœ¨å¤šé€‰é¢˜ç›®ä¸Šçš„è¡¨ç°ï¼Œå¹¶æ˜¾ç¤ºå‡ºåœ¨å¤„ç†ä¸“ä¸šé¢†åŸŸé—®é¢˜æ—¶çš„å¹¿æ³›æ½œåŠ›ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.06225v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.06225.md)  |

---

## 09æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>09-04</span> | **Benchmarking Large Language Models in Retrieval-Augmented Generation**<br><sub>æœºæ„: Chinese Information Processing Laboratory <br>æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºå®é™…æ–°é—»æ–‡ç« çš„æ£€ç´¢å¢å¼ºç”ŸæˆåŸºå‡†æµ‹è¯•ï¼Œç”¨ä»¥å½»åº•è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ä¿¡æ¯ç¯å¢ƒä¸­çš„å¤šé¡¹èƒ½åŠ›ï¼Œå¹¶é€šè¿‡å®éªŒç»“æœå±•ç°äº†ç°æœ‰LLMsåœ¨è¿™äº›æ–¹é¢çš„å±€é™æ€§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2309.01431v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-09/2309.01431.md)  |

---

## 08æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>08-18</span> | **Learning Representations on Logs for AIOps**<br><sub>æœºæ„: IBM Research<br>æœ¬æ–‡æå‡ºçš„BERTOpsæ¨¡å‹é€šè¿‡ä½¿ç”¨LLMsä¸­çš„é€šç”¨è¡¨ç¤ºï¼Œå¹¶ç»“åˆä¸“é—¨é’ˆå¯¹AIOpsæ—¥å¿—æ•°æ®çš„é¢„è®­ç»ƒï¼Œæœ‰æ•ˆåœ°æé«˜äº†è‡ªåŠ¨åŒ–æ—¥å¿—åˆ†æä»»åŠ¡çš„æ€§èƒ½ï¼Œå¹¶å±•ç¤ºäº†æ˜¾è‘—çš„æ”¹è¿›ã€‚BERTOpsä¸ä»…ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œåœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­ä¹Ÿè¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œæœ‰åŠ©äºåŠ é€ŸAIOpsçš„å®è·µåº”ç”¨ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2308.11526v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-08/2308.11526.md)  |

---

## 07æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>07-11</span> | **Towards Understanding In-Context Learning with Contrastive Demonstrations and Saliency Maps**<br><sub>æœºæ„: UNIVERSITY OF MARYLAND<br>æœ¬ç ”ç©¶ä½¿ç”¨å¯¹æ¯”ç¤ºä¾‹å’Œæ˜¾è‘—å›¾åˆ†ææ³•æ¥æ¢ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ä¸Šä¸‹æ–‡å­¦ä¹ çš„å†…åœ¨æœºåˆ¶ï¼Œæ­ç¤ºäº†æ ‡ç­¾ç¿»è½¬ã€è¾“å…¥å˜åŒ–ã€å’Œè¡¥å……æ€§è§£é‡Šå¯¹é¢„æµ‹çš„ä¸åŒå½±å“ï¼Œå¹¶ä¸ºå®è·µè€…æä¾›äº†å¦‚ä½•ç­–åˆ’ç¤ºä¾‹çš„æ´è§ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2307.05052v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-07/2307.05052.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/paihengxu/XICL)</div> |

---

## 05æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>05-24</span> | **In-Context Demonstration Selection with Cross Entropy Difference**<br><sub>æœºæ„: Microsoft Cognitive Service Research<br>æ–‡ç« æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºäº¤å‰ç†µå·®å¼‚ï¼ˆCEDï¼‰çš„ä¸Šä¸‹æ–‡ç¤ºä¾‹é€‰æ‹©æ–¹æ³•ï¼Œå¹¶æä¾›äº†ç†è®ºä¸Šçš„è§£é‡Šï¼Œå®ç°äº†å¯¹ä¸åŒå¤§å°å’Œç±»å‹çš„å¤§å‹è¯­è¨€æ¨¡å‹æ€§èƒ½çš„æå‡ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2305.14726v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-05/2305.14726.md)  |
| <span style='display: inline-block; width: 42px;'>05-23</span> | **Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning**<br><sub>æœºæ„: Lean Wang, Lei Li, Damai Dai, Deli Chen, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun<br>æœ¬è®ºæ–‡é€šè¿‡ä¿¡æ¯æµè§†è§’ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰çš„å†…éƒ¨æœºåˆ¶ï¼Œå‘ç°äº†æ ‡ç­¾è¯åœ¨ä¿¡æ¯æµä¸­ä½œä¸ºé”šç‚¹çš„ç°è±¡ï¼Œæå‡ºäº†æ–°å‡è®¾ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œä½¿ç”¨æ‰€å¾—æ´è§æå‡ºäº†æé«˜ICLæ€§èƒ½çš„æ–¹æ³•ï¼Œä¸ºæœªæ¥ç›¸å…³ç ”ç©¶æä¾›äº†ç†è®ºåŸºç¡€å’Œå®è·µæŒ‡å¯¼ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2305.14160v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-05/2305.1416.md)  |
| <span style='display: inline-block; width: 42px;'>05-19</span> | **How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings**<br><sub>æœºæ„: The Ohio State University<br>æœ¬ç ”ç©¶æ­ç¤ºå‡ºæœ‰æ•ˆæç¤ºæ„é€ çš„å…³é”®æ•°æ®åº“çŸ¥è¯†å’Œæœ€ä¼˜è¡¨è¿°ï¼Œä¸ºLLMsåœ¨text-to-SQLä»»åŠ¡ä¸­çš„åº”ç”¨æä¾›æŒ‡å¯¼ï¼Œå¹¶æŒ‡å‡ºåœ¨è·¨åŸŸè®¾ç½®ä¸­å¯¹äºæç¤ºé•¿åº¦å­˜åœ¨ä¸€ä¸ªâ€œç”œèœœç‚¹â€ã€‚æœ¬ç ”ç©¶çš„å‘ç°å¯èƒ½å¯¹äºç‰¹å®šæ•°æ®åº“ä¸æ€»æ˜¯é€‚ç”¨ï¼Œç‰¹åˆ«æ˜¯å¦‚æœè¯¥æ•°æ®åº“ä¸Spideræ•°æ®åº“æ˜¾è‘—ä¸åŒã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2305.11853v3)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-05/2305.11853.md)  |

---

## 03æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>03-31</span> | **A Survey of Large Language Models**<br><sub>æœºæ„: Renmin University of China<br>æ€»çš„æ¥è¯´ï¼Œè¿™ç¯‡ç»¼è¿°æ–‡ç« ä»‹ç»äº†LLMsé¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œç‰¹åˆ«æ˜¯OpenAIæ¨å‡ºçš„ChatGPTå’ŒGPT-4æ¨¡å‹ï¼Œå¹¶å¼ºè°ƒäº†è¿™äº›äº§å“å¯¹äººå·¥æ™ºèƒ½ç ”ç©¶çš„é‡å¤§å½±å“ï¼Œç‰¹åˆ«æŒ‡å‡ºäº†å®ƒä»¬åœ¨äººæœºäº¤æµã€å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆã€ä»¥åŠäººå·¥æ™ºèƒ½å¯¹é½å’Œå®‰å…¨æ€§æ–¹é¢çš„çªç ´ã€‚åŒæ—¶ï¼Œæ–‡ç« è®¤è¯†åˆ°å°½ç®¡å–å¾—äº†å·¨å¤§çš„æŠ€æœ¯è¿›å±•ï¼Œä½†åœ¨å®‰å…¨æ€§ã€ç”Ÿæˆè´¨é‡å’Œå¤šæ¨¡æ€æ€§åŠŸèƒ½æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†ä¸€ç³»åˆ—çš„æŠ€æœ¯å’Œç­–ç•¥æ¥ç¼“è§£è¿™äº›é—®é¢˜ã€‚é€šè¿‡è¿™ç¯‡æ–‡ç« ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å¥½åœ°ç†è§£LLMsçš„å‘å±•æ–¹å‘ä»¥åŠå¯¹æœªæ¥äººå·¥æ™ºèƒ½åº”ç”¨å’Œç ”ç©¶çš„æ½œåœ¨å½±å“ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2303.18223v13)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-03/2303.18223.md)  |

---

## 02æœˆ

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>02-08</span> | **A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity**<br><sub>æœºæ„: Centre for Artificial Intelligence Research<br>æ–‡ç« é€šè¿‡æ›´ç»†ç²’åº¦çš„æ–¹å¼è¯„ä¼°äº†ChatGPTçš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶ä¸”æ‰¾åˆ°äº†LLMsä¸­çš„ä¸€ä¸ªå…³é”®é—®é¢˜ï¼Œå³åœ¨éæ–‡æœ¬è¯­ä¹‰ç†è§£æ–¹é¢çš„ä¸è¶³ã€‚è¿™ä¸€å‘ç°å¯¹äºæœªæ¥LLMsçš„æ”¹è¿›å’Œæ¨ç†èƒ½åŠ›çš„ç ”ç©¶æä¾›äº†é‡è¦çš„æ–¹å‘ã€‚</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2302.04023v4)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-02/2302.04023.md)  |

---

