<h2 align='center'>llm-paper-daily 日常论文精选</h2>
<div align='center'>

[![Status](https://img.shields.io/badge/status-Update_12.08_12:20-success.svg)]() [![简体中文 badge](https://img.shields.io/badge/%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87-Simplified%20Chinese-blue)](./README.md) [![English badge](https://img.shields.io/badge/%E8%8B%B1%E6%96%87-English-blue)](./README_en.md) 

</div>

**每篇论文会携带相关资料:**
- arXiv 地址 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)
- GitHub 地址 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  ![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)
- GPT-4 的总结 &nbsp;&nbsp;&nbsp;&nbsp;  ![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)
- 相关的精选博客 &nbsp; ![Blog](https://img.shields.io/badge/Blog-Posts-yellow?logo=rss)

<details>
  <summary>查看更新文章 &nbsp;&nbsp;<sub>更新时间: 12月08日 12:20</sub></summary>
<br>
周末无论文更新.....

</details>

## 12月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Cost-Effective In-Context Learning for Entity Resolution: A Design Space Exploration**<br><sub>机构: Renmin University of China, Beijing Institute of Technology, HKUST (GZ)<br>这篇论文提供了一个全面的研究，旨在探索如何开发一种成本效益的批量提示方法来进行实体解析。主要贡献是介绍 BATCHER 框架并提出基于覆盖的演示选择策略。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03987v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03987.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **A Study on the Calibration of In-context Learning**<br><sub>机构: Harvard University<br>该论文深入研究了上下文内学习(ICL)在语言模型(LMs)中的校准准确性问题，并提出了评估和分析方法。它揭示了校准误差与模型大小和微调过程中的变化关系，以及校准在推理任务生成中的降低。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04021v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04021.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models**<br><sub>机构: MPI for Intelligent Systems, University of Washington<br>此研究为测试和分析大型语言模型（LLMs）在正规因果推理上的能力提出了CLADDER数据集和CAUSALCOT思维路径提示策略，通过实验突显了LLMs的局限并为未来研究提出了方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04350v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0435.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/causalNLP/cladder)</div> |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Generating Illustrated Instructions**<br><sub>机构: GenAI Meta, Columbia University<br>本论文介绍了一种名为StackedDiffusion的新方法，用于生成插图说明，这是一种将文本和图像结合起来描述如何实现某一目标的任务。该方法通过结合大型语言模型和文本到图像扩散模型，并引入一些新颖的建模技巧，解决了现有T2I模型无法直接从用户查询中生成视觉效果的问题，并在人类评估中超越了现有技术水平。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04552v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04552.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool Use**<br><sub>机构: Gaoling School of Artificial Intelligence, Renmin University of China, Alibaba Group<br>该论文针对LLMs在工具使用时对上下文认知的不足提出了Attention Buckets方法，通过处理不同的RoPE角度基础来强化对上下文的关注，显著提升了LLMs在工具使用任务的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04455v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04455.md)  |
| <span style='display: inline-block; width: 42px;'>12-07</span> | **An LLM Compiler for Parallel Function Calling**<br><sub>机构: UC Berkeley, ICSI, LBNL<br>论文提出了一个名为LLMCompiler的系统，解决了大型语言模型在执行多功能调用时的高延迟成本和效率低下的问题，通过并行化函数调用和优化协调来提高速度，节省成本并提升准确率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.04511v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.04511.md)  |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **OneLLM: One Framework to Align All Modalities with Language**<br><sub>机构: MMLab The Chinese University of Hong Kong, Shanghai Artificial Intelligence Laboratory<br>OneLLM通过其统一的多模态编码框架和渐进式对齐管道，在推理和利用方面展示了强大的多模态理解和处理能力，并成功地处理了扩展多模态LLMs的挑战。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03700v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.037.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/csuhan/OneLLM)</div> |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **Efficient Large Language Models: A Survey**<br><sub>机构: The Ohio State University, Google Research, Amazon AWS AI<br>论文综述了大型语言模型中对于稀疏激活方法的最新进展，特别是混合专家系统（MoE）及其在长文本处理方面的应用。它总结了MoE模型优化的各种方法，包括算法级别的改进和系统级别的加速框架。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03863v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03863.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/AIoT-MLSys-Lab/EfficientLLMs)</div> |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **Holmes: Towards Distributed Training Across Clusters with Heterogeneous NIC Environment**<br><sub>机构: Zhejiang Lab<br>文章成功介绍了一个能在网络接口卡异构环境中进行大型语言模型训练的框架——Holmes。通过实证研究其性能，Holmes被证明可在异构环境中实现与同构RDMA NICs相当的性能水平，从而使LLM训练更加普及并扩大了有效扩展的可能性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03549v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03549.md)  |
| <span style='display: inline-block; width: 42px;'>12-06</span> | **Generative agent-based modeling with actions grounded in physical, social, or digital space using Concordia**<br><sub>机构: Google DeepMind, Google Research<br>本论文提出了利用生成式大型语言模型增强基于代理的模型的方法，通过Concordia库实现了在社会、物理和数字空间中模拟代理的交互。该模型旨在提供逼真的社会模拟，并探索模型的有效性验证。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03664v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03664.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education**<br><sub>机构: Carnegie Mellon University  <br>本文的主要贡献是开发了一个基于GPT-4的自动化MCQ生成系统，通过专门的弹性构架和精确的LO对齐机制，成功生成与高等教育Python课程LO一致的MCQs。研究结果表明，自动生成的MCQ在大多数情况下与LO保持良好的一致性，质量接近人工设计的MCQ，但在拥有单一正确答案和高质量干扰项方面略显欠缺，未来工作应该集中在减轻这些问题上。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03173v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03173.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Prompt Optimization via Adversarial In-Context Learning**<br><sub>机构: National University of Singapore, Hong Kong University of Science and Technology, Institute for Infocomm Research (I2R) A*STAR<br>论文介绍了一个新颖的Adversarial In-Context Learning（adv-ICL）方法，用于优化大型模型中prompt的选择，以此提高模型性能。它可以实现对抗训练目标，克服数据和计算资源限制，通过优化prompt而不是模型参数来提升性能，且实验结果在多个任务上显著优于现有技术。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02614v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02614.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Large Knowledge Model: Perspectives and Challenges**<br><sub>机构: Zhejiang University<br>本文提出了一种大型知识模型（LKM）的概念，旨在更有效地管理和解读知识表示的多样性。研究指出了从现有的大型语言模型到LKM转变的挑战，强调了结构化知识在预训练中的重要性，并提出了一套LKM的设计原则。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02706v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02706.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **RankZephyr: Effective and Robust Zero-Shot Listwise Reranking is a Breeze!**<br><sub>机构: University of Waterloo<br>RankZephyr是一款新型开源LLM，特别优化了零样本列表重新排序任务。它提供了与大型专有模型相当或更优的重新排序效果，同时强调了数据增强对于提升模型鲁棒性的重要性，并通过实验证明了其有效性和在现实场景中的应用潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02724v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02724.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/castorini/rank_llm)</div> |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Rank-without-GPT: Building GPT-Independent Listwise Rerankers on Open-Source Large Language Models**<br><sub>机构: University of Waterloo, 2Cohere, Comcast Applied AI<br>本文的核心成果是演示了如何构建一种不依赖GPT模型的有效列表重排序器，能显著超越现有基于GPT的重排序器，并呼吁研究社区开发更高质量的列表排序训练数据，以提升模型的表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02969v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02969.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph Construction**<br><sub>机构: Zhejiang Lab, Ant Group<br>通过在KGC中引入多智能体合作的方法，cooperKGC框架提升了智能体解决实体、关系和事件提取任务中的精确度，并有望为AI的协作意识化未来奠定了基础。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03022v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03022.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Inherent limitations of LLMs regarding spatial information**<br><sub>机构: ProtagoLabs, International Monetary Fund, NetMind.ai  <br>论文为GPT-4等大型语言模型在处理空间信息方面的能力提供了新的评估框架和专门设计的数据集，并分析了GPT-4在处理空间信息方面的能力和局限性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03042v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03042.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **A Hardware Evaluation Framework for Large Language Model Inference**<br><sub>机构: Princeton University<br>LLMCompass 作为一种硬件评估框架，成功地应对了设计LLM推理硬件时面临的挑战。它不仅快速精准，而且具有架构描述性和成本意识，已经在商业硬件上进行了验证且显示出优异的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03134v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.03134.md)  |
| <span style='display: inline-block; width: 42px;'>12-05</span> | **Let's Think Outside the Box: Exploring Leap-of-Thought in Large Language Models with Creative Humor Generation**<br><sub>机构: Sea AI Lab, Sun Yat-sen University, Harvard University  <br>本论文提出了一种旨在提升大型语言模型创造性思维能力的Creative Leap-of-Thought (CLoT)范式，并验证了其在多种任务中的有效性和概括能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02439v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02439.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/sail-sg/CLoT)</div> |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **ChatGPT as a Math Questioner? Evaluating ChatGPT on Generating Pre-university Math Questions**<br><sub>机构: Nanyang Technological University, National University of Singapore<br>该研究提出了第一个系统的评估ChatGPT在生成前大学数学问题潜力的研究。通过两种主要场景：给定上下文和未给定上下文的生成问题，并为教育工作者提供实用的洞察。研究的结果有可能促进现代AI技术在教育领域的应用，并提高自动化数学问题生成的实用性和效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01661v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01661.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **On the Effectiveness of Large Language Models in Domain-Specific Code Generation**<br><sub>机构: Shanghai Jiao Tong University, Chongqing University, East China Normal University<br>这项研究表明，通过有效地整合领域知识到代码生成过程中，可以增强LLMs在特定领域内的代码生成能力。DomCoder作为一个新的代码生成方法，利用了不同策略以整合领域知识，并在特定设置下提升了代码生成的实际效果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01639v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01639.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication**<br><sub>机构: Fudan University, National University of Singapore, Shanghai AI Laboratory  <br>本文提出的Exchange-of-Thought（EoT）框架通过模型间交流提升LLMs的推理能力，凭借四种通信范例和信心评估机制，在多个推理任务上取得了显著成效，并证明了外部思维在增强模型性能中的作用。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01823v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01823.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning**<br><sub>机构: Allen Institute for Artificial Intelligence, University of Washington<br>本论文提出了一个通过上下文学习实现LLMs对齐的简单无须调整方法（URIAL），表现出与传统调整对齐方法相匹配甚至更好的效果。这一发现对未来LLMs研究具有重要的启示，说明了在LLMs对齐上更深入的分析和理论理解的重要性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01552v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01552.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large Language Models**<br><sub>机构: Xiamen University, MBZUAI, Tencent AI Lab<br>文章通过引入动态自动检索机制和分层抽样方法，成功提升了多模态任务中LLMs的CoT推理能力。提出的方法不仅提高了模型性能，而且通过多样化示例选择进一步细化了推理过程，为多模态推理领域树立了新的性能标杆。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01714v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01714.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Data Management For Large Language Models: A Survey**<br><sub>机构: Peking University, Huawei Noah’s Ark Lab<br>这篇综述研究了在LLMs的预训练和监督式微调阶段，数据管理的研究现状以及数据管理策略的设计。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01700v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.017.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/ZigeW/data_management_LLM)</div> |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **Competition-Level Problems are Effective LLM Evaluators**<br><sub>机构: Microsoft Research Asia, Xiamen University, Microsoft Azure AI<br>本研究通过评估大型语言模型在处理竞赛级编程问题上的表现，揭示了GPT-4等模型在真实推理能力上的不足，并提出了一些提升表现的方法。这些发现突显了这类问题作为评估LLMs的有效工具的重要性，并促进了对于提高LLMs复杂推理能力的进一步研究。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02143v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02143.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **LLMs Accelerate Annotation for Medical Information Extraction**<br><sub>机构: Google Research<br>本论文展示了一个利用大型语言模型，特别是Google的PaLM 2，来提升医学信息抽取任务中注释速度的方法。这个基于LLM的注释流程提高了效率且不需要对模型进行复杂的调参，使其成为一个有潜力的工具来加速医疗领域的数据注释工作。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02296v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02296.md)  |
| <span style='display: inline-block; width: 42px;'>12-04</span> | **A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly**<br><sub>机构: Elsevier<br>这篇论文总结了大型语言模型（LLMs）在安全性和隐私保护中的应用及相关挑战，指出LLMs在这些领域的好处、坏处和丑陋之处，同时强调了其在数据保护方面的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02003v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02003.md)  |
| <span style='display: inline-block; width: 42px;'>12-03</span> | **D-Bot: Database Diagnosis System using Large Language Models**<br><sub>机构: Tsinghua University, Pigsty, ModelBest<br>D-Bot是一个基于大型语言模型的数据库诊断系统，它通过文档中的知识提取和生成有效的诊断报告来提高数据库诊断的效率和准确性，解决了区域专家在数据库诊断中遇到的挑战。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01454v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01454.md)  |
| <span style='display: inline-block; width: 42px;'>12-03</span> | **TextGenSHAP: Scalable Post-hoc Explanations in Text Generation with Long Documents**<br><sub>机构: University of Southern California, Google Cloud AI<br>TextGenSHAP是一个为大型语言模型设计的高效后验解释性方法，通过改进解释生成的速度，并展示了如何利用这些解释改进长文档问答和文档检索系统。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01279v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01279.md)  |
| <span style='display: inline-block; width: 42px;'>12-03</span> | **Running cognitive evaluations on large language models: The do's and the don'ts**<br><sub>机构: Massachusetts Institute of Technology<br>这篇论文为大型语言模型的认知评估研究方法提供了指导性的建议，探讨了在方法论上如何避免在运行认知评估时可能出现的问题。论文的目标是贡献于AI心理学领域最佳实践的更广泛讨论。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01276v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01276.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Just-in-Time Security Patch Detection -- LLM At the Rescue for Data Augmentation**<br><sub>机构: University of Luxembourg, Windows Copilot Microsoft, Singapore Management University<br>论文提出了一种新颖的安全补丁检测框架 LLMDA，使用大型语言模型进行补丁分析和数据增强，并对多模态输入进行对齐。这使系统能够从补丁和代码的联合上下文中提取更丰富的信息，提升检测准确性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01241v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01241.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Axiomatic Preference Modeling for Longform Question Answering**<br><sub>本文提出的基于公理的框架为长篇问答偏好模型提供了一种新方法，通过细致审视人类偏好，并优化了偏好打分的准确性与效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02206v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.02206.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Exploring and Improving the Spatial Reasoning Abilities of Large Language Models**<br><sub>机构: Stanford University  <br>论文提高了对LLMs在空间推理和序列标注方面能力的理解，提出了一种改进LLMs处理3D轨迹识别任务的方法，具有显著的性能提升。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01054v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01054.md)  |
| <span style='display: inline-block; width: 42px;'>12-02</span> | **Large Language Models Are Zero-Shot Text Classifiers**<br><sub>机构: Florida Atlantic University<br>论文展示了LLMs可以有效作为零样本文本分类器的能力，这对于需要快速部署文本分类器的小团队或小企业来说特别有益。研究结果表明，在所有四个数据集中，GPT-4一致超过了传统ML算法。文章还建议未来的研究方向包括优化提示以获得更高的精度或引入评论代理以评估和提升LLM的结果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.01044v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.01044.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Leveraging Large Language Models to Improve REST API Testing**<br><sub>机构: Georgia Institute of Technology, IBM Research<br>RESTGPT通过利用LLMs，特别是GPT-3.5 Turbo的高效准确性和少量示例学习的精准性，解决了现有方法在提取自然语言描述中规则和生成有效值时的限制，显著提升了REST API测试的质量和准确度。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00894v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00894.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games**<br><sub>这篇论文贡献了适应JuBensha游戏复杂性和新挑战的评估方法，并创建了一个能够评估交互式环境中LLM智能体能力的新框架ThinkThrice，推动了AI在多玩家角色扮演游戏中的应用。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00746v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00746.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Nash Learning from Human Feedback**<br><sub>机构: Google DeepMind<br>这篇文章提出了一种全新的调节大型语言模型以通过纳什均衡与人类偏好对齐的方法，展示了其在复杂任务中的潜能，并通过实验证明了其效果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00886v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00886.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **The Cost of Compression: Investigating the Impact of Compression on Parametric Knowledge in Language Models**<br><sub>机构: University of Wisconsin - Madison<br>本论文通过对大型语言模型（LLMs）进行压缩技术（剪枝和量化）的全面研究，揭示了这些技术对模型参数知识保留的影响，为实践者提供了关于模型压缩的有价值见解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00960v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0096.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **The Cost of Compression: Investigating the Impact of Compression on Parametric Knowledge in Language Models**<br><sub>机构: University of Wisconsin - Madison<br>这项研究首次大规模考察了LLMs的压缩技术对模型参数知识的影响，并为实际应用提供了重要见解，特别是在关于修剪和量化技术相关的决策方面。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00960v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.0096.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Instruction-tuning Aligns LLMs to the Human Brain**<br><sub>本研究表明，通过指令调整训练的大型语言模型在世界知识表示方面以及与人脑活动的对齐程度上表现更佳。这为未来LLMs的发展提供了将世界知识集成到模型中的重要视角。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00575v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00575.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **Beyond ChatBots: ExploreLLM for Structured Thoughts and Personalized Model Responses**<br><sub>本文介绍了探索LLM系统ExploreLLM，它通过结合基于提示的任务分解方法和全新的类似图式的图形用户界面（UI），在用户和LLM助手之间提供了一种全新的交互模式。该系统通过在结构化和交互式界面中表示生成子任务，旨在减轻用户完成复杂任务时的认知负担，同时提高个性化响应的水平。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00763v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00763.md)  |
| <span style='display: inline-block; width: 42px;'>12-01</span> | **On Exploring the Reasoning Capability of Large Language Models with Knowledge Graphs**<br><sub>研究结果显示，LLMs能够通过其内部知识图成功处理知识图推理任务，并能从上下文中推断出知识图关系，展示了LLMs在知识图推理中的潜力及应用价值。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00353v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-12/2312.00353.md)  |

---

## 11月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **Autonomous Agents in Software Development: A Vision Paper**<br><sub>本论文提出了一个关于利用多个 GPT 代理来自动执行软件工程任务的愿景，并演示了在简单软件任务上所取得的初步成功。这项工作有可能彻底改变软件开发的方式，并缩短开发时间。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18440v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1844.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **MicroCinema: A Divide-and-Conquer Approach for Text-to-Video Generation**<br><sub>MicroCinema以其创新的文本到视频生成两阶段流程和有效的Appearance Injection Network及Appearance Noise Prior机制，在视频生成质量上实现了新的突破，为后续工作提供了可借鉴的范例。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18829v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18829.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **IAG: Induction-Augmented Generation Framework for Answering Reasoning Questions**<br><sub>IAG框架通过归纳提示法加强知识陈述的真实性，并且优化了知识融合机制和学生归纳模型，以解决现有基于检索的方法在隐性推理问答任务上的不足。研究成果表明，IAG在回答涉及隐性推理的问答任务上表现更优。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18397v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18397.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation**<br><sub>CoDi-2是一种具有前沿能力的多模态生成模型，可以处理复杂的多模态输入、在上下文中指导生成、通过多轮交互与用户互动，并实现了优秀的零样本和少样本性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18775v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18775.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **TaskBench: Benchmarking Large Language Models for Task Automation**<br><sub>该文献提出了TaskBench基准测试和TASKEVAL评估系统，通过数据生成和量化评估系统，有效地解决了在任务自动化领域对LLMs的评估问题。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18760v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1876.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text**<br><sub>研究展示了GPT-4处理混淆文本的强大能力，设置了两项新指标RR和RPG，并通过它们验证了GPT-4在不同混淆场景和比率下的稳定表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18805v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18805.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **PoseGPT: Chatting about 3D Human Pose**<br><sub>PoseGPT是一个新型框架，它通过在LLM中嵌入SMPL姿态标记，使模型可以直接从文本和视觉输入生成三维人体姿态，并在解释三维人体姿态方面实现了一定程度的创新。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18836v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18836.md)  |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **What Do Llamas Really Think? Revealing Preference Biases in Language Model Representations**<br><sub>作者们提出了一个新型探针来检测LLMs表示中的内隐关联偏见，并通过实验在偏好检测中达到了最新水平。研究还发现了多个指令遵循型和“传统”的LLMs中的显著偏见，这些偏见存在于国籍、政治、宗教和性别等方面，尽管LLMs已经经过明确的安全指导调整。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18812v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18812.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/castorini/biasprobe)</div> |
| <span style='display: inline-block; width: 42px;'>11-30</span> | **Applying Large Language Models and Chain-of-Thought for Automatic Scoring**<br><sub>机构: University of Georgia<br>本文展示了LLMs在促进自动评分方面的潜力，并强调CoT在配合项茎和评分标准使用时能显著增强评分的准确度。通过结合LLMs和CoT的方法，可以降低自动评分模型构建的复杂性和人力成本，并可能提供更接近人类评分结果的评分。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.03748v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2312.03748.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Large Language Models for Networking: Applications, Enabling Techniques, and Challenges**<br><sub>该论文提出了一个整合大型语言模型与网络技术的新框架ChatNet，并探究了它在网络规划中的应用。研究表明，ChatNet可以有效提升网络任务的自动化和智能化水平，尽管在部署前仍需解决多模态数据整合和插件开发等挑战。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17474v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17474.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Are Large Language Models Good Fact Checkers: A Preliminary Study**<br><sub>这篇文章通过系统评估LLMs在整个事实核查流程中的潜力，发现尽管LLMs在某些方面表现出潜力，但依然需要更多研究和尝试来提升它们在事实核查任务上的表现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17355v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17355.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **TaskWeaver: A Code-First Agent Framework**<br><sub>TaskWeaver是为构建基于LLM的自治代理而设计的代码优先框架，实现了对复杂数据的高效处理以及插件的灵活使用，并将特定域知识成功整合入系统中。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17541v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17541.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/microsoft/TaskWeaver)</div> |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **How to Build an AI Tutor that Can Adapt to Any Course and Provide Accurate Answers Using Large Language Model and Retrieval-Augmented Generation**<br><sub>这篇论文代表了一次开创性的尝试，构建了一个可以适应任何学科并提供高质量的定制化教育支持的AI导师系统。这不仅能促进AI教育技术的应用，而且为AI教学系统的发展开辟了新路径。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17696v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17696.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Understanding and Improving In-Context Learning on Vision-language Models**<br><sub>本文提出了一个用于视觉-语言模型在背景学习中选择示范的新方法MMICES，并通过一系列实验展示了其在不同模型和数据集上的良好性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18021v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18021.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Towards Top-Down Reasoning: An Explainable Multi-Agent Approach for Visual Question Answering**<br><sub>这项工作通过创新性地结合三个代理来模拟人类认知中的自顶向下推理过程，并引入了多视角知识库的概念，显著提升了VQA模型的表现力和解释能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17331v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17331.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **Zero-shot Conversational Summarization Evaluations with small Large Language Models**<br><sub>文章以大型语言模型在会话摘要任务中的应用作为焦点，深入探讨了不同指令对模型执行效果的影响，并研究了在有限硬件下使用压缩模型的优化方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.18041v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.18041.md)  |
| <span style='display: inline-block; width: 42px;'>11-29</span> | **TimeBench: A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models**<br><sub>TIMEBENCH基准的提出是对大型语言模型时间推理能力综合评估的重要步骤，它展示了当前模型与人类在这方面的差距，并为未来的研究提供了指引。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17667v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17667.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/zchuz/TimeBench)</div> |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine**<br><sub>本文通过系统的提示工程方法探讨了在无需专家监督的情况下，如何指导通用的基础模型在专业任务上发挥专家级别的能力，具体以医学领域为案例研究。所提出的Medprompt策略证明了其在增强基础模型专业能力方面的显著优势，并展示了广泛适用于多个学科的可能性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16452v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16452.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **RELIC: Investigating Large Language Model Responses using Self-Consistency**<br><sub>RELIC是一个交互式系统，它通过多样本的事实一致性检验，帮助用户验证和指导LLMs生成的文本。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16842v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16842.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **RankingGPT: Empowering Large Language Models in Text Ranking with Progressive Enhancement**<br><sub>本研究提出了一种用于文本排序的二阶段训练模型，结合了弱监督预训练和监督细化训练，通过在不损害预训练益处的基础上增强模型细化训练性能，完成了从预训练到细化训练的平滑过渡，并在实验中显著优于现有技术。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16720v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1672.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Beyond Hallucinations: Enhancing LVLMs through Hallucination-Aware Direct Preference Optimization**<br><sub>文章提出了一个新颖的策略来优化LVLMs并减少幻觉现象，同时介绍了一种新的评估方法来更全面地衡量幻觉现象，并通过实验验证了所提方法的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16839v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16839.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up?**<br><sub>这篇综述文章提供了对开源LLMs在多任务领域相较ChatGPT的性能评估的考察，突出了目前开源LLMs的强项和潜在问题，并为未来的研究和开发提供了启示。此外，文章还总结了众多的最佳实践和挑战，显示出开源领域在一定程度上有望缩小与商业模型之间的差距。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16989v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16989.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation**<br><sub>本文提出了一个利用扩散模型进行角色动画的新框架“Animate Anyone”。该框架通过ReferenceNet保持外观一致性，并通过姿态引导器与时间层确保动画的可控性与连续性，取得了先进的角色动画生成结果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.17117v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.17117.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/HumanAIGC/AnimateAnyone)</div><div style='min-width:85px;'>[![Blog](https://img.shields.io/badge/Blog-Posts-yellow?logo=rss)](https://humanaigc.github.io/animate-anyone/)</div> |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **AvatarGPT: All-in-One Framework for Motion Understanding, Planning, Generation and Beyond**<br><sub>研究提出了一个创新的，一体化的框架AvatarGPT，用于处理理解、规划以及生成人类动作相关的高级和低级任务，展现出长时间运动合成的能力和减少手动干预的可能性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16468v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16468.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **Training Chain-of-Thought via Latent-Variable Inference**<br><sub>机构: Google<br>本论文开发了一种基于MCMC-EM的微调策略，通过平均理由帮助LLMs生成正确的答案，具有潜在的推广应用的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.02179v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2312.02179.md)  |
| <span style='display: inline-block; width: 42px;'>11-28</span> | **LLaFS: When Large-Language Models Meet Few-Shot Segmentation**<br><sub>本文提出了一个基于大型语言模型（LLM）的小样本图像分割框架，并解决了让LLMs理解和执行视觉任务的核心挑战。通过定制指导和细粒度上下文指导相结合的方法，实现了高质量的小样本分割。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.16926v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.16926.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/lanyunzhu99/LLaFS)</div> |
| <span style='display: inline-block; width: 42px;'>11-27</span> | **RoboGPT: an intelligent agent of making embodied long-term decisions for daily instruction tasks**<br><sub>文章提出了一个名为RoboGPT的智能体，该智能体用于制定执行日常指令任务的长期决策。该智能体通过一项新的机器人数据集，结合了LLMs的通用知识和机器人领域的专业知识，并引入了Re-Plan模块和RoboSkill模块以增强任务规划的逻辑性和适应性。在ALFRED基准测试和泛化任务上，RoboGPT优于现有的先进方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.15649v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.15649.md)  |
| <span style='display: inline-block; width: 42px;'>11-24</span> | **Data-Efficient Alignment of Large Language Models with Human Feedback Through Natural Language**<br><sub>文章提出了一个有效的CnR方法，它能够通过使用自然语言的精细反馈和响应修正，高效地校准LLMs以符合人类预期。通过相对较少的人类反馈数据，此方法可以显著改善即使是顶尖LLMs的响应质量，如ChatGPT。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.14543v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.14543.md)  |
| <span style='display: inline-block; width: 42px;'>11-24</span> | **Calibrated Language Models Must Hallucinate**<br><sub>该文章展示了预训练语言模型在充分校准的条件下，必然产生幻觉的统计根源，并介绍了预测性能良好的模型固有的幻觉产生机制。同时，文章还提供了幻觉产生率的下界估算，并探讨了不同类型事实产生幻觉的可能性，指出了未来减轻特定类型幻觉的可能方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.14648v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.14648.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **Probabilistic Tree-of-thought Reasoning for Answering Knowledge-intensive Complex Questions**<br><sub>文章提出了一种新颖的概率树状推理（ProbTree）方法，通过探索LLM在回答知识密集型复杂问题时的能力，并将不确定性引入推理过程，在统一框架中整合了外部和参数知识。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13982v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13982.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs**<br><sub>文章提出了一种名为ZipLoRA的新策略，旨在通过一个优化过程有效地合并独立训练的主题和风格LoRAs，从而能够生成任何用户提供的主题风格的组合。ZipLoRA对生成任何特定主题和风格的图像这一开放性研究问题提供了创新的解决方案，且由于其无需手动超参数调整，使用起来更加简便高效。实验证明该方法在保持主题和风格真实性的同时，相比于现有方法和其他基本方法而言，具有更好的生成质量和鲁棒性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13600v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.136.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **Diffusion Model Alignment Using Direct Preference Optimization**<br><sub>本文提出了一个名为Diffusion-DPO的方法，其通过直接优化基于人类比较数据的模型来实现对扩散模型与人类偏好的对齐。此外，文章也探索了基于AI反馈的训练，取得了与基于人类偏好训练相媲美的成绩。这明显提升了模型在视觉吸引力和文本对齐方面的性能，为利用AI反馈扩展扩散模型对齐方法提供了新的途径。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12908v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12908.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes**<br><sub>LucidDreamer是一个能够用于生成逼真而且分辨率更高的3D场景的模型。它优于现有的场景生成模型，因为它不依赖特定的训练数据集，并能够适应多种输入样式。LucidDreamer通过约束点云的移动和使用插值算法，克服了形状扭曲和点云与图像错位的问题，从而在操纵3D空间中的点云时保持了场景的真实感和一致性。在实验中明显展示了其优越性和高泛化能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13384v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13384.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **GAIA: a benchmark for General AI Assistants**<br><sub>GAIA 是一项针对通用人工智能助理的基准测试，其目的在于提出真实世界的挑战性问题，并避开传统 LLMs 评价中的许多陷阱。该基准测试强调任务对人类简单而对AI难度较大，以此来评估AI的执行复杂行动序列的准确能力，这些任务在设计上无法简单地通过暴力方法得以解决。GAIA 还考虑了如何扩展基准测试，并探讨了一些最先进的助理的成功与短板，展示了增强 LLMs 的潜力。最终，文章旨在设立一个开发者问题集，为人工智能研究提供一个可扩展的基准测试平台。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12983v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12983.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach**<br><sub>LLaMAC框架展示了基于LLM的多智能体系统在长期规划、数学推理、优化问题和空间推理方面的卓越表现，并且减少了大规模多智能体协作的访问成本。随着LLM的进一步提升和更多协作框架的出现，多智能体协作领域将迎来新的发展机遇。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13884v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13884.md)  |
| <span style='display: inline-block; width: 42px;'>11-23</span> | **FusionFrames: Efficient Architectural Aspects for Text-to-Video Generation Pipeline**<br><sub>总体而言，该论文提出了一个新型两阶段潜在扩散的文本到视频生成架构，解决了关键帧合成和插值帧生成中存在的问题，通过使用独立的时域块和有效的插值架构，减少了计算成本，并在多个质量指标上取得了优于现有技术的表现。此外，论文还针对视频解码器设计了不同的架构选项，进一步优化了视频的一致性和整体质量。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13073v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13073.md)  |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms**<br><sub>本论文的主要贡献包括：在开源模型上微调不同大小和风格的指令数据集，评估微调模型在不同的评估范式下的表现，并且发现较少的样本（特别是当这些样本结合了不同来源和风格时）足以在不同类型的评估中获得良好的性能。这表明在培养LLMs的指令遵从能力时，“少即是多”，且通过精心选择微调样本，可以使模型在执行指令能力上得到显著提升。这一发现对于如何有效地微调LLMs以及如何评估它们的实用性具有重要意义。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13133v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13133.md)  |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **Visual In-Context Prompting**<br><sub>本论文提出了DINOv，一个新的视觉上下文内提示框架，能够有效处理多样化的视觉提示，使用无标签数据，并在多个任务中达到很好的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13601v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13601.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/UX-Decoder/DINOv)</div> |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **Enhancing Summarization Performance through Transformer-Based Prompt Engineering in Automated Medical Reporting**<br><sub>这项研究验证了在自动化医疗报告中应用基于转换器的提示工程可以提高摘要性能。尽管存在一些局限性，但研究提出的方法证明了在提示制定时加入示例和上下文信息的效用，并且指出了未来工作的方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13274v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13274.md)  |
| <span style='display: inline-block; width: 42px;'>11-22</span> | **XAGen: 3D Expressive Human Avatars Generation**<br><sub>研究提出了XAGen模型，它是首个能够生成全面可控3D人类化身的GAN模型。XAGen在细粒度属性控制上具有独立的能力，并通过多尺度和多部分的3D表示与渲染技术提升了面部和手部的生成质量。实验结果证明XAGen在外观质量、控制能力和数据利用率方面都超过了现有最先进的方法，推进了3D虚拟化身生成技术的发展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13574v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13574.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks**<br><sub>本文针对微调对预定义能力的影响开展了一项全面的分析和评估。通过Tracr编译式的能力设计和基于PCFG的学习式能力设计，文章详细探讨了微调过程中嵌入特征的相关性，提出了reFT来强化分析微调影响的深度。本研究的发现改进了对微调影响机理的理解，并为后续的模型设计和微调策略提供了实证支持。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12786v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12786.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey**<br><sub>文章为了解决LLMs在应对长上下文时的挑战，提出了一系列方法和综合分类体系，提高了LLMs在注意力机制、记忆效率和最大长度处理上的性能。通过综合回顾和分类学界最近的进展，本文为未来的LLMs架构设计和优化提供了清晰的指导方向。。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12351v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12351.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Strivin0311/long-llms-learning)</div> |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **A Survey on Multimodal Large Language Models for Autonomous Driving**<br><sub>该论文全面回顾了MLLMs在自动驾驶领域的应用，表明MLLMs具备解析非文本数据和融合多种模态（如视觉、语言）的能力，这些能力对于行为预测和动作规划尤为重要。通过在不同的自动驾驶环节中部署MLLMs（如理解交通场景、规划控制、模式生成），可以改善决策流程，并实现类似人类的驾驶直觉和决策模式，同时提高车辆导航和规划的效率和安全性。此外，模型通过为多个任务的预训练提供了一种新的可能性，这可能会推动把智能系统推向人工普遍智能（AGI）的发展路径。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12320v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1232.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Prompting Frameworks for Large Language Models: A Survey**<br><sub>这项研究提供了一个框架，它通过实现新的技术手段来增强与LLMs的交互，包括改善与编程语言的兼容性，使能LLMs使用外部工具，并维护历史交互信息，并以此指导未来的研究方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12785v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12785.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/lxx0628/Prompting-Framework-Survey)</div> |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Oasis: Data Curation and Assessment System for Pretraining of Large Language Models**<br><sub>本文提出的Oasis系统是针对大型语言模型预训练的数据整理和评估问题的解决方案。Oasis通过其交互式的自定义数据整理模块、针对偏差的模型过滤器和全面的数据评估系统，旨在提高数据集的质量和多样性，同时降低内存需求和资源消耗。系统的实现立足于提升数据处理的灵活性和评估的准确性，填补了现有工作在全面性和多维度评估方面的空白。通过综合使用人类评估、启发式度量和最新的大型语言模型如GPT-4进行质量评估，Oasis展现了对预训练数据集进行全方位优化的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12537v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12537.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **How Capable Can a Transformer Become? A Study on Synthetic, Interpretable Tasks**<br><sub>本文通过设计合成数据生成过程和系统性实验，以评估和理解自回归Transformer模型在组合其原始能力方面的潜力。研究结果突显了模型学习组合结构的能力，揭示了训练数据对此能力的影响以及模型内部注意力层在组合学习过程中的重要性。这或许为评估和提高现代神经网络对真实世界数据的理解和应用，特别是在其可能面临前所未见的任务时，提供了新的见解。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12997v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12997.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Do Smaller Language Models Answer Contextualised Questions Through Memorisation Or Generalisation?**<br><sub>本论文提出了一种新方法以评价小型语言模型在问答任务中答案的生成是否为记忆或概括能力的结果。通过语义相似度分析，确定了不太可能被模型记住答案的评估样本，并用增加额外训练数据集的方式，针对特定评估子集进行了模型性能的优化。最终，研究结果显示增加了数据集的模型在特定评估数据集上有了显著提升，并推断这种改善与模型的泛化能力有关。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12337v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12337.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **Latent Lab: Large Language Models for Knowledge Exploration**<br><sub>Latent Lab作为一种探索大型数据集中相互联系关系的创新和强大工具，通过利用LLMs和视觉引人注目的接口，它超越了常规搜索的局限性，提供了一个语义上有意义和情境感知的体验。强调探索的价值和迭代设计，在直观地访问大量相互连接的信息方面实现了信息技术专家的长期追求，并通过AI辅助探索将这一愿景变为现实，为未来人工智能共创系统的发展奠定了基础，并促进了更直观和高效的合作，有能力产生新颖和有影响力的创造物。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.13051v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.13051.md)  |
| <span style='display: inline-block; width: 42px;'>11-21</span> | **AcademicGPT: Empowering Academic Research**<br><sub>AcademicGPT针对学术研究的特定需求进行了优化，通过结合针对性强的训练数据和多方面的应用开发，为学术领域提供了实质性的支持和工具。它标志着大型语言模型个性化与专业化发展的一个重要步骤，并有望对学术社区产生深远的影响。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12315v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12315.md)  |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents**<br><sub>本文作为首篇系统性探讨CoT基步机制、范式转变，以及CoT与代理间复杂交互的工作，提供了一些关键见解。文章揭示了CoT在特定条件下显示出的有效性，指出了使CoT工作的多个条件，以及理论和实证研究为其成功提供了何种解释。文章还对CoT理论进行了深入分析，提出了CoT对于LLMs在多个领域的优化和革新可能具有重要的贡献，并指出尽管LLMs、CoT推理和语言代理快速发展，但仍存在未解决的挑战，如对未见领域的泛化、提高交互效率、代理定制化、代理扩展及代理安全性等【10†源】。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11797v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11797.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Zoeyyao27/CoT-Igniting-Agent)</div> |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **GPQA: A Graduate-Level Google-Proof Q&A Benchmark**<br><sub>GPQA 数据集提供了一个用于测试 AI 系统在处理需深度理解和推理能力的复杂问题上的能力的基准。通过严格的问题质量控制和专家级别的难度，它可能促进人类专家与 AI 系统合作的方法发展，并推动 AI 系统设计的进步。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12022v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12022.md)  |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **Assessing Prompt Injection Risks in 200+ Custom GPTs**<br><sub>该论文着重研究了自定义GPT模型中的安全风险，尤其是提示注入攻击。研究者们提出了一个包含扫描、注入敌意提示和提取目标信息三个步骤的攻击方法，并通过实施评估发现自定义GPT模型存在严重的系统提示提取和文件泄露漏洞。这些发现突出了自定义GPT模型中的关键安全缺陷，并指出了提升这些模型安全性结构的必要性。此外，红队评估清楚地显示出，现有防护措施并不足够强大，甚至有时候明确指出不应该分享的信息也能被提取出来，这表明亟需进一步加强对抗提示注入攻击的防御机制。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11538v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11538.md)  |
| <span style='display: inline-block; width: 42px;'>11-20</span> | **Continual Learning: Applications and the Road Forward**<br><sub>论文综述了当前的持续学习研究现状，指出了其在记忆限制条件下研究较多而忽视计算成本的问题，并提出了四个有前途的研究方向。这些方向包括：1) 真实世界数据处理的挑战，2) 计算成本的考虑，以及其他如何获取数据和理论理解方面的关注点。论文主张未来的CL算法应在减少对完全标记和封闭世界假设的依赖上做出实质性的进展，以使CL成为解决实际机器学习问题的一个有效工具。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11908v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11908.md)  |
| <span style='display: inline-block; width: 42px;'>11-19</span> | **TPTU-v2: Boosting Task Planning and Tool Usage of Large Language Model-based Agents in Real-world Systems**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11315v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11315.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **An Embodied Generalist Agent in 3D World**<br><sub>LEO是一个新型的身体化、多模态、多任务的通用型智能体，专注于在3D世界中的感知、基础、推理、规划和行动。通过对3D视觉-语言对齐和视觉-语言-动作指令调优的训练，LEO能在3D世界中执行一系列任务。文章通过一系列严格实验和消融实验的结果，证实了LEO在一系列任务上的高效性能，并为未来身体化通用型智能体的发展提供了宝贵洞见。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.12871v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.12871.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **RecExplainer: Aligning Large Language Models for Recommendation Model Interpretability**<br><sub>文章针对推荐模型解释性的研究提出了一种新型的方法，即通过大型语言模型进行对齐，以提高解释的质量和准确性。文章介绍了三种不同的对齐方法，并通过一系列任务训练LLM以模仿推荐模型的逻辑。论文采用了多种评估策略和评分体系，包括使用最新的GPT-4模型和人类评分来验证所提出方法的有效性，并在三个不同的数据集上进行了测试，显示出其在提高推荐模型解释性方面的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10947v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10947.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **Orca 2: Teaching Small Language Models How to Reason**<br><sub>文章通过介绍一个新的小型语言模型Orca 2，并展示其在多种推理任务上能够与更大的模型相匹敌或超越它们的性能，对当前小型语言模型在复杂推理任务中表现不佳的问题提出了有效的解决方案。Orca 2的开发依赖于对训练数据和训练策略的精心设计，证明了即使是小型模型，也可以通过改进训练方法来增强其理解和推理能力。文章还提供了Orca 2在各种标准测试中的卓越性能结果，验证了其方法论在实际应用中的有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11045v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11045.md)  |
| <span style='display: inline-block; width: 42px;'>11-18</span> | **Adapters: A Unified Library for Parameter-Efficient and Modular Transfer Learning**<br><sub>论文提出了一个统一的库——Adapters，它整合并扩展了参数高效和模块化迁移学习方法，实现了与Transformers库的紧密整合，通过多个NLP任务的对比实验，展示了其有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.11077v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.11077.md)  |
| <span style='display: inline-block; width: 42px;'>11-17</span> | **Camels in a Changing Climate: Enhancing LM Adaptation with Tulu 2**<br><sub>TÜLU 2通过采用新的基础模型和调整策略，在多个性能指标上实现了突破，对进一步理解和改进预训练语言模型的适配具有重要意义。通过引入新的数据混合物和先进的训练方法（如DPO），TÜLU 2提高了模型在各种推理和知识探测任务上的性能，并在开放式生成指标上取得了显著的提升。此外，研究者们通过公开相关模型、数据和代码，推动了语言模型适配方法的开放研究和发展。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10702v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10702.md)  |
| <span style='display: inline-block; width: 42px;'>11-17</span> | **Exploring the Relationship between In-Context Learning and Instruction Tuning**<br><sub>论文提供了ICL与IT之间密切相关的实证证据，即使ICL中不更改模型参数，二者所使用的指令和示例都驱动模型朝着收敛的隐藏状态前进。这一发现对于如何设计高效的数据集和任务以推进基础模型在下游应用的发展和对齐具有启示作用。研究结果还可以帮助理解示例在ICL和IT中的作用，以及如何利用这些见解来设计有效的示例任务和数据集，从而提升LLM的性能。论文中申明将会提供实验代码以供复现。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10367v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10367.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **Automatic Engineering of Long Prompts**<br><sub>本文针对语言模型长指令工程中存在的问题，提出了一种新的算法框架，并解决了贪婪算法易陷入局部最优和遗传算法初期收敛慢的问题。通过对指令的每个句子进行语义保持重述，并利用波束搜索来维护和优化候选指令集合，使算法在有限训练数据上表现出良好的性能和较快的收敛速度。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10117v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10117.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **MacGyver: Are Large Language Models Creative Problem Solvers?**<br><sub>本研究通过创造MACGYVER数据集，探索了LLMs在解决非传统问题上的能力，并通过人类评估员对GPT-4的表现进行了评价。研究结果展示了LLMs在这类任务上的局限性，同时提出了提高其表现的新方法。研究强调了创造性问题解决能力在日常生活中的重要性，并尝试通过LLMs补充人类的创造性思维，以期提高解决问题的能力和效率。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09682v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.09682.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **Crafting In-context Examples according to LMs' Parametric Knowledge**<br><sub>本文的重点研究是如何根据LM的参数知识有效地创建上下文示例：选择最优的示例（已知与未知的比较）以及在上下文示例中如何排序答案。实验结果支持了半已知示例的有效性以及基于参数知识的答案排序方法，这些发现为提高大型语言模型在多答案生成任务中的性能提供了可行的技术途径。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09579v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.09579.md)  |
| <span style='display: inline-block; width: 42px;'>11-16</span> | **Predictive Minds: LLMs As Atypical Active Inference Agents**<br><sub>本论文将活动推断的概念应用于大型语言模型（LLMs），从一个新的视角分析了LLMs的行为和学习机制。论文提出，尽管LLMs在物理上无法直接与环境互动，但它们通过生成文本在虚拟环境中的“行动”间接影响世界，并有可能将这些影响反馈到模型的训练中。研究指出，增强LLMs与用户交互的反馈循环，将有助于提升模型的自我意识，让其更好地适应和响应环境变化，这将带来重大的社会影响和潜在的风险。论文为理解和改进LLMs在实际部署时的行为提供了重要的理论基础，预测了这些系统未来可能的发展方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10215v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10215.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Contrastive Chain-of-Thought Prompting**<br><sub>本论文提出了对比式链式思维方法，以解决传统链式思维中存在的问题，即缺乏对错误避免的指导以及实现推理效果的不确定性。通过提供有效和无效的推理示例，新方法旨在引导模型减少推理错误并一步步推理，同时该方法提供了自动化构建对比示例的技术以便泛化到各种任务。实验结果证实，该方法能够作为一种通用增强手段，显著提升链式思维的性能。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09277v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.09277.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models**<br><sub>论文提出的CHAIN-OF-NOTE（CON）框架旨在提高RALMs的鲁棒性，主要通过引入结构化的阅读笔记过程来批判性地评估检索到的文档。实验结果表明，该框架提高了模型在噪声数据和未知情况下的健壮性，改善了整体QA性能，并在检索文档失败还是成功时均提高了模型的性能。CON框架通过生成读取笔记和最终回答，提高了模型对噪声的鲁棒性，并在缺乏信息时能够给出“未知”的回答，增强了模型的适应性和可靠性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.09210v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.0921.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Memory Augmented Language Models through Mixture of Word Experts**<br><sub>本论文提出了一个称为MoWE的新型架构，它通过融合稀疏模型的效率和大型语言模型的性能，出色地处理了性能与计算成本之间的平衡。通过采取创新的设计原则，并且在NLP多种任务中验证了其超越传统模型如T5和MoE的性能，MoWE展示了在学术和实际应用领域的潜力，尤其是在处理知识密集型任务时。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10768v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10768.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **Exponentially Faster Language Modelling**<br><sub>本文介绍了UltraFastBERT，这是一个大规模语言模型的变种，它显著减少了在推理时需要使用的神经元数量，并通过使用快速前馈网络来提高计算效率。尽管不具备原生的高效实现，但该模型提供了一个能够显著加速推理过程的CPU代码实现，并在标准下游任务中表现良好。这一工作展示了条件神经执行在语言建模领域巨大的潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10770v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.1077.md)  |
| <span style='display: inline-block; width: 42px;'>11-15</span> | **ToolTalk: Evaluating Tool-Usage in a Conversational Setting**<br><sub>ToolTalk 是一个致力于评估和提高 LLM 在对话环境中使用多步骤外部工具性能的基准。它通过创新的评估方法和真实场景模拟，挑战和扩展了现有 LLMs 的能力边界，并为未来的研究指出了方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.10775v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.10775.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/microsoft/ToolTalk)</div> |
| <span style='display: inline-block; width: 42px;'>11-14</span> | **Learning to Filter Context for Retrieval-Augmented Generation**<br><sub>本文提出的FILCO方法针对开放领域问答和事实验证等知识密集型任务，通过改善提供给生成模型的上下文质量来解决生成输出时面临的问题。通过结合词汇和信息论方法来识别有用上下文，并训练模型以在测试时过滤检索上下文，很好地解决了以前方法的局限性。实验结果显示，相比传统方法，FILCO在多个知识密集型任务上都取得了显著的性能改进，并且在上下文过滤训练上显示出其有效性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.08377v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.08377.md)  |
| <span style='display: inline-block; width: 42px;'>11-14</span> | **Instruction-Following Evaluation for Large Language Models**<br><sub>本文提出了一种评估大型语言模型的指令遵循能力的新方法——IFEval，它通过合成逻辑一致的指令和计算指令遵循准确性的新准则来解决评估过程中的挑战。此方法为自动化且无偏见，它通过多步骤过程避免指令间的潜在冲突，并引入了严格和宽松的准确性评价标准来减少误判，同时认为未来可以通过增加多样化和使用多模态指令来改进该方法。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.07911v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.07911.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/google-research/google-research/tree/master/instruction_following_eval)</div> |
| <span style='display: inline-block; width: 42px;'>11-14</span> | **KTRL+F: Knowledge-Augmented In-Document Search**<br><sub>文章提出了一个新的问题——KTRL+F，以解决文献搜索中的实时、准确性、引入外部知识的需求。通过分析现有基线，文章发现它们存在局限性，在此基础上提出了Knowledge-Augmented Phrase Retrieval模型。该模型有效地在短语检索中整合了外部知识，通过简单的扩展保持了快速响应，无需额外训练。通过用户研究，证明了该模型能够提升用户搜索体验，减少搜索时间和外部信息检索量。作者鼓励研究社区关注KTRL+F这一独特挑战，提高文献信息访问的效率和效果。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.08329v3)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.08329.md)  |
| <span style='display: inline-block; width: 42px;'>11-13</span> | **Can LLMs Patch Security Issues?**<br><sub>本文介绍了一种新型的代码修正方法FDSS，通过与静态代码分析工具Bandit集成，能显著提高LLMs解决代码中安全问题的能力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2312.00024v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2312.00024.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/Kamel773/LLM-code-refine)</div> |
| <span style='display: inline-block; width: 42px;'>11-11</span> | **In-context Vectors: Making In Context Learning More Effective and Controllable Through Latent Space Steering**<br><sub>本论文提出的ICV方法为大型语言模型的上下文学习提供了一种新颖且更加有效的替代方案。通过将演示示例的关键信息集成到一个可以控制的向量中，ICV方法提高了任务指导的精确度和效果，并显著优于现有的方法。实验结果表明，ICV在多项任务中展现了较高的性能，包括在不同的LLMs上进行语言模型解毒、风格转换和角色扮演。ICV方法的计算开销低，并且易于控制，有助于提升语言模型在实际应用中的适用性和弹性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.06668v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.06668.md)  |
| <span style='display: inline-block; width: 42px;'>11-10</span> | **Making LLMs Worth Every Penny: Resource-Limited Text Classification in Banking**<br><sub>论文首次将多种在资源受限环境下的方法进行了全面评估，包括成本分析、RAG方法和利用GPT-4的数据增强，为金融行业提供了新的方法用以应对数据和预算限制的挑战。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.06102v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.06102.md)  |
| <span style='display: inline-block; width: 42px;'>11-05</span> | **ChaTA: Towards an Intelligent Question-Answer Teaching Assistant using Open-Source LLMs**<br><sub>本文提供了一个使用开源LLMs增强在线教育QA平台的新方案，并对其进行了广泛的评估和测试。通过将RAG、SFT和DPO等技术结合应用，确保了回答质量的显著提升和数据隐私的保护，对于开发智能QA助手具有重要的意义。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.02775v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.02775.md)  |
| <span style='display: inline-block; width: 42px;'>11-01</span> | **LLMRec: Large Language Models with Graph Augmentation for Recommendation**<br><sub>LLMRec作为开创性的工作，它引入LLMs来增强图推荐系统，成功地解决了交互数据的稀疏性和低质量侧信息的问题，并通过强化用户-项目交互边、项目节点属性以及用户画像等手段提升了推荐系统的性能，确保了推荐质量的同时降低了数据噪声的影响。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2311.00423v5)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-11/2311.00423.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/HKUDS/LLMRec.git)</div> |

---

## 10月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>10-20</span> | **The History and Risks of Reinforcement Learning and Human Feedback**<br><sub></sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.13595v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.13595.md)  |
| <span style='display: inline-block; width: 42px;'>10-17</span> | **Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection**<br><sub>论文推出了SELF-RAG，这是一种新的框架，通过按需检索和自我反思来增加LLMs的质量和事实性。它通过生成反思标记让LM在推理阶段变得可控，可以满足多样化的任务要求。SELF-RAG在多个任务上显著超越了现有LLMs和RAG模型，并通过定制的解码算法和反思标记，为模型自我评估和定制提供了新的方案。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.11511v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.11511.md)  |
| <span style='display: inline-block; width: 42px;'>10-11</span> | **OpsEval: A Comprehensive Task-Oriented AIOps Benchmark for Large Language Models**<br><sub>OpsEval 作为一个全面的 AIOps 任务导向型基准测试，不仅评估了大型语言模型的综合性能、推理和实际应用能力，还可能改变未来大规模质量评估中使用的评价指标。它提供了一个用于持续研究和优化AIOps领域大型语言模型的坚实基础。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.07637v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.07637.md)  |
| <span style='display: inline-block; width: 42px;'>10-10</span> | **GPT-4 as an Agronomist Assistant? Answering Agriculture Exams Using Large Language Models**<br><sub>本研究展示了在农业领域使用LLMs进行问题回答的新方法，特别是通过Ensemble Refinement策略，大幅提升了LLMs在多选题目上的表现，并显示出在处理专业领域问题时的广泛潜力。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2310.06225v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-10/2310.06225.md)  |

---

## 09月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>09-04</span> | **Benchmarking Large Language Models in Retrieval-Augmented Generation**<br><sub>本论文提出了一种新的基于实际新闻文章的检索增强生成基准测试，用以彻底评估大型语言模型在复杂信息环境中的多项能力，并通过实验结果展现了现有LLMs在这些方面的局限性。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2309.01431v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-09/2309.01431.md)  |

---

## 08月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>08-18</span> | **Learning Representations on Logs for AIOps**<br><sub>本文提出的BERTOps模型通过使用LLMs中的通用表示，并结合专门针对AIOps日志数据的预训练，有效地提高了自动化日志分析任务的性能，并展示了显著的改进。BERTOps不仅优于现有模型，在多个下游任务中也表现出卓越的性能，有助于加速AIOps的实践应用。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2308.11526v1)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-08/2308.11526.md)  |

---

## 07月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>07-11</span> | **Towards Understanding In-Context Learning with Contrastive Demonstrations and Saliency Maps**<br><sub>本研究使用对比示例和显著图分析法来探究大型语言模型中上下文学习的内在机制，揭示了标签翻转、输入变化、和补充性解释对预测的不同影响，并为实践者提供了如何策划示例的洞见。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2307.05052v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-07/2307.05052.md) <div style='min-width:85px;'>[![GitHub](https://img.shields.io/badge/GitHub-View-brightgreen?logo=github)](https://github.com/paihengxu/XICL)</div> |

---

## 05月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>05-24</span> | **In-Context Demonstration Selection with Cross Entropy Difference**<br><sub>文章提出了一种新的基于交叉熵差异（CED）的上下文示例选择方法，并提供了理论上的解释，实现了对不同大小和类型的大型语言模型性能的提升。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2305.14726v2)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-05/2305.14726.md)  |
| <span style='display: inline-block; width: 42px;'>05-19</span> | **How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings**<br><sub>本研究揭示出有效提示构造的关键数据库知识和最优表述，为LLMs在text-to-SQL任务中的应用提供指导，并指出在跨域设置中对于提示长度存在一个“甜蜜点”。本研究的发现可能对于特定数据库不总是适用，特别是如果该数据库与Spider数据库显著不同。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2305.11853v3)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-05/2305.11853.md)  |

---

## 03月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>03-31</span> | **A Survey of Large Language Models**<br><sub>总的来说，这篇综述文章介绍了LLMs领域的最新进展，特别是OpenAI推出的ChatGPT和GPT-4模型，并强调了这些产品对人工智能研究的重大影响，特别指出了它们在人机交流、多模态理解和生成、以及人工智能对齐和安全性方面的突破。同时，文章认识到尽管取得了巨大的技术进展，但在安全性、生成质量和多模态性功能方面仍面临挑战，并提出了一系列的技术和策略来缓解这些问题。通过这篇文章，我们可以更好地理解LLMs的发展方向以及对未来人工智能应用和研究的潜在影响。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2303.18223v13)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-03/2303.18223.md)  |

---

## 02月

| &nbsp;Date&nbsp;&nbsp; | Paper | Links & Summary |
| --- | --- | --- |
| <span style='display: inline-block; width: 42px;'>02-08</span> | **A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity**<br><sub>文章通过更细粒度的方式评估了ChatGPT的推理能力，并且找到了LLMs中的一个关键问题，即在非文本语义理解方面的不足。这一发现对于未来LLMs的改进和推理能力的研究提供了重要的方向。</sub>| <div style='min-width:85px;'>[![arXiv](https://img.shields.io/badge/arXiv-Paper-%23D2691E?logo=arxiv)](http://arxiv.org/pdf/2302.04023v4)</div><div style='min-width:85px;'>[![Summary](https://img.shields.io/badge/Sum.-Read-blue?logo=dependabot)](summary/2023-02/2302.04023.md)  |

---

